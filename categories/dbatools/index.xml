<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>dbatools on Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/categories/dbatools/</link><description>Recent content in dbatools on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 28 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/categories/dbatools/index.xml" rel="self" type="application/rss+xml"/><item><title>How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</guid><description>&lt;img src="https://images.unsplash.com/photo-1614791962365-7590111b1b1c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80" alt="Featured image of post How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error" />&lt;p>There are a number of methods to import PowerShell modules into Azure automation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>as described in the documentation here&lt;/a>&lt;/p>
&lt;p>You may however miss an important piece of information hidden in that documentation if you are uploading a module from a GitHub release instead of via the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. The name that you refer to the module must match the module name and module folder name in the zip file.&lt;/p>
&lt;h1 id="method-one---from-gallery">Method one - from Gallery&lt;/h1>
&lt;p>This is my preferred method for importing modules into Azure Automation accounts, the only bothersome part is remembering to do it twice, once for 5.1 and once for 7.1 as I am sure that if I forget that will be the one module that I will need!&lt;/p>
&lt;h2 id="find-the-module">Find the module&lt;/h2>
&lt;p>Go to the Module page for the automation account and then Add module and browse the gallery and search for &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> (other modules are available!) and install it&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550108-e6096986-3392-4585-a57a-5c515c2890bf.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>It will take a few moments to install but you will see it in the list with a green tick once it has imported.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181548887-0ec695e4-41b9-45b3-8ab3-a004968c2323.png"
loading="lazy"
alt="image"
>#&lt;/p>
&lt;p>Then it is available in all of my PowerShell 7.1 runbooks in my automation account - Here I have just run &lt;code>Get-DbaToolsConfig&lt;/code> in a test runbook to prove that the module has imported&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550937-7e89c7b3-31e8-4af1-b965-c82f2f63562f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="method-two---using-the-zip-file-from-a-github-release">Method two - using the zip file from a GitHub Release&lt;/h1>
&lt;p>Sometimes you may wish to not use the PowerShell Gallery to import the modules, maybe you have a custom module that you are not ready to upload to the gallery or maybe the module is just internally developed and not available on the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. In this scenario, you can still import hte module so that it can be used by your runbooks.&lt;/p>
&lt;p>To demonstrate, I will remove the dbatools module from the Automation Account&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181553061-9be2da4d-344d-4027-aa7f-902445cee12b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and download the latest release from GitHub directly&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/dataplat/dbatools/releases/tag/v1.1.118" target="_blank" rel="noopener"
>https://github.com/dataplat/dbatools/releases/tag/v1.1.118&lt;/a>&lt;/p>
&lt;p>If you are unable to use the PowerShell Gallery to get the latest dbatools release, I would always use the official signed release.&lt;/p>
&lt;p>You can then upload the zip from the same Modules page using the Browse for file but here is the &lt;em>important bit&lt;/em> You must update the name of the module. By default Azure will set the name to match the name of the zip file as that is what is expected and indeed mentioned in the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules#author-modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft documentation here &lt;/a>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181561112-6aecd5e3-efaa-4b2a-84d7-f7e521035d04.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and once it is imported successfully and I have a green tick&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181564377-df8c707e-24ec-43eb-8d57-702fcb39400b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>I can run the test - Again I just ran &lt;code>Get-DbaToolsConfig&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181569077-2b2e59e2-4bf1-46b6-851f-2e624cf9c43c.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>This method will work with both PowerShell 5.1 and PowerShell 7.1, you will just have to upload the zip (and remember to rename the module entry) twice.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571123-8acb8ff5-7b36-4b62-91f7-34b3df36a1d8.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571518-909ecc6f-9270-45d2-a7b5-0de4406c88c4.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="when-it-goes-wrong">When it goes wrong&lt;/h1>
&lt;p>If you do not rename the module correctly but leave it as the name of file &lt;code>dbatools-signed&lt;/code> in this example&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571939-b881b4bc-4449-4569-b71a-66142436158a.png"
loading="lazy"
alt="image"
>
.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181572041-2fe18929-cc14-40ae-b654-62653206903f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;blockquote>
&lt;p>Error importing the module dbatools-signed. Import failed with the following error:&lt;br>
Orchestrator.Shared.AsyncModuleImport.ModuleImportException: Cannot import the module of name dbatools-signed, as the module structure was invalid. at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.ExecuteInternal(CodeActivityContext context, Byte[] moduleContent, String moduleName, ModuleLanguage moduleLanguage) at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.Execute(CodeActivityContext context) at&lt;br>
System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)&lt;/p>
&lt;/blockquote>
&lt;p>If you get that, just re-upload the zip file and use the correct name in the form.&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Quickly Creating Test Users in SQL Server using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/02/remove-them-all.png" alt="Featured image of post Quickly Creating Test Users in SQL Server using dbatools" /></description></item><item><title>Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/08/image-16.png" alt="Featured image of post Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools" />&lt;p>Following on from my posts about using Secret Management &lt;a class="link" href="https://blog.robsewell.com/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>Good bye Import-CliXml&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/" target="_blank" rel="noopener"
>running programmes as a different user&lt;/a>, I have another use case.&lt;/p>
&lt;p>After creating Azure SQL Databases in an Elastic Pool using a process pretty similar to this one &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>I blogged about last year&lt;/a>, I needed to be able to programmatically create users and assign permissions.&lt;/p>
&lt;h2 id="i-need-a-user-to-login-with">I need a user to login with&lt;/h2>
&lt;p>When I created my Azure SQL Server with Terraform, I set the Azure Admin to be a SPN as you can see in the image from the portal and set it to have an identity using the documentation for &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_server.html" target="_blank" rel="noopener"
>azurerm_mssql_server&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-18.png"
loading="lazy"
>
This allows this user to manage the access for the SQL Server as long as the SQL Server Azure AD identity has Directory Reader privileges. The SQL Server is called temp-beard-sqls and as you can see the identity is assigned to the role.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-11.png"
loading="lazy"
>
The privileges required to do this for a single identity are quite high&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>so now, you can assign an Azure Active Directory Group to that Role and allow less-privileged users to add the identity to this group . The documentation is &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> and there is a tutorial &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal-tutorial?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> explaining the steps you need to take.&lt;/p>
&lt;h2 id="what-is-an-azure-spn">What is an Azure SPN?&lt;/h2>
&lt;blockquote>
&lt;p>An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest&lt;/a>&lt;/p>
&lt;p>I created the SPN using Azure CLI straight from the Azure Portal by clicking this button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and running&lt;/p>
&lt;pre>&lt;code>az ad sp create-for-rbac --name ServicePrincipalName
&lt;/code>&lt;/pre>
&lt;p>This will quickly create a SPN for you and return the password&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes I have deleted this one&lt;/p>
&lt;h2 id="add-azure-key-vault-to-secret-management">Add Azure Key Vault to Secret Management&lt;/h2>
&lt;p>In my previous posts, I have been using the Default Key Vault which is limited to your local machine and the user that is running the code. It would be better to use Azure Key Vault to store the details for the SPN so that it safely stored in the cloud and not on my machine and also so that anyone (or app) that has permissions to the vault can use it.&lt;/p>
&lt;p>First you need to login to Azure in PowerShell (You will need to have the AZ* modules installed)&lt;/p>
&lt;pre>&lt;code>Connect-AzAccount
&lt;/code>&lt;/pre>
&lt;p>Be aware, the login box can appear behind the VS Code or Azure Data Studio window!&lt;/p>
&lt;p>Once connected, if you have several Azure subscriptions, you can list them with&lt;/p>
&lt;pre>&lt;code>Get-AzSubscription
&lt;/code>&lt;/pre>
&lt;p>You can choose your subscription with&lt;/p>
&lt;pre>&lt;code>$AzureSubscription = Set-AzContext -SubscriptionName &amp;quot;NAME OF SUBSCRIPTION&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>For the Secret Management Module to manage the Azure Key Vault, you first need to register it.&lt;/p>
&lt;p>Ensure that you have permissions to connect by following the details in the network security documentationÂ &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/network-security?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/network-security&lt;/a>Â and the secure access documentationÂ &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault&lt;/a>&lt;/p>
&lt;p>Then you can runÂ &lt;code>Register-SecretVault&lt;/code>Â . You need to provide the local name for the key vault, the module nameÂ &lt;code>Az.KeyVault&lt;/code>, and aÂ &lt;code>VaultParameters&lt;/code>Â hashtable with the KeyVault name and the Azure Subscription ID. You can register other types of Key Vaults to the Secret Management module in this way and they will require different values for theÂ &lt;code>VaultParameters&lt;/code>Â parameter.&lt;/p>
&lt;pre>&lt;code>$KeyVaultName = 'beard-key-vault'
Register-SecretVault -Name BeardKeyVault -ModuleName Az.KeyVault -VaultParameters @{ AZKVaultName = $KeyVaultName; SubscriptionId = $AzureSubscription.Subscription.Id }
&lt;/code>&lt;/pre>
&lt;h2 id="adding-the-spn-details-to-the-azure-key-vault">Adding the SPN details to the Azure Key Vault&lt;/h2>
&lt;p>Using the values for AppID â€“ (Note NOT the display name) and the values for the password from the Azure CLI output or by creating a new secret for the SPN with PowerShell or via the portal. You can use the following code to add the SPN details and the tenantid to the Azure Key Vault using the Secret Management module&lt;/p>
&lt;pre>&lt;code>$ClientId = Read-Host &amp;quot;Enter ClientID&amp;quot; -AsSecureString
$SecretFromPortal = Read-Host &amp;quot;Enter Client Secret&amp;quot; -AsSecureString
$tenantid = Read-Host &amp;quot;Enter TenantId&amp;quot; -AsSecureString
Set-Secret -Vault BeardKeyVault -Name service-principal-guid -Secret $ClientId
Set-Secret -Vault BeardKeyVault -Name service-principal-secret -SecureStringSecret $SecretFromPortal
Set-Secret -Vault BeardKeyVault -Name Tenant-Id -Secret $tenantid
&lt;/code>&lt;/pre>
&lt;p>You can also do this with the Az.KeyVault module by following the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can see the secrets in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>and also at the command line with the Secret Management module using&lt;/p>
&lt;pre>&lt;code>Get-SecretInfo -Vault RegisteredNameOfVault
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="can-my-user-connect">Can my user connect?&lt;/h2>
&lt;p>If I try to connect in Azure Data Studio to my Azure SQL Database with my AAD account to the temp-sql-db-beard database. It fails.&lt;/p>
&lt;p>By the way a great resource for troubleshooting the SQL error 18456 failure states can be found here &lt;a class="link" href="https://sqlblog.org/2020/07/28/troubleshooting-error-18456" target="_blank" rel="noopener"
>https://sqlblog.org/2020/07/28/troubleshooting-error-18456&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-13.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="dbatools-to-the-rescue-">dbatools to the rescue ðŸ™‚&lt;/h2>
&lt;p>dbatools is an open source community collaboration PowerShell module for administrating SQL Server. You can find more about it at &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.io&lt;/a> and get the book that Chrissy and I are writing about dbatools at &lt;a class="link" href="http://dbatools.io%5Cbook" target="_blank" rel="noopener"
>dbatools.io\book&lt;/a>&lt;/p>
&lt;p>You can connect to Azure SQL Database with an Azure SPN using the following code. It will get the secrets from the Azure Key Vault that have been set above and create a connection. Lets see if I can run a query as the SPN.&lt;/p>
&lt;pre>&lt;code>$SqlInstance = 'temp-beard-sqls.database.windows.net'
$databasename = 'master'
$appid = Get-Secret -Vault BeardKeyVault -Name service-principal-guid -AsPlainText
$Clientsecret = Get-Secret -Vault BeardKeyVault -Name service-principal-secret
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = Get-Secret -Vault BeardKeyVault -Name Sewells-Tenant-Id -AsPlainText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
Invoke-DbaQuery -SqlInstance $AzureSql -Database master -SqlCredential $credential -Query &amp;quot;Select SUSER_NAME() as 'username'&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Excellent ðŸ™‚&lt;/p>
&lt;h2 id="add-a-user-to-the-user-database">Add a user to the user database&lt;/h2>
&lt;p>I can then add my user to the temp-sql-db-beard Database. I need to create a new connection to the user database as you cannot use the &lt;code>USE [DatabaseName]&lt;/code> statement&lt;/p>
&lt;pre>&lt;code>$Userdatabasename = 'temp-sql-db-beard'
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $Userdatabasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre>
&lt;p>Whilst you can use dbatools to create new users in Azure SQL Database at present you cant create AAD users. You can run a T-SQL Script to do this though. This script will create a contained database user in the database. I have added the role membership also but this can also be done with &lt;a class="link" href="https://docs.dbatools.io/#Add-DbaDbRoleMember" target="_blank" rel="noopener"
>Add-DbaDbRoleMember&lt;/a> from dbatools&lt;/p>
&lt;pre>&lt;code>$Query = @&amp;quot;
CREATE USER [rob@sewells-consulting.co.uk] FROM EXTERNAL PROVIDER
ALTER ROLE db_datareader ADD MEMBER [rob@sewells-consulting.co.uk]
&amp;quot;@
Invoke-DbaQuery -SqlInstance $AzureSql -Database $Userdatabasename -SqlCredential $credential -Query $Query
&lt;/code>&lt;/pre>
&lt;p>Lets check the users on the database with dbatools&lt;/p>
&lt;pre>&lt;code>Get-DbaDbUser -SqlInstance $AzureSql -Database $Userdatabasename |Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>I have my user and it is of type External user. Lets see if I can connect&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Bingo ðŸ™‚&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>Because I dont like to see awesome people struggling with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Here is the same code using just the Az.KeyVault module&lt;/p>
&lt;pre>&lt;code>$appid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-guid&amp;quot;).SecretValueText
$Clientsecret = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-secret&amp;quot;).SecretValue
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;Sewells-Tenant-Id&amp;quot;).SecretValueText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre></description></item><item><title>Notifying a Teams Channel of a SQL Agent Job result</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</link><pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-18.png" alt="Featured image of post Notifying a Teams Channel of a SQL Agent Job result" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>yesterdays post about creating an overview of SQL Agent Job Results and sending it to a Teams channel&lt;/a>, I was given another challenge&lt;/p>
&lt;blockquote>
&lt;p>Can you write a job step that I can add to SQL Agent jobs that can send the result of that job to a Teams Channel&lt;/p>
&lt;p>A person with a need&lt;/p>
&lt;/blockquote>
&lt;p>The use case was for some migration projects that had steps that were scheduled via SQL Agent Jobs and instead of the DBA having to estimate when they would finish and keep checking so that they could let the next team know that it was time for their part to start, they wanted it to notify a Teams channel. This turned out especially useful as the job finished earlier than expected at 3am and the off-shore team could begin their work immediately.&lt;/p>
&lt;h2 id="using-sql-agent-job-tokens-with-powershell">Using SQL Agent Job tokens with PowerShell&lt;/h2>
&lt;p>You can use &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/ssms/agent/use-tokens-in-job-steps?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>SQL Agent job tokens in Job step commands to reference the existing instance or job&lt;/a> but I did not know if you could use that with PowerShell until I read &lt;a class="link" href="https://littlekendra.com/2009/12/02/sql-2008-agent-jobs-tokens-work-in-powershell/" target="_blank" rel="noopener"
>Kendra Littleâ€™s blog post from 2009&lt;/a>.&lt;/p>
&lt;p>Thank you Kendra&lt;/p>
&lt;h2 id="nothing-is-ever-as-easy-as-you-think">Nothing is ever as easy as you think&lt;/h2>
&lt;p>So I thought, this is awesome, I can create a function and pass in the Instance and the JobId and all will be golden.&lt;/p>
&lt;p>Nope&lt;/p>
&lt;h2 id="job_id--jobid">job_id &amp;lt;&amp;gt; $(JobID)&lt;/h2>
&lt;p>If we look in the sysjobs table at the Agent Job that we want to notify Teams about the result.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>We can see that the job_id is&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>If we look at the JobId property with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-15.png?resize=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>We get&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>Awesome, they are the same&lt;/p>
&lt;p>But&lt;/p>
&lt;p>If we look at the value of the $(JobID) SQL Agent Job Token,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>we get&lt;/p>
&lt;pre>&lt;code>C33759DC6F76B747A5A548365708659A
&lt;/code>&lt;/pre>
&lt;p>which makes matching it to the JobId tricky&lt;/p>
&lt;p>I tried all sorts of ways of casting and converting this value in SQL and PowerShell and in the end I just decided to manually convert the value&lt;/p>
&lt;pre>&lt;code> $CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
&lt;/code>&lt;/pre>
&lt;h2 id="send-the-information-to-teams">Send the information to Teams&lt;/h2>
&lt;p>Following the &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>same pattern as yesterdays post&lt;/a>, I created a function to send a message, depending on the outcome of the job and post it to the Teams function.&lt;/p>
&lt;p>Again, I used Enter-PsSession to run the Teams notification from a machine that can send the message. (I have also included the code to do this without requiring that below so that you can send the message from the same machine that runs the job if required)&lt;/p>
&lt;p>This code below is saved on a UNC share or the SQL Server as SingleNotifyTeams.ps1&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$NotifyCommand = {
$parameters = @{
&amp;quot;URI&amp;quot; = $Using:webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $Using:TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre>
&lt;p>Then it can be called in a SQL Agent job step, again following the guidelines at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a>&lt;/p>
&lt;p>It is called slightly differently as you ned to pass in the SQL Agent tokens as parameters to the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-16.png"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>powershell.exe -File path to Notify-TeamsSQLAgentJob.ps1 -SQLInstance $(ESCAPE_SQUOTE(SRVR)) -JobID $(ESCAPE_NONE(JOBID))
&lt;/code>&lt;/pre>
&lt;h2 id="sql-agent-job-step-success-and-failure">SQL Agent Job Step Success and Failure&lt;/h2>
&lt;p>We need to take another step to ensure that this works as expected. We have to change the On Failure action for each job step to the â€œGo To Notify Teamsâ€ step&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-17.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="making-people-smile">Making people smile&lt;/h2>
&lt;p>You can also add images (make sure the usage rights allow) so that the success notification can look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>and the failure looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Happy Automating !&lt;/p>
&lt;p>Here is the code that does not require remoting to another server to send the message&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;https://outlook.office.com/webhook/5a8057cd-5e1a-4c84-9227-74a309f1c738@b122247e-1ebf-4b52-b309-c2aa7436fc6b/IncomingWebhook/affb85f05804438eb7ffb57665879248/f32fc7e6-a998-4670-8b33-635876559b80&amp;quot;
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre></description></item><item><title>Sending a SQL Agent Job results overview to a Microsoft Teams Channel</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</link><pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-11.png" alt="Featured image of post Sending a SQL Agent Job results overview to a Microsoft Teams Channel" />&lt;p>Microsoft Teams is fantastic for collaboration. It enables groups of people, teams if you like to be able to communicate, collaborate on documents, hold meetings and much much more.&lt;/p>
&lt;h2 id="sql-agent-job-overview">SQL Agent Job Overview&lt;/h2>
&lt;p>Using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> we can create a simple script to gather the results of Agent Jobs form a list of instances. Maybe it would be good to be able to get the job runs results every 12 hours so that at 6am in the morning the early-bird DBA can quickly identify if there are any failures that need immediate action and at 6pm , the team can check that everything was ok before they clock off.&lt;/p>
&lt;p>Here is an example of such a script&lt;/p>
&lt;pre>&lt;code>$SqlInstances = (Get-Vm -ComputerName BEARDNUC,BEARDNUC2).Where{$_.State -eq 'Running' -and $_.Name -like '*SQL*'}.Name
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and an example of running it.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-2.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-teams-channel">Create a Teams Channel&lt;/h2>
&lt;p>If you have permissions, you can create a new Teams channel by clicking on the 3 ellipses and add channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Then fill in the blanks&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-webhook-connector-for-the-channel">Create a Webhook Connector for the channel&lt;/h2>
&lt;p>Next, you need to have a connector for the channel, click on the 3 ellipses for the channel and click on connectors&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Then you can choose the Incoming Webhook connector and click configure&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>Give the connector a name and upload an image if you wish and click create&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The resulting screen will give you a URL that you can copy. If you need to find it again, then use the 3 ellipses again, click connectors and look at configured. You can then choose the webhook that you have created and click manage and you will find the URL.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-8.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="send-to-teams-using-powershell">Send to Teams using PowerShell&lt;/h2>
&lt;p>Now you can send a message to that Teams channel using PowerShell. You will need to add the webhook URL from your Teams connector&lt;/p>
&lt;pre>&lt;code>[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = &amp;quot;&amp;quot;
$Text = @&amp;quot;
# Here is a Title
and a message
Image is from
https://www.flickr.com/photos/157270154@N05/38494483572
Photo by CreditDebitPro
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;This is my summary&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Something Important &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;I have something to say&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>The code above will send a message that looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-9.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="running-as-a-sql-agent-job">Running as a SQL Agent Job&lt;/h2>
&lt;p>Now we can run this code as a SQL Agent Job and schedule it. Now, you may not be able to run that code on your SQL Server. It cannot connect to the internet, so how can we contact the Teams webhook?&lt;/p>
&lt;p>There are probably a number of ways to do this but the solution that I took, was to allow a proxy account the ability to use PSRemoting and run the part of the script that connects to Teams on a different machine, that does have connectivity.&lt;/p>
&lt;p>The script I used was as follows. You will need to add in the SQL Instances or better still dynamically gather them from your source of truth. You will need the webhook URL and the name of the server that can connect to Teams&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
$NotifyCommand = {
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = $Using:TeamsWebhook
$allJobsMessage = $Using:AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($Using:startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($Using:startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
&lt;/code>&lt;/pre>
&lt;p>Then, follow the steps at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a> to create an agent job to run the script above on an instance with the dbatools module available to the SQL Service account. Use or create a proxy with permissions on the notify server and create an Agent Job.&lt;/p>
&lt;pre>&lt;code>USE [msdb]
GO
/****** Object: Job [I am a Job that notifies Teams] Script Date: 27/07/2020 20:27:27 ******/
BEGIN TRANSACTION
DECLARE @ReturnCode INT
SELECT @ReturnCode = 0
/****** Object: JobCategory [[Uncategorized (Local)]] Script Date: 27/07/2020 20:27:28 ******/
IF NOT EXISTS (SELECT name FROM msdb.dbo.syscategories WHERE name=N'[Uncategorized (Local)]' AND category_class=1)
BEGIN
EXEC @ReturnCode = msdb.dbo.sp_add_category @class=N'JOB', @type=N'LOCAL', @name=N'[Uncategorized (Local)]'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
END
DECLARE @jobId BINARY(16)
EXEC @ReturnCode = msdb.dbo.sp_add_job @job_name=N'12 Hour Teams Notify',
@enabled=1,
@notify_level_eventlog=0,
@notify_level_email=0,
@notify_level_netsend=0,
@notify_level_page=0,
@delete_level=0,
@description=N'This job will notify Teams every 12 hours',
@category_name=N'[Uncategorized (Local)]',
@owner_login_name=N'THEBEARD\SQL_SVC', @job_id = @jobId OUTPUT
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
/****** Object: Step [Notify Teams] Script Date: 27/07/2020 20:27:28 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N'Notify Teams',
@step_id=1,
@cmdexec_success_code=0,
@on_success_action=1,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N'CmdExec',
@command=N'powershell.exe -File C:\temp\AgentJobs\NotifyTeams.ps1',
@flags=0,
@proxy_name=N'TheBeardIsMighty'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_update_job @job_id = @jobId, @start_step_id = 1
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_add_jobserver @job_id = @jobId, @server_name = N'(local)'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
COMMIT TRANSACTION
GOTO EndSave
QuitWithRollback:
IF (@@TRANCOUNT &amp;gt; 0) ROLLBACK TRANSACTION
EndSave:
GO
&lt;/code>&lt;/pre>
&lt;p>When the job runs&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>The results are posted to the Teams Channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>If you can run the Agent Job on a machine that can connect to Teams and your SQL Instances then you can remove the need to use a remote session by using this code&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$allJobsMessage = $AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Results &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>Happy automating!&lt;/p></description></item><item><title>Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/runas.png" alt="Featured image of post Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>my last post about the Secret Management module&lt;/a>. I was asked another question.&lt;/p>
&lt;blockquote>
&lt;p>Can I use this to run applications as my admin account?&lt;/p>
&lt;p>A user with a beard&lt;/p>
&lt;/blockquote>
&lt;p>It is good practice to not log into your work station with an account with admin privileges. In many shops, you will need to open applications that can do administration tasks with another set of account credentials.&lt;/p>
&lt;p>Unfortunately, people being people, they will often store their admin account credentials in a less than ideal manner (OneNote, Notepad ++ etc) to make it easier for them, so that when they right click and run as a different user, they can copy and paste the password.&lt;/p>
&lt;h2 id="use-the-secret-management-module">Use the Secret Management module&lt;/h2>
&lt;p>Again, I decided to use a notebook to show this as it is a fantastic way to share code and results and because it means that anyone can try it out.&lt;/p>
&lt;p>The notebook may not render on a mobile device.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Using the notebook, I can quickly store my admin password safely and open and run the applications using the credential&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/runas.png"
loading="lazy"
>&lt;/p></description></item><item><title>Good Bye Import-CliXML â€“ Use the Secrets Management module for your labs and demos</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</link><pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-1.png" alt="Featured image of post Good Bye Import-CliXML â€“ Use the Secrets Management module for your labs and demos" />&lt;p>Donâ€™t want to read all this? There are two dotnet interactive notebooks here with the relevant information for you to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;h2 id="jaap-is-awesome">Jaap is awesome&lt;/h2>
&lt;p>&lt;img src="https://pbs.twimg.com/media/DBbP9lHXYAAopb3?format=jpg&amp;amp;name=4096x4096"
loading="lazy"
>&lt;/p>
&lt;p>I have to start here. For the longest time, whenever anyone has asked me how I store my credentials for use in my demos and labs I have always referred them to Jaap Brassers &lt;a class="link" href="https://twitter.com/Jaap_Brasser" target="_blank" rel="noopener"
>t&lt;/a> blog post&lt;/p>
&lt;p>&lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/&lt;/a>&lt;/p>
&lt;h2 id="joel-is-also-awesome">Joel is also awesome!&lt;/h2>
&lt;p>When people wanted a method of storing credentials that didn&amp;rsquo;t involve files on disk I would suggest Joel Bennettâ€™s &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>t&lt;/a> module BetterCredentials which uses the Windows Credential Manager&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/BetterCredentials/4.5" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/BetterCredentials/4.5&lt;/a>&lt;/p>
&lt;h2 id="microsoft-also-awesome">Microsoft? Also awesome!&lt;/h2>
&lt;p>In February, Microsoft released the SecretManagement module for preview.&lt;/p>
&lt;p>&lt;a class="link" href="https://devblogs.microsoft.com/powershell/secrets-management-development-release?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://devblogs.microsoft.com/powershell/secrets-management-development-release/&lt;/a>&lt;/p>
&lt;p>Sydney &lt;a class="link" href="https://twitter.com/sydneysmithreal" target="_blank" rel="noopener"
>t&lt;/a> gave a presentation at the European PowerShell Conference which you can watch on Youtube.&lt;/p>
&lt;h2 id="good-bye-import-clixml">Good Bye Import-CliXML&lt;/h2>
&lt;p>So now I say, it is time to stop using Import-Clixml for storing secrets and use the Microsoft.PowerShell.SecretsManagement module instead for storing your secrets.&lt;/p>
&lt;h2 id="notebooks-are-as-good-as-blog-posts">Notebooks are as good as blog posts&lt;/h2>
&lt;p>I love notebooks and to show some people who had asked about storing secrets, I have created some. So, because I am efficient lazy I have embedded them here for you to see. You can find them in my Jupyter Notebook repository&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;p>in the Secrets folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-1.png?resize=630%2C349&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-and-using-the-secrets-management-module">Installing and using the Secrets Management Module&lt;/h2>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="using-the-secret-management-module-in-your-scripts">Using the Secret Management Module in your scripts&lt;/h2>
&lt;p>Here is a simple example of using the module to provide the credential for a docker container and then to dbatools to query the container&lt;/p>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>New .NET Notebooks are here â€“ PowerShell 7 notebooks are here.</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</link><pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-13.png" alt="Featured image of post New .NET Notebooks are here â€“ PowerShell 7 notebooks are here." />&lt;p>Data Science folk used Notebooks for documentation and to show re-runnable research. Azure Data Studio included this notebook functionality and &lt;a class="link" href="https://blog.robsewell.com/dbatools/dbachecks/blog/jupyter%20notebooks/azure%20data%20studio/powershell/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>added SQL&lt;/a> kernel where &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbachecks/dbatools/powershell-in-sql-notebooks-in-azure-data-studio//" target="_blank" rel="noopener"
>with a little bit of faffing you could run PowerShell&lt;/a> and then a &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/powershell-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>Python kernel that enabled PowerShell&lt;/a>. It seems that notebooks are so cool that everyone is creating them these days! I was browsing twitter when I saw this tweet.&lt;/p>
&lt;blockquote>
&lt;p>.NET Notebooks Preview 2 is here! Preview 2 includes ðŸŽ‰&lt;a class="link" href="https://twitter.com/PowerShell_Team?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@PowerShell_Team&lt;/a>, &lt;a class="link" href="https://twitter.com/nteractio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@nteractio&lt;/a>, and a new tool. Check out our blog to learn more. Congratulations to &lt;a class="link" href="https://twitter.com/jonsequitur?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@jonsequitur&lt;/a> &lt;a class="link" href="https://twitter.com/colombod?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@colombod&lt;/a> and our entire team&lt;a class="link" href="https://t.co/WqNWQWR3Bo" target="_blank" rel="noopener"
>https://t.co/WqNWQWR3Bo&lt;/a>&lt;a class="link" href="https://twitter.com/dotnet?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@dotnet&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/jupyter?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#jupyter&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/PowerShell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#PowerShell&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/interactiveprogramming?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#interactiveprogramming&lt;/a>.&lt;/p>
&lt;p>â€” Maria Naggaga (@LadyNaggaga) &lt;a class="link" href="https://twitter.com/LadyNaggaga/status/1225464258823163906?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="powershell-7-notebooks-">PowerShell 7 Notebooks ðŸ™‚&lt;/h2>
&lt;p>A notebook experience for PowerShell 7 that sounds amazing. This will enable a true cross-platform PowerShell Notebook experience which is lacking from the Python version as it uses Windows PowerShell on Windows and PowerShell Core on other OSâ€™s&lt;/p>
&lt;p>The first thing I asked was â€“ Will this come to Azure Data Studio. I got an immediate response from Sydney Smith PowerShell Program Manager saying it is on the roadmap&lt;/p>
&lt;blockquote>
&lt;p>Moving this kernel into ADS is on our roadmap! Right now our kernel uses hosted pwsh 7 but we would love to know if you have scenarios that don&amp;rsquo;t work with 7&lt;/p>
&lt;p>â€” Sydney Smith (@sydneysmithreal) &lt;a class="link" href="https://twitter.com/sydneysmithreal/status/1225488719567818752?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="install-dependencies">Install dependencies&lt;/h2>
&lt;p>To be able to run the notebook, you need to install some dependencies. First install the .NET CORE SDK which you can download from &lt;a class="link" href="https://dotnet.microsoft.com/download?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://dotnet.microsoft.com/download&lt;/a> This needs admin permissions to install.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image.png?resize=620%2C418&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You also need a Python installation â€“ You can use Anaconda, which you can download from here &lt;a class="link" href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener"
>https://www.anaconda.com/distribution/&lt;/a> This does not need admin to install&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-1.png?resize=531%2C232&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-2.png?fit=630%2C490&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-anaconda-to-windows-terminal">Add Anaconda to Windows Terminal&lt;/h2>
&lt;p>I have added the Anaconda prompt to Windows Terminal so that I have one entry point for all my CLIs. Open the settings file and add the code below. (It will also give you an icon and background.&lt;/p>
&lt;pre>&lt;code> {
// Make changes here to the Anaconda.exe profile
&amp;quot;guid&amp;quot;: &amp;quot;{0caa0dad-35be-5f56-a7ff-afceeeaa6101}&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;Anaconda&amp;quot;,
&amp;quot;commandline&amp;quot;: &amp;quot;cmd.exe /K C:\\Users\\mrrob\\Anaconda3\\Scripts\\activate.bat&amp;quot;,
&amp;quot;hidden&amp;quot;: false,
&amp;quot;backgroundImage&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;icon&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;backgroundImageAlignment&amp;quot;: &amp;quot;topRight&amp;quot;,
&amp;quot;backgroundImageStretchMode&amp;quot;: &amp;quot;uniform&amp;quot;,
&amp;quot;backgroundImageOpacity&amp;quot;: 0.1
}
&lt;/code>&lt;/pre>
&lt;p>and it appears in the drop down&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-3.png?resize=509%2C409&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>With Anaconda installed, check that that the kernel is available on your path. If like me you have Azure Data Studio installed, you will have additional kernels but the important one line here is&lt;/p>
&lt;p>&lt;code>python3 C:\Users\USERNAME\Anaconda3\share\jupyter\kernels\python3&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-4.png?resize=630%2C210&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>In Windows Terminal move to a PowerShell 7 prompt and install the dotnet interactive tool&lt;/p>
&lt;pre>&lt;code>dotnet tool install --global Microsoft.dotnet-interactive
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-5.png?resize=630%2C259&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can install the .NET kernel in your Anaconda prompt using this command&lt;/p>
&lt;pre>&lt;code>dotnet interactive jupyter install
&lt;/code>&lt;/pre>
&lt;h2 id="sometimes-new-things-have-errors">Sometimes new things have errors&lt;/h2>
&lt;p>I had an error when I tried this first time&lt;/p>
&lt;blockquote>
&lt;p>Could not execute because the specified command or file was not found.&lt;br>
Possible reasons for this include:&lt;br>
* You misspelled a built-in dotnet command.&lt;br>
* You intended to execute a .NET Core program, but dotnet-interactive does not exist.&lt;br>
* You intended to run a global tool, but a dotnet-prefixed executable with this name could not be found on the PATH.&lt;/p>
&lt;/blockquote>
&lt;p>This is easily fixed by adding &lt;code>%USERPROFILE%\.dotnet\tools&lt;/code> to my path with &lt;code>set PATH=%PATH%;%USERPROFILE%\.dotnet\tools&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-6.png?fit=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Running &lt;code>jupyter kernelspec list&lt;/code> shows that the .NET kernel is installed for C Sharp, F Sharp and .NET PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-7.png?resize=630%2C197&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="lets-open-a-notebook">Lets open a Notebook&lt;/h2>
&lt;p>Now you want to play with it!&lt;br>
You can run the lab environment using `jupyter lab`&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-8.png?fit=630%2C194&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>This opens a browser&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-9.png?fit=630%2C272&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can open existing Azure Data Studio PowerShell notebooks (but not SQL ones)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-10.png?fit=630%2C492&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="sometimes-new-things-have-errors-part-2">Sometimes new things have errors Part 2&lt;/h2>
&lt;p>Unfortunately, I get errors when trying to import Pester which means I can not use my dbachecks notebooks in this blog post. &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>I have raised an issue on the repo here&lt;/a>.&lt;/p>
&lt;h2 id="create-a-new-notebook">Create a New Notebook&lt;/h2>
&lt;p>But it is easy to create a new Notebook&lt;/p>
&lt;p>In the launcher page click the .NET PowerShell button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-12.png?resize=567%2C171&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Which will open a new Notebook in the directory that you launched the lab from. You can then add Code or Markdown as I have &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>described before here&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-11.png?resize=316%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can add code, markdown and images to create your notebook.&lt;/p>
&lt;p>Once you have finished using the notebook lab, you can shut it down in the Anaconda prompt with &lt;code>CTRL + C&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-15.png?fit=630%2C103&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Here is a video of running a notebook which anyone can use to create a couple of Docker containers running SQL 2019 and query them with dbatools. You can find the notebook further down this post.&lt;/p>
&lt;h2 id="sharing-notebooks">Sharing Notebooks&lt;/h2>
&lt;p>You can create notebooks to run common tasks. Even better, from the lab you can convert the notebook including the results to a variety of formats to share with other none-technical people. I used this functionality this week to export Azure Data Studio Notebooks to HTML and PDF for a Project manager ðŸ™‚&lt;/p>
&lt;p>You can find the Export Notebook command in the File menu&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-13.png?resize=610%2C542&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Exporting to HTML did not export the images but it does include the results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-14.png?fit=630%2C476&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can share notebooks via GitHub â€“ Either in a gist like this&lt;/p>
&lt;p>or by providing a straight link to the notebook in GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb&lt;/a>&lt;/p>
&lt;p>You can also use Binder &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a>&lt;/p>
&lt;p>This uses Docker to create an interactive Notebook. Create a GitHub repo like &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks&lt;/a> (or just clone it) Copy your notebooks into the notebooks folder and push the changes to GitHub and then go to &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a> and add your URL to the repository.&lt;/p>
&lt;p>You can see what it looks like by clicking the button below which Binder creates for you&lt;/p>
&lt;p>&lt;a class="link" href="https://mybinder.org/v2/gh/SQLDBAWithABeard/Notebooks/master" target="_blank" rel="noopener"
>&lt;img src="https://mybinder.org/badge_logo.svg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Unfortunately the kernel only supports Python for the moment but you can see the possibilities ðŸ™‚&lt;/p></description></item><item><title>How to fork a GitHub repository and contribute to an open source project</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/CreatePR.png" alt="Featured image of post How to fork a GitHub repository and contribute to an open source project" />&lt;p>I enjoy maintaining open source GitHub repositories such as &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>. I absolutely love it when people add more functionality to them.&lt;/p>
&lt;p>To collaborate with a repository in GitHub you need to follow these steps&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/GitHub.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>Fork the repository into your own GitHub&lt;/li>
&lt;li>Clone the repository to your local machine&lt;/li>
&lt;li>Create a new branch for your changes&lt;/li>
&lt;li>Make some changes and commit them with useful messages&lt;/li>
&lt;li>Push the changes to your repository&lt;/li>
&lt;li>Create a Pull Request from your repository back to the original one&lt;/li>
&lt;/ul>
&lt;p>You will need to have &lt;code>git.exe&lt;/code> available which you can download and install from &lt;a class="link" href="https://git-scm.com/downloads" target="_blank" rel="noopener"
>https://git-scm.com/downloads&lt;/a> if required&lt;/p>
&lt;h2 id="fork-the-repository-into-your-own-github">Fork the repository into your own GitHub&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/ForkRepo.png"
loading="lazy"
>&lt;/p>
&lt;p>A fork is a copy of the original repository. This allows you to make changes without affecting the original project. It does not get updated when the original project gets updated (We will talk about that in the next post) This enables you to code a new feature or a bug fix, test it locally and make sure it is working.&lt;/p>
&lt;p>Letâ€™s take dbachecks as our example. Start by going to the project in GiHub. In this case the URL is &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks&lt;/a> You will see a Fork button at the top right of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-41.png?fit=630%2C74&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When you click the button the repository is copied into your own GitHub account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-42.png?resize=630%2C304&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The page will open at &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> in this case &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/dbachecks&lt;/a> You will be able to see that it is a fork of the original repository at the top of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-43.png?resize=474%2C119&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="clone-the-repository-to-your-local-machine">Clone the repository to your local machine&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CloneRepo-2.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Forking the repository has created a &lt;em>remote&lt;/em> repository stored on the GitHub servers. Now that the repository has been forked you need to clone it to your local machine to create a &lt;em>local&lt;/em> repository so that you can start coding your amazing fix. When you have finished you can then sync it back to your &lt;em>remote&lt;/em> repository ready for a Pull Request back to the original repository.&lt;/p>
&lt;p>In your browser, at your &lt;em>remote&lt;/em> repository that you just created (&lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> if you have closed the page) click on &lt;code>Clone or Download&lt;/code> and then the icon to the right to copy the url&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-46.png?fit=630%2C316&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone your repository in &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>VS Code&lt;/a> or &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> by clicking F1 or CTRL + SHIFT + P in Windows or Linux and â‡§âŒ˜P or F1 on a Mac&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-44.png?fit=630%2C206&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>then start typing clone until you see &lt;code>Git:Clone&lt;/code> and press enter or click&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-45.png?fit=630%2C100&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Paste in the URL that you just copied and click enter. A dialog will open asking you to select a folder. This is the parent directory where your &lt;em>local&lt;/em> repository will be created. The clone will create a directory for your repository so you do not need to. I suggest that you use a folder called GitHub or something similar to place all of the repositories that you are going to clone and create.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-47.png?fit=630%2C345&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When it has finished it will ask you if you wish to open the repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-49.png?fit=630%2C215&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>if you click &lt;code>Open&lt;/code> it will close anything that you have already got opened and open the folder. If you click &lt;code>Add to Workspace&lt;/code> it will add the folder to the workspace and leave everything you already had open as it was and surprisingly clicking &lt;code>Open in New Window&lt;/code> will open the folder in a new instance of Visual Studio Code or Azure Data Studio!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-51.png?fit=630%2C997&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and you will also be able to see the local repository files on your computer&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-50.png?resize=442%2C244&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone the repository at the command line if you wish by navigating to your local GitHub directory and running &lt;code>git clone TheURLYouCopied&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-48.png?fit=630%2C165&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now your &lt;em>local&lt;/em> repository has been created, itâ€™s time to do your magic coding.&lt;/p>
&lt;h2 id="create-a-new-branch-for-your-changes">Create a new branch for your changes&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/NewBranch.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>It is a good idea to create a branch for your &lt;code>amazing new feature&lt;/code> This enables you to work on coding for that feature in isolation. It has the added advantage that if you mess it right royally up, you can just delete that branch and start again with a new one!&lt;/p>
&lt;p>To create a branch in VS Code or Azure Data Studio you can click on the branch name at the bottom left.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-52.png?resize=630%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Or open the Command Palette and type Branch until you see &lt;code>Git: Create Branch&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-53.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will be prompted for a branch name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-54.png?fit=630%2C96&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I like to choose a name that relates to the code that I am writing like &lt;code>configurable_engine&lt;/code> or &lt;code>removeerroringexample&lt;/code> You can see the name of the branch in the bottom left so that you always know which branch you are working on.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?fit=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The icon shows that the branch is only &lt;em>local&lt;/em> and hasnâ€™t been pushed (published) to the &lt;em>remote&lt;/em> repository yet&lt;/p>
&lt;h2 id="make-some-changes-and-commit-them-with-useful-messages">Make some changes and commit them with useful messages&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/awesomenewfeature.png?resize=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now you can start writing your code for your awesome new feature, bug fix or maybe just documentation improvement. Keep your commits small and give them useful commit messages that explain &lt;em>why&lt;/em> you have made the change as the diff tooling will be able to show &lt;em>what&lt;/em> change you have made&lt;/p>
&lt;p>Write your code or change the documentation, save the file and in Visual Studio Code or Azure Data Studio you will see that the source control icon has a number on it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-56.png?fit=630%2C143&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Clicking on the icon will show the files that have changes ready&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-57.png?fit=630%2C290&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can write your commit message in the box and click CTRL + ENTER to commit your changes with a message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-58.png?fit=630%2C296&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you want to do this at the command line, you can use &lt;code>git status&lt;/code> to see which files have changes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-59.png?fit=630%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will need to &lt;code>git add .&lt;/code>or &lt;code>git add .\pathtofile&lt;/code> to stage your changes ready for committing and then &lt;code>git commit -m 'Commit Message'&lt;/code> to commit them&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-60.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Notice that I did exactly what I just said not to do! A better commit message would have been &lt;em>So that people can find the guide to forking and creating a PR&lt;/em>&lt;/p>
&lt;h2 id="push-the-changes-to-your-repository">Push the changes to your repository&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/publishbranch.png?resize=630%2C219&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You only have the changes that you have made in your &lt;em>local&lt;/em> repository on your computer. Now you need to push those changes to GitHub your &lt;em>remote&lt;/em> repository. You can click on the publish icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?resize=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will get a pop-up asking you if you wish to stage your changes. I click &lt;code>Yes&lt;/code> and never &lt;code>Always&lt;/code> so that I can use this prompt as a sanity check that I am doing the right thing&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-75.png?fit=630%2C150&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>At the command line you can push the branch, if you do that, you will have to tell git where the branch needs to go. If you just type &lt;code>git push&lt;/code> it will helpfully tell you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-61.png?fit=630%2C121&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>fatal: The current branch AwesomeNewFeature has no upstream branch.
To push the current branch and set the remote as upstream, use
git push --set-upstream origin AwesomeNewFeature
&lt;/code>&lt;/pre>
&lt;p>So you will need to use that command&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-62.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can see in the bottom left that the icon has changed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-63.png?fit=630%2C186&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and if you read the output of the &lt;code>git push&lt;/code> command you will see what the next step is also.&lt;/p>
&lt;h2 id="create-a-pull-request-from-your-repository-back-to-the-original-one">Create a Pull Request from your repository back to the original one&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CreatePR.png?resize=630%2C238&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can CTRL click the link in the &lt;code>git push&lt;/code> output if you have pushed from the command line or if you visit either you repository or the original repository in your browser you will see that there is a &lt;code>Compare and Pull Request&lt;/code> button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-64.png?fit=630%2C334&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You click that and let GitHub do its magic&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-65.png?fit=630%2C459&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will create a Pull Request for you ready for you to fill in the required information, ask for reviewers and other options. Once you have done that you can click &lt;code>Create pull request&lt;/code> and wait for the project maintainer to review it and (hopefully) accept it into their project&lt;/p>
&lt;p>You can find the Pull Request that I created here &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/720" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks/pull/720&lt;/a> and see how the rest of this blog post was created.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-66.png?fit=630%2C489&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you make more changes to the code in the same branch in your &lt;em>local&lt;/em> repository and push them, they will automatically be added to this Pull Request whilst it is open. You can do this if the maintainer or reviewer asks for changes.&lt;/p>
&lt;p>Shane has asked for a change&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-67.png?resize=630%2C110&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can go to my &lt;em>local&lt;/em> repository in Azure Data Studio and make the requested change and save the file. If I look in the source control in Azure Data Studio I can again see there is a change waiting to be committed and if I click on the name of the file I can open the diff tool to see what the change was&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-68.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Once I am happy with my change I can commit it again in the same way as before either in the editor or at the command line. The icon at the bottom will change to show that I have one commit in my &lt;em>local&lt;/em> repository waiting to be pushed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-69.png?fit=630%2C160&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>To do the same thing at the command line I can type &lt;code>git status&lt;/code> and see the same thing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-70.png?fit=630%2C138&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can then push my change to my remote repository either in the GUI or by using &lt;code>git push&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-72.png?fit=630%2C213&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will automatically be added to the Pull Request as you can see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-73.png?fit=630%2C480&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now that the required changes for the review have been made, the review has been approved by Shane and the pull request is now ready to be merged. (You can also see that dbachecks runs some checks against the code when a Pull Request is made)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-74.png?resize=630%2C359&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Many, many thanks to Shane &lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>t&lt;/a> who helped with the writing of this post even whilst on a â€œno techâ€ holiday.&lt;/p>
&lt;h2 id="go-ahead--contribute-to-an-open-source-project">Go Ahead â€“ Contribute to an Open Source Project&lt;/h2>
&lt;p>Hopefully you can now see how easy it is to create a fork of a GitHub repository, clone it to your own machine and contribute. There are many open source projects that you can contribute to.&lt;/p>
&lt;p>You can use this process to contribute to the Microsoft Docs for example by clicking on the edit button on any page.&lt;/p>
&lt;p>You can contribute other open source projects like&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/PowerShell/PowerShell" target="_blank" rel="noopener"
>PowerShell&lt;/a>&lt;/strong> by Microsoft&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/tigertoolbox" target="_blank" rel="noopener"
>tigertoolbox&lt;/a>&lt;/strong> by Microsoft Tiger Team&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/PSDatabaseClone" target="_blank" rel="noopener"
>PSDatabaseClone&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/OpenQueryStore/OpenQueryStore" target="_blank" rel="noopener"
>OpenQueryStore&lt;/a>&lt;/strong> by William Durkin and Enrico van de Laar&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/marcingminski/sqlwatch" target="_blank" rel="noopener"
>sqlwatch&lt;/a>&lt;/strong> by Marcin Gminski&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/red-gate/SQLCop" target="_blank" rel="noopener"
>SQLCop&lt;/a> by Redgate&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/amachanic/sp_whoisactive" target="_blank" rel="noopener"
>sp_whoisactive&lt;/a>&lt;/strong> by Adam Machanic&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/olahallengren/sql-server-maintenance-solution" target="_blank" rel="noopener"
>sql-server-maintenance-solution&lt;/a>&lt;/strong> by Ola Hallengren&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit" target="_blank" rel="noopener"
>SQL-Server-First-Responder-Kit&lt;/a>&lt;/strong> by Brent Ozar Unlimited&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>ReportingServicesTools&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>or go and find the the ones that you use and can help with.&lt;/p></description></item><item><title>Create a PowerShell Notebook for Azure Data Studio with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</link><pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</guid><description>&lt;p>The latest update to the ADSNotebook PowerShell module &lt;a class="link" href="https://blog.robsewell.com/create-azure-data-studio-sql-notebooks-with-powershell/" target="_blank" rel="noopener"
>I blogged about here&lt;/a> now enables the creation of PowerShell notebooks with PowerShell.&lt;/p>
&lt;p>You can install the module with&lt;/p>
&lt;pre>&lt;code>Install-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>or if you have already installed it you can use&lt;/p>
&lt;pre>&lt;code>Update-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>In the latest release, there is an extra parameter for &lt;code>New-AdsWorkBook&lt;/code> of &lt;code>-Type&lt;/code> which will accept either SQL or PowerShell&lt;/p>
&lt;h2 id="create-a-powershell-notebook-with-powershell-rob">Create a PowerShell Notebook with PowerShell Rob&lt;/h2>
&lt;p>OK!&lt;/p>
&lt;p>Here is some code to create a PowerShell Notebook. First we will create some cells using &lt;code>New-AdsWorkBookCell&lt;/code> including all the markdown to add images and links. You can find my notebooks which explain how to write the markdown for your notebooks in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/2019/PASS%20Summit/SQL%20Notebooks%20in%20Azure%20Data%20Studio%20for%20the%20DBA" target="_blank" rel="noopener"
>GitHub Presentations Repository&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then we will create a new workbook using those cells&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then, when that code is run we can open the Notebook and ta-da&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?fit=630%2C505&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>And it is super quick to run as well&lt;/p>
&lt;p>UPDATE â€“ Tyler Leonhardt &lt;a class="link" href="https://twitter.com/TylerLeonhardt" target="_blank" rel="noopener"
>t&lt;/a> from the PowerShell team asked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-36.png?resize=597%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Challenge accepted, with extra meta, here is the PowerShell to create a PowerShell Notebook which will create a PowerShell Notebook!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item><item><title>My current VS Code Extensions and using a workspace file</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-26.png" alt="Featured image of post My current VS Code Extensions and using a workspace file" />&lt;p>I have been asked a couple of times recently what my Visual Studio Code extensions are at the moment so I thought I would write a quick post and also look at workspaces and how you can enable and disable extensions within them&lt;/p>
&lt;h2 id="listing-extensions">Listing Extensions&lt;/h2>
&lt;p>From the command line you can list your extensions using&lt;/p>
&lt;pre>&lt;code>code --list-extensions
code-insiders --list-extensions
&lt;/code>&lt;/pre>
&lt;p>My list looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can also see them in the view on the left of default Visual Studio Code and open them with CTRL + SHIFT + X (unless like me you have Snagit installed and it has taken that shortcut&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-31.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-extensions">Installing Extensions&lt;/h2>
&lt;p>You can install extensions by opening the Extensions view in Visual Studio Code and searching for the extension. The list I have below has the precise names for each extension which you can use to search&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-24.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also install extensions from the command-line with&lt;/p>
&lt;pre>&lt;code>code --install-extension &amp;lt;extensionid&amp;gt;
code-insiders --install-extension &amp;lt;extensionid&amp;gt;
&lt;/code>&lt;/pre>
&lt;h2 id="my-extensions">My Extensions&lt;/h2>
&lt;p>I am going to list these in alphabetical order by display name for ease (my ease that is!)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Because Chrissy LeMaire and I are writing &lt;a class="link" href="https://beard.media/book" target="_blank" rel="noopener"
>dbatools in a Month of Lunches&lt;/a> using AsciiDoc, it makes sense to have an extension enabling previewing and syntax, you can find it &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=stayfool.vscode-asciidoc" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure I use the Azure Account Extension â€“ ms-vscode.azure-account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>I use Azure CLI so I make use of the functionality of the Azure CLI Tools extension ms-vscode.azurecli&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure Repos I use the ms-vsts.team extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>When creating ARM templates, this extension is very useful msazurermtools.azurerm-vscode-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I have a few theme extensions, this one is for fun in demos ðŸ˜‰ beardedbear.beardedtheme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The blackboard theme is my default one gerane.theme-blackboard&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Chasing closing brackets is much easier with the Bracket Pair Colorizer, I use the beta version coenraads.bracket-pair-colorizer-2&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>I am rubbish at spelling and typing so I use this to help point out the issues! streetsidesoftware.code-spell-checker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>Using the Docker extension adds another view to Visual Studio Code to ease working with containers ms-azuretools.vscode-docker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>As an open-source project maintainer it is good to be able to work with GitHub pull requests without leaving Visual Studio Code github.vscode-pull-request-github_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>GitLens is absolutely invaluable when working with source control. It has so many features. This is an absolute must eamodio.gitlens&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Working with Kubernetes? This extension adds another view for interacting with your cluster ms-kubernetes-tools.vscode-kubernetes-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>Visual Studio Live Share enables you to collaborate in real-time in Visual Studio Code with your colleagues or friends. I blogged about this &lt;a class="link" href="https://blog.robsewell.com/visual-studio-code-live-sharing-set-up/" target="_blank" rel="noopener"
>here&lt;/a> ms-vsliveshare.vsliveshare&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I love writing markdown and this linter assists me to ensure that my markdown is correct davidanson.vscode-markdownlint&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>The Material Icon Theme ensures that there are pretty icons in my editor! pkief.material-icon-theme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I have both the PowerShell extension ms-vscode.powershell and the PowerShell preview extension ms-vscode.powershell-preview installed but only one can be enabled at a time&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>This suite of extensions enables easy remote development so that you can develop your PowerShell scripts, for example, inside a ubuntu container running PowerShell 7 or inside Windows Subsystem for LInux ms-vscode-remote.vscode-remote-extensionpack_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-20.png"
loading="lazy"
>&lt;/p>
&lt;p>Writing for cross-platform means looking out for line endings and this extension will display them and any whitespace in your editor medo64.render-crlf&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-21.png"
loading="lazy"
>&lt;/p>
&lt;p>An absolutely essential extension which enables me to backup all of my Visual Studio Code settings, shortcuts, extensions into a GitHub gist and keep all of my machines feeling the same. shan.code-settings-sync&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-22.png"
loading="lazy"
>&lt;/p>
&lt;p>For working with SQL Server within Visual Studio Code and having a view for my instances as well as a linter and intellisense I use ms-mssql.mssql&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-23.png"
loading="lazy"
>&lt;/p>
&lt;p>Yaml files and spaces! I no longer get so confused with this extension to help me ðŸ™‚ redhat.vscode-yaml&lt;/p>
&lt;h2 id="workspaces">Workspaces&lt;/h2>
&lt;p>Now that is a lot of extensions and I dont need all of them everytime. I use workspaces to help with this. I will create a workspace file for the project I am working on.&lt;/p>
&lt;p>I open or create the folders I will be working on and then click File and Save Workspace As and save the file in the root of the folder.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-25.png"
loading="lazy"
>&lt;/p>
&lt;p>Now, the next time I want to open the workspace, I can open the workspace file or if I open the folder Visual Studio Code will helpfully prompt me&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-26.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can have all of my settings retained for that workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-27.png"
loading="lazy"
>&lt;/p>
&lt;p>For this folder, I am ensuring that the PowerShell extension uses the PSScriptAnalyzer Settings file that I have created so that it will show if the code is compatible with the versions of PowerShell I have chosen. I can define settings for a workspace in the settings file, which you can open using CTRL and ,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-28.png"
loading="lazy"
>&lt;/p>
&lt;p>But I can also enable or disable extensions for a workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-29.png"
loading="lazy"
>&lt;/p>
&lt;p>So everytime I open this workspace I am only loading the extensions I want&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-30.png"
loading="lazy"
>&lt;/p></description></item><item><title>PowerShell Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-8.png" alt="Featured image of post PowerShell Notebooks in Azure Data Studio" />&lt;p>The latest release of the &lt;a class="link" href="https://github.com/microsoft/azuredatastudio#try-out-the-latest-insiders-build-from-master" target="_blank" rel="noopener"
>insiders edition of Azure Data Studio&lt;/a> brings the first edition of PowerShell Notebooks!&lt;/p>
&lt;p>You can download the latest insiders edition from the link above, it can be installed alongside the stable release.&lt;/p>
&lt;p>To access many of the commands available use F1 to open the command palette (like many of my tips this also works in Visual Studio Code). You can then start typing to get the command that you want.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>You can then hit enter with the command that you want highlighted, use the mouse or use the shortcut which is displayed to the right.&lt;/p>
&lt;p>In a new notebook, you can click the drop down next to kernel and now you can see that PowerShell is available&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>When you choose the PowerShell kernel, you will get a prompt asking you to configure the Python installation&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>If you have Python already installed you can browse to the location that it is installed or you can install Python. In the bottom pane you will be able to see the progress of the installation.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>When it has completed, you will see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>You may also get a prompt asking if you would like to upgrade some packages&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>Again this will be displayed in the tasks pane&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-14.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="addingpowershell">&lt;strong>AddingÂ PowerShell&lt;/strong>&lt;/h2>
&lt;p>ToÂ addÂ PowerShellÂ CodeÂ toÂ theÂ notebookÂ clickÂ theÂ CodeÂ buttonÂ atÂ theÂ top of the file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>orÂ theÂ oneÂ youÂ canÂ findÂ byÂ highlightingÂ aboveÂ orÂ belowÂ aÂ block&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I did not have intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block.&lt;/p>
&lt;p>Interestingly Shawn Melton ( &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>t&lt;/a> ) did&lt;/p>
&lt;blockquote>
&lt;p>Curious, you state &amp;ldquo;There is not any intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block&amp;rdquo;â€¦&lt;/p>
&lt;p>It works flawlessly for me on Windows. &lt;a class="link" href="https://t.co/Lx6fGH9F5L" target="_blank" rel="noopener"
>pic.twitter.com/Lx6fGH9F5L&lt;/a>&lt;/p>
&lt;p>â€” Shawn Melton (@wsmelton) &lt;a class="link" href="https://twitter.com/wsmelton/status/1184819132598013952?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>October 17, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This was because he had the PowerShell extension installed and I did not (I know !!)&lt;br>
If you find you dont have intellisense then install the PowerShell extension!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the play button (which is only visible when you hover the mouse over it) will run the code&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can clear the results from every code block using the clear results button at the top&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>Otherwise, you can save the results with the Notebook by saving it. This is the part that is missing from running PowerShell in the Markdown blocks in a &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>SQL Notebook as I described here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>I am looking forward to how this develops. You can find my sample PowerShell notebook (with the code results) &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/powershell.ipynb" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p></description></item><item><title>Getting SQL Server installation date with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-7.png" alt="Featured image of post Getting SQL Server installation date with PowerShell using dbatools" />&lt;p>Most of my writing time at the moment is devoted to Â &lt;em>&lt;a class="link" href="https://dbatools.io/book" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> which is now available but here is a short post following a question someone asked me.&lt;/p>
&lt;h2 id="how-can-i-get-the-installation-date-for-sql-server-on-my-estate-into-a-database-with-dbatools-">How can I get the Installation Date for SQL Server on my estate into a database with dbatools ?&lt;/h2>
&lt;p>You can get the date that SQL Server was installed using the creation date of the NT Authority\System login using T-SQL&lt;/p>
&lt;pre>&lt;code>SELECT create_date
FROM sys.server_principals
WHERE sid = 0x010100000000000512000000
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="with-dbatools">With dbatools&lt;/h2>
&lt;p>To do this with dbatools you can use the command &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaInstanceInstallDate" target="_blank" rel="noopener"
>Get-DbaInstanceInstallDate&lt;/a> command&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-1.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="more-than-one-instance">More than one instance&lt;/h2>
&lt;p>If we want to get the installation date for more than one instance we can simply create an array of instances for the SqlInstance parameter&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE
&lt;/code>&lt;/pre>
&lt;h2 id="get-the-windows-installation-date-too">Get the Windows installation date too&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also get the windows installation date with the IncludeWindows switch&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE -IncludeWindows
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-3.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="gather-your-instances">Gather your instances&lt;/h2>
&lt;p>How you get the instances in your estate is going to be different per reader but here is an example using Registered Servers from my local registered servers list, you can also use a Central Management Server&lt;/p>
&lt;pre>&lt;code>Get-DbaRegisteredServer -Group local
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>So we can gather those instances into a variable and pass that to Get-DbaInstanceInstallDate&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-to-database">Add to database&lt;/h2>
&lt;p>To add the results of any PowerShell command to a database, you can pipe the results to &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDbTableData" target="_blank" rel="noopener"
>Write-DbaDbTableData&lt;/a>&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
$writeDbaDataTableSplat = @{
SqlInstance = 'localhost'
Table = 'InstallDate'
Database = 'tempdb'
Schema = 'dbo'
AutoCreateTable = $true
}
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances | Write-DbaDataTable @writeDbaDataTableSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>This will create a table called InstallDate and put the results of the Get-DbaInstanceInstallDate command. Note â€“ If you want to try this code, I would advise using a different database than tempdb!!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>It is important to note that the table created may not have the most optimal data types and that you may want to pre-create the table.&lt;/p>
&lt;p>So there you go, all the installation dates for your estate in a database table. Hope that helps you Jonny.&lt;/p></description></item><item><title>MEAP MEAP â€“ #dbatoolsMoL â€“ Live Book edition</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</link><pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</guid><description>&lt;p>Itâ€™s been a busy time!&lt;/p>
&lt;p>As well as many other things, the fantastical &lt;a class="link" href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life" target="_blank" rel="noopener"
>BDFL&lt;/a> of &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> Chrissy LemaireÂ &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a> and myself have written enough of a chunk ofÂ &lt;em>&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> that our publisherÂ &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Manning Publications&lt;/a> have agreed to release it as a MEAP. Not a text book, this book is written in a fun conversational style and split up into chapters that you can read in a lunch-time.&lt;/p>
&lt;p>It is impossible for me to hear MEAP and not think of this ðŸ™‚&lt;/p>
&lt;p>&lt;a class="link" href="https://tenor.com/view/hungry-coyote-looney-tunes-gif-5063446" target="_blank" rel="noopener"
>Roadrunner Speeding GIF&lt;/a> from &lt;a class="link" href="https://tenor.com/search/hungry-gifs" target="_blank" rel="noopener"
>Hungry GIFs&lt;/a>&lt;/p>
&lt;p>but I expect you are wondering what a MEAP is?&lt;/p>
&lt;blockquote>
&lt;p>What is MEAP?&lt;br>
A book can take a year or more to write, so how do you learn that hot new technology today? The answer is MEAP, the Manning Early Access Program. In MEAP, you read a book chapter-by-chapter while itâ€™s being written and get the final eBook as soon as itâ€™s finished. If you pre-order the pBook, youâ€™ll get it long before itâ€™s available in stores.&lt;/p>
&lt;p>&lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>https://www.manning.com/meap-program&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Basically, to make it easy to get and for those that like to get in early, you can order the book and get the first 4 chapters (three in reality) RIGHT NOW!! (It also means that Chrissy and I have to write the rest of book â€“ dang still going to be busy!)&lt;/p>
&lt;p>Simply head over to &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a> and use the code mlsewell and you can get access to the book too.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/08/meap.png"
loading="lazy"
>](&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a>)&lt;/p>
&lt;p>This will also give you access to the live book.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/livebook.png"
loading="lazy"
>&lt;/p>
&lt;p>live book&lt;/p>
&lt;p>The live book is fantastic, you can read the whole book from within your browser. See the three icons that appear to the right of the book?&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/stuffage.png"
loading="lazy"
>&lt;/p>
&lt;p>3 little icons (no porridge)&lt;/p>
&lt;p>The left hand one enables you to bookmark an important part so that you can come back to it easily using the bookmarks link in the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/bookmark.png"
loading="lazy"
>&lt;/p>
&lt;p>bookmarks&lt;/p>
&lt;p>The middle icon enables you to write notes for yourself, maybe ways that you can use the information or maybe comments about an awesome Italian.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/satori.png"
loading="lazy"
>&lt;/p>
&lt;p>Shoes&lt;/p>
&lt;p>The last one is the way that you can make comments and engage us , the authors in conversation, ask questions, request clarification or wonder about Dutch data manglers&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/sander.png"
loading="lazy"
>&lt;/p>
&lt;p>I think its down to PII&lt;/p>
&lt;p>If you select a piece of text, another menu opens up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlight.png"
loading="lazy"
>&lt;/p>
&lt;p>The first icon lets you highlight the text, to make it easier to find later&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlightyellow.png"
loading="lazy"
>&lt;/p>
&lt;p>Hover over the highlight and you can choose different colours for different things.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/image.png"
loading="lazy"
>&lt;/p>
&lt;p>or even create pretty pictures for Mathias&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/pretty.png"
loading="lazy"
>&lt;/p>
&lt;p>Mathias â€“ Why isnâ€™t he an MVP?&lt;/p>
&lt;p>You can choose to annotate, which is sort of like highlighting and writing a note with the next icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/other-users.png"
loading="lazy"
>&lt;/p>
&lt;p>When you want to share a link to a particular part of the book with someone else, you can highlight part of it and click the link icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/linkylinky.png"
loading="lazy"
>&lt;/p>
&lt;p>Itâ€™s easy to start PowerShell as another user as long as you remember when to press SHIFT&lt;/p>
&lt;p>Which will highlight the paragraph and open a dialogue at the bottom where you can create and copy the link.&lt;/p>
&lt;p>By far the most important part for Chrissy and I is the last link. When you find something wrong you can mark it for our attention. Yes, even with Chrissy and I proof reading each others words, the fabulous proof reader ClÃ¡udio Silva (&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a>Â |Â &lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>t&lt;/a>)Â and awesome tech editor Mike Shepard (&lt;a class="link" href="https://powershellstation.com/" target="_blank" rel="noopener"
>b&lt;/a>Â |Â &lt;a class="link" href="https://twitter.com/MikeShepard70" target="_blank" rel="noopener"
>t&lt;/a>)Â  as well as many community reviewers there are still, and will continue to be, issues. So when you find them, highlight them and click the right hand most link&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/withwith.png"
loading="lazy"
>&lt;/p>
&lt;p>with with more more than than one one&lt;/p>
&lt;p>This will open up as shown so that you can fill in what was wrong (Please donâ€™t report this error again Shane &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>t&lt;/a> has beaten you to it!)&lt;/p>
&lt;p>You will have noticed on social media and elsewhere that we have left some easter eggs in the book&lt;/p>
&lt;blockquote>
&lt;p>Yup, we have some easter eggs in &lt;a class="link" href="https://twitter.com/hashtag/dbatoolsMol?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatoolsMol&lt;/a>&lt;/p>
&lt;p>We hope you enjoy them &lt;a class="link" href="https://t.co/iZa3u8iLPC" target="_blank" rel="noopener"
>https://t.co/iZa3u8iLPC&lt;/a>&lt;/p>
&lt;p>â€” Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1167116661503266819?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>August 29, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you find them or whenever you want to talk about the book on social media, please use the hashtag #dbatoolsMoL â€“ you never know what goodies may end up in your inbox.&lt;/p>
&lt;p>Oh and if you have got this far and donâ€™t know what dbatools in a Month of Lunches is, listen to the hair and read more &lt;a class="link" href="https://dbatools.io/meap/" target="_blank" rel="noopener"
>https://dbatools.io/meap/&lt;/a>&lt;/p></description></item><item><title>PowerShell in SQL Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</link><pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/07/image-4.png" alt="Featured image of post PowerShell in SQL Notebooks in Azure Data Studio" />&lt;p>I have done a lot of writing in the last few months but you see no blog posts! My wonderful friend Chrissy and I are writing â€œdbatools in a Month of Lunchesâ€ to be published by Manning. That has taken up a lot of my writing mojo. We have hit a little break whilst we have some reviews done ready for the &lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>MEAP&lt;/a> (For everyone who asks, the answer is the unfulfilling â€˜soonâ€™) so itâ€™s time for a blog post!&lt;/p>
&lt;h2 id="sql-notebooks-are-cool">SQL Notebooks are cool&lt;/h2>
&lt;p>I have had a lot of fun with SQL Notebooks recently. I have presented a session about them at a couple of events this month &lt;a class="link" href="http://datagrillen.com" target="_blank" rel="noopener"
>DataGrillen&lt;/a> and SQL Saturday Cork. Here is a little snippet&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/hashtag/dbatools?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatools&lt;/a> in PowerShell in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> SQL Notebooks for creating the containers and restoring the &lt;a class="link" href="https://twitter.com/hashtag/dbachecks?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbachecks&lt;/a> historical database for running queries in ðŸ™‚&lt;br>
Getting ready for presentation for &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/wiQ41bblQV" target="_blank" rel="noopener"
>pic.twitter.com/wiQ41bblQV&lt;/a>&lt;/p>
&lt;p>â€” Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1130871277449875456?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 21, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Yes, you can run PowerShell in a SQL Notebook in Azure Data Studio just by clicking a link in the markdown cell. This opens up a lot of excellent possibilities.&lt;/p>
&lt;p>I have had several discussions about how SQL Notebooks can be used by SQL DBAs within their normal everyday roles. (Mainly because I donâ€™t really understand what the sorcerers of data science do with notebooks!). I have helped clients to look at some of their processes and use SQL Notebooks to help with them. Creating Disaster Recovery or Change Run-books or Incident Response Templates or using them for product demonstrations. Of course, I needed to use PowerShell in that ðŸ™‚&lt;/p>
&lt;p>I have really enjoyed working out how to run PowerShell in the markdown in a SQL Notebook in Azure Data Studio and I think &lt;a class="link" href="http://www.centinosystems.com/blog/author/aencentinosystems-com/" target="_blank" rel="noopener"
>Anthony the kubernetes magician&lt;/a> did too!&lt;/p>
&lt;blockquote>
&lt;p>I think &lt;a class="link" href="https://twitter.com/sqldbawithbeard?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@sqldbawithbeard&lt;/a> is an actual wizard! You should see the things he can do with &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/KMeZR3CrPK" target="_blank" rel="noopener"
>pic.twitter.com/KMeZR3CrPK&lt;/a>&lt;/p>
&lt;p>â€” Anthony E. Nocentino (@nocentino) &lt;a class="link" href="https://twitter.com/nocentino/status/1141709511700467712?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>June 20, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>OK enough magic puns lets talk about PowerShell in SQL Notebooks. You can read about &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>how to create a SQL Notebook and run T-SQL queries here&lt;/a>, (you no longer need the Insider Edition by the way)&lt;/p>
&lt;h2 id="powershell-in-markdown">PowerShell in Markdown!&lt;/h2>
&lt;p>First, before I go any further, I must say this. I was at the European PowerShell Conference when I was working this out and creating my sessions and I said the words&lt;/p>
&lt;blockquote>
&lt;p>â€œCool, I can click a link and run PowerShell, this is neatâ€&lt;/p>
&lt;p>A Beardy fellow in Hannover&lt;/p>
&lt;/blockquote>
&lt;p>This stopped some red team friends of mine in their tracks and they said â€œShow meâ€. One of them was rubbing their hands with glee! You can imagine the sort of wicked, devious things that they were immediately considering doing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes, itâ€™s funny but also it carries a serious warning. Without understanding what it is doing, please donâ€™t enable PowerShell to be run in a SQL Notebook that someone sent you in an email or you find on a GitHub. In the same way as you donâ€™t open the word document attachment which will get a thousand million trillion europounddollars into your bank account or run code you copy from the internet on production without understanding what it does, this could be a very dangerous thing to do.&lt;/p>
&lt;p>With that warning out of the way, there are loads of really useful and fantastic use cases for this. SQL Notebooks make great run-books or incident response recorders and PowerShell is an obvious tool for this. (If only we could save the PowerShell output in a SQL Notebook, this would be even better)&lt;/p>
&lt;h2 id="how-on-earth-did-you-work-this-out">How on earth did you work this out?&lt;/h2>
&lt;p>Someone asked me how I worked it out. I didnâ€™t! It began with Vicky Harp PM lead for the SQL Tools team at Microsoft&lt;/p>
&lt;blockquote>
&lt;p>Did you know you can add markdown links to open a terminal and paste in a command in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> notebooks? &lt;a class="link" href="https://t.co/YHX9pIVQco" target="_blank" rel="noopener"
>pic.twitter.com/YHX9pIVQco&lt;/a>&lt;/p>
&lt;p>â€” Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1128359827128950784?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 14, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I then went and looked at &lt;a class="link" href="https://twitter.com/kevcunnane" target="_blank" rel="noopener"
>Kevin Cunnane&lt;/a>â€˜s notebook. Kevin is a member of the tools team working on Azure Data Studio. With SQL Notebooks, you can double click the markdown cell and see the code that is behind it. To understand how it is working, lets deviate a little.&lt;/p>
&lt;h2 id="keyboard-shortcuts">Keyboard Shortcuts&lt;/h2>
&lt;p>IF you click the cog at the bottom left of Azure Data Studio and choose Keyboard Shortcuts&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image.png"
loading="lazy"
>&lt;/p>
&lt;p>you can make Azure Data Studio (and Visual Studio Code) work exactly how you want it to. Typing in the top box will find a command and you can then set the shortcuts that you want to use to save yourself time.&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1" target="_blank" rel="noopener"
>https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This also enables you to see the command that is called when you use a keyboard shortcut. For example, you can see that for the focus terminal command it says &lt;code>workbench.action.terminal.focus&lt;/code>.&lt;/p>
&lt;p>It turns out that you can call this as a link in a Markdown document using HTML with &lt;code>&amp;lt;a href=&amp;quot;&amp;quot;&amp;gt;&lt;/code> and adding &lt;code>command:&lt;/code> prior to the command text. When the link is clicked the command will run. Cool ðŸ™‚&lt;/p>
&lt;p>For this to be able to work (you read the warning above?) you need to set the Notebook to be trusted by clicking this button.&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1" target="_blank" rel="noopener"
>https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This will allow any command to be run. Of course, people with beards will helpfully advise when this is required for a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/05%20-Working%20with%20dbachecks%20Validation%20Results.ipynb" target="_blank" rel="noopener"
>SQL Notebook&lt;/a>. (Safe to say people attempting nefarious actions will try the same with your users)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Now that we know how to run an Azure Data Studio command using a link in a markdown cell the next step is to run a PowerShell command. I headed to the &lt;a class="link" href="https://code.visualstudio.com/docs/editor/integrated-terminal" target="_blank" rel="noopener"
>Visual Studio Code documentation&lt;/a> and found&lt;/p>
&lt;blockquote>
&lt;p>Send text from a keybinding&lt;br>
TheÂ &lt;code>workbench.action.terminal.sendSequence&lt;/code>Â command can be used to send a specific sequence of text to the terminal, including escape sequence&lt;/p>
&lt;/blockquote>
&lt;p>Thatâ€™s the command we need, however, we still need to craft the command so that it will work as a link. It needs to be converted into a URL.&lt;/p>
&lt;p>I started by using this websiteÂ &lt;a class="link" href="https://www.url-encode-decode.com/" target="_blank" rel="noopener"
>https://www.url-encode-decode.com/&lt;/a>Â to do this. This isÂ &lt;strong>how you can check the code in other peoples notebook, use the decode capability.&lt;/strong>&lt;/p>
&lt;p>Encoding &lt;code>Set-Location C:\dbachecks&lt;/code> gives `Set-Location+C%3A%5Cdbacheck``&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59567164-e5044300-9061-11e9-802b-7b28c3aee345.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can just put that code into the href link and bingo!&lt;/p>
&lt;p>If only it was that easy!!&lt;/p>
&lt;h2 id="some-replacing-is-required">Some Replacing is required&lt;/h2>
&lt;p>The + needs to be replaced with a space or &lt;code>%20&lt;/code>&lt;/p>
&lt;p>You also need to double the &lt;code>\&lt;/code> and replace the &lt;code>%3A&lt;/code> with a &lt;code>:&lt;/code>&lt;br>
The &lt;code>&amp;quot;&lt;/code> needs to be replaced with &lt;code>\u022&lt;/code>, the &lt;code>'&lt;/code> with &lt;code>\u027&lt;/code>, the curly braces wonâ€™t work unless you remove the &lt;code>%0D%0A&lt;/code>. Got all that? Good!&lt;/p>
&lt;p>Once you have written your PowerShell, encoded it, performed the replacements, you addÂ &lt;code>\u000D&lt;/code>Â at the end of the code to pass an enter to run the code and then place all of that into a link like this&lt;/p>
&lt;p>&lt;code>&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 PLACE THE ENCODED CODE HERE %22%7D&amp;quot;&amp;gt;Link Text&amp;lt;/a&amp;gt;&lt;/code>&lt;/p>
&lt;p>This means that if you want to add the PowerShell code to set a location and then list the files and folders in that location to a Markdown cell using PowerShell like this&lt;/p>
&lt;pre>&lt;code>Set-Location C:\dbachecks
Get-ChildItem
&lt;/code>&lt;/pre>
&lt;p>You would end up with a link like this&lt;/p>
&lt;p>&lt;code>`&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 Set-Location C:%5C%5Cdbachecks \u000D Get-ChildItem \u000D %22%7D&amp;quot;&amp;gt;Set Location and list files&amp;lt;/a`&lt;/code>&amp;gt;&lt;/p>
&lt;h2 id="doing-something-more-than-once">Doing something more than once?&lt;/h2>
&lt;p>I donâ€™t want to remember that all of the time so I wrote a PowerShell function. You can find it on GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1&lt;/a>&lt;/p>
&lt;p>This will take a PowerShell command and turn it into a link that will work in an Azure Data Studio markdown. Itâ€™s not magic, itâ€™s PowerShell. There is a â€“&lt;code>ToClipboard&lt;/code> parameter which will copy the code to the clipboard ready for you to paste into the cell (On Windows machines only)&lt;/p>
&lt;h2 id="giants">Giants&lt;/h2>
&lt;p>There are many uses for this but hereâ€™s one I think is cool.&lt;/p>
&lt;p>The link below will go to a notebook, which will show how you the giants upon whose shoulders I stand&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/GlennAlanBerry" target="_blank" rel="noopener"
>Glenn Berry&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>AndrÃ©&lt;/a> &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Kamman&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/spaghettidba" target="_blank" rel="noopener"
>Gianluca Sartori&lt;/a>&lt;/p>
&lt;p>have enabled me to create a SQL Notebook with a link which will run some PowerShell to create a SQL Notebook which will have all of the Diagnostic Queries in it.&lt;/p>
&lt;p>You could possibly use something like it for your incident response SQL Notebook.&lt;/p>
&lt;p>Itâ€™s also cool that GitHub renders the notebook in a browser (You canâ€™t run PowerShell or T-SQL from there though, you need Azure Data Studio!)&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-4.png"
loading="lazy"
>&lt;/p></description></item><item><title>Azure SQL Linux VM â€“ configuring SQL, installing pwsh and connecting and interacting with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</link><pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-125.png" alt="Featured image of post Azure SQL Linux VM â€“ configuring SQL, installing pwsh and connecting and interacting with dbatools" />&lt;p>In my posts about using Azure Devops to build Azure resources with Terraform, &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>I built a Linux SQL VM.&lt;/a> I used the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>Terraform in this GitHub&lt;/a> repository and created this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-mobaxterm">Connecting with MobaXterm&lt;/h2>
&lt;p>I had set the Network security rules to accept connections only from my static IP using variables in the Build Pipeline. I use &lt;a class="link" href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener"
>MobaXterm&lt;/a> as my SSH client. Its a free download. I click on sessions&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-120.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose a SSH session and fill in the remote host address from the portal&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-121.png"
loading="lazy"
>&lt;/p>
&lt;p>fill in the password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-122.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="configuring-sql">Configuring SQL&lt;/h2>
&lt;p>The next task is to configure the SQL installation. Following the instructions on the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sql/provision-sql-server-linux-virtual-machine?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft docs site&lt;/a> I run&lt;/p>
&lt;pre>&lt;code>sudo systemctl stop mssql-server
sudo /opt/mssql/bin/mssql-conf set-sa-password
&lt;/code>&lt;/pre>
&lt;p>enter the sa password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-123.png"
loading="lazy"
>&lt;/p>
&lt;p>Now to start SQL&lt;/p>
&lt;pre>&lt;code>sudo systemctl start mssql-server
&lt;/code>&lt;/pre>
&lt;h2 id="installing-pwsh">Installing pwsh&lt;/h2>
&lt;p>Installing PowerShell Core (pwsh) is easy with snap&lt;/p>
&lt;p>sudo snap install powershell &amp;ndash;classic&lt;/p>
&lt;p>A couple of minutes of downloads and install&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-124.png"
loading="lazy"
>&lt;/p>
&lt;p>and pwsh is ready for use&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-125.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-dbatools">Installing dbatools&lt;/h2>
&lt;p>To install &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbatools" target="_blank" rel="noopener"
>Powershell Gallery&lt;/a> simply run&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser&lt;/p>
&lt;p>This will prompt you to allow installing from an untrusted repository&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-126.png"
loading="lazy"
>&lt;/p>
&lt;p>and dbatools is ready to go&lt;/p>
&lt;pre>&lt;code>#Set a credential
$cred = Get-Credential
# Show the databases on the local instance
Get-DbaDatabase -SqlInstance localhost -SqlCredential $cred
&lt;/code>&lt;/pre>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-127.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-azure-data-studio">Connecting with Azure Data Studio&lt;/h2>
&lt;p>I can also connect with Azure Data Studio&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-128.png"
loading="lazy"
>&lt;/p>
&lt;p>and connect&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/p>
&lt;p>Just a quick little post explaining what I did ðŸ™‚&lt;/p>
&lt;p>Happy Linuxing!&lt;/p></description></item><item><title>Generating a Workload against AdventureWorks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</link><pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-51.png" alt="Featured image of post Generating a Workload against AdventureWorks with PowerShell" />&lt;p>For a later blog post I have been trying to generate some workload against an AdventureWorks database.&lt;/p>
&lt;p>I found this excellent blog post by Pieter Vanhove &lt;a class="link" href="https://twitter.com/Pieter_Vanhove" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/&lt;/a> which references this 2011 post by Jonathan Kehayias &lt;a class="link" href="https://twitter.com/SQLPoolBoy" target="_blank" rel="noopener"
>t&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/" target="_blank" rel="noopener"
>https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/&lt;/a>&lt;/p>
&lt;p>Both of these run a random query in a single thread so I thought I would use &lt;a class="link" href="https://www.powershellgallery.com/packages/PoshRSJob/1.7.4.4" target="_blank" rel="noopener"
>PoshRSJob&lt;/a> by Boe Prox &lt;a class="link" href="https://learn-powershell.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>t&lt;/a> to run multiple queries at the same time ðŸ™‚&lt;/p>
&lt;p>To install PoshRSJob, like with any PowerShell module, you run&lt;/p>
&lt;pre>&lt;code>Install-Module -Name PoshRSJob
&lt;/code>&lt;/pre>
&lt;p>I downloaded AdventureWorksBOLWorkload zip from Pieters blog post and extracted to my &lt;code>C:\temp folder&lt;/code>. I created a &lt;code>Invoke-RandomWorkload&lt;/code> function which you can get from my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions" target="_blank" rel="noopener"
>functions repository in GitHub&lt;/a>. The guts of the function are&lt;/p>
&lt;pre>&lt;code> 1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
&lt;/code>&lt;/pre>
&lt;p>which will created $NumberOfJobs jobs and then run $Throttle number of jobs in the background until they have all completed. Each job will run a random query from the query file using Invoke-SqlCmd. Why did I use Invoke-SqlCmd and not Invoke-DbaQuery from dbatools? dbatools creates runspaces in the background to help with logging and creating runspaces inside background jobs causes errors&lt;/p>
&lt;p>Then I can run the function with&lt;/p>
&lt;pre>&lt;code>Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?resize=630%2C256&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and create a random workload. Creating lots of background jobs takes resources so when I wanted to run a longer workload I created a loop.&lt;/p>
&lt;pre>&lt;code>$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
&lt;/code>&lt;/pre>
&lt;p>You can get the function here. The full code is below&lt;/p>
&lt;pre>&lt;code># With thanks to Jonathan Kehayias and Pieter Vanhove
&amp;lt;#
.SYNOPSIS
Runs a random workload against a database using a sql file
.DESCRIPTION
Runs a random workload against a database using PoshRSJobs to create parallel jobs to run random
queries from a T-SQL file by default it uses the AdventureWorksBOLWorkload.sql from Pieter Vanhove
.PARAMETER SqlInstance
The SQL instance to run the queries against
.PARAMETER SqlCredential
The SQL Credential for the Instance if required
.PARAMETER Database
The name of the database to run the queries against
.PARAMETER NumberOfJobs
The number of jobs to create - default 10
.PARAMETER Delay
The delay in seconds for the output for the running jobs - default 10
.PARAMETER Throttle
The number of parallel jobs to run at a time - default 5
.PARAMETER PathToScript
The path to the T-SQL script holding the queries - default 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql'
.PARAMETER Delimiter
The delimiter in the T-SQL Script between the queries - default ------
.PARAMETER ShowOutput
Shows the output from the jobs
.EXAMPLE
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 100 -Delay 10 -Throttle 10
Runs 100 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23
.EXAMPLE
$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
Runs 1000 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23 10 times in a loop
.NOTES
With thanks to Pieter Vanhove
https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/
and
Jonathan Kehayias
https://www.sqlskills.com/blogs/jonathan/ the-adventureworks2008r2-books-online-random-workload-generator /
&amp;gt;
function Invoke-RandomWorkload {
#Requires -Module PoshRsJob
#Requires -Module SQLServer
Param(
[string]$SqlInstance,
[pscredential]$SqlCredential,
[string]$Database,
[int]$NumberOfJobs = 10,
[int]$Delay = 10,
[int]$Throttle = 5,
[string]$PathToScript = 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql',
[string]$Delimiter = &amp;quot;------&amp;quot;,
[switch]$ShowOutput
)
#Check if there are old Workload Jobs
$WorkloadJobs = Get-RSJob -Name Workload
if ($WorkloadJobs) {
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
$WorkloadJobs |Stop-RSJob
$WorkloadJobs | Remove-RSJob
}
Write-Output &amp;quot;Creating Background Jobs&amp;quot;
1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
$runningJobs = (Get-RSJob -Name WorkLoad -State Running). Count
While ($runningJobs -ne 0) {
$jobs = Get-RSJob -Name WorkLoad
$runningJobs = $Jobs.Where{$PSItem.State -eq 'Running'} .Count
$WaitingJobs = $Jobs.Where{$PSItem.State -eq 'NotStarted'}.Count
$CompletedJobs = $Jobs.Where{$PSItem.State -eq 'Completed'}.Count
Write-Output &amp;quot;$runningJobs jobs running - $WaitingJobs jobs waiting - $CompletedJobs -jobs finished&amp;quot;
Start-Sleep -Seconds $Delay
}
Write-Output &amp;quot;Jobs have finished&amp;quot;
if ($ShowOutput) {
Write-Output &amp;quot;WorkLoad Jobs Output below -&amp;quot;
Get-RSJob -Name WorkLoad | Receive-RSJob
}
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
Get-RSJob -Name WorkLoad | Remove-RSJob
Write-Output &amp;quot;Finished&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Whats a SQL Notebook in Azure Data Studio?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-7.png" alt="Featured image of post Whats a SQL Notebook in Azure Data Studio?" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-2017?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a cross-platform database tool for data professionals using the Microsoft family of on-premises and cloud data platforms on Windows, MacOS, and Linux.&lt;/p>
&lt;p>Recently Vicky Harp tweeted&lt;/p>
&lt;blockquote>
&lt;p>We&amp;rsquo;re getting very close to release of SQL Notebooks in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>! You can give the feature an early spin today with the insider build. &lt;a class="link" href="https://t.co/SEZp7ZdxCp" target="_blank" rel="noopener"
>pic.twitter.com/SEZp7ZdxCp&lt;/a>&lt;/p>
&lt;p>â€” Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1104127412944551936?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 8, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>By the way, you can watch a recording from SQLBits of Vickyâ€™s session&lt;/p>
&lt;blockquote>
&lt;p>If you missed &lt;a class="link" href="https://twitter.com/hashtag/sqlbits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#sqlbits&lt;/a>, you will definitely want to watch this demo by &lt;a class="link" href="https://twitter.com/vickyharp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@vickyharp&lt;/a> and &lt;a class="link" href="https://twitter.com/MGoCODE?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@MGoCODE&lt;/a> about &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>. Learn the latest about our cross-platform tool, including a new feature, SQL Notebooks &lt;a class="link" href="https://twitter.com/hashtag/SQLServer?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLServer&lt;/a> &lt;a class="link" href="https://t.co/diubYwQckn" target="_blank" rel="noopener"
>https://t.co/diubYwQckn&lt;/a>&lt;/p>
&lt;p>â€” Azure Data Studio (@AzureDataStudio) &lt;a class="link" href="https://twitter.com/AzureDataStudio/status/1103806327065722880?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 7, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>So in the interest of learning about something new I decided to give it a try.&lt;/p>
&lt;h2 id="install-the-insiders-edition">Install The Insiders Edition&lt;/h2>
&lt;p>Unlike &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> which has a link to the insiders download on the front page, you will have to &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio#azure-data-studio" target="_blank" rel="noopener"
>visit the GitHub repository for the links to download the insiders release of Azure Data Studio&lt;/a>. Scroll down and you will see&lt;/p>
&lt;p>Try out the latest insiders build fromÂ &lt;code>master&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider" target="_blank" rel="noopener"
>Windows User Installer â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider" target="_blank" rel="noopener"
>Windows System Installer â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider" target="_blank" rel="noopener"
>Windows ZIP â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider" target="_blank" rel="noopener"
>macOS ZIP â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider" target="_blank" rel="noopener"
>Linux TAR.GZ â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See theÂ &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>change log&lt;/a>Â for additional details of whatâ€™s in this release.
Once you have installed you can connect to an instance, right click and choose New Notebook or you can use File â€“ New Notebook
&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image.png"
loading="lazy"
>&lt;/p>
&lt;p>Incidentally, I use the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> to create the containers and I map &lt;code>C:\MSSQL\BACKUP\KEEP&lt;/code> on my local machine (where my backups are) to &lt;code>/var/opt/mssql/backups&lt;/code> on the containers on lines 10 and 17 of the docker-compose so change as required . If you want to follow along then put the ValidationResults.bak in the folder on your local machine.
The &lt;code>Create-Ag.ps1&lt;/code> shows the code and creates an AG with &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.&lt;/a> But I digress!&lt;/p>
&lt;h2 id="install-notebook-dependencies">Install Notebook Dependencies&lt;/h2>
&lt;p>Once you click New Notebook you will get a prompt to install the dependencies.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>It will show its output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and take a few minutes to run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>It took all but 11 minutes on my machine&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-notebook">Create a Notebook&lt;/h2>
&lt;p>OK, so now that we have the dependencies installed we can create a notebook. I decided to use the ValidationResults database that &lt;a class="link" href="https://blog.robsewell.com/dbachecks-save-the-results-to-a-database-for-historical-reporting/" target="_blank" rel="noopener"
>I use for my dbachecks demos and describe here&lt;/a>. I need to restore it from my local folder that I have mapped as a volume to my container. Of course, I use dbatools for this ðŸ™‚&lt;/p>
&lt;pre>&lt;code># U: sqladmin P: dbatools.IO
$cred = Get-Credential
$restoreDbaDatabaseSplat = @{
SqlInstance = $sqlinstance1
SqlCredential = $cred
UseDestinationDefaultDirectories = $true
Path = '/var/opt/mssql/backups/ValidationResults.bak'
}
Restore-DbaDatabase @restoreDbaDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>I had already got a connection saved to the instance in Azure Data Studio, you may need to create a new one using the new connection icon at the top left and filling in the details. The password is in the code above.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can start with my notebook. I am faced with this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I click on text and provide an intro&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I had written that and clicked out, I couldnâ€™t see what to do straight away!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I saw the code and text buttons at the top ðŸ™‚ Right, lets get on with it ðŸ™‚ I hit the code button and paste in the T-SQL to reset the dates in the database to simulate dbachecks having been run this morning.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-9.png"
loading="lazy"
>
Thereâ€™s a run cell button on the right and when I press it&amp;gt;&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->
Cool ðŸ™‚&lt;/p>
&lt;p>If the SQL query has results then they are shown as well&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>This is fun and I can see plenty of uses for it. Go and have a play with SQL notebooks ðŸ™‚&lt;/p>
&lt;h2 id="source-control">Source Control&lt;/h2>
&lt;p>I used CTRL K, CTRL O to open a folder and saved my notebook in my local Presentations folder which is source controlled. When I opened the explorer CTRL + SHIFT + E I can see that the folder and the file are colour coded green and have a U next to them marking them as Untracked. I can also see that the source control icon has a 1 for the number of files with changes and in the bottom left that I am in the master branch.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>If I click on the source control icon (or CTRL + SHIFT + G) I can see the files with the changes and can enter a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>I then press CTRL + ENTER to commit my change and get this pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>As I only have one file and it has all the changes for this commit I click yes. If I had changed more than one file and only wanted to commit a single one at a time I would hover my mouse over the file and click the + to stage my change.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>If I make a further change to the notebook and save it, I can see that the source control provider recognises the change but this time the folder the file is in and the file are colour coded brown with an M to show that they have been modified.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Unlike Visual Studio Code, when you then click on the source control icon and click on the change it does not show the differences in the notebook although this works with SQL files.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>When I have made all my changes and committed them with good commit messages&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/imgs.xkcd.com/comics/git_commit.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can see that there are 3 local changes ready to be pushed to by remote repository (GitHub in this case) and 0 remote commits in this branch by looking at the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I can click on the â€œroundy roundyâ€ icon (I don&amp;rsquo;t know its proper name ðŸ˜Š) and synchronise my changes. This comes with a pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Personally I never press OK, Donâ€™t Show Again because I like the double check and to think â€œIs this really what I want to do right nowâ€. Once I press OK my changes will be synched with the remote repository. Explaining this means that you can find the notebook I have used in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/Notebooks" target="_blank" rel="noopener"
>Presentations GitHub Repository&lt;/a> which means that you can run the Notebook too using the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> and the instructions further up in the post.&lt;/p></description></item><item><title>Using Docker to run Integration Tests for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</link><pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</guid><description>&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>AndrÃ© Kamman&lt;/a> wrote a fantastic blog post this week &lt;a class="link" href="https://andrekamman.com/sql-server-container-instances-via-cloudshell/" target="_blank" rel="noopener"
>SQL Server Container Instances via Cloudshell&lt;/a> about how he uses containers in Azure to test code against different versions of SQL Server.&lt;/p>
&lt;p>It reminded me that I do something very similar to test &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> code changes. I thought this might make a good blog post. I will talk through how I do this locally as I merge a PR from another great friend &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>ClÃ¡udio Silva&lt;/a> who has added &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/582" target="_blank" rel="noopener"
>agent job history checks.&lt;/a>&lt;/p>
&lt;h2 id="github-pr-vs-code-extension">GitHub PR VS Code Extension&lt;/h2>
&lt;p>I use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github" target="_blank" rel="noopener"
>GitHub Pull Requests extension for VS Code&lt;/a> to work with pull requests for &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pulls" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This enables me to see all of the information about the Pull Request, merge it, review it, comment on it all from VS Code&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/GitHub-Pull-Request-VsCode-Extension.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see which files have been changed and which changes have been made&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/viewing-a-change.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I am ready to test the pull request I perform a checkout using the extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/checkout-pull-request-checkout.png"
loading="lazy"
>&lt;/p>
&lt;p>This will update all of the files in my local repository with all of the changes in this pull request&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>You can see at the bottom left that the branch changes from development to the name of the PR.&lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-unit-tests">Running The Unit Tests&lt;/h2>
&lt;p>The first thing that I do is to run the Unit Tests for the module. These will test that the code is following all of the guidelines that we require and that the tests are formatted in the correct way for the Power Bi to parse. I have blogged about this &lt;a class="link" href="https://blog.robsewell.com/using-the-ast-in-pester-for-dbachecks/" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-the-powershell-ast-to-find-a-foreach-method/" target="_blank" rel="noopener"
>here&lt;/a> and we use this Pester in our CI process in Azure DevOps which I described &lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>here.&lt;/a>&lt;/p>
&lt;p>I navigate to the root of the dbachecks repository on my local machine and run&lt;/p>
&lt;pre>&lt;code> $testresults = Invoke-Pester .\tests -ExcludeTag Integration -Show Fails -PassThru
&lt;/code>&lt;/pre>
&lt;p>and after about a minute&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/pester-tests.png"
loading="lazy"
>&lt;/p>
&lt;p>Thank you ClÃ¡udio, the code has passed the tests ðŸ˜‰&lt;/p>
&lt;h2 id="running-some-integration-tests">Running Some Integration Tests&lt;/h2>
&lt;p>The difference between Unit tests and Integration tests in a nutshell is that the Unit tests are testing that the code is doing what is expected without any other external influences whilst the Integration tests are checking that the code is doing what is expected when running on an actual environment. In this scenario we know that the code is doing what is expected but we want to check what it does when it runs against a SQL Server and even when it runs against multiple SQL Servers of different versions.&lt;/p>
&lt;h2 id="multiple-versions-of-sql-server">Multiple Versions of SQL Server&lt;/h2>
&lt;p>As I have described &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>before&lt;/a> my friend and former colleague Andrew Pruski &lt;a class="link" href="http://dbafromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="http://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has many resources for running SQL in containers. This means that I can quickly and easily create fresh uncontaminated instances of SQL 2012, 2014, 2016 and 2017 really quickly.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/creating-contatiners.png"
loading="lazy"
>&lt;/p>
&lt;p>I can create 4 instances of different versions of SQL in (a tad over) 1 minute. How about you?&lt;/p>
&lt;p>Imagine how long it would take to run the installers for 4 versions of SQL and the pain you would have trying to uninstall them and make sure everything is â€˜cleanâ€™. Even images that have been sysprepâ€™d wonâ€™t be done in 1 minute.&lt;/p>
&lt;h2 id="docker-compose-up-">Docker Compose Up ?&lt;/h2>
&lt;p>So what is this magic command that has enabled me to do this? docker compose uses a YAML file to define multi-container applications. This means that with a file called docker-compose.yml like &lt;a class="link" href="https://gist.github.com/SQLDBAWithABeard/b589d499484af4ebfb7d637cb6b4efa3" target="_blank" rel="noopener"
>this&lt;/a>&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/ mssql-server-windows-developer:2017-latest
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and in that directory just run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>and 4 SQL containers are available to you. You can interact with them via SSMS if you wish with localhost comma PORTNUMBER. The port numbers in the above file are 15586, 15587,15588 and 15589&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?resize=630%2C188&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>Now it must be noted, as I &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>describe here&lt;/a> that first I pulled the images to my laptop. The first time you run docker compose will take significantly longer if you havenâ€™t pulled the images already (pulling the images will take quite a while depending on your broadband speed)&lt;/p>
&lt;h2 id="credential">Credential&lt;/h2>
&lt;p>The next thing is to save a credential to make it easier to automate.&lt;del>I use the method described by my PowerShell friend Jaap Brasser &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/del>&lt;/p>
&lt;p>EDIT (September or is it March? 2020) - Nowadays I use the Secret Management Module&lt;/p>
&lt;p>I run this code&lt;/p>
&lt;pre>&lt;code> $CredentialPath = 'C:\MSSQL\BACKUP\KEEP\sacred.xml'
Get-Credential | Export-Clixml -Path $CredentialPath
&lt;/code>&lt;/pre>
&lt;p>and then I can create a credential object using&lt;/p>
&lt;pre>&lt;code>$cred = Import-Clixml $CredentialPath
&lt;/code>&lt;/pre>
&lt;h2 id="check-the-connections">Check The Connections&lt;/h2>
&lt;p>I ensure a clean session by removing the dbatools and dbachecks modules and then import the local version of dbachecks and set some variables&lt;/p>
&lt;pre>&lt;code>$dbacheckslocalpath = 'GIT:\dbachecks\'
Remove-Module dbatools, dbachecks -ErrorAction SilentlyContinue
Import-Module $dbacheckslocalpath\dbachecks.psd1
$cred = Import-Clixml $CredentialPath
$containers = 'localhost,15589', 'localhost,15588', 'localhost, 15587', 'localhost,15586'
&lt;/code>&lt;/pre>
&lt;p>Now I can start to run my Integration tests. First reset the dbachecks configuration and set some configuration values&lt;/p>
&lt;pre>&lt;code># run the checks against these instances
$null = Set-DbcConfig -Name app.sqlinstance $containers
# We are using SQL authentication
$null = Set-DbcConfig -Name policy.connection.authscheme -Value SQL
# sometimes its a bit slower than the default value
$null = Set-DbcConfig -Name policy.network.latencymaxms -Value 100 # because the containers run a bit slow!
&lt;/code>&lt;/pre>
&lt;p>Then I will run the dbachecks connectivity checks and save the results to a variable without showing any output&lt;/p>
&lt;pre>&lt;code>$ConnectivityTests = Invoke-DbcCheck -SqlCredential $cred -Check Connectivity -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>I can then use Pester to check that dbachecks has worked as expected by testing if the failedcount property returned is 0.&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;Testing the checks are running as expected&amp;quot; -Tag Integration {
Context &amp;quot;Connectivity Checks&amp;quot; {
It &amp;quot;All Tests should pass&amp;quot; {
$ConnectivityTests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default settings&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/check-connectivity.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="what-is-the-unit-test-for-this-pr">What is the Unit Test for this PR?&lt;/h2>
&lt;p>Next I think about what we need to be testing for the this PR. The Unit tests will help us.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/what-are-the-unit-tests.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="choose-some-integration-tests">Choose some Integration Tests&lt;/h2>
&lt;p>This check is checking the Agent job history settings and the unit tests are&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows disabled (-1)â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows disabled (-1) but configured value is 1000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows being 10000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows being less than 10000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows per job being 100â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows per job being less than 100â€&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So we will check the same things on real actual SQL Servers. First though we need to start the SQL Server Agent as it is not started by default. We can do this as follows&lt;/p>
&lt;pre>&lt;code>docker exec -ti integration_sql2012_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2014_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2016_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2017_1 powershell start-service SQLSERVERAGENT
&lt;/code>&lt;/pre>
&lt;p>Unfortunately, the agent service wont start in the SQL 2014 container so I cant run agent integration tests for that container but itâ€™s better than no integration tests.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/agent-wont-start.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="this-is-what-we-will-test">This is What We Will Test&lt;/h2>
&lt;p>So we want to test if the check will pass with default settings. In general, dbachecks will pass for default instance, agent or database settings values by default.&lt;/p>
&lt;p>We also want the check to fail if the configured value for dbachecks is set to default but the value has been set on the instance.&lt;/p>
&lt;p>We want the check to pass if the configured value for the dbachecks configuration is set and the instance (agent, database) setting matches it.&lt;/p>
&lt;h2 id="if-you-are-doing-something-more-than-once-">If You Are Doing Something More Than Once â€¦â€¦&lt;/h2>
&lt;p>Letâ€™s automate that. We are going to be repeatedly running those three tests for each setting that we are running integration tests for. I have created 3 functions for this again checking that FailedCount or Passed Count is 0 depending on the test.&lt;/p>
&lt;pre>&lt;code>function Invoke-DefaultCheck {
It &amp;quot;All Checks should pass with default for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)default&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default setting (Yes we may set some values before but you get my drift)&amp;quot;
}
}
function Invoke-ConfigCheck {
It &amp;quot;All Checks should fail when config changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)configchanged&amp;quot; -ValueOnly
$Tests.PassedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and fail when we have changed the config values&amp;quot;
}
}
function Invoke-ValueCheck {
It &amp;quot;All Checks should pass when setting changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check) value changed&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass when we have changed the settings to match the config values&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Now I can use those functions inside a loop in my Integration Pester Test&lt;/p>
&lt;pre>&lt;code>$TestingTheChecks = @('errorlogscount','jobhistory')
Foreach ($Check in $TestingTheChecks) {
Context &amp;quot;$Check Checks&amp;quot; {
Invoke-DefaultCheck
Invoke-ConfigCheck
Invoke-ValueCheck
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="write-some-integration-tests">Write Some Integration Tests&lt;/h2>
&lt;p>So for this new test I have added a value to the TestingTheChecks array then I can test my checks. The default check I can check like this&lt;/p>
&lt;pre>&lt;code># run the checks against these instances (SQL2014 agent wont start :-( ))
$null = Set-DbcConfig -Name app.sqlinstance $containers.Where {$_ -ne 'localhost,15588'}
# by default all tests should pass on default instance settings
$jobhistorydefault = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Now I need to change the configurations so that they do not match the defaults and run the checks again&lt;/p>
&lt;pre>&lt;code>#Change the configuration to test that the checks fail
$null = Set-DbcConfig -Name agent.history. maximumjobhistoryrows -value 1000
$null = Set-DbcConfig -Name agent.history.maximumhistoryrows -value 10000
$jobhistoryconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Next we have to change the instance settings so that they match the dbachecks configuration and run the checks and test that they all pass.&lt;/p>
&lt;p>We will (of course) use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> for this. First we need to find the command that we need&lt;/p>
&lt;pre>&lt;code>Find-DbaCommand jobserver
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/find-dbacommand.png"
loading="lazy"
>&lt;/p>
&lt;p>and then work out how to use it&lt;/p>
&lt;pre>&lt;code>Get-Help Set-DbaAgentServer -Detailed
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/set-the-values.png"
loading="lazy"
>&lt;/p>
&lt;p>There is an example that does exactly what we want ðŸ™‚ So we can run this.&lt;/p>
&lt;pre>&lt;code>$setDbaAgentServerSplat = @{
MaximumJobHistoryRows = 1000
MaximumHistoryRows = 10000
SqlInstance = $containers.Where{$_ -ne 'localhost,15588'}
SqlCredential = $cred
}
Set-DbaAgentServer @setDbaAgentServerSplat
$jobhistoryvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;h2 id="run-the-integration-tests">Run the Integration Tests&lt;/h2>
&lt;p>And then we will check that all of the checks are passing and failing as expected&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\DockerTests.ps1
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/testing-the-checks.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="integration-test-for-error-log-counts">Integration Test For Error Log Counts&lt;/h2>
&lt;p>There is another integration test there for the error logs count. This works in the same way. Here is the code&lt;/p>
&lt;pre>&lt;code>#region error Log Count - PR 583
# default test
$errorlogscountdefault = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set a value and then it will fail
$null = Set-DbcConfig -Name policy.errorlog.logcount -Value 10
$errorlogscountconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set the value and then it will pass
$null = Set-DbaErrorLogConfig -SqlInstance $containers -SqlCredential $cred -LogCount 10
$errorlogscountvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
#endregion
&lt;/code>&lt;/pre>
&lt;h2 id="merge-the-changes">Merge the Changes&lt;/h2>
&lt;p>So with all the tests passing I can merge the PR into the development branch and Azure DevOps will start a build. Ultimately, I would like to add the integration to the build as well following &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>AndrÃ©&lt;/a>â€˜s blog post but for now I used the GitHub Pull Request extension to merge the pull request into development which started a &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_build/results?buildId=365&amp;amp;view=results" target="_blank" rel="noopener"
>build&lt;/a> and then merged that into master which signed the code and deployed it to the PowerShell gallery as you can see &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=81&amp;amp;environmentId=81" target="_blank" rel="noopener"
>here&lt;/a> and the result is&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.164" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/dbachecks/1.1.164&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/powershell-gallery.png"
loading="lazy"
>&lt;/p></description></item><item><title>How to run a PowerShell script file with Verbose, Confirm or WhatIf</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</link><pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Showing-the-results.png" alt="Featured image of post How to run a PowerShell script file with Verbose, Confirm or WhatIf" />&lt;p>Before you run a PowerShell command that makes a change to something you should check that it is going to do what you expect. You can do this by using the WhatIf parameter for commands that support it. For example, if you wanted to create a New SQL Agent Job Category you would use the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>awesome dbatools module&lt;/a> and write some code like this&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup'
&lt;/code>&lt;/pre>
&lt;p>before you run it, you can check what it is going to do using&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup' -WhatIf
&lt;/code>&lt;/pre>
&lt;p>which gives a result like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Whatif.png"
loading="lazy"
>&lt;/p>
&lt;p>This makes it easy to do at the command line but when we get confident with PowerShell we will want to write scripts to perform tasks using more than one command. So how can we ensure that we can check that those will do what we are expecting without actually running the script and see what happens? Of course, there are Unit and integration testing that should be performed using &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>Pester&lt;/a> when developing the script but there will still be occasions when we want to see what this script will do this time in this environment.&lt;/p>
&lt;p>Lets take an example. We want to place our SQL Agent jobs into specific custom categories depending on their name. We might write a script like this&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.SYNOPSIS
Adds SQL Agent Jobs to categories and creates the categories if needed
.DESCRIPTION
Adds SQL Agent Jobs to categories and creates the categories if needed. Creates
Backup', 'Index', 'TroubleShooting','General Info Gathering' categories and adds
the agent jobs depending on name to the category
.PARAMETER Instance
The Instance to run the script against
#&amp;gt;
Param(
[string]$Instance
)
$Categories = 'Backup', 'Index','DBCC', 'TroubleShooting', 'General Info Gathering'
$Categories.ForEach{
## Create Category if it doesnot exist
If (-not (Get-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem)) {
New-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem -CategoryType LocalJob
}
}
## Get the agent jobs and iterate through them
(Get-DbaAgentJob -SqlInstance $instance).ForEach{
## Depending on the name of the Job - Put it in a Job Category
switch -Wildcard ($PSItem.Name) {
'*DatabaseBackup*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Backup'
}
'*Index*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Index'
}
'*DatabaseIntegrity*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'DBCC'
}
'*Log SP_*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'TroubleShooting'
}
'*Collection*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'General Info Gathering'
}
## Otherwise put it in the uncategorised category
Default {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category '[Uncategorized (Local)]'
}
}
}
&lt;/code>&lt;/pre>
&lt;p>You can run this script against any SQL instance by callingÂ  it and passing an instance parameter from the command line like this&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>If you wanted to see what would happen, you could edit the script and add the WhatIf parameter to every changing command but thatâ€™s not really a viable solution. What you can do is&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $true
&lt;/code>&lt;/pre>
&lt;p>this will set all commands that accept WhatIf to use the WhatIf parameter. This means that if you are using functions that you have written internally you must ensure that you write your functions to use the common parameters&lt;/p>
&lt;p>Once you have set the default value for WhatIf as above, you can simply call your script and see the WhatIf output&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>which will show the WhatIf output for the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Showing-the-results.png"
loading="lazy"
>&lt;/p>
&lt;p>Once you have checked that everything is as you expected then you can remove the default value for the WhatIf parameter and run the script&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $false
&amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>and get the expected output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-run-the-script-1.png"
loading="lazy"
>&lt;/p>
&lt;p>If you wish to see the verbose output or ask for confirmation before any change you can set those default parameters like this&lt;/p>
&lt;pre>&lt;code>## To Set Verbose output
$PSDefaultParameterValues['*:Verbose'] = $true
## To Set Confirm
$PSDefaultParameterValues['*:Confirm'] = $true
&lt;/code>&lt;/pre>
&lt;p>and set them back by setting to false&lt;/p></description></item><item><title>Pester 4.2.0 has a Becauseâ€¦â€¦ because :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</link><pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/01-Because-1.png" alt="Featured image of post Pester 4.2.0 has a Becauseâ€¦â€¦ because :-)" />&lt;p>I was going through my demo for the &lt;a class="link" href="http://meetu.ps/e/DdYV6/gHMdv/g" target="_blank" rel="noopener"
>South Coast User Group meeting&lt;/a> tonight and decided to add some details about the Because parameter available in the Pester pre-release version 4.2.0.&lt;/p>
&lt;p>To install a pre-release version you need to get the latestÂ Â &lt;a class="link" href="https://go.microsoft.com/fwlink/?linkid=846259" target="_blank" rel="noopener"
>PowerShellGet&lt;/a>Â module. This is pre-installed with PowerShell v6 but for earlier versions open PowerShell as administrator and run&lt;/p>
&lt;pre>&lt;code>Install-Module PowerShellGet
&lt;/code>&lt;/pre>
&lt;p>You can try out the Pester pre-release version (once you have the latest PowerShellGet) by installing it from the &lt;a class="link" href="http://powershellgallery.com" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> with&lt;/p>
&lt;pre>&lt;code>Install-Module -Name Pester -AllowPrerelease -Force # -Scope CurrentUser # if not admin
&lt;/code>&lt;/pre>
&lt;p>There are a number of improvements as you can see in &lt;a class="link" href="https://github.com/pester/Pester/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>the change log&lt;/a>Â I particularly like the&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>Add -BeTrue to test for truthy values&lt;/li>
&lt;li>Add -BeFalse to test for falsy values&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>This release adds the Because parameter to the all assertions. This means that you can add a reason why the test has failed. As &lt;a class="link" href="http://jakubjares.com/2017/12/19/using-because/" target="_blank" rel="noopener"
>JAKUB JAREÅ  writes here&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Reasons force you think more&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons document your intent&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons make your TestCases clearer&lt;/p>
&lt;/li>
&lt;li>
&lt;p>So you can do something like this&lt;/p>
&lt;p>Describe &amp;ldquo;This shows the Because&amp;rdquo;{
It &amp;ldquo;Should be true&amp;rdquo; {
$false | Should -BeTrue -Because &amp;ldquo;The Beard said so&amp;rdquo;
}
}&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Which gives an error message like this ðŸ™‚&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Because-1.png"
loading="lazy"
>&lt;/p>
&lt;p>As you can see the Expected gives the expected value and then your Because statement and then the actual result. Which means that you could write validation tests like&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;My System&amp;quot; {
Context &amp;quot;Server&amp;quot; {
It &amp;quot;Should be using XP SP3&amp;quot; {
(Get-CimInstance -ClassName win32_operatingsystem) .Version | Should -Be '5.1.2600' -Because &amp;quot;We have failed to bother to update the App and it only works on XP&amp;quot;
}
It &amp;quot;Should be running as rob-xps\\mrrob&amp;quot; {
whoami | Should -Be 'rob-xps\\mrrob' -Because &amp;quot;This is the user with the permissions&amp;quot;
}
It &amp;quot;Should have SMB1 enabled&amp;quot; {
(Get-SmbServerConfiguration).EnableSMB1Protocol | Should -BeTrue -Because &amp;quot;We don't care about the risk&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>and get a result like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Or if you were looking to validate your SQL Server you could write something like this&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_.Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG&amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>or maybe your security policies allow Windows Groups as logins on your SQL instances. You could easily link to the documentation and explain why this is important. This way you could build up a set of tests to validate your SQL Server is just so for your environment&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins). LoginType -contains 'WindowsUser' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>Just for fun, these would look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and the code looks like&lt;/p>
&lt;pre>&lt;code>$Instances = 'Rob-XPS', 'Rob-XPS\\Bolton'
foreach ($instance in $Instances) {
$Server, $InstanceName = $Instance.Split('/')
if ($InstanceName.Length -eq 0) {$InstanceName = 'MSSSQLSERVER'}
Describe &amp;quot;Testing the instance $instance&amp;quot; {
Context &amp;quot;SQL Agent Jobs&amp;quot; {
It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_. Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG &amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
Context &amp;quot;Logins&amp;quot; {
It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins).LoginType -contains 'WindowsUser' | Should @Should
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This will be a useful improvement to Pester when it is released and enable you to write validation checks with explanations.&lt;/p>
&lt;blockquote>
&lt;p>Come and Learn Some PowerShell Magic* at &lt;a class="link" href="https://twitter.com/hashtag/SQLBits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLBits&lt;/a> with &lt;a class="link" href="https://twitter.com/cl?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@cl&lt;/a> and I&lt;br>
Details &lt;a class="link" href="https://t.co/7OfK75e6Y1" target="_blank" rel="noopener"
>https://t.co/7OfK75e6Y1&lt;/a>&lt;br>
Registration &lt;a class="link" href="https://t.co/RDSkPlfMMx" target="_blank" rel="noopener"
>https://t.co/RDSkPlfMMx&lt;/a>&lt;br>
*PowerShell is not magic â€“ it just might appear that way &lt;a class="link" href="https://t.co/5czPzYR3QD" target="_blank" rel="noopener"
>pic.twitter.com/5czPzYR3QD&lt;/a>&lt;/p>
&lt;p>â€” Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/935143475418402816?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>November 27, 2017&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p></description></item><item><title>Using the AST in Pester for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</link><pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Pester-results-1.png" alt="Featured image of post Using the AST in Pester for dbachecks" />&lt;p>TagLine â€“ My goal â€“ Chrissy will appreciate Unit Tests one day ðŸ™‚&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>ClÃ¡udio Silva&lt;/a> has improved my &lt;a class="link" href="https://blog.robsewell.com/a-pretty-powerbi-pester-results-template-file/" target="_blank" rel="noopener"
>PowerBi For Pester&lt;/a>Â file and made it beautiful and whilst we were discussing this we found that if the Pester Tests were not formatted correctly the Power Bi looked â€¦ well rubbish to be honest! Chrissy asked if we could enforce some rules for writing our Pester tests.&lt;/p>
&lt;p>The rules were&lt;/p>
&lt;p>The Describe title should be in double quotes&lt;br>
The Describe should use the plural Tags parameter&lt;br>
The Tags should be singular&lt;br>
The first Tag should be a unique tag in Get-DbcConfig&lt;br>
The context title should end with $psitem&lt;br>
The code should use Get-SqlInstance or Get-ComputerName&lt;br>
The Code should use the forEach method&lt;br>
The code should not use $_&lt;br>
The code should contain a Context block&lt;/p>
&lt;p>She asked me if I could write the Pester Tests for it and this is how I did it. I needed to look at the Tags parameter for the Describe. It occurred to me that this was a job for the Abstract Syntax Tree (AST). I donâ€™t know very much about the this but I sort of remembered reading a blog post by &lt;a class="link" href="http://www.lazywinadmin.com/2016/08/powershellpester-make-sure-your.html" target="_blank" rel="noopener"
>Francois-Xavier Cat about using it with Pester&lt;/a> so I went and read that and &lt;a class="link" href="https://stackoverflow.com/questions/39909021/parsing-powershell-script-with-ast" target="_blank" rel="noopener"
>found an answer on Stack Overflow&lt;/a> as well. These looked just like what I needed so I made use of them. Thank you very much to Francois-Xavier and wOxxOm for sharing.&lt;/p>
&lt;p>The first thing I did was to get the Pester Tests which we have located in a checks folder and loop through them and get the content of the file with the Raw parameter&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Describes titles and tags&amp;quot; {
&lt;/code>&lt;/pre>
&lt;p>Then I decided to look at the Describes using the method thatÂ wOxxOm (I know no more about this person!) showed.&lt;/p>
&lt;pre>&lt;code>$Describes = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\]\] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'describe'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
$tagIdx = $CE.IndexOf(($CE |Where ParameterName -eq'Tags') ) + 1
$tags = if ($tagIdx -and $tagIdx -lt $CE.Count) {
$CE\[$tagIdx\].Extent
}
New-Object PSCustomObject -Property @{
Name = $secondString
Tags = $tags
}
}
&lt;/code>&lt;/pre>
&lt;p>As I understand it, this code is using the Parser on the $check (which contains the code from the file) and finding all of the Describe commands and creating an object of the title of the Describe with the StaticType equal to String and values from the Tag parameter.&lt;/p>
&lt;p>When I ran this against the database tests file I got the following results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-describes-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Then it was a simple case of writing some tests for the values&lt;/p>
&lt;pre>&lt;code>@($describes).Foreach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$title Should Use a double quote after the Describe&amp;quot; {
$PSItem.Name.ToString().Startswith('&amp;quot;')| Should be $true
$PSItem.Name.ToString().Endswith('&amp;quot;')| Should be $true
}
It &amp;quot;$title should use a plural for tags&amp;quot; {
$PsItem.Tags| Should Not BeNullOrEmpty
}
# a simple test for no esses apart from statistics and Access!!
if ($null -ne $PSItem.Tags) {
$PSItem.Tags.Text.Split(',').Trim().Where{($_ -ne '$filename') -and ($_ -notlike '\*statistics\*') -and ($_ -notlike '\*BackupPathAccess\*') }.ForEach{
It &amp;quot;$PsItem Should Be Singular&amp;quot; {
$_.ToString().Endswith('s')| Should Be $False
}
}
It &amp;quot;The first Tag Should Be in the unique Tags returned from Get-DbcCheck&amp;quot; {
$UniqueTags -contains $PSItem.Tags.Text.Split(',') \[0\].ToString()| Should Be $true
}
}
else {
It &amp;quot;You haven't used the Tags Parameter so we can't check the tags&amp;quot; {
$false| Should be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The Describes variable is inside @() so that if there is only one the ForEach Method will still work. The unique tags are returned from our command Get-DbcCheck which shows all of the checks. We will have a unique tag for each test so that they can be run individually.&lt;/p>
&lt;p>Yes, I have tried to ensure that the tags are singular by ensuring that they do not end with an s (apart from statistics) and so had to not checkÂ  BackupPathAccess and statistics. Filename is a variable that we add to each Describe Tags so that we can run all of the tests in one file. I added a little if block to the Pester as well so that the error if the Tags parameter was not passed was more obvious&lt;/p>
&lt;p>I did the same with the context blocks as well&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Contexts&amp;quot; {
## Find the Contexts
$Contexts = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\] \] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'Context'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
New-Object PSCustomObject -Property @{
Name = $secondString
}
}
@($Contexts).ForEach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$Title Should end with `$psitem So that the PowerBi will work correctly&amp;quot; {
$PSItem.Name.ToString().Endswith('psitem&amp;quot;')| Should Be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This time we look for the Context command and ensure that the string value ends with psitem as the PowerBi parses the last value when creating columns&lt;/p>
&lt;p>Finally I got all of the code and check if it matches some coding standards&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Code&amp;quot; {
## This just grabs all the code
$AST = \[System.Management.Automation.Language.Parser\] ::ParseInput($Check, \[ref\]$null, \[ref\]$null)
$Statements = $AST.EndBlock.statements.Extent
## Ignore the filename line
@($Statements.Where{$_.StartLineNumber -ne 1}).ForEach{
$title = \[regex\]::matches($PSItem.text, &amp;quot;Describe(. *)-Tag&amp;quot;).groups\[1\].value.Replace('&amp;quot;', '').Replace ('''', '').trim()
It &amp;quot;$title Should Use Get-SqlInstance or Get-ComputerName&amp;quot; {
($PSItem.text -Match 'Get-SqlInstance') -or ($psitem.text -match 'Get-ComputerName')| Should be $true
}
It &amp;quot;$title Should use the ForEach Method&amp;quot; {
($Psitem.text -match 'Get-SqlInstance\\).ForEach {') -or ($Psitem.text -match 'Get-ComputerName\\). ForEach{')| Should Be $true# use the \ to escape the )
}
It &amp;quot;$title Should not use `$_&amp;quot; {
($Psitem.text -match '$_')| Should Be $false
}
It &amp;quot;$title Should Contain a Context Block&amp;quot; {
$Psitem.text -match 'Context'| Should Be $True
}
}
&lt;/code>&lt;/pre>
&lt;p>I trim the title from the Describe block so that it is easy to see where the failures (or passes) are with some regex and then loop through each statement apart from the first line to ensure that the code is using our internal commands Get-SQLInstance or Get-ComputerName to get information, that we are looping through each of those arrays using the ForEach method rather than ForEach-Object and using $psitem rather than $_ to reference the â€œThis Itemâ€ in the array and that each Describe block has a context block.&lt;/p>
&lt;p>This should ensure that any new tests that are added to the module follow the guidance we have set up on the Wiki and ensure that the Power Bi results still look beautiful!&lt;/p>
&lt;p>Anyone can run the tests using&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\\tests\\Unit.Tests.ps1 -show Fails
&lt;/code>&lt;/pre>
&lt;p>before they create a Pull request and it looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Pester-results-1.png"
loading="lazy"
>&lt;/p>
&lt;p>if everything is Green then they can submit their Pull Request ðŸ™‚ If not they can see quickly that something needs to be fixed. (fail early ðŸ™‚ )&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-fails.png"
loading="lazy"
alt="03 fails.png"
>&lt;/p></description></item><item><title>Altering a Job Step on Hundreds of SQL Servers with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/altering-a-job-step-on-hundreds-of-sql-servers-with-powershell/</link><pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/altering-a-job-step-on-hundreds-of-sql-servers-with-powershell/</guid><description>&lt;img src="https://dbatools.io/wp-content/uploads/2016/05/dbatools-logo-1.png" alt="Featured image of post Altering a Job Step on Hundreds of SQL Servers with PowerShell" />&lt;p>I flew to Utrecht last week to present with &lt;!-- raw HTML omitted -->Chrissy LeMaire&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Sander Stad&lt;!-- raw HTML omitted --> for the joint Dutch SQL and PowerShell User Groups. Whilst I was sat at the airport I got a phone call from my current client.&lt;/p>
&lt;blockquote>
&lt;p>Them - We need to change the backup path for all of the servers to a different share, how long will it take you?&lt;/p>
&lt;p>Me - About 5 minutes&lt;/p>
&lt;/blockquote>
&lt;p>(PowerShell is very powerful â€“ be careful when following these examples ðŸ˜‰ )&lt;/p>
&lt;p>This code was run using PowerShell version 5 and will not work on Powershell version 3 or lower as it uses the where method.
Lets grab all of our jobs on the estate. (You will need to fill the $Servers variable with the names of your instances, maybe from a database or CMS or a text file)&lt;!-- raw HTML omitted -->$Jobs = Get-SQLAgentJob -ServerInstance $Servers&lt;!-- raw HTML omitted -->
Once we have the jobs we need to iterate only through the ones we need to. This step could also have been done in the line above. Lets assume we are using the Ola Hallengren Solution to backup our estate&lt;!-- raw HTML omitted -->Foreach($job in $Jobs.Where{$&lt;em>.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo; -and $&lt;/em>.isenabled -eq $true})&lt;!-- raw HTML omitted -->
Then because I have to target a specific job step I can iterate through those and filter in the same way&lt;!-- raw HTML omitted -->foreach ($Step in $Job.jobsteps.Where{$_.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo;})&lt;!-- raw HTML omitted -->
Now all I need to do is to replace C:\Backup with C:\MSSQL\Backup (in this example I am using my labs backup paths)&lt;!-- raw HTML omitted -->$Step.Command = $Step.Command.Replace(&amp;ldquo;Directory = N&amp;rsquo;C:\Backup&amp;rsquo;&amp;rdquo;,&amp;ldquo;Directory = N&amp;rsquo;C:\MSSQL\Backup&amp;rsquo;&amp;rdquo;)&lt;!-- raw HTML omitted -->
And then call the Alter method&lt;!-- raw HTML omitted -->$Step.Alter()&lt;!-- raw HTML omitted -->
And that is all there is to it. Here is the full script I used&lt;!-- raw HTML omitted -->$Jobs = Get-SQLAgentJob -ServerInstance $Servers&lt;/p>
&lt;p>Foreach($job in $Jobs.Where{$&lt;em>.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo; -and $&lt;/em>.isenabled -eq $true})
{
foreach ($Step in $Job.jobsteps.Where{$_.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo;})
{
$Step.Command = $Step.Command.Replace(&amp;ldquo;Directory = N&amp;rsquo;C:\Backup&amp;rsquo;&amp;rdquo;,&amp;ldquo;Directory = N&amp;rsquo;C:\MSSQL\Backup&amp;rsquo;&amp;rdquo;)
$Step.Alter()
}
}&lt;!-- raw HTML omitted -->
In only a few minutes I had altered several hundred instances worth of Ola Hallengren Jobs ðŸ™‚
This is one of the many reasons I love PowerShell, it enables me to perform mass changes very quickly and easily. Of course, you need to make sure that you know that what you are changing is what you want to change. I have caused severe issues by altering the SQL alerts frequency to 1 second instead of one hour on an estate!! Although the beauty of PowerShell meant that I was able to change it very quickly once the problem was realised&lt;!-- raw HTML omitted -->You can change a lot of settings. If you look at what is available at a job step level&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->Happy Automating&lt;/p></description></item><item><title>Refreshing A SQL Mirrored Database Using Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</link><pubDate>Mon, 25 Aug 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</guid><description>&lt;p>SQL mirroring is a means of providing high availability for your SQL database. It is available in Standard Edition and although the feature is deprecated it is still widely utilised. &lt;a class="link" href="http://msdn.microsoft.com/en-gb/library/ms189852.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>You can read more about it on MSDN here&lt;/a> and &lt;a class="link" href="http://www.brentozar.com/archive/2013/07/database-mirroring-faq/" target="_blank" rel="noopener"
>Jes Borland wrote a useful post answering many questions here&lt;/a>&lt;/p>
&lt;p>There are situations where you may need to refresh these databases. Disaster Recovery is an obvious one but also during development to provide testing or development environments to test your High Availability implementations, run through disaster scenarios, create run books or ensure that the code changes still work with mirroring. There are other scenarios but this post covers the automation of restoring a mirrored database from a backup.&lt;/p>
&lt;p>I have mentioned before and no doubt I shall again, &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>John Sansom wrote a great post about automation&lt;/a> and I am a strong follower of that principle.&lt;/p>
&lt;p>To refresh a SQL mirror the following steps are required, there are some gotchas that you need to be aware of which I will discuss later&lt;/p>
&lt;ul>
&lt;li>remove mirroring&lt;/li>
&lt;li>restore principle database from backup&lt;/li>
&lt;li>perform a transaction log backup of the principle database&lt;/li>
&lt;li>restore both backups on the mirror server with no recovery&lt;/li>
&lt;li>recreate mirroring&lt;/li>
&lt;li>resolve orphaned users&lt;/li>
&lt;li>check mirroring status&lt;/li>
&lt;/ul>
&lt;p>Regular blog followers will know that I prefer to use Powershell when I can (and where it is relevant to do so) and so I have used Powershell to automate all of the steps above&lt;/p>
&lt;p>The script requires some variables to be set up at the beginning. You can easily change this and make the script into a function and call it if you desire, but for this post I shall consider the script as a standalone. The reasoning for this is that I imagine that it will be placed into a run book or stored for use in a repository for specific use and therefore reduces any pre-requisites for using it.&lt;/p>
&lt;p>Set variables as follows, the last three variables set the types for the backup action type and device type and do not need to be altered.&lt;/p>
&lt;pre>&lt;code>\# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
&lt;/code>&lt;/pre>
&lt;p>After some error checking the first thing is to create server and database SMO objects&lt;/p>
&lt;pre>&lt;code>\# Create Server objects $Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer $Mirror = New-Object Microsoft.SQLServer.Management.Smo. server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
&lt;/code>&lt;/pre>
&lt;p>(Added Extra â€“ Use New-ISESnippet to create a SMO Server Snippet and use CTRL + J to find it&lt;/p>
&lt;pre>&lt;code>New-IseSnippet -Title SMO-Server -Description &amp;quot;Create A SQL Server SMO Object&amp;quot; -Text &amp;quot;`$srv = New-Object Microsoft.SqlServer.Management.Smo.Server `$server&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="remove-mirroring">Remove Mirroring&lt;/h4>
&lt;p>Before we can restore the database we need to remove mirroring&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
&lt;/code>&lt;/pre>
&lt;h4 id="restore-principle-database-from-backup">restore principle database from backup&lt;/h4>
&lt;p>Once mirroring has been removed we can restore the database. &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>Stuart Mooreâ€™s Great Series&lt;/a> provides all the code you need to backup and restore databases with Powershell. There is however a bug which can catch you out. Hereâ€™s the code&lt;/p>
&lt;pre>&lt;code>$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;p>The bug is as follows, if your restore is going to take longer than 10 minutes and you are using an earlier version of SQL than SQL 2012 SP1 CU8 then you will find that the restore fails after 10 minutes. This is the default timeout. You may try to set the&lt;/p>
&lt;pre>&lt;code>$srv.ConnectionContext.StatementTimeout
&lt;/code>&lt;/pre>
&lt;p>Value to a larger value or 0 and this will work after SQL 2012 SP1 CU8 but prior to that you will still face the same error. The simple workaround is to use &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/7985b7ef-ed89-4dfd-b02a-433cc4e30894" target="_blank" rel="noopener"
>Invoke-SQLCmd2&lt;/a> and to script the restore as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="perform-a-transaction-backup-of-the-principle-database">perform a transaction backup of the principle database&lt;/h4>
&lt;p>We need to have a full and transaction log backup to set up mirroring. Again you may need to use the script method if your backup will take longer than 600 seconds.&lt;/p>
&lt;pre>&lt;code>#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = â€œLog Backup of â€œ + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object â€“TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 â€“ServerInstance $PrincipalServer â€“Database master â€“Query $query â€“ConnectionTimeout 0 # comment out if not used
&lt;/code>&lt;/pre>
&lt;h4 id="restore-both-backups-on-the-mirror-server-with-no-recovery">Restore both backups on the mirror server with no recovery&lt;/h4>
&lt;p>To complete the mirroring set up we need to restore the backups onto the mirror server with no recovery as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="recreate-mirroring">Recreate mirroring&lt;/h4>
&lt;p>You recreate mirroring in the same way as you would if you were using T-SQL simply add the principal endpoint to the mirror, and the mirror and witness endpoints to the principal&lt;/p>
&lt;pre>&lt;code>#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
&lt;/code>&lt;/pre>
&lt;h4 id="resolve-orphaned-users">Resolve orphaned users&lt;/h4>
&lt;p>You will need to resolve any users and permissions on your destination servers. I do not know a way to do this with PowerShell and would be interested if anyone has found a way to replace the password or the SID on a user object, please contact me if you know.&lt;/p>
&lt;p>Many people do this with the &lt;a class="link" href="http://support.microsoft.com/kb/918992" target="_blank" rel="noopener"
>sp_rev_logins stored procedure&lt;/a> which will create the T-SQL for recreating the logins. However, Powershell cannot read the outputs of the message window where the script prints the script. If you know that your logins are staying static then run sp_rev_logins and store the output in a sql file and call it with Invoke-SQLCmd2&lt;/p>
&lt;pre>&lt;code>$SQL = â€˜â€™ #Path to File
Invoke-Sqlcmd2 â€“ServerInstance $Server â€“Database master â€“InputFile $SQL
&lt;/code>&lt;/pre>
&lt;p>The other option is to &lt;a class="link" href="http://dbadiaries.com/how-to-transfer-logins-to-another-sql-server-or-instance" target="_blank" rel="noopener"
>set up a SSIS package following this blog post&lt;/a> and call it from Powershell as follows&lt;/p>
&lt;p>**2020 Edit ** - You should use &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> to do this&lt;/p>
&lt;pre>&lt;code>Invoke-Command â€“ComputerName $Server â€“scriptblock {DTExec.exe /File â€œPATHTOPackage.dtsxâ€}
&lt;/code>&lt;/pre>
&lt;p>This requires &lt;a class="link" href="http://technet.microsoft.com/en-us/magazine/ff700227.aspx" target="_blank" rel="noopener"
>Powershell Remoting&lt;/a> to have been set up on the server which may or may not be available to you in your environment.&lt;/p>
&lt;p>IMPORTANT NOTE â€“ The script does not include any methods for resolving orphaned users so you will need to test and then add your own solution to the script.&lt;/p>
&lt;h4 id="check-mirroring-status">check mirroring status&lt;/h4>
&lt;p>Lastly you want to check that the script has run successfully and that mirroring is synchronised (I am from the UK!!) To do this I check that time and file used for the last database backup &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/1860/identify-when-a-sql-server-database-was-restored-the-source-and-backup-date/" target="_blank" rel="noopener"
>using this script&lt;/a>&lt;/p>
&lt;pre>&lt;code>#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 1 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize â€“Wrap
&lt;/code>&lt;/pre>
&lt;p>and that mirroring has synchronised using the following Powershell command&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>Depending on your needs you may add some error checking using the results of the above scripts. As I said at the top of the post, you can turn this script into a function and call it at will or add it to an Agent Job for regular scheduling or just kept in a folder ready to be run when required. The choice is yours but all usual rules apply. Donâ€™t believe anything you read on this blog post, donâ€™t run any scripts on production, test before running any scripts, understand what the code is doing before you run it or I am not responsible if you break anything&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: Refresh Mirrored Database
Author: Rob Sewell https://blog.robsewell.com
Requires: Invoke-SQLCMD2 (included)
Version History:
1.2 22/08/2014
.SYNOPSIS
Refreshes a mirrored database
.DESCRIPTION
This script will refresh a mirrored database, recreate mirroring and chekc status of mirroring.
Further details on the website
Requires the variables at the top of the script to be filled in
IMPORTANT - Orpahaned users are not resolved with this acript without additions. See blog post for options
#&amp;gt;
# Load Invoke-SQLCMD2
#Load the assemblies the script requires
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Management.Common&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoEnum&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Smo&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoExtended &amp;quot; );
[void][System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;Microsoft.SqlServer.ConnectionInfo&amp;quot;)
[System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;System.Windows.Forms&amp;quot;)|Out-Null
# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationFUll = $FileShare + $DBName + 'formirroring.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
######################
&amp;lt;#
.SYNOPSIS
Runs a T-SQL script.
.DESCRIPTION
Runs a T-SQL script. Invoke-Sqlcmd2 only returns message output, such as the output of PRINT statements when -verbose parameter is specified
.INPUTS
None
You cannot pipe objects to Invoke-Sqlcmd2
.OUTPUTS
System.Data.DataTable
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;SELECT login_time AS 'StartTime' FROM sysprocesses WHERE spid = 1&amp;quot;
This example connects to a named instance of the Database Engine on a computer and runs a basic T-SQL query.
StartTime
-----------
2010-08-12 21:21:03.593
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -InputFile &amp;quot;C:\MyFolder\tsqlscript.sql&amp;quot; | Out-File -filePath &amp;quot;C:\MyFolder\tsqlscript.rpt&amp;quot;
This example reads a file containing T-SQL statements, runs the file, and writes the output to another file.
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;PRINT 'hello world'&amp;quot; -Verbose
This example uses the PowerShell -Verbose parameter to return the message output of the PRINT command.
VERBOSE: hello world
.NOTES
Version History
v1.0 - Chad Miller - Initial release
v1.1 - Chad Miller - Fixed Issue with connection closing
v1.2 - Chad Miller - Added inputfile, SQL auth support, connectiontimeout and output message handling. Updated help documentation
v1.3 - Chad Miller - Added As parameter to control DataSet, DataTable or array of DataRow Output type
#&amp;gt;
function Invoke-Sqlcmd2 {
[CmdletBinding()]
param(
[Parameter(Position = 0, Mandatory = $true)] [string]$ServerInstance,
[Parameter(Position = 1, Mandatory = $false)] [string]$Database,
[Parameter(Position = 2, Mandatory = $false)] [string]$Query,
[Parameter(Position = 3, Mandatory = $false)] [string]$Username,
[Parameter(Position = 4, Mandatory = $false)] [string]$Password,
[Parameter(Position = 5, Mandatory = $false)] [Int32]$QueryTimeout = 600,
[Parameter(Position = 6, Mandatory = $false)] [Int32]$ConnectionTimeout = 15,
[Parameter(Position = 7, Mandatory = $false)] [ValidateScript( {test-path $_})] [string]$InputFile,
[Parameter(Position = 8, Mandatory = $false)] [ValidateSet(&amp;quot;DataSet&amp;quot;, &amp;quot;DataTable&amp;quot;, &amp;quot;DataRow&amp;quot;)] [string]$As = &amp;quot;DataRow&amp;quot;
)
if ($InputFile) {
$filePath = $(resolve-path $InputFile).path
$Query = [System.IO.File]::ReadAllText(&amp;quot;$filePath&amp;quot;)
}
$conn = new-object System.Data.SqlClient.SQLConnection
if ($Username)
{ $ConnectionString = &amp;quot;Server={0};Database={1};User ID={2};Password={3};Trusted_Connection=False;Connect Timeout={4}&amp;quot; -f $ServerInstance, $Database, $Username, $Password, $ConnectionTimeout }
else
{ $ConnectionString = &amp;quot;Server={0};Database={1};Integrated Security=True;Connect Timeout={2}&amp;quot; -f $ServerInstance, $Database, $ConnectionTimeout }
&amp;amp;amp;n bsp; $conn.ConnectionString = $ConnectionString
#Following EventHandler is used for PRINT and RAISERROR T-SQL statements. Executed when -Verbose parameter specified by caller
if ($PSBoundParameters.Verbose) {
$conn.FireInfoMessageEventOnUserErrors = $true
$handler = [System.Data.SqlClient.SqlInfoMessageEventHandler] {Write-Verbose &amp;quot;$($_)&amp;quot;}
$conn.add_InfoMessage($handler)
}
$conn.Open()
$cmd = new-object system.Data.SqlClient.SqlCommand($Query, $conn)
$cmd.CommandTimeout = $QueryTimeout
$ds = New-Object system.Data.DataSet
$da = New-Object system.Data.SqlClient.SqlDataAdapter($cmd)
[void]$da.fill($ds)
$conn.Close()
switch ($As) {
'DataSet' { Write-Output ($ds) }
'DataTable' { Write-Output ($ds.Tables) }
'DataRow' { Write-Output ($ds.Tables[0]) }
}
} #Invoke-Sqlcmd2
# Check for existence of Backup file with correct name
If (!(Test-Path $LocationReplace)) {
Write-Output &amp;quot; There is no file called &amp;quot;
Write-Output $LocationReplace
Write-Output &amp;quot;Please correct and re-run&amp;quot;
break
}
# Remove Old Backups
if (Test-Path $locationFull) {
Remove-Item $LocationFUll -Force
}
if (Test-Path $locationTran) {
Remove-Item $LocationTran -Force
}
# Create Server objects
$Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer
$Mirror = New-Object Microsoft.SQLServer.Management.Smo.server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
# If database is on Mirror server fail it over to Principal
if ($DatabasePrincipal.IsAccessible -eq $False) {
$DatabaseMirror.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Failover)
}
# remove mirroring
$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Full Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup
$Backup.Action = $Full
$Backup.BackupSetDescription = &amp;quot;Full Backup of &amp;quot; + $DBName
$Backup.Database = $DatabasePrincipal.Name
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFull, $File)
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = &amp;quot;Log Backup of &amp;quot; + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFUll, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
# Resolve Orphaned Users if needed
#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 20 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize -Wrap
$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre></description></item><item><title>Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</link><pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</guid><description>&lt;p>There is a newer &lt;a class="link" href="https://blog.robsewell.com/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/" target="_blank" rel="noopener"
>up to date version of this post here&lt;/a> using the &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> and the sqlserver module&lt;/p>
&lt;p>But if you want to continue with this way read on!!&lt;/p>
&lt;p>Having created &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Windows Users&lt;/a> or &lt;a class="link" href="https://blog.robsewell.com/creating-sql-user-and-adding-to-server-role-with-powershell/" target="_blank" rel="noopener"
>SQL Users&lt;/a> using the last two days posts, today we shall add them to a role on a database.&lt;/p>
&lt;p>As I discussed &lt;a class="link" href="https://blog.robsewell.com/checking-sql-server-user-role-membership-with-powershell/" target="_blank" rel="noopener"
>previously&lt;/a> I believe that to follow good practice I try to ensure that database permissions are granted by role membership and each role is created with the minimum amount of permissions required for successful execution of the task involved.&lt;/p>
&lt;p>So with each database having the correct roles created and the users created we just need to add the user to the database and to the role. This is easily done with PowerShell.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image70.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image70.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The &lt;code>Add-UserToRole&lt;/code> function takes four parameters Server,Database,User and Role and does a series of error checks.&lt;/p>
&lt;p>With these functions you can easily create a number of Users and add them to database roles quickly and easily and repeatedly.&lt;/p>
&lt;p>If the test team come to you and require 10 Test Users and 3 Test Administrators adding to the test database. I create 2 notepad files&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image71.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image71.png"
loading="lazy"
alt="image"
>&lt;/a>Â  &lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image72.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image72.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and use them with the &lt;code>Add-SQLAccountToSQLRole&lt;/code> and &lt;code>Add-UserToRole&lt;/code> functions to create the users&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image73.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image73.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Here are the results in PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image74.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image74.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and in SSMS&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image75.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image75.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The Code is here&lt;/p>
&lt;pre>&lt;code>############################################################# ################################
#
# NAME: Add-UserToRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to add user or group to a role on a database
#
# USAGE: Add-UserToRole fade2black Aerosmith Test db_owner
#
Function Add-UserToRole ([string] $server, [String] $Database , [string]$User, [string]$Role)
{
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
#Check Database Name entered correctly
$db = $svr.Databases[$Database]
if($db -eq $null)
{
Write-Output &amp;quot; $Database is not a valid database on $Server&amp;quot;
Write-Output &amp;quot; Databases on $Server are :&amp;quot;
$svr.Databases|select name
break
}
#Check Role exists on Database
$Rol = $db.Roles[$Role]
if($Rol -eq $null)
{
Write-Output &amp;quot; $Role is not a valid Role on $Database on $Server &amp;quot;
Write-Output &amp;quot; Roles on $Database are:&amp;quot;
$db.roles|select name
break
}
if(!($svr.Logins.Contains($User)))
{
Write-Output &amp;quot;$User not a login on $server create it first&amp;quot;
break
}
if (!($db.Users.Contains($User)))
{
# Add user to database
$usr = New-Object ('Microsoft.SqlServer.Management. Smo.User') ($db, $User)
$usr.Login = $User
$usr.Create()
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User was not a login on $Database on $server&amp;quot;
Write-Output &amp;quot;$User added to $Database on $Server and $Role Role&amp;quot;
}
else
{
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User added to $Role Role in $Database on $Server &amp;quot;
}
}
&lt;/code>&lt;/pre></description></item></channel></rss>