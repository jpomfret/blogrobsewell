<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PowerShell on Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/categories/powershell/</link><description>Recent content in PowerShell on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 10 Jan 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/categories/powershell/index.xml" rel="self" type="application/rss+xml"/><item><title>SQLBits Agenda and PowerShell, displaying and searching</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-agenda-and-powershell-displaying-and-searching/</link><pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-agenda-and-powershell-displaying-and-searching/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2023/dragonsqlbitslogo.png" alt="Featured image of post SQLBits Agenda and PowerShell, displaying and searching" />&lt;h1 id="what-is-sqlbits">What is SQLBits?&lt;/h1>
&lt;p>&lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> is the largest data platform conference in Europe. It has been running every year since 2007 in a different city in the UK providing sessions into all things data platform. I have frequently &lt;a class="link" href="https://blog.robsewell.com/tags/#sqlbits" target="_blank" rel="noopener"
>written about SQLBits&lt;/a>, it is a conference close to my heart and has had a significant impact on my life, my career and my circle of friends.&lt;/p>
&lt;h2 id="where-and-when">Where and when?&lt;/h2>
&lt;p>This year it is in Newport, Wales at the International Convention Centre Wales (ICC) Tuesday 14th to Saturday 18th of March, 2023&lt;/p>
&lt;p>&lt;a class="link" href="https://events.sqlbits.com/2023/begin" target="_blank" rel="noopener"
>You can register to attend here&lt;/a>&lt;/p>
&lt;h2 id="what-is-there-at-sqlbits">What is there at SQLBits?&lt;/h2>
&lt;p>Tuesday and Wednesday are training days with all day sessions provided by subject matter experts including Microsoft Product Group members, Microsoft Valued Professionals, Microsoft Certified Trainers, and other experts. There are 30 options covering all areas of the Data Platform and none-technical sessions as well.&lt;/p>
&lt;p>You can see the &lt;a class="link" href="https://events.sqlbits.com/2023/training-days" target="_blank" rel="noopener"
>training day agenda here&lt;/a>&lt;/p>
&lt;p>Thursday and Friday have 50 minute, 20 minute and 5 minute sessions with a wide range of topics and levels.&lt;/p>
&lt;p>Saturday is the &lt;strong>FREE to attend&lt;/strong> day. It also has 50 minute, 20 minute and 5 minute sessions with a wide range of topics and levels.&lt;/p>
&lt;p>There are about 250 sessions on Thursday, Friday and Saturday&lt;/p>
&lt;p>You can see the &lt;a class="link" href="https://events.sqlbits.com/2023/agenda" target="_blank" rel="noopener"
>general session agenda here&lt;/a>&lt;/p>
&lt;h2 id="what-else-is-there-outside-of-technical-stuff">What else is there outside of technical stuff?&lt;/h2>
&lt;p>Oh My!!&lt;/p>
&lt;p>The biggest benefit is the people, for networking, for answering questions, building relationships with Microsoft product group or local Microsoft, meeting companies who are sponsoring, finding your new job or your new team members, learning and sharing with your peers.&lt;/p>
&lt;p>There is also a pub quiz on Thursday evening, the Friday night costume party, the community zone.&lt;/p>
&lt;h1 id="how-do-i-find-the-sessions">How do I find the sessions?&lt;/h1>
&lt;p>With so many sessions, its hard to find the ones that you want or to get a good overview in the format that you want. So I built a PowerShell module to get that information for you easily in any format you like. (Editor - thats a fib, he built it so that he could write Pester to ensure that speakers were not scheduled when they were not available)&lt;/p>
&lt;h1 id="the-sqlbitsps-module">The SQLBitsPS module&lt;/h1>
&lt;p>You can find the SQLBitsPS PowerShell module on the &lt;a class="link" href="https://www.powershellgallery.com/packages/SQLBitsPS" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211528862-5226d25a-5642-44a3-9c14-f88bfa334aa2.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211528862-5226d25a-5642-44a3-9c14-f88bfa334aa2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>As with all PowerShell modules from the Gallery, you can install it by running&lt;/p>
&lt;p>&lt;code>Install-Module SQLBitsPS&lt;/code>&lt;/p>
&lt;p>I find that a lot of people like to use the &lt;code>ShowWindow&lt;/code> parameter to have the help in another searchable window.&lt;/p>
&lt;p>&lt;code>Get-Help Get-SQLBitsSchedule -ShowWindow&lt;/code>
&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211530034-596f0fc9-ec1d-43fc-bd7a-ff1cf01c7c15.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211530034-596f0fc9-ec1d-43fc-bd7a-ff1cf01c7c15.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="use-the-help">Use the help&lt;/h2>
&lt;p>to find out how to use any PowerShell command you should use Get-Help and this module is no different. The help for the commands is built in and can be accessed with&lt;/p>
&lt;p>&lt;code>Get-Help Get-SQLBitsSchedule&lt;/code>&lt;/p>
&lt;h2 id="getting-the-schedule">Getting the schedule&lt;/h2>
&lt;p>You can just run &lt;code>Get-SQLBitsSchedule&lt;/code> and by default it will get the schedule and if you have the &lt;code>ImportExcel&lt;/code> module available it will write an Excel Workbook with each days agenda on a different sheet and colour code the service sessions like Registration, lunch and coffee breaks&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211530884-1d2b2752-a729-499d-8334-1e4404199002.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211530884-1d2b2752-a729-499d-8334-1e4404199002.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>To save you having to click to open Excel I have added a &lt;code>Show&lt;/code> parameter which will open it for you!&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211531837-2396cfd5-b843-4fd8-8a90-d1e1a06e654f.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211531837-2396cfd5-b843-4fd8-8a90-d1e1a06e654f.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="i-would-like-a-csv-instead">I would like a csv instead&lt;/h2>
&lt;p>The &lt;code>output&lt;/code> parameter gives you a number of options for the format of the output. If you do not have the &lt;code>ImportExcel&lt;/code> module it will default to &lt;code>-output csv&lt;/code> which you can also combine with the &lt;code>Show&lt;/code> parameter&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output csv -show&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211532406-bc928085-ab6f-4d8c-b42e-edc53ce027ca.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211532406-bc928085-ab6f-4d8c-b42e-edc53ce027ca.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="i-would-like-a-html-page-instead">I would like a html page instead&lt;/h2>
&lt;p>It&amp;rsquo;s not awesome but you can also create an HTML page. This may be useful if you wish to print the agenda yourself so that you have a hard copy.&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output html -show&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211533198-9bd8c53f-71b1-4426-bc1f-d7a8e874a86a.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211533198-9bd8c53f-71b1-4426-bc1f-d7a8e874a86a.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="let-me-decide-what-format-i-want">Let me decide what format I want&lt;/h2>
&lt;p>You can also output a &lt;code>[pscustomobject]&lt;/code> which you may use to PowerShell to your hearts content!!&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output object |Format-Table&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211533959-ee9f2fb5-e4be-45f2-9142-581833ee214f.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211533959-ee9f2fb5-e4be-45f2-9142-581833ee214f.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Maybe you would like to see the sessions that are on Friday at 16:50&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output object |Where-Object {$_.Day -eq 'Friday' -and $_.StartTime -eq '16:50'} &lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211534901-f75cfc82-71bc-456e-bb2c-306dd753cf9b.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211534901-f75cfc82-71bc-456e-bb2c-306dd753cf9b.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>They look amazing, I recommend Mladen Prajdic session. That one blew me away at Data Grillen and I may very well attend that again.&lt;/p>
&lt;h2 id="i-cant-do-anything-fancy-just-let-me-search">I can&amp;rsquo;t do anything fancy, just let me search&lt;/h2>
&lt;p>If all you want is to search for your favourite speaker then you can use the &lt;code>search&lt;/code> parameter which will perform a wildcard search.&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search Cathrine -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211536336-0202aec6-56f1-4f72-aa5b-4cc15de8f848.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211536336-0202aec6-56f1-4f72-aa5b-4cc15de8f848.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search Monica -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211535867-93496665-3423-4809-a1b3-561d56315594.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211535867-93496665-3423-4809-a1b3-561d56315594.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You can also use it search for topics&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search 'Mental Health' -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211536684-5b9a56e3-a487-40f4-aad7-f3656654c21a.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211536684-5b9a56e3-a487-40f4-aad7-f3656654c21a.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and even to search for wisdom!!&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search wisdom -output object &lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211537382-2a0ae647-cdc1-4ccc-82ba-87efe7fb857e.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211537382-2a0ae647-cdc1-4ccc-82ba-87efe7fb857e.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h1 id="i-want-to-make-it-better">I want to make it better&lt;/h1>
&lt;p>Awesome, thank you.&lt;/p>
&lt;p>This is all open-source and you can find it on GitHub at&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/SQLBitsPS" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/SQLBitsPS&lt;/a>&lt;/p>
&lt;p>There are some brief instructions here&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/SQLBitsPS/blob/main/DevelopingREADME.md" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/SQLBitsPS/blob/main/DevelopingREADME.md&lt;/a>&lt;/p>
&lt;h1 id="join-us">Join us&lt;/h1>
&lt;p>&lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> is the largest data platform conference in Europe. It has been running every year since 2007 in a different city in the UK providing sessions into all things data platform.&lt;/p>
&lt;h2 id="where-and-when-1">Where and when?&lt;/h2>
&lt;p>This year it is in Newport, Wales at the International Convention Centre Wales (ICC) Tuesday 14th to Saturday 18th of March, 2023&lt;/p>
&lt;p>&lt;a class="link" href="https://events.sqlbits.com/2023/begin" target="_blank" rel="noopener"
>You can register to attend here&lt;/a>&lt;/p></description></item><item><title>How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</guid><description>&lt;img src="https://images.unsplash.com/photo-1614791962365-7590111b1b1c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80" alt="Featured image of post How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error" />&lt;p>There are a number of methods to import PowerShell modules into Azure automation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>as described in the documentation here&lt;/a>&lt;/p>
&lt;p>You may however miss an important piece of information hidden in that documentation if you are uploading a module from a GitHub release instead of via the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. The name that you refer to the module must match the module name and module folder name in the zip file.&lt;/p>
&lt;h1 id="method-one---from-gallery">Method one - from Gallery&lt;/h1>
&lt;p>This is my preferred method for importing modules into Azure Automation accounts, the only bothersome part is remembering to do it twice, once for 5.1 and once for 7.1 as I am sure that if I forget that will be the one module that I will need!&lt;/p>
&lt;h2 id="find-the-module">Find the module&lt;/h2>
&lt;p>Go to the Module page for the automation account and then Add module and browse the gallery and search for &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> (other modules are available!) and install it&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550108-e6096986-3392-4585-a57a-5c515c2890bf.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>It will take a few moments to install but you will see it in the list with a green tick once it has imported.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181548887-0ec695e4-41b9-45b3-8ab3-a004968c2323.png"
loading="lazy"
alt="image"
>#&lt;/p>
&lt;p>Then it is available in all of my PowerShell 7.1 runbooks in my automation account - Here I have just run &lt;code>Get-DbaToolsConfig&lt;/code> in a test runbook to prove that the module has imported&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550937-7e89c7b3-31e8-4af1-b965-c82f2f63562f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="method-two---using-the-zip-file-from-a-github-release">Method two - using the zip file from a GitHub Release&lt;/h1>
&lt;p>Sometimes you may wish to not use the PowerShell Gallery to import the modules, maybe you have a custom module that you are not ready to upload to the gallery or maybe the module is just internally developed and not available on the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. In this scenario, you can still import hte module so that it can be used by your runbooks.&lt;/p>
&lt;p>To demonstrate, I will remove the dbatools module from the Automation Account&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181553061-9be2da4d-344d-4027-aa7f-902445cee12b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and download the latest release from GitHub directly&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/dataplat/dbatools/releases/tag/v1.1.118" target="_blank" rel="noopener"
>https://github.com/dataplat/dbatools/releases/tag/v1.1.118&lt;/a>&lt;/p>
&lt;p>If you are unable to use the PowerShell Gallery to get the latest dbatools release, I would always use the official signed release.&lt;/p>
&lt;p>You can then upload the zip from the same Modules page using the Browse for file but here is the &lt;em>important bit&lt;/em> You must update the name of the module. By default Azure will set the name to match the name of the zip file as that is what is expected and indeed mentioned in the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules#author-modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft documentation here &lt;/a>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181561112-6aecd5e3-efaa-4b2a-84d7-f7e521035d04.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and once it is imported successfully and I have a green tick&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181564377-df8c707e-24ec-43eb-8d57-702fcb39400b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>I can run the test - Again I just ran &lt;code>Get-DbaToolsConfig&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181569077-2b2e59e2-4bf1-46b6-851f-2e624cf9c43c.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>This method will work with both PowerShell 5.1 and PowerShell 7.1, you will just have to upload the zip (and remember to rename the module entry) twice.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571123-8acb8ff5-7b36-4b62-91f7-34b3df36a1d8.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571518-909ecc6f-9270-45d2-a7b5-0de4406c88c4.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="when-it-goes-wrong">When it goes wrong&lt;/h1>
&lt;p>If you do not rename the module correctly but leave it as the name of file &lt;code>dbatools-signed&lt;/code> in this example&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571939-b881b4bc-4449-4569-b71a-66142436158a.png"
loading="lazy"
alt="image"
>
.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181572041-2fe18929-cc14-40ae-b654-62653206903f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;blockquote>
&lt;p>Error importing the module dbatools-signed. Import failed with the following error:&lt;br>
Orchestrator.Shared.AsyncModuleImport.ModuleImportException: Cannot import the module of name dbatools-signed, as the module structure was invalid. at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.ExecuteInternal(CodeActivityContext context, Byte[] moduleContent, String moduleName, ModuleLanguage moduleLanguage) at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.Execute(CodeActivityContext context) at&lt;br>
System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)&lt;/p>
&lt;/blockquote>
&lt;p>If you get that, just re-upload the zip file and use the correct name in the form.&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Creating A Training Day Speakers List with GitHub Action from a GitHub Issue</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-training-day-speakers-list-with-github-action-from-a-github-issue/</link><pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-training-day-speakers-list-with-github-action-from-a-github-issue/</guid><description>&lt;img src="https://images.unsplash.com/photo-1620712943543-bcc4688e7485?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=930&q=80" alt="Featured image of post Creating A Training Day Speakers List with GitHub Action from a GitHub Issue" />&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/blog/community/Training-Day-Speakers-List" >The last post&lt;/a> showed the resource that we created to enable speakers to let events know that they have content for pre-cons/training days. This post will describe how the automation was created using a GitHub Issue and two GitHub Actions.&lt;/p>
&lt;h1 id="what-do-we-need">What do we need?&lt;/h1>
&lt;p>The idea was to have a form for user input that could easily allow a person to add themselves and some information to a web page. The page holds a list of speakers who can present training day sessions for data platform events. &lt;a class="link" href="https://callfordataspeakers.com/precon" target="_blank" rel="noopener"
>The web page can be found here&lt;/a>. This page is generated from a JSON file.&lt;/p>
&lt;h1 id="a-new-repository">A new repository&lt;/h1>
&lt;p>It was decided to use a GitHub repository to hold this information so that it is available publicly as well as via the website.&lt;/p>
&lt;h1 id="create-a-dev-container">Create a dev container&lt;/h1>
&lt;p>It&amp;rsquo;s a brand new repository &lt;code>.devcontainer&lt;/code> directory was created and the files from the &lt;a class="link" href="https://github.com/microsoft/vscode-dev-containers/tree/main/containers/powershell/.devcontainer" target="_blank" rel="noopener"
>Microsoft VS Code Remote / GitHub Codespaces Container Definitions repository PowerShell containers&lt;/a> added. This means that whenever I or anyone else wants to work on the repo the development experience will be the same.&lt;/p>
&lt;h2 id="add-extensions">Add extensions&lt;/h2>
&lt;p>There are a number of default extensions that I install for PowerShell or generic development&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.powershell" target="_blank" rel="noopener"
>ms-vscode.powershell&lt;/a> - because I am working with PowerShell&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=2gua.rainbow-brackets" target="_blank" rel="noopener"
>2gua.rainbow-brackets&lt;/a> - because I like to easily see which opening bracket matches which closing bracket&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=oderwat.indent-rainbow" target="_blank" rel="noopener"
>oderwat.indent-rainbow&lt;/a> - so that I can quickly see the indentations, invaluable with YAML files&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=usernamehw.errorlens" target="_blank" rel="noopener"
>usernamehw.errorlens&lt;/a> - so that linting errors are displayed in the editor alongside the code&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens" target="_blank" rel="noopener"
>eamodio.gitlens&lt;/a> - to make source control easier&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=TylerLeonhardt.vscode-inline-values-powershell" target="_blank" rel="noopener"
>TylerLeonhardt.vscode-inline-values-powershell&lt;/a> - so that you can see inline values when debugging&lt;/li>
&lt;/ul>
&lt;p>I also added two more for this repository as we are using GitHub Actions&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=me-dutour-mathieu.vscode-github-actions" target="_blank" rel="noopener"
>me-dutour-mathieu.vscode-github-actions&lt;/a> - for intellisense for GitHub Action files&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=cschleiden.vscode-github-actions" target="_blank" rel="noopener"
>cschleiden.vscode-github-action&lt;/a> - to be able to start/stop/monitor GitHub Actions from the workspace&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/githubactionsview.png"
loading="lazy"
alt="the view in codespaces of the GitHub Actions"
>&lt;/p>
&lt;h1 id="gather-the-information">Gather the Information&lt;/h1>
&lt;p>People can update repositories using Pull Requests but this needed to be a little more guided and it was decided that it was to be done with &lt;a class="link" href="https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/configuring-issue-templates-for-your-repository#creating-issue-forms" target="_blank" rel="noopener"
>forms via GitHub Issues&lt;/a>&lt;/p>
&lt;h2 id="where-to-put-it">Where to put it?&lt;/h2>
&lt;p>You can create custom GitHub Issues using YAML files in the &lt;code>.github/ISSUE_TEMPLATE&lt;/code> directory. An Add Speaker issue template file was created. The name and the description will be seen on the &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/new/choose" target="_blank" rel="noopener"
>new issues page&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">name: Add Speaker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">description: Add New Speaker information
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">body:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - type: markdown
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> attributes:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> value: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Please follow the instructions to create a new speaker entry.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> We wil display this on callfordataspeakers.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There are a number of &lt;code>-type&lt;/code> entries. &lt;a class="link" href="https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/syntax-for-githubs-form-schema" target="_blank" rel="noopener"
>You can find the definitions in the docs&lt;/a> or you can use the intellisense from the extensions. The types are checkboxes, dropdown, input, markdown, textarea&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/intellisense-ghactions.png"
loading="lazy"
alt="The intellisense showing the type options"
>&lt;/p>
&lt;p>I used the intellisense to build a quick simple form to gather 5 pieces of information&lt;/p>
&lt;ul>
&lt;li>full name&lt;/li>
&lt;li>topics&lt;/li>
&lt;li>regions&lt;/li>
&lt;li>sessionize profile URL&lt;/li>
&lt;li>languages&lt;/li>
&lt;/ul>
&lt;p>You can find &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/blob/main/.github/ISSUE_TEMPLATE/Add-Speaker.yml" target="_blank" rel="noopener"
>the YAML file here&lt;/a> and &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/new?assignees=&amp;amp;labels=&amp;amp;template=Add-Speaker.yml" target="_blank" rel="noopener"
>the issue here&lt;/a>&lt;/p>
&lt;h1 id="process-the-information">Process the information&lt;/h1>
&lt;p>Now that we have a method of gathering the information, the next stage is to process it automagically. For this we are going to be &lt;a class="link" href="https://docs.github.com/en/actions" target="_blank" rel="noopener"
>using GitHub Actions&lt;/a>&lt;/p>
&lt;h2 id="workflow">Workflow&lt;/h2>
&lt;p>GitHub Actions is a platform that can run automated processes called workflows that are defined as YAML files and triggered by events in the repository. We create another directory called &lt;code>workflows&lt;/code> also in the &lt;code>.github&lt;/code> directory.&lt;/p>
&lt;h2 id="triggering-the-workflow">Triggering the workflow&lt;/h2>
&lt;p>Many people are comfortable with a DevOps process that will build, test and deploy code when a pull request is raised and approved, GitHub Actions are able to do more as they can be triggered by any events in the repository.&lt;/p>
&lt;p>You can automatically add labels, close stale issues and much more. There are a large number of events open to you as &lt;a class="link" href="https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows" target="_blank" rel="noopener"
>can be seen here &lt;/a>. Even looking at just issues there are a number of activities types that can be used&lt;/p>
&lt;ul>
&lt;li>opened&lt;/li>
&lt;li>edited&lt;/li>
&lt;li>deleted&lt;/li>
&lt;li>transferred&lt;/li>
&lt;li>pinned&lt;/li>
&lt;li>unpinned&lt;/li>
&lt;li>closed&lt;/li>
&lt;li>reopened&lt;/li>
&lt;li>assigned&lt;/li>
&lt;li>unassigned&lt;/li>
&lt;li>labeled&lt;/li>
&lt;li>unlabeled&lt;/li>
&lt;li>locked&lt;/li>
&lt;li>unlocked&lt;/li>
&lt;li>milestoned&lt;/li>
&lt;li>demilestoned&lt;/li>
&lt;/ul>
&lt;p>(and there are separate ones for issue comments)&lt;/p>
&lt;p>The beginning of the workflow YAML file has the name and then the trigger. This triggers the workflow when an issue is opened.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">name: Add a new speaker json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issues:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> types:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#34;opened&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="getting-all-the-source">Getting all the source&lt;/h2>
&lt;p>The workflow consists of &lt;a class="link" href="https://docs.github.com/en/actions/using-jobs" target="_blank" rel="noopener"
>one or many jobs&lt;/a> that can be run on different runners. The first job is named &lt;code>AddNewSpeaker&lt;/code> and runs on the latest ubuntu version. Each job can have a number of steps and the first step in this scenario is to checkout the latest version of the repository.&lt;/p>
&lt;p>We &lt;strong>&lt;em>use&lt;/em>&lt;/strong> a default &lt;strong>&lt;em>action&lt;/em>&lt;/strong> to checkout and because we push changes back to the repository (more on that later) we choose a &lt;code>fetch-depth&lt;/code> of 0 to get all of the history and the &lt;code>ref&lt;/code> main as that is the branch we are working with.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">jobs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addNewSpeaker:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> runs-on: ubuntu-latest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> steps:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - uses: actions/checkout@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fetch-depth: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ref: main
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="being-polite">Being polite&lt;/h2>
&lt;p>costs nothing so this action from Peter Evans can be used to add or update a comment&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Add comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Hi @${{ github.event.issue.user.login }},
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Thank you so much for your Speaker submission.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The Action should be running now and adding it to the webpage. It should should update here.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If it doesn&amp;#39;t - get in touch with Rob on Twitter https://twitter.com/sqldbawithbeard
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="wait-a-minute-how-did-you-work-that-out">wait a minute, how did you work that out?&lt;/h3>
&lt;p>The say thank you comment uses &lt;code>github.event.issue.number&lt;/code> and &lt;code>github.event.issue.user.login&lt;/code> to ensure that the comment goes on the issue that triggered the workflow and thanks the user that created it. To work out what is available, I used this PowerShell step to write out the GitHub context to the logs as JSON&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># You also can print the whole GitHub context to the logs to view more details.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: View the GitHub context
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> run: Write-Host &amp;#34;$GITHUB_CONTEXT&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> env:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> GITHUB_CONTEXT: ${{ toJson(github) }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shell: pwsh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="get-the-info-into-a-file">Get the info into a file&lt;/h2>
&lt;p>Whilst developing, I first saved the issue body to a file so that I could work with it. As I moved forward I forgot and just left the code in and it works. The issue form creates &lt;code>### &amp;lt;label&amp;gt;&lt;/code> and then a blank line and then the data that was entered. This enabled me to use some regex and capture each label, grab the data and put it in a &lt;code>pscustomobject&lt;/code>&lt;/p>
&lt;p>Then I could convert it to Json and save it to a file. I chose to save each speakers information in their own file in case anything else would be needed in the future and also so that if the process failed it only affected this speakers information.&lt;/p>
&lt;p>I also add the speaker file name to a text file that I may make use of at some future point.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Get Speaker Information to file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> run: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Host &amp;#34;What do we have?&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # gci -recurse = this is for troubleshooting because paths are hard
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IssueBody = &amp;#34;${{ github.event.issue.body }}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write-Host $IssueBody
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IssueBody | Out-File speakers/temp.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # get the temp file contents - I do this so I don&amp;#39;t lose anything
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $file = Get-Content ./speakers/temp.txt -Raw
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # parse the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $regexResult = [regex]::Matches($file, &amp;#39;(?ms)fullname\n\n(?&amp;lt;fullname&amp;gt;.*)\n\n### topics\n\n(?&amp;lt;topics&amp;gt;.*)\n\n### regions\n\n(?&amp;lt;regions&amp;gt;.*)\n\n### Sessionize\n\n(?&amp;lt;Sessionize&amp;gt;.*)\n\n### language\n\n(?&amp;lt;language&amp;gt;.*)\n&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # create an object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerObject = [PSCustomObject]@{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name = $regexResult[0].Groups[&amp;#39;fullname&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> topics = $regexResult[0].Groups[&amp;#39;topics&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> regions = $regexResult[0].Groups[&amp;#39;regions&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sessionize = $regexResult[0].Groups[&amp;#39;Sessionize&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> language = $regexResult[0].Groups[&amp;#39;language&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #save it to a file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerFileName = $SpeakerObject.name -replace &amp;#39; &amp;#39;, &amp;#39;-&amp;#39; -replace &amp;#39;&amp;#39;&amp;#39;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;/&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\\&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;:&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\*&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\?&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;&amp;#34;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\|&amp;#39;,&amp;#39;-&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $filePath = &amp;#39;./speakers/{0}.json&amp;#39; -f $speakerFileName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $SpeakerObject |ConvertTo-Json | Out-FIle -FilePath $filePath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerFileName | OUt-File ./speakers/list.txt -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shell: pwsh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="because-ben-is-a-fantastic-tester">Because Ben is a fantastic tester&lt;/h3>
&lt;p>All the best testers will do unexpected but valid actions and my wonderful friend Ben Weissman (&lt;a class="link" href="https://twitter.com/bweissman" target="_blank" rel="noopener"
>Twitter&lt;/a> &lt;a class="link" href="https://bweissman.azurewebsites.net/" target="_blank" rel="noopener"
>Blog&lt;/a>) added some characters into the full name option that made the file save fail. He added his pronouns, which is awesome but not what I expected for a full name option. This is totally my fault for not considering either using pronouns or that as a user input field that is used in code the data should be validated. I used a few replaces to ensure the file name is acceptable.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$speakerFileName = $SpeakerObject.name -replace &amp;#39; &amp;#39;, &amp;#39;-&amp;#39; -replace &amp;#39;&amp;#39;&amp;#39;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;/&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\\&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;:&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\*&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\?&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;&amp;#34;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\|&amp;#39;,&amp;#39;-&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="let-the-user-know-and-commit-the-new-file">Let the user know and commit the new file&lt;/h2>
&lt;p>Next up is another comment, this time to show some progress but also add a link to the created files directory so that the speaker can see it. They can also edit this file if they wish to make any changes. (yes, maybe I should have thought of a way to do it with issues but this is an iterative process).&lt;/p>
&lt;p>I love the &lt;code>EndBug/add-and-commit&lt;/code> action as it enables me to make changes in a workflow and commit those changes safely back to the repository.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Add another comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The Speaker Json has been added https://github.com/dataplat/DataSpeakers/tree/main/speakers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Add &amp;amp; Commit
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: EndBug/add-and-commit@v8.0.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> author_name: Beardy McBeardFace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> author_email: mrrobsewell@outlook.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> message: &amp;#39;The Beard says hooray we have another speaker @${{ github.event.issue.user.login }} - This is an automated message&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="dry">DRY&lt;/h2>
&lt;p>Don&amp;rsquo;t repeat yourself. The idea is to create the JSON file for the web-page from each of the speakers individual json files. People will want to change what they have entered or they will make mistakes, future functionality might require the same steps. With this in mind I created a separate workflow file to create the &lt;code>speaker-list.json&lt;/code> file. This used two different triggers&lt;/p>
&lt;ul>
&lt;li>&lt;code>workflow_calls&lt;/code> so that it can be called from another workflow&lt;/li>
&lt;li>&lt;code>workflow_dispatch&lt;/code> so that it can be run manually&lt;/li>
&lt;/ul>
&lt;p>The other workflow cannot be triggered manually as it relies on an issue to create the required file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_call:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_dispatch:
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="only-run-if">Only run if&lt;/h2>
&lt;p>The second workflow file uses a PowerShell action to combine the individual JSONs into a single one and commits that to the repository. It also comments on the issue but it can only do this if the workflow was triggered from the add speaker job and not manually so some conditional logic was required. There were a number of options that I could choose to decide if to run this step but I decided on using the event issue number &lt;code>if: github.event.issue.number != null&lt;/code> as if there was no issue, there was nothing to comment and this would leave this step open to be used in future coding if required.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">- name: Add another comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if: github.event.issue.number != null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The speaker-list.json file has been recreated ready for the website https://github.com/dataplat/DataSpeakers/blob/main/website/speaker-list.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> https://callfordataspeakers.com/precon should be updated now
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="calling-another-workflow">Calling another workflow&lt;/h2>
&lt;p>To call another workflow in a job you use the &lt;code>uses:&lt;/code> field and the path to the yaml file and the branch. We also added the &lt;code>needs:&lt;/code> so that this job will run after the &lt;code>addNewSpeaker&lt;/code> has completed.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">createSpeakerListJson:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> needs: addNewSpeaker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: dataplat/DataSpeakers/.github/workflows/wesbiteFile.yml@main
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="close-the-issue">Close the issue&lt;/h2>
&lt;p>This process needed to be completely automatic and so we use Peter Evans close issue action and tag the speaker and say thankyou as well as closing the issue. We have a &lt;code>needs:&lt;/code> property so that this job will only run following the successful run of the previous two jobs.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">closeIssue:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> needs: [addNewSpeaker,createSpeakerListJson]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> runs-on: ubuntu-latest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> steps:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Close Issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/close-issue@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> comment: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Hey @${{ github.event.issue.user.login }},
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Closing this issue now that the Action has run successfully.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Thank you so much for adding your information to the list.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It will be active on callfordataspeakers.com shortly.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Please share on social media.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Love and Hugs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Rob and Daniel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @SqlDbaWithABeard @dhmacher
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="show-me-what-it-looks-like">Show me what it looks like&lt;/h1>
&lt;p>You can &lt;a class="link" href="https://github.com/dataplat/DataSpeakers" target="_blank" rel="noopener"
>take a look at the repo&lt;/a> there are a &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues?q=is%3Aissue&amp;#43;is%3Aclosed" target="_blank" rel="noopener"
>number of issues&lt;/a> like &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/36" target="_blank" rel="noopener"
>this one from Monica Rathbun&lt;/a> (&lt;a class="link" href="https://twitter.com/SQLEspresso" target="_blank" rel="noopener"
>Twitter&lt;/a> - &lt;a class="link" href="https://sqlespresso.com/" target="_blank" rel="noopener"
>Blog&lt;/a>)&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/monissue.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/monissue.png"
loading="lazy"
alt="Monicas Image"
>&lt;/a>&lt;/p>
&lt;p>you can see the workflows &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/actions" target="_blank" rel="noopener"
>running here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/workflowrun.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/workflowrun.png"
loading="lazy"
alt="workflow run"
>&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Using PowerShell to Automate StreamLabs OBS and Show Your Webcam in PowerPoint</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-automate-streamlabs-obs-and-show-your-webcam-in-powerpoint/</link><pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-automate-streamlabs-obs-and-show-your-webcam-in-powerpoint/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/09/scottwitter.png" alt="Featured image of post Using PowerShell to Automate StreamLabs OBS and Show Your Webcam in PowerPoint" />&lt;h2 id="it-started-with-a-tweet">It started with a tweet&lt;/h2>
&lt;p>As with many things in my life it started with a tweet&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/sammydeprez/status/1307674009669074945" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/scottwitter.png"
loading="lazy"
alt="Twitter"
>&lt;/a>&lt;/p>
&lt;p>That looks awesome, I thought, so I watched the YouTube video.Scott has written a C# application that would change the scene depending on some text in the PowerPoint slide notes. Then, by applying a Chroma filter to the display capture and placing the webcam capture appropriately, when the slide changed, the Obs scene changed and the webcam became embedded in the slide!!!!!!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>It is truly awesome but it is for Obs and I use StreamLabs and I wondered if it could be done with PowerShell.&lt;/p>
&lt;p>(If you just want the code, &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/PowerPointSlobs.ps1" target="_blank" rel="noopener"
>you can find it here&lt;/a>)&lt;/p>
&lt;h2 id="listen-to-powerpoint-events-with-powershell">Listen to PowerPoint Events with PowerShell&lt;/h2>
&lt;h3 id="create-a-com-object">Create a Com Object&lt;/h3>
&lt;p>The first thing that we need to do is to find out when the PowerPoint Slide has changed.&lt;/p>
&lt;p>You can create a PowerPoint Com Object with&lt;/p>
&lt;pre>&lt;code>$Application = New-Object -ComObject PowerPoint.Application
&lt;/code>&lt;/pre>
&lt;p>and make it visible with&lt;/p>
&lt;pre>&lt;code>$Application.Visible = 'MsoTrue'
&lt;/code>&lt;/pre>
&lt;h3 id="get-the-slide-number-and-notes">Get the Slide Number and Notes&lt;/h3>
&lt;p>Next step is to get the slide number. It is not truly required for the code, but I like to print it out so that I know which slide I was on for trouble shooting.&lt;/p>
&lt;p>Looking at &lt;a class="link" href="https://github.com/shanselman/PowerPointToOBSSceneSwitcher/blob/accf2c40d0f1cbb31287751bd7be4ae2fe0d3bb7/Program.cs#L34" target="_blank" rel="noopener"
>Scotts code here&lt;/a> I worked out that the slide number via PowerShell was&lt;/p>
&lt;pre>&lt;code>$slideNumber = $PowerPoint.SlideShowWindows[1].view.Slide.SlideIndex
&lt;/code>&lt;/pre>
&lt;p>The notes (by looking at &lt;a class="link" href="https://github.com/shanselman/PowerPointToOBSSceneSwitcher/blob/accf2c40d0f1cbb31287751bd7be4ae2fe0d3bb7/Program.cs#L37" target="_blank" rel="noopener"
>code&lt;/a>) can be accessed at&lt;/p>
&lt;pre>&lt;code>$notes = $PowerPoint.SlideShowWindows[1].View.Slide.NotesPage.Shapes[2].TextFrame.TextRange.Text
&lt;/code>&lt;/pre>
&lt;p>then parse the notes to get the scene name which is defined as &lt;code>OBS:SceneName&lt;/code>&lt;/p>
&lt;pre>&lt;code>$SceneName = ($notes -split &amp;quot;`r&amp;quot;)[0] -replace 'OBS:', ''
&lt;/code>&lt;/pre>
&lt;p>The first part gets the first line and it was thanks to Andreas on twitch who got this working, Thank you Andreas.&lt;/p>
&lt;h3 id="listen-to-an-event">Listen to an Event&lt;/h3>
&lt;p>With PowerShell, you can subscribes to events and take action when they fire. The event that we are going to subscribe to is called &lt;code>SlideShowNextSlide&lt;/code>&lt;/p>
&lt;pre>&lt;code>$subscriber = Register-ObjectEvent -InputObject $PowerPoint -EventName SlideShowNextSlide -Action $action
&lt;/code>&lt;/pre>
&lt;p>We have defined an $action variable in the code but we need to provide an action and this is where things got a little tricky.&lt;/p>
&lt;h2 id="automating-streamlabs-obs">Automating StreamLabs OBS&lt;/h2>
&lt;p>In Scotts code he uses OBS.WebSocket.NET to control OBS. Excellent, PowerShell and .NET.Unfrotunately, StreamLabs uses an RPC-based API &lt;a class="link" href="https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html" target="_blank" rel="noopener"
>https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html&lt;/a>&lt;/p>
&lt;p>This documentation specifies&lt;/p>
&lt;blockquote>
&lt;p>You can access services&amp;rsquo; methods and properties by sending JSON-RPC messages to the named pipe slobs.&lt;/p>
&lt;/blockquote>
&lt;h3 id="thank-you-keith-hill">Thank you Keith Hill&lt;/h3>
&lt;p>So Rob traversed a rabbit warren of investigation to understand how to send messages to this API with PowerShell and eventually stumbled across the marvelous Keith Hill &lt;a class="link" href="https://rkeithhill.wordpress.com/" target="_blank" rel="noopener"
>blog&lt;/a> &lt;a class="link" href="https://twitter.com/r_keith_hill" target="_blank" rel="noopener"
>twitter&lt;/a> and a blog post from 2014&lt;/p>
&lt;p>&lt;a class="link" href="https://rkeithhill.wordpress.com/2014/11/01/windows-powershell-and-named-pipes/" target="_blank" rel="noopener"
>https://rkeithhill.wordpress.com/2014/11/01/windows-powershell-and-named-pipes/&lt;/a>&lt;/p>
&lt;h3 id="create-a-connection-and-send-and-receive-messages">Create a connection and send and receive messages&lt;/h3>
&lt;p>Now I had everything I needed to create a connection to SLOBS via named pipes. SLOBS needs to be started here!&lt;/p>
&lt;pre>&lt;code># Create Client
$npipeClient = New-Object System.IO.Pipes.NamedPipeClientStream($Env:ComputerName, 'slobs', [System.IO.Pipes.PipeDirection]::InOut, [System.IO.Pipes.PipeOptions]::None, [System.Security.Principal.TokenImpersonationLevel]::Impersonation)
$npipeClient.Connect()
$npipeClient
# Create Reader and writer and send and receive message
$pipeReader = New-Object System.IO.StreamReader($npipeClient)
$pipeWriter = New-Object System.IO.StreamWriter($npipeClient)
$pipeWriter.AutoFlush = $true
# Send message
$pipeWriter.WriteLine($scenesMessage)
# Receive message
$pipeReader.ReadLine()
&lt;/code>&lt;/pre>
&lt;h3 id="which-messages">Which messages?&lt;/h3>
&lt;p>Next I needed to get the messages to send formatted correctly. Looking at the &lt;a class="link" href="https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html#examples" target="_blank" rel="noopener"
>API docs&lt;/a> I saw&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,
&amp;quot;id&amp;quot;: 1,
&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>So I was able to get the current available scenes with&lt;/p>
&lt;pre>&lt;code>$scenesMessage = '{&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,&amp;quot;id&amp;quot;: 6,&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,&amp;quot;params&amp;quot;: {&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;}}'
$pipeWriter.WriteLine($scenesMessage)
($pipeReader.ReadLine() | ConvertFrom-Json).result | Select Name, id
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/getslobsscenes.png"
loading="lazy"
alt="Get SLOBS Scenes"
>&lt;/p>
&lt;h3 id="change-scenes">Change Scenes&lt;/h3>
&lt;p>The last part of the jigsaw was to change the scene via the named pipe connection&lt;/p>
&lt;pre>&lt;code>$scenesMessage = '{&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,&amp;quot;id&amp;quot;: 6,&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,&amp;quot;params&amp;quot;: {&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;}}'
$pipeWriter.WriteLine($scenesMessage)
$scenes = ($pipeReader.ReadLine() | ConvertFrom-Json).result | Select Name, id
$SceneId = ($scenes | Where Name -eq $SceneName).id
$MakeSceneActiveMessage = '{ &amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;, &amp;quot;id&amp;quot;: 1, &amp;quot;method&amp;quot;: &amp;quot;makeSceneActive&amp;quot;, &amp;quot;params&amp;quot;: { &amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;,&amp;quot;args&amp;quot;: [&amp;quot;' + $SceneId + '&amp;quot;]}}'
$pipeWriter.WriteLine($MakeSceneActiveMessage)
$switchResults = $pipeReader.ReadLine() | ConvertFrom-Json
&lt;/code>&lt;/pre>
&lt;p>Which looks like this :-)&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="setting-up-powerpoint-and-scenes">Setting up PowerPoint and Scenes&lt;/h2>
&lt;p>With the PowerShell set up, we next need to set it up to use the scenes. I followed Scotts example and used &lt;code>OBS:SceneName&lt;/code> as the reference to the Scene. I added this to the first line of the notes on a slide&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/pptxnotes.png"
loading="lazy"
alt="Slide Notes"
>&lt;/p>
&lt;p>and then created a text box with a green fill&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/greenbox.png"
loading="lazy"
alt="Green Box"
>&lt;/p>
&lt;p>In StreamLabs, I set up the scene with the same name, the order of the sources is important. They are displayed from top to bottom, front to back so the Display Capture will be on top of the Sony Camera here&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/sourceorder.png"
loading="lazy"
alt="Source order"
>&lt;/p>
&lt;p>Then I right clicked on the Display Capture and chose Filters&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/choosefilters.png"
loading="lazy"
alt="choose filters"
>&lt;/p>
&lt;p>and chose a Chroma Key filter&lt;/p>
&lt;p>With the PowerPoint in SlideShow mode, I set the Chroma Key filter colour to match the colour of the green box, placed the camera source in the correct location and saved.&lt;/p>
&lt;p>The image below shows form left to right, the Chroma Key settings, the scene in SLOBS and the PowerPoint slideshow&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/setfilter.png"
loading="lazy"
alt="set filters"
>&lt;/p>
&lt;p>Normally, I would do this on seperate screens of course!&lt;/p>
&lt;p>I set up each slide like this and then I closed the PowerPoint and ran the code, &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/PowerPointSlobs.ps1" target="_blank" rel="noopener"
>you can find it here,&lt;/a>)leaving PowerShell running in the background. This opened PowerPoint and I opened the deck and started the slide show and as I navigate through the slide, the scene changes and so does the webcam position :-)&lt;/p>
&lt;p>You can see a test run below&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>and &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2020/test.pptx" target="_blank" rel="noopener"
>the demo pptx can be found here&lt;/a>&lt;/p></description></item><item><title>#tsql2sday #130 - Automate your stress away - Getting more SSIS Agent Job information</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-130-automate-your-stress-away-getting-more-ssis-agent-job-information/</link><pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-130-automate-your-stress-away-getting-more-ssis-agent-job-information/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/images/TSQL2sDay150x150.jpg" alt="Featured image of post #tsql2sday #130 - Automate your stress away - Getting more SSIS Agent Job information" />&lt;h1 id="automation">Automation&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>This month it is hosted by Elizabeth Noble &lt;!-- raw HTML omitted -->blog&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->twitter&lt;!-- raw HTML omitted -->.&lt;/p>
&lt;p>Thank you Elizabeth&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/p>
&lt;p>Elizabeth asks&lt;/p>
&lt;blockquote>
&lt;p>My invitation to you is I want to know what you have automated to make your life easier?&lt;/p>
&lt;/blockquote>
&lt;h2 id="from-the-past">From the Past&lt;/h2>
&lt;p>I am in the process of migrating my blog to GitHub pages and whilst doing so, I read my first ever technical blog post &lt;a class="link" href="https://blog.robsewell.com/blog/you-have-to-start-somewhere/" target="_blank" rel="noopener"
>You have to start somewhere&lt;/a> In it I mention this blog post by John Sansom &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>The Best Database Administrators Automate Everything&lt;/a> which I am pleased to see is still available nearly a decade later&lt;/p>
&lt;p>Here is a quote from his blog entry&lt;/p>
&lt;blockquote>
&lt;h2 id="automate-everything">Automate Everything&lt;/h2>
&lt;p>Thats right, I said everything. Just sit back and take the &lt;em>time&lt;/em> to consider this point for a moment. Let it wander around your mind whilst you consider the processes and tasks that you could look to potentially automate. Now eliminate the word &lt;em>potentially&lt;/em> from your vocabulary and evaluate how you could automate &lt;strong>e-v-e-r-y-t-h-i-n-g&lt;/strong> that you do.&lt;/p>
&lt;p>Even if you believe that there is only a remote possibility that you will need to repeat a given task, just go ahead and automate it anyway! Chances are that when the need to repeat the process comes around again, you will either be under pressure to get it done, or even better have more important &lt;em>Proactive Mode&lt;/em> tasks/projects to be getting on with&lt;/p>
&lt;/blockquote>
&lt;h2 id="i-love-automation">I love Automation&lt;/h2>
&lt;p>I have tried my best at all times to follow this advice in the last decade and pretty much I am happy that I have managed it.&lt;/p>
&lt;ul>
&lt;li>I use PowerShell (a lot!) to automate all sorts of routine tasks including migrating this blog&lt;/li>
&lt;li>I use &lt;a class="link" href="https://blog.robsewell.com/tags/#jupyter-notebooks" target="_blank" rel="noopener"
>Jupyter Notebooks&lt;/a> to enable myself and others to automate Run Books, Training, Documentation, Demonstrations, Incident Response. You can find my notebooks &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>here&lt;/a>&lt;/li>
&lt;li>I use Azure DevOps to automate infrastructure creation and changes with terraform and delivery of changes to code as well as unit testing.&lt;/li>
&lt;li>I use GitHub actions to create this blog, publish the &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a> module&lt;/li>
&lt;li>I use &lt;a class="link" href="https://chocolatey.org/" target="_blank" rel="noopener"
>Chocolatey&lt;/a> to install and update software&lt;/li>
&lt;li>I have used Desired State Configuration to ensure that infrastructure is as it is expected to be&lt;/li>
&lt;/ul>
&lt;p>At every point I am looking for a means to automate the thing that I am doing because it is almost guaranteed that there will be a time in the future after you have done a thing that there will be a need to do it again or to do it slightly differently.&lt;/p>
&lt;h2 id="whats-the-last-thing-that-you-automated">Whats the last thing that you automated?&lt;/h2>
&lt;p>Following my blog post about &lt;a class="link" href="https://blog.robsewell.com/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/" target="_blank" rel="noopener"
>Notifying a Teams Channel about a SQL Agent Job result&lt;/a> I was asked if this could be tweaked to reduce the time spent getting information about SSIS Execution failures.&lt;/p>
&lt;h3 id="finding-ssis-failures">Finding SSIS failures&lt;/h3>
&lt;p>When you run an SSIS package in an Agent Job and it fails, the Agent Job History shows something along these lines&lt;/p>
&lt;blockquote>
&lt;p>The job failed. The Job was invoked by User MyDomain\MyUserName. The last step to run was step 1 (scheduling ssis package).
Executed as user: NT Service\SQLSERVERAGENT. Microsoft (R) SQL Server Execute Package Utility Version 11.0.5058.0 for 64-bit Copyright (C) Microsoft Corporation. All rights reserved. Started: 4:17:12 PM Package execution on IS Server failed. &lt;strong>Execution ID: 123456789&lt;/strong>, Execution Status:4. To view the details for the execution, right-click on the Integration Services Catalog, and open the [All Executions] report Started: 4:17:12 PM Finished: 4:17:12 PM Elapsed: 4.493 seconds. The package execution failed. The step failed.&lt;/p>
&lt;/blockquote>
&lt;p>The next step is to open SSMS, go to the SSISDb and click through to the SSIS reports and then scroll through to find the package and then the message. This is not particularly efficient and the SSIS reports are not known for their speedy executions!&lt;/p>
&lt;p>This meant that the team member responsible for checking in the morning, could see which instance and which job had failed from the Teams message but then had to manually follow the above steps to find an error message that they could take action on.&lt;/p>
&lt;h3 id="automate-it">Automate it&lt;/h3>
&lt;p>In the SSISDB database there is an &lt;code>event_messages&lt;/code> view so if I could query that and filter by the Execution ID then I could get the message and place it into the Teams message. Now the Teams message contains the error for the SSIS execution and each time this happens it probably saves the team member 4 or 5 minutes :-)&lt;/p>
&lt;p>In the code below, I&lt;/p>
&lt;ol>
&lt;li>
&lt;p>check if the failure comes from an SSIS instance&lt;br>
if($Inst -in ($SSISInstances)){&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Get the Execution ID from the Error message&lt;br>
&lt;code>$ExecutionId = [regex]::matches($BaseerrMessage, 'Execution ID: (\d{3,})').groups[1].value&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a query for the SSISDB&lt;/p>
&lt;p>&lt;code>$SSISQuery = @&amp;quot;&lt;/code>&lt;br>
&lt;code>SELECT * FROM catalog.event_messages em&lt;/code>&lt;br>
&lt;code>WHERE em.operation_id = $ExecutionId&lt;/code>&lt;br>
&lt;code>AND (em.event_name = 'OnError')&lt;/code>&lt;br>
&lt;code>ORDER BY em.event_message_id;&lt;/code>&lt;br>
&lt;code>&amp;quot;@&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set the Error Message and the Execution Path to variables&lt;br>
&lt;code>$errMessage = $SSISQueryResults.Message&lt;/code>&lt;br>
&lt;code>$ExecutionPath = $SSISQueryResults.execution_path&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Get the Error Message for none SSIS failures&lt;br>
&lt;code>}else{&lt;/code>&lt;br>
&lt;code>$errMessage = $j.group[-1].Message&lt;/code>&lt;br>
&lt;code>$ExecutionPath = 'the job'&lt;/code>&lt;br>
&lt;code>}&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create the Teams message&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>You will see that I used &lt;code>SELECT *&lt;/code> because someone will always ask for some extra information in the future!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/images/happyrob.jpg"
loading="lazy"
>&lt;/p>
&lt;p>The full script is below, Happy Automating!&lt;/p>
&lt;pre>&lt;code>$webhookurl = &amp;quot;https://outlook.office.com/webhook/ the rest of it here&amp;quot;
$SSISInstances = # to identify SSIS instances
$ProdInstances = # ALL instances for checking
$startdate = (Get-Date).AddHours(-1)
$AllFailedJobs = foreach ($Instance in $ProdInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs # | Where-Object { $Psitem.Job -match '^Beard-\d\d\d\d\d' -or $Psitem.Job -like 'BeardJob*' } # if you need to filter
$FailedJobs = $jobs | Where-Object { $Psitem.Status -ne 'Succeeded' }
$FailedJobs | Group-Object Job
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;We have $($AllFailedJobs.Count) Failed Jobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
foreach ($j in $AllFailedJobs) {
$Inst = $j.group[-1].SqlInstance
$jName = $j.name
$sname = $j.group[-1].StepName
$edate = $j.group[-1].EndDate
if($Inst -in ($SSISInstances)){
$BaseerrMessage = $j.group[-1].Message
$ExecutionId = [regex]::matches($BaseerrMessage, 'Execution ID: (\d{3,})').groups[1].value
$SSISQuery = @&amp;quot;
SELECT * FROM catalog.event_messages em
WHERE em.operation_id = $ExecutionId
AND (em.event_name = 'OnError')
ORDER BY em.event_message_id;
&amp;quot;@
$SSISQueryResults = Invoke-DbaQuery -SqlInstance $Inst -Database SSISDB -Query $SSISQuery
$errMessage = $SSISQueryResults.Message
$ExecutionPath = $SSISQueryResults.execution_path
}else{
$errMessage = $j.group[-1].Message
$ExecutionPath = 'the job'
}
$Text = @&amp;quot;
# **$Inst**
## **$JName**
- The Job step that failed is - **$sname**
- It failed at - **$edate**
- It failed in $ExecutionPath with the message
- $errMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;in the Last 1 hour&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://blog.robsewell.com/assets/images/sobrob.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
if(-not $AllFailedJobs){
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There were no job failures in the last hour at $ (Get-Date)&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;There were no job failures at $ (Get-Date)&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;in the Last hour&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://blog.robsewell.com/assets/images/happyrob.jpg&amp;quot;
&amp;quot;text&amp;quot; = &amp;quot;All is well&amp;quot;
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
&lt;/code>&lt;/pre></description></item><item><title>Sending a SQL Agent Job results overview to a Microsoft Teams Channel</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</link><pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-11.png" alt="Featured image of post Sending a SQL Agent Job results overview to a Microsoft Teams Channel" />&lt;p>Microsoft Teams is fantastic for collaboration. It enables groups of people, teams if you like to be able to communicate, collaborate on documents, hold meetings and much much more.&lt;/p>
&lt;h2 id="sql-agent-job-overview">SQL Agent Job Overview&lt;/h2>
&lt;p>Using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> we can create a simple script to gather the results of Agent Jobs form a list of instances. Maybe it would be good to be able to get the job runs results every 12 hours so that at 6am in the morning the early-bird DBA can quickly identify if there are any failures that need immediate action and at 6pm , the team can check that everything was ok before they clock off.&lt;/p>
&lt;p>Here is an example of such a script&lt;/p>
&lt;pre>&lt;code>$SqlInstances = (Get-Vm -ComputerName BEARDNUC,BEARDNUC2).Where{$_.State -eq 'Running' -and $_.Name -like '*SQL*'}.Name
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and an example of running it.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-2.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-teams-channel">Create a Teams Channel&lt;/h2>
&lt;p>If you have permissions, you can create a new Teams channel by clicking on the 3 ellipses and add channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Then fill in the blanks&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-webhook-connector-for-the-channel">Create a Webhook Connector for the channel&lt;/h2>
&lt;p>Next, you need to have a connector for the channel, click on the 3 ellipses for the channel and click on connectors&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Then you can choose the Incoming Webhook connector and click configure&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>Give the connector a name and upload an image if you wish and click create&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The resulting screen will give you a URL that you can copy. If you need to find it again, then use the 3 ellipses again, click connectors and look at configured. You can then choose the webhook that you have created and click manage and you will find the URL.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-8.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="send-to-teams-using-powershell">Send to Teams using PowerShell&lt;/h2>
&lt;p>Now you can send a message to that Teams channel using PowerShell. You will need to add the webhook URL from your Teams connector&lt;/p>
&lt;pre>&lt;code>[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = &amp;quot;&amp;quot;
$Text = @&amp;quot;
# Here is a Title
and a message
Image is from
https://www.flickr.com/photos/157270154@N05/38494483572
Photo by CreditDebitPro
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;This is my summary&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Something Important &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;I have something to say&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>The code above will send a message that looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-9.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="running-as-a-sql-agent-job">Running as a SQL Agent Job&lt;/h2>
&lt;p>Now we can run this code as a SQL Agent Job and schedule it. Now, you may not be able to run that code on your SQL Server. It cannot connect to the internet, so how can we contact the Teams webhook?&lt;/p>
&lt;p>There are probably a number of ways to do this but the solution that I took, was to allow a proxy account the ability to use PSRemoting and run the part of the script that connects to Teams on a different machine, that does have connectivity.&lt;/p>
&lt;p>The script I used was as follows. You will need to add in the SQL Instances or better still dynamically gather them from your source of truth. You will need the webhook URL and the name of the server that can connect to Teams&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
$NotifyCommand = {
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = $Using:TeamsWebhook
$allJobsMessage = $Using:AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($Using:startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($Using:startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
&lt;/code>&lt;/pre>
&lt;p>Then, follow the steps at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a> to create an agent job to run the script above on an instance with the dbatools module available to the SQL Service account. Use or create a proxy with permissions on the notify server and create an Agent Job.&lt;/p>
&lt;pre>&lt;code>USE [msdb]
GO
/****** Object: Job [I am a Job that notifies Teams] Script Date: 27/07/2020 20:27:27 ******/
BEGIN TRANSACTION
DECLARE @ReturnCode INT
SELECT @ReturnCode = 0
/****** Object: JobCategory [[Uncategorized (Local)]] Script Date: 27/07/2020 20:27:28 ******/
IF NOT EXISTS (SELECT name FROM msdb.dbo.syscategories WHERE name=N'[Uncategorized (Local)]' AND category_class=1)
BEGIN
EXEC @ReturnCode = msdb.dbo.sp_add_category @class=N'JOB', @type=N'LOCAL', @name=N'[Uncategorized (Local)]'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
END
DECLARE @jobId BINARY(16)
EXEC @ReturnCode = msdb.dbo.sp_add_job @job_name=N'12 Hour Teams Notify',
@enabled=1,
@notify_level_eventlog=0,
@notify_level_email=0,
@notify_level_netsend=0,
@notify_level_page=0,
@delete_level=0,
@description=N'This job will notify Teams every 12 hours',
@category_name=N'[Uncategorized (Local)]',
@owner_login_name=N'THEBEARD\SQL_SVC', @job_id = @jobId OUTPUT
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
/****** Object: Step [Notify Teams] Script Date: 27/07/2020 20:27:28 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N'Notify Teams',
@step_id=1,
@cmdexec_success_code=0,
@on_success_action=1,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N'CmdExec',
@command=N'powershell.exe -File C:\temp\AgentJobs\NotifyTeams.ps1',
@flags=0,
@proxy_name=N'TheBeardIsMighty'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_update_job @job_id = @jobId, @start_step_id = 1
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_add_jobserver @job_id = @jobId, @server_name = N'(local)'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
COMMIT TRANSACTION
GOTO EndSave
QuitWithRollback:
IF (@@TRANCOUNT &amp;gt; 0) ROLLBACK TRANSACTION
EndSave:
GO
&lt;/code>&lt;/pre>
&lt;p>When the job runs&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>The results are posted to the Teams Channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>If you can run the Agent Job on a machine that can connect to Teams and your SQL Instances then you can remove the need to use a remote session by using this code&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$allJobsMessage = $AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Results &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>Happy automating!&lt;/p></description></item><item><title>Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/runas.png" alt="Featured image of post Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>my last post about the Secret Management module&lt;/a>. I was asked another question.&lt;/p>
&lt;blockquote>
&lt;p>Can I use this to run applications as my admin account?&lt;/p>
&lt;p>A user with a beard&lt;/p>
&lt;/blockquote>
&lt;p>It is good practice to not log into your work station with an account with admin privileges. In many shops, you will need to open applications that can do administration tasks with another set of account credentials.&lt;/p>
&lt;p>Unfortunately, people being people, they will often store their admin account credentials in a less than ideal manner (OneNote, Notepad ++ etc) to make it easier for them, so that when they right click and run as a different user, they can copy and paste the password.&lt;/p>
&lt;h2 id="use-the-secret-management-module">Use the Secret Management module&lt;/h2>
&lt;p>Again, I decided to use a notebook to show this as it is a fantastic way to share code and results and because it means that anyone can try it out.&lt;/p>
&lt;p>The notebook may not render on a mobile device.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Using the notebook, I can quickly store my admin password safely and open and run the applications using the credential&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/runas.png"
loading="lazy"
>&lt;/p></description></item><item><title>Good Bye Import-CliXML  Use the Secrets Management module for your labs and demos</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</link><pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-1.png" alt="Featured image of post Good Bye Import-CliXML  Use the Secrets Management module for your labs and demos" />&lt;p>Dont want to read all this? There are two dotnet interactive notebooks here with the relevant information for you to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;h2 id="jaap-is-awesome">Jaap is awesome&lt;/h2>
&lt;p>&lt;img src="https://pbs.twimg.com/media/DBbP9lHXYAAopb3?format=jpg&amp;amp;name=4096x4096"
loading="lazy"
>&lt;/p>
&lt;p>I have to start here. For the longest time, whenever anyone has asked me how I store my credentials for use in my demos and labs I have always referred them to Jaap Brassers &lt;a class="link" href="https://twitter.com/Jaap_Brasser" target="_blank" rel="noopener"
>t&lt;/a> blog post&lt;/p>
&lt;p>&lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/&lt;/a>&lt;/p>
&lt;h2 id="joel-is-also-awesome">Joel is also awesome!&lt;/h2>
&lt;p>When people wanted a method of storing credentials that didn&amp;rsquo;t involve files on disk I would suggest Joel Bennetts &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>t&lt;/a> module BetterCredentials which uses the Windows Credential Manager&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/BetterCredentials/4.5" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/BetterCredentials/4.5&lt;/a>&lt;/p>
&lt;h2 id="microsoft-also-awesome">Microsoft? Also awesome!&lt;/h2>
&lt;p>In February, Microsoft released the SecretManagement module for preview.&lt;/p>
&lt;p>&lt;a class="link" href="https://devblogs.microsoft.com/powershell/secrets-management-development-release?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://devblogs.microsoft.com/powershell/secrets-management-development-release/&lt;/a>&lt;/p>
&lt;p>Sydney &lt;a class="link" href="https://twitter.com/sydneysmithreal" target="_blank" rel="noopener"
>t&lt;/a> gave a presentation at the European PowerShell Conference which you can watch on Youtube.&lt;/p>
&lt;h2 id="good-bye-import-clixml">Good Bye Import-CliXML&lt;/h2>
&lt;p>So now I say, it is time to stop using Import-Clixml for storing secrets and use the Microsoft.PowerShell.SecretsManagement module instead for storing your secrets.&lt;/p>
&lt;h2 id="notebooks-are-as-good-as-blog-posts">Notebooks are as good as blog posts&lt;/h2>
&lt;p>I love notebooks and to show some people who had asked about storing secrets, I have created some. So, because I am efficient lazy I have embedded them here for you to see. You can find them in my Jupyter Notebook repository&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;p>in the Secrets folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-1.png?resize=630%2C349&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-and-using-the-secrets-management-module">Installing and using the Secrets Management Module&lt;/h2>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="using-the-secret-management-module-in-your-scripts">Using the Secret Management Module in your scripts&lt;/h2>
&lt;p>Here is a simple example of using the module to provide the credential for a docker container and then to dbatools to query the container&lt;/p>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>Running Jupyter Notebooks as Agent Jobs</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-jupyter-notebooks-as-agent-jobs/</link><pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-jupyter-notebooks-as-agent-jobs/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/03/image-22.png" alt="Featured image of post Running Jupyter Notebooks as Agent Jobs" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a great tool for connecting with your data platform whether it is in Azure or on your hardware. &lt;a class="link" href="https://blog.robsewell.com/?s=notebooks" target="_blank" rel="noopener"
>Jupyter Notebooks&lt;/a> are fantastic, you can have words, pictures, code and code results all saved in one document.&lt;/p>
&lt;p>I have created a repository in my GitHub &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>https://beard.media/Notebooks&lt;/a> where I have stored a number of Jupyter notebooks both for Azure Data Studio and the &lt;a class="link" href="https://blog.robsewell.com/new-net-notebooks-are-here-powershell-7-notebooks-are-here/" target="_blank" rel="noopener"
>new .NET interactive&lt;/a> notebooks.&lt;/p>
&lt;p>Another thing that you can do with notebooks is run them as Agent Jobs and save the results of the run.&lt;/p>
&lt;h3 id="notebooks-running-t-sql">Notebooks running T-SQL&lt;/h3>
&lt;p>This works easily for T-SQL notebooks. I am going to &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/blob/master/notebooks/NotDotNet/Audit/AUDIT%20-%20T-SQL%20Gather%20Permissions%20Notebook%20Template.ipynb" target="_blank" rel="noopener"
>use this one&lt;/a> that I created that uses T-SQL to gather permissions using old code that was in a share somewhere. We can run the notebook and get the permissions and save the notebook and the results will be available for all time (unless you delete the notebook!)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image.png?fit=630%2C327&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="sql-agent-extension-in-azure-data-studio">SQL Agent Extension in Azure Data Studio&lt;/h3>
&lt;p>In Azure Data Studio, if you press CTRL + SHIFT + X it will open the Extensions tab&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-1.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-1.png?resize=188%2C300&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can add extra functionality to Azure Data Studio. Search in the top bar for Agent and press the install button to install the extension. You can connect to and instance in the connections tab (CTRL + SHIFT + D) and right click on it and click Manage. This will open up the server dashboard (why isnt it instance dashboard?)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/7e393013-e088-4dfb-93e4-5e4961931999" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-2.png?fit=630%2C297&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and you will also have the SQL Agent dashboard available&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-3.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-3.png?fit=630%2C353&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Its pretty neat, it has green and red bars against the jobs showing success or failure and the larger the bar the longer the run time. On the left you will see a book. Click that&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-4.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-4.png?fit=630%2C295&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="notebooks-in-agent-jobs">Notebooks in Agent Jobs&lt;/h3>
&lt;p>You can create an Agent Job to run a notebook. As a notebook is just a json file, it can be stored in a database table. This interface will create two tables one to store the templates and one for the results. Click New Notebook Job&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-5.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-5.png?fit=630%2C989&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then navigate to the notebook and select it.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/d312799d-0cf7-4e9f-86ac-11c7f6e4977b" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-6.png?fit=630%2C379&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Choose a database for the storage of the template and the results and one for the execution context.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/a70ffec6-6ed9-43f5-8b4b-b3eed86abecd" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-7.png?fit=630%2C991&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The name of the job will be the file name of the notebook. You can change this but there is a bug where you can only enter one character at a time in the name before it changes focus so beware!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/03d25ab1-ccd9-4c8b-a880-1f6bf1641b42" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-8.png?fit=630%2C157&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Once the job is created, you will see two tables in the storage database notebooks.nb_materialized and notebooks.nb_template&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-9.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-9.png?fit=630%2C790&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The materialised table is empty right now&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-10.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-10.png?fit=630%2C405&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>but the template table has a row for the job which includes the notebook in json format.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/6b019c65-cd07-4295-9b8e-609456829574" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-11.png?fit=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If you click on the jobs in the Notebook Jobs window in the SQL Agent extension, you can see more information about the job run&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/5f93224f-b2a6-4c9c-9e71-a5f3668dcab9" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-12.png?fit=630%2C321&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can also run the job from here. It doesnt have to be run from here, it is just a normal agent job which you can run or schedule in any normal manner. Running it from here gives a pop-up&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-13.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-13.png?fit=630%2C106&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You have to refresh to see when the job is finished and it will be red if the job failed, green if it succeeded or orange if some cells failed like this!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-14.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-14.png?fit=630%2C270&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>But this is the good bit. Clicking on that icon will open the notebook that was created by that agent job run. Lets see what we get&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/f5376e7e-4150-471c-b018-f7ae440427b1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-15.png?fit=630%2C339&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see that we have the results of the queries that we wrote in the notebook alongside the documentation (or maybe explanation of the expected results)&lt;br>
If we scroll down a little (and change the theme colour so that you can see the error)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-18.png?fit=630%2C135&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Msg , Level , State , Line
Duplicate column names are not permitted in SQL PowerShell. To repeat a column, use a column alias for the duplicate column in the format Column_Name AS New_Name.&lt;/p>
&lt;p>We have got an error from running the code via SQL PowerShell which is how the job is run. This error is also inserted into the notebooks.nb_template table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/391f8b82-204d-4331-9084-2eefa33a5bc8" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-21.png?fit=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I edited the notebook locally to remove that block of code&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/51b34091-962f-4e8b-bc3c-b4b33866ef93" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-19.png?fit=630%2C283&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then edited the job and selected the updated notebook&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/063630fc-98a5-4c82-b6ad-e814bc33324e" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-20.png?fit=630%2C338&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and re-ran the job and got a green tick.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/5ad81496-c6c8-4ddf-8384-d0087f71dd38" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-22.png?fit=630%2C279&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now I can open the notebook from the latest run, but notice that from this view I can also open the previous notebook.&lt;/p>
&lt;p>If I look in the nb_template table, the last_run_notebook_error has cleared&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-23.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-23.png?fit=630%2C450&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and if I look in the nb materialized table I can see two rows, one for each job run. The error from the first run is also stored in this table. The notebook column has the json for the notebook if you wish to access it in a different manner.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/25685dd2-78d6-40cd-8dc8-18e0149feb86" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-24.png?fit=630%2C267&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Tomorrow, we will see what the job steps look like and how to make this run on an instance which does not and cannot have the required PowerShell.&lt;/p>
&lt;p>Spoiler Alert  May contain dbatools &lt;/p></description></item><item><title>Use Jupyter Notebooks to Help People on StackOverFlow</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-jupyter-notebooks-to-help-people-on-stackoverflow/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-jupyter-notebooks-to-help-people-on-stackoverflow/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-16.png" alt="Featured image of post Use Jupyter Notebooks to Help People on StackOverFlow" />&lt;p>I am sat in the PowerShell Saturday in Hamburg. You can see me on the right of this picture writing &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/pester/net-powershell-notebooks-using-pester/" target="_blank" rel="noopener"
>my previous blog post!&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/JanDamaschke?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@JanDamaschke&lt;/a> spricht ber Asynchrones Logging in &lt;a class="link" href="https://twitter.com/hashtag/powershell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#powershell&lt;/a> mit Classes und Runspaces &lt;img src="https://pbs.twimg.com/media/ERYdg-6XUAAbwBk?format=jpg"
loading="lazy"
> (&lt;a class="link" href="https://twitter.com/hhpsug?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>https://twitter.com/hhpsug?ref_src=twsrc%5Etfw&lt;/a>) &lt;a class="link" href="https://twitter.com/hashtag/pssaturday?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pssaturday&lt;/a>&lt;/p>
&lt;p> Christoph Burmeister (@chrburmeister) &lt;a class="link" href="https://twitter.com/chrburmeister/status/1231204011270909954?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 22, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I was talking with my friend Mathias Jessen &lt;a class="link" href="https://twitter.com/IISResetMe" target="_blank" rel="noopener"
>@IISResetMe on Twitter&lt;/a> about notebooks and he said that another great use case was to use them on Stack OverFlow&lt;/p>
&lt;p>Now Mathias is an active answerer on Stack OverFlow&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>and he puts a lot of effort into writing his answers, formatting them, including code and results. Basically exactly the same as a Notebook. However, with a Notebook, you can enable people to &lt;strong>&lt;em>run&lt;/em>&lt;/strong> the code as well on their own machines.&lt;/p>
&lt;p>Mathias says he will use notebooks to help people when he answers their PowerShell questions on Stack OverFlow. If you are a Stack OverFlow Answerer then you can too.&lt;/p></description></item><item><title>New .NET Notebooks are here  PowerShell 7 notebooks are here.</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</link><pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-13.png" alt="Featured image of post New .NET Notebooks are here  PowerShell 7 notebooks are here." />&lt;p>Data Science folk used Notebooks for documentation and to show re-runnable research. Azure Data Studio included this notebook functionality and &lt;a class="link" href="https://blog.robsewell.com/dbatools/dbachecks/blog/jupyter%20notebooks/azure%20data%20studio/powershell/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>added SQL&lt;/a> kernel where &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbachecks/dbatools/powershell-in-sql-notebooks-in-azure-data-studio//" target="_blank" rel="noopener"
>with a little bit of faffing you could run PowerShell&lt;/a> and then a &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/powershell-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>Python kernel that enabled PowerShell&lt;/a>. It seems that notebooks are so cool that everyone is creating them these days! I was browsing twitter when I saw this tweet.&lt;/p>
&lt;blockquote>
&lt;p>.NET Notebooks Preview 2 is here! Preview 2 includes &lt;a class="link" href="https://twitter.com/PowerShell_Team?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@PowerShell_Team&lt;/a>, &lt;a class="link" href="https://twitter.com/nteractio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@nteractio&lt;/a>, and a new tool. Check out our blog to learn more. Congratulations to &lt;a class="link" href="https://twitter.com/jonsequitur?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@jonsequitur&lt;/a> &lt;a class="link" href="https://twitter.com/colombod?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@colombod&lt;/a> and our entire team&lt;a class="link" href="https://t.co/WqNWQWR3Bo" target="_blank" rel="noopener"
>https://t.co/WqNWQWR3Bo&lt;/a>&lt;a class="link" href="https://twitter.com/dotnet?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@dotnet&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/jupyter?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#jupyter&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/PowerShell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#PowerShell&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/interactiveprogramming?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#interactiveprogramming&lt;/a>.&lt;/p>
&lt;p> Maria Naggaga (@LadyNaggaga) &lt;a class="link" href="https://twitter.com/LadyNaggaga/status/1225464258823163906?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="powershell-7-notebooks-">PowerShell 7 Notebooks &lt;/h2>
&lt;p>A notebook experience for PowerShell 7 that sounds amazing. This will enable a true cross-platform PowerShell Notebook experience which is lacking from the Python version as it uses Windows PowerShell on Windows and PowerShell Core on other OSs&lt;/p>
&lt;p>The first thing I asked was  Will this come to Azure Data Studio. I got an immediate response from Sydney Smith PowerShell Program Manager saying it is on the roadmap&lt;/p>
&lt;blockquote>
&lt;p>Moving this kernel into ADS is on our roadmap! Right now our kernel uses hosted pwsh 7 but we would love to know if you have scenarios that don&amp;rsquo;t work with 7&lt;/p>
&lt;p> Sydney Smith (@sydneysmithreal) &lt;a class="link" href="https://twitter.com/sydneysmithreal/status/1225488719567818752?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="install-dependencies">Install dependencies&lt;/h2>
&lt;p>To be able to run the notebook, you need to install some dependencies. First install the .NET CORE SDK which you can download from &lt;a class="link" href="https://dotnet.microsoft.com/download?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://dotnet.microsoft.com/download&lt;/a> This needs admin permissions to install.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image.png?resize=620%2C418&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You also need a Python installation  You can use Anaconda, which you can download from here &lt;a class="link" href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener"
>https://www.anaconda.com/distribution/&lt;/a> This does not need admin to install&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-1.png?resize=531%2C232&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-2.png?fit=630%2C490&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-anaconda-to-windows-terminal">Add Anaconda to Windows Terminal&lt;/h2>
&lt;p>I have added the Anaconda prompt to Windows Terminal so that I have one entry point for all my CLIs. Open the settings file and add the code below. (It will also give you an icon and background.&lt;/p>
&lt;pre>&lt;code> {
// Make changes here to the Anaconda.exe profile
&amp;quot;guid&amp;quot;: &amp;quot;{0caa0dad-35be-5f56-a7ff-afceeeaa6101}&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;Anaconda&amp;quot;,
&amp;quot;commandline&amp;quot;: &amp;quot;cmd.exe /K C:\\Users\\mrrob\\Anaconda3\\Scripts\\activate.bat&amp;quot;,
&amp;quot;hidden&amp;quot;: false,
&amp;quot;backgroundImage&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;icon&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;backgroundImageAlignment&amp;quot;: &amp;quot;topRight&amp;quot;,
&amp;quot;backgroundImageStretchMode&amp;quot;: &amp;quot;uniform&amp;quot;,
&amp;quot;backgroundImageOpacity&amp;quot;: 0.1
}
&lt;/code>&lt;/pre>
&lt;p>and it appears in the drop down&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-3.png?resize=509%2C409&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>With Anaconda installed, check that that the kernel is available on your path. If like me you have Azure Data Studio installed, you will have additional kernels but the important one line here is&lt;/p>
&lt;p>&lt;code>python3 C:\Users\USERNAME\Anaconda3\share\jupyter\kernels\python3&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-4.png?resize=630%2C210&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>In Windows Terminal move to a PowerShell 7 prompt and install the dotnet interactive tool&lt;/p>
&lt;pre>&lt;code>dotnet tool install --global Microsoft.dotnet-interactive
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-5.png?resize=630%2C259&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can install the .NET kernel in your Anaconda prompt using this command&lt;/p>
&lt;pre>&lt;code>dotnet interactive jupyter install
&lt;/code>&lt;/pre>
&lt;h2 id="sometimes-new-things-have-errors">Sometimes new things have errors&lt;/h2>
&lt;p>I had an error when I tried this first time&lt;/p>
&lt;blockquote>
&lt;p>Could not execute because the specified command or file was not found.&lt;br>
Possible reasons for this include:&lt;br>
* You misspelled a built-in dotnet command.&lt;br>
* You intended to execute a .NET Core program, but dotnet-interactive does not exist.&lt;br>
* You intended to run a global tool, but a dotnet-prefixed executable with this name could not be found on the PATH.&lt;/p>
&lt;/blockquote>
&lt;p>This is easily fixed by adding &lt;code>%USERPROFILE%\.dotnet\tools&lt;/code> to my path with &lt;code>set PATH=%PATH%;%USERPROFILE%\.dotnet\tools&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-6.png?fit=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Running &lt;code>jupyter kernelspec list&lt;/code> shows that the .NET kernel is installed for C Sharp, F Sharp and .NET PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-7.png?resize=630%2C197&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="lets-open-a-notebook">Lets open a Notebook&lt;/h2>
&lt;p>Now you want to play with it!&lt;br>
You can run the lab environment using `jupyter lab`&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-8.png?fit=630%2C194&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>This opens a browser&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-9.png?fit=630%2C272&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can open existing Azure Data Studio PowerShell notebooks (but not SQL ones)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-10.png?fit=630%2C492&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="sometimes-new-things-have-errors-part-2">Sometimes new things have errors Part 2&lt;/h2>
&lt;p>Unfortunately, I get errors when trying to import Pester which means I can not use my dbachecks notebooks in this blog post. &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>I have raised an issue on the repo here&lt;/a>.&lt;/p>
&lt;h2 id="create-a-new-notebook">Create a New Notebook&lt;/h2>
&lt;p>But it is easy to create a new Notebook&lt;/p>
&lt;p>In the launcher page click the .NET PowerShell button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-12.png?resize=567%2C171&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Which will open a new Notebook in the directory that you launched the lab from. You can then add Code or Markdown as I have &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>described before here&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-11.png?resize=316%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can add code, markdown and images to create your notebook.&lt;/p>
&lt;p>Once you have finished using the notebook lab, you can shut it down in the Anaconda prompt with &lt;code>CTRL + C&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-15.png?fit=630%2C103&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Here is a video of running a notebook which anyone can use to create a couple of Docker containers running SQL 2019 and query them with dbatools. You can find the notebook further down this post.&lt;/p>
&lt;h2 id="sharing-notebooks">Sharing Notebooks&lt;/h2>
&lt;p>You can create notebooks to run common tasks. Even better, from the lab you can convert the notebook including the results to a variety of formats to share with other none-technical people. I used this functionality this week to export Azure Data Studio Notebooks to HTML and PDF for a Project manager &lt;/p>
&lt;p>You can find the Export Notebook command in the File menu&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-13.png?resize=610%2C542&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Exporting to HTML did not export the images but it does include the results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-14.png?fit=630%2C476&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can share notebooks via GitHub  Either in a gist like this&lt;/p>
&lt;p>or by providing a straight link to the notebook in GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb&lt;/a>&lt;/p>
&lt;p>You can also use Binder &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a>&lt;/p>
&lt;p>This uses Docker to create an interactive Notebook. Create a GitHub repo like &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks&lt;/a> (or just clone it) Copy your notebooks into the notebooks folder and push the changes to GitHub and then go to &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a> and add your URL to the repository.&lt;/p>
&lt;p>You can see what it looks like by clicking the button below which Binder creates for you&lt;/p>
&lt;p>&lt;a class="link" href="https://mybinder.org/v2/gh/SQLDBAWithABeard/Notebooks/master" target="_blank" rel="noopener"
>&lt;img src="https://mybinder.org/badge_logo.svg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Unfortunately the kernel only supports Python for the moment but you can see the possibilities &lt;/p></description></item><item><title>Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-40.png" alt="Featured image of post Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps" />&lt;h1 id="fixing-the-failed-to-generate-the-compressed-file-for-module-cprogram-filesdotnetdotnetexe-error-when-deploying-to-the-powershell-gallery-using-azure-devops">Fixing the Failed to generate the compressed file for module C:\Program Files\dotnet\dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps&lt;/h1>
&lt;p>The PowerShell module for validating your SQL Server estate &lt;a class="link" href="http://beard.media/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> is deployed via &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_release?_a=releases&amp;amp;view=mine&amp;amp;definitionId=2" target="_blank" rel="noopener"
>Azure DevOps, you can see how it is working (or not) via this link&lt;/a>&lt;/p>
&lt;h2 id="grrr-automation-for-the-lose">Grrr Automation for the Lose!&lt;/h2>
&lt;p>Until recently, this had worked successfully. In the last few weeks I have been receiving errors&lt;/p>
&lt;pre>&lt;code>Exception : Microsoft.PowerShell.Commands.WriteErrorException: Failed to generate the compressed file for module 'C:\Program Files\dotnet\dotnet.exe failed to pack: error
C:\Program Files\dotnet\sdk\3.0.100\Sdks\NuGet.Build.Tasks.Pack\build\NuGet.Build.Tasks.Pack.targets(198,5): error :
2 Index was outside the bounds of the array.
[C:\Users\VssAdministrator\AppData\Local\Temp\cbc14ba6-5832-46fd-be89-04bb552a83ac\Temp.csproj]
'.
At C:\Program Files\WindowsPowerShell\Modules\PowerShellGet\2.2.1\PSModule.psm1:10944 char:17
20 Publish-PSArtifactUtility @PublishPSArtifactUtility_Param ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ CategoryInfo : InvalidOperation: (:) [Write-Error], WriteErrorException
2019-11-25T22:44:46.8459493Z + FullyQualifiedErrorId : FailedToCreateCompressedModule,Publish-PSArtifactUtility
&lt;/code>&lt;/pre>
&lt;p>You can see these errors in the &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_apps/hub/ms.vss-releaseManagement-web.cd-release-progress?_a=release-environment-logs&amp;amp;releaseId=127&amp;amp;environmentId=127" target="_blank" rel="noopener"
>release pipeline logs here&lt;/a>&lt;/p>
&lt;h2 id="confusion">Confusion&lt;/h2>
&lt;p>This was very frustrating as it was stopping the continuous delivery to the PowerShell Gallery. It was even more confusing as I was successfully deploying the &lt;a class="link" href="http://beard.media/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook module&lt;/a> to the gallery using the same method as &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/ADSSQLNotebook/_build/results?buildId=541" target="_blank" rel="noopener"
>you can see here&lt;/a>.&lt;/p>
&lt;h2 id="raise-an-issue-on-github">Raise an Issue on GitHub&lt;/h2>
&lt;p>I went and looked at the &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/" target="_blank" rel="noopener"
>PowerShellGet GitHub repository&lt;/a> and opened an &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/554" target="_blank" rel="noopener"
>issue&lt;/a> I also found &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/551" target="_blank" rel="noopener"
>another issue regarding Required Modules&lt;/a>&lt;/p>
&lt;p>But this doesn&amp;rsquo;t help to get dbachecks released.&lt;/p>
&lt;h2 id="just-try-to-make-it-work">Just Try to Make it Work&lt;/h2>
&lt;p>I asked the wonderful folk in the &lt;a class="link" href="http://powershell.slack.com" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a>  Through the magic of automation, you can also interact with them via the powershellhelp channel in the &lt;a class="link" href="http://beard.media/sqlslack" target="_blank" rel="noopener"
>SQL Server Slack&lt;/a> as well but there were no answers that could assist.&lt;/p>
&lt;p>So I had to go searching for an answer. PowerShellGet uses &lt;a class="link" href="https://www.nuget.org/" target="_blank" rel="noopener"
>nuget&lt;/a> for package management. I found that if I downloaded an earlier version and placed it in my user profile (in the right location) I could publish the module.&lt;/p>
&lt;p>I found this out by removing the nuget.exe from anywhere useful on the machine and trying to publish the module. The error message says&lt;/p>
&lt;pre>&lt;code>NuGet.exe upgrade is required to continue
This version of PowerShellGet requires minimum version '4.1.0' of NuGet.exe to publish an item to the NuGet-based repositories. NuGet.exe must be available in
'C:\ProgramData\Microsoft\Windows\PowerShell\PowerShellGet\' or 'C:\Users\BeardyMcBeardFace\AppData\Local\Microsoft\Windows\PowerShell\PowerShellGet\', or under
one of the paths specified in PATH environment variable value. NuGet.exe can be downloaded from https://aka.ms/psget-nugetexe. For more information, see
https://aka.ms/installing-powershellget . Do you want PowerShellGet to upgrade to the latest version of NuGet.exe now?
&lt;/code>&lt;/pre>
&lt;p>If I said yes then I got the latest version and the error continued.&lt;/p>
&lt;p>However, on my laptop I can go to the &lt;a class="link" href="https://www.nuget.org/downloads" target="_blank" rel="noopener"
>nuget downloads page&lt;/a> and download an earlier version and place it in one of those paths then I could publish the module.&lt;/p>
&lt;h2 id="can-i-automate-it">Can I Automate it?&lt;/h2>
&lt;p>I would rather not have to deploy manually though, and as I use hosted agents my access to the operating system is limited so I wondered if I could place the nuget.exe in the user profile and it would get used or if it would look for the the latest one. Turns out it uses the one in the user profile &lt;/p>
&lt;p>So now I have this code as a step in my Azure DevOps Release pipeline before calling &lt;code>Publish-Module&lt;/code> and we have automated the releases again.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>and now deployments to the PowerShell Gallery are just triggered by the build and the pipeline is green again &lt;/p>
&lt;p>&lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=129&amp;amp;environmentId=129" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-40.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>test&lt;/p></description></item><item><title>Dynamically Creating Azure Data Studio Notebooks with PowerShell for an Incident Response Index Notebook</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/</link><pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-39.png" alt="Featured image of post Dynamically Creating Azure Data Studio Notebooks with PowerShell for an Incident Response Index Notebook" />&lt;p>Now that &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> has &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/release-notes-azure-data-studio?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Notebooks&lt;/a> and there is a &lt;a class="link" href="https://blog.robsewell.com/create-a-powershell-notebook-for-azure-data-studio-with-powershell/" target="_blank" rel="noopener"
>PowerShell Module for creating notebooks&lt;/a>. I have been asked, more than once, what is the point? What is the use case? How does this help. I hope that this post will spark some ideas of one particular use-case.&lt;/p>
&lt;p>I showed my silly example PowerShell code to create a PowerShell Notebook that created a PowerShell Notebook to my good friend Nick.&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Thanks Nick.&lt;/p>
&lt;h2 id="the-use-case">The Use Case&lt;/h2>
&lt;p>The use case that Nick has is that he is converting some troubleshooting runbooks from their original locations (you know the sort of places  Sharepoint Docs, OneNote Notebooks, Shared Folders, the desktop of the Bastion Host) into a single repository of Azure Data Studio SQL or PowerShell Notebooks.&lt;/p>
&lt;p>The idea is to have a single entry point into the troubleshooting steps and for the on-call DBA to create a Notebook from a template for the issue at hand which could be attached to an incident in the incident management solution. I suppose you could call it an Index Notebook.&lt;/p>
&lt;h2 id="work-flow">Work Flow&lt;/h2>
&lt;p>When the DBA (or another team) opens this Notebook, they can choose the task that they are going to perform and click the link which will&lt;/p>
&lt;ul>
&lt;li>copy the Notebook to the local machine&lt;/li>
&lt;li>Rename the Notebook with the username and date&lt;/li>
&lt;li>Open it ready for the work.&lt;/li>
&lt;/ul>
&lt;p>Once the work has been completed, the DBA can then attach the Notebook to the task or incident that has been created or use it in the Wash-Up/ Post Incident meeting.&lt;/p>
&lt;p>This ensures that the original template notebook stays intact and unchanged and it is easy (which is always good when you are called out at 3am!) to create a uniquely named notebook .&lt;/p>
&lt;h2 id="azure-devops">Azure DevOps&lt;/h2>
&lt;p>Nick has placed this code into the deploy step in Azure DevOps which will deploy the template Notebooks from source control into the common folder and then this code will dynamically create the index Notebook each time there is a release.&lt;/p>
&lt;p>Whilst the initial use case is incident response, this could easily be adapted for Notebooks used for Common Tasks or Run Books.&lt;/p>
&lt;h2 id="notebooks">Notebooks&lt;/h2>
&lt;p>There are a number of Notebooks for different issue stored in directories. For this post, I have used the Notebooks from Microsoft that explain SQL 2019 features and troubleshooting which you can find in their GitHub repositories by &lt;a class="link" href="https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql2019notebooks" target="_blank" rel="noopener"
>following this link&lt;/a>&lt;/p>
&lt;p>The Azure DevOps deploys the Notebooks to a directory which then looks something like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-38.png?resize=494%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Some directories of Notebooks in a directory&lt;/p>
&lt;h2 id="create-an-index-notebook">Create an Index Notebook&lt;/h2>
&lt;p>Here is the code to create an index Notebook&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>This creates a Notebook in the root of the folder. It also uses the new &lt;code>-Collapse&lt;/code> parameter in &lt;code>New-AdsNoteBookCell&lt;/code> that creates the code blocks with the code collapsed so that it looks neater. The index Notebook looks like this in the root of the folder&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-39.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-39.png?resize=630%2C680&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="three-oclock-in-the-morning">Three OClock in the Morning&lt;/h2>
&lt;p>Its 3am and I have been called out. I can open up the Index Notebook, find the set of queries I want to run and click the run button.&lt;/p>
&lt;p>A new workbook opens up, named with my name and the time and I can get to work  I think its neat.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Maybe you can find him at SQL Bits next year. Did you know that SQL Bits 2020 was announced?&lt;/p>
&lt;p>Check out &lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>https://sqlbits.com&lt;/a> for more details&lt;/p></description></item><item><title>Create a PowerShell Notebook for Azure Data Studio with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</link><pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</guid><description>&lt;p>The latest update to the ADSNotebook PowerShell module &lt;a class="link" href="https://blog.robsewell.com/create-azure-data-studio-sql-notebooks-with-powershell/" target="_blank" rel="noopener"
>I blogged about here&lt;/a> now enables the creation of PowerShell notebooks with PowerShell.&lt;/p>
&lt;p>You can install the module with&lt;/p>
&lt;pre>&lt;code>Install-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>or if you have already installed it you can use&lt;/p>
&lt;pre>&lt;code>Update-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>In the latest release, there is an extra parameter for &lt;code>New-AdsWorkBook&lt;/code> of &lt;code>-Type&lt;/code> which will accept either SQL or PowerShell&lt;/p>
&lt;h2 id="create-a-powershell-notebook-with-powershell-rob">Create a PowerShell Notebook with PowerShell Rob&lt;/h2>
&lt;p>OK!&lt;/p>
&lt;p>Here is some code to create a PowerShell Notebook. First we will create some cells using &lt;code>New-AdsWorkBookCell&lt;/code> including all the markdown to add images and links. You can find my notebooks which explain how to write the markdown for your notebooks in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/2019/PASS%20Summit/SQL%20Notebooks%20in%20Azure%20Data%20Studio%20for%20the%20DBA" target="_blank" rel="noopener"
>GitHub Presentations Repository&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then we will create a new workbook using those cells&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then, when that code is run we can open the Notebook and ta-da&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?fit=630%2C505&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>And it is super quick to run as well&lt;/p>
&lt;p>UPDATE  Tyler Leonhardt &lt;a class="link" href="https://twitter.com/TylerLeonhardt" target="_blank" rel="noopener"
>t&lt;/a> from the PowerShell team asked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-36.png?resize=597%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Challenge accepted, with extra meta, here is the PowerShell to create a PowerShell Notebook which will create a PowerShell Notebook!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item><item><title>Create Azure Data Studio SQL Notebooks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-azure-data-studio-sql-notebooks-with-powershell/</link><pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-azure-data-studio-sql-notebooks-with-powershell/</guid><description>&lt;p>At PASS Summit today I gave a presentation about SQL Notebooks in Azure Data Studio for the DBA. I demod the &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook" target="_blank" rel="noopener"
>PowerShell module ADSNotebook&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-32.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>which you can also find on GitHub&lt;/a> (where I will be glad to take PRs to improve it  )&lt;/p>
&lt;p>This module has 3 functions&lt;/p>
&lt;p>This module contains only 3 commands at present&lt;/p>
&lt;ul>
&lt;li>Convert-ADSPowerShellForMarkdown&lt;/li>
&lt;/ul>
&lt;p>This will create the markdown link for embedding PowerShell code in a Text Cell for a SQL Notebook as described &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>in this blog post&lt;/a>&lt;/p>
&lt;ul>
&lt;li>New-ADSWorkBookCell&lt;/li>
&lt;/ul>
&lt;p>This command will create a workbook text cell or a code cell for adding to the New-ADSWorkBook command&lt;/p>
&lt;ul>
&lt;li>New-ADSWorkBook&lt;/li>
&lt;/ul>
&lt;p>This will create a new SQL Notebook using the cell objects created by New-ADSWorkBookCell&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>Convert-ADSPowerShellForMarkdown&lt;/p>
&lt;pre>&lt;code>Convert-ADSPowerShellForMarkdown -InputText &amp;quot;Get-ChildItem&amp;quot; -LinkText 'This will list the files' -ToClipBoard
Converts the PowerShell so that it works with MarkDown and sets it to the clipboard for pasting into a workbook cell
&lt;/code>&lt;/pre>
&lt;p>New-ADSWorkBookCell&lt;/p>
&lt;pre>&lt;code>$introCelltext = &amp;quot;# Welcome to my Auto Generated Notebook
## Automation
Using this we can automate the creation of notebooks for our use
&amp;quot;
$Intro = New-ADSWorkBookCell -Type Text -Text $introCelltext
Creates an Azure Data Studio Text cell and sets it to a variable for passing to New-AdsWorkBook
&lt;/code>&lt;/pre>
&lt;p>New-ADSWorkBook&lt;/p>
&lt;pre>&lt;code>$introCelltext = &amp;quot;# Welcome to my Auto Generated Notebook
## Automation
Using this we can automate the creation of notebooks for our use
&amp;quot;
$SecondCelltext = &amp;quot;## Running code
The next cell will have some code in it for running
## Server Principals
Below is the code to run against your instance to find the server principals that are enabled&amp;quot;
$thirdcelltext = &amp;quot;SELECT Name
FROM sys.server_principals
WHERE is_disabled = 0&amp;quot;
$Intro = New-ADSWorkBookCell -Type Text -Text $introCelltext
$second = New-ADSWorkBookCell -Type Text -Text $SecondCelltext
$third = New-ADSWorkBookCell -Type Code -Text $thirdcelltext
$path = 'C:\temp\AutoGenerated.ipynb'
New-ADSWorkBook -Path $path -cells $Intro,$second,$third
Creates 3 cells with New-AdsWorkBookCells to add to the workbook,
two text ones and a code one, then creates a SQL Notebook with
those cells and saves it as C:\temp\AutoGenerated.ipynb
&lt;/code>&lt;/pre>
&lt;h1 id="installation">Installation&lt;/h1>
&lt;p>You can install this Module from the PowerShell Gallery using&lt;/p>
&lt;p>&lt;code>Install-Module ADSNotebook&lt;/code>&lt;/p>
&lt;h1 id="compatability">Compatability&lt;/h1>
&lt;p>This module has been tested on Windows PowerShell 5.1, PowerShell Core 6 and PowerShell 7 on Windows 10 and Ubuntu&lt;/p>
&lt;h2 id="demo">Demo&lt;/h2>
&lt;!-- raw HTML omitted --></description></item><item><title>My current VS Code Extensions and using a workspace file</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-26.png" alt="Featured image of post My current VS Code Extensions and using a workspace file" />&lt;p>I have been asked a couple of times recently what my Visual Studio Code extensions are at the moment so I thought I would write a quick post and also look at workspaces and how you can enable and disable extensions within them&lt;/p>
&lt;h2 id="listing-extensions">Listing Extensions&lt;/h2>
&lt;p>From the command line you can list your extensions using&lt;/p>
&lt;pre>&lt;code>code --list-extensions
code-insiders --list-extensions
&lt;/code>&lt;/pre>
&lt;p>My list looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can also see them in the view on the left of default Visual Studio Code and open them with CTRL + SHIFT + X (unless like me you have Snagit installed and it has taken that shortcut&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-31.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-extensions">Installing Extensions&lt;/h2>
&lt;p>You can install extensions by opening the Extensions view in Visual Studio Code and searching for the extension. The list I have below has the precise names for each extension which you can use to search&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-24.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also install extensions from the command-line with&lt;/p>
&lt;pre>&lt;code>code --install-extension &amp;lt;extensionid&amp;gt;
code-insiders --install-extension &amp;lt;extensionid&amp;gt;
&lt;/code>&lt;/pre>
&lt;h2 id="my-extensions">My Extensions&lt;/h2>
&lt;p>I am going to list these in alphabetical order by display name for ease (my ease that is!)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Because Chrissy LeMaire and I are writing &lt;a class="link" href="https://beard.media/book" target="_blank" rel="noopener"
>dbatools in a Month of Lunches&lt;/a> using AsciiDoc, it makes sense to have an extension enabling previewing and syntax, you can find it &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=stayfool.vscode-asciidoc" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure I use the Azure Account Extension  ms-vscode.azure-account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>I use Azure CLI so I make use of the functionality of the Azure CLI Tools extension ms-vscode.azurecli&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure Repos I use the ms-vsts.team extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>When creating ARM templates, this extension is very useful msazurermtools.azurerm-vscode-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I have a few theme extensions, this one is for fun in demos  beardedbear.beardedtheme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The blackboard theme is my default one gerane.theme-blackboard&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Chasing closing brackets is much easier with the Bracket Pair Colorizer, I use the beta version coenraads.bracket-pair-colorizer-2&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>I am rubbish at spelling and typing so I use this to help point out the issues! streetsidesoftware.code-spell-checker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>Using the Docker extension adds another view to Visual Studio Code to ease working with containers ms-azuretools.vscode-docker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>As an open-source project maintainer it is good to be able to work with GitHub pull requests without leaving Visual Studio Code github.vscode-pull-request-github_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>GitLens is absolutely invaluable when working with source control. It has so many features. This is an absolute must eamodio.gitlens&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Working with Kubernetes? This extension adds another view for interacting with your cluster ms-kubernetes-tools.vscode-kubernetes-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>Visual Studio Live Share enables you to collaborate in real-time in Visual Studio Code with your colleagues or friends. I blogged about this &lt;a class="link" href="https://blog.robsewell.com/visual-studio-code-live-sharing-set-up/" target="_blank" rel="noopener"
>here&lt;/a> ms-vsliveshare.vsliveshare&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I love writing markdown and this linter assists me to ensure that my markdown is correct davidanson.vscode-markdownlint&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>The Material Icon Theme ensures that there are pretty icons in my editor! pkief.material-icon-theme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I have both the PowerShell extension ms-vscode.powershell and the PowerShell preview extension ms-vscode.powershell-preview installed but only one can be enabled at a time&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>This suite of extensions enables easy remote development so that you can develop your PowerShell scripts, for example, inside a ubuntu container running PowerShell 7 or inside Windows Subsystem for LInux ms-vscode-remote.vscode-remote-extensionpack_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-20.png"
loading="lazy"
>&lt;/p>
&lt;p>Writing for cross-platform means looking out for line endings and this extension will display them and any whitespace in your editor medo64.render-crlf&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-21.png"
loading="lazy"
>&lt;/p>
&lt;p>An absolutely essential extension which enables me to backup all of my Visual Studio Code settings, shortcuts, extensions into a GitHub gist and keep all of my machines feeling the same. shan.code-settings-sync&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-22.png"
loading="lazy"
>&lt;/p>
&lt;p>For working with SQL Server within Visual Studio Code and having a view for my instances as well as a linter and intellisense I use ms-mssql.mssql&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-23.png"
loading="lazy"
>&lt;/p>
&lt;p>Yaml files and spaces! I no longer get so confused with this extension to help me  redhat.vscode-yaml&lt;/p>
&lt;h2 id="workspaces">Workspaces&lt;/h2>
&lt;p>Now that is a lot of extensions and I dont need all of them everytime. I use workspaces to help with this. I will create a workspace file for the project I am working on.&lt;/p>
&lt;p>I open or create the folders I will be working on and then click File and Save Workspace As and save the file in the root of the folder.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-25.png"
loading="lazy"
>&lt;/p>
&lt;p>Now, the next time I want to open the workspace, I can open the workspace file or if I open the folder Visual Studio Code will helpfully prompt me&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-26.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can have all of my settings retained for that workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-27.png"
loading="lazy"
>&lt;/p>
&lt;p>For this folder, I am ensuring that the PowerShell extension uses the PSScriptAnalyzer Settings file that I have created so that it will show if the code is compatible with the versions of PowerShell I have chosen. I can define settings for a workspace in the settings file, which you can open using CTRL and ,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-28.png"
loading="lazy"
>&lt;/p>
&lt;p>But I can also enable or disable extensions for a workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-29.png"
loading="lazy"
>&lt;/p>
&lt;p>So everytime I open this workspace I am only loading the extensions I want&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-30.png"
loading="lazy"
>&lt;/p></description></item><item><title>PowerShell Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-8.png" alt="Featured image of post PowerShell Notebooks in Azure Data Studio" />&lt;p>The latest release of the &lt;a class="link" href="https://github.com/microsoft/azuredatastudio#try-out-the-latest-insiders-build-from-master" target="_blank" rel="noopener"
>insiders edition of Azure Data Studio&lt;/a> brings the first edition of PowerShell Notebooks!&lt;/p>
&lt;p>You can download the latest insiders edition from the link above, it can be installed alongside the stable release.&lt;/p>
&lt;p>To access many of the commands available use F1 to open the command palette (like many of my tips this also works in Visual Studio Code). You can then start typing to get the command that you want.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>You can then hit enter with the command that you want highlighted, use the mouse or use the shortcut which is displayed to the right.&lt;/p>
&lt;p>In a new notebook, you can click the drop down next to kernel and now you can see that PowerShell is available&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>When you choose the PowerShell kernel, you will get a prompt asking you to configure the Python installation&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>If you have Python already installed you can browse to the location that it is installed or you can install Python. In the bottom pane you will be able to see the progress of the installation.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>When it has completed, you will see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>You may also get a prompt asking if you would like to upgrade some packages&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>Again this will be displayed in the tasks pane&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-14.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="addingpowershell">&lt;strong>AddingPowerShell&lt;/strong>&lt;/h2>
&lt;p>ToaddPowerShellCodetothenotebookclicktheCodebuttonatthetop of the file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>ortheoneyoucanfindbyhighlightingaboveorbelowablock&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I did not have intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block.&lt;/p>
&lt;p>Interestingly Shawn Melton ( &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>t&lt;/a> ) did&lt;/p>
&lt;blockquote>
&lt;p>Curious, you state &amp;ldquo;There is not any intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block&amp;rdquo;&lt;/p>
&lt;p>It works flawlessly for me on Windows. &lt;a class="link" href="https://t.co/Lx6fGH9F5L" target="_blank" rel="noopener"
>pic.twitter.com/Lx6fGH9F5L&lt;/a>&lt;/p>
&lt;p> Shawn Melton (@wsmelton) &lt;a class="link" href="https://twitter.com/wsmelton/status/1184819132598013952?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>October 17, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This was because he had the PowerShell extension installed and I did not (I know !!)&lt;br>
If you find you dont have intellisense then install the PowerShell extension!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the play button (which is only visible when you hover the mouse over it) will run the code&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can clear the results from every code block using the clear results button at the top&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>Otherwise, you can save the results with the Notebook by saving it. This is the part that is missing from running PowerShell in the Markdown blocks in a &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>SQL Notebook as I described here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>I am looking forward to how this develops. You can find my sample PowerShell notebook (with the code results) &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/powershell.ipynb" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p></description></item><item><title>Getting SQL Server installation date with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-7.png" alt="Featured image of post Getting SQL Server installation date with PowerShell using dbatools" />&lt;p>Most of my writing time at the moment is devoted to &lt;em>&lt;a class="link" href="https://dbatools.io/book" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> which is now available but here is a short post following a question someone asked me.&lt;/p>
&lt;h2 id="how-can-i-get-the-installation-date-for-sql-server-on-my-estate-into-a-database-with-dbatools-">How can I get the Installation Date for SQL Server on my estate into a database with dbatools ?&lt;/h2>
&lt;p>You can get the date that SQL Server was installed using the creation date of the NT Authority\System login using T-SQL&lt;/p>
&lt;pre>&lt;code>SELECT create_date
FROM sys.server_principals
WHERE sid = 0x010100000000000512000000
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="with-dbatools">With dbatools&lt;/h2>
&lt;p>To do this with dbatools you can use the command &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaInstanceInstallDate" target="_blank" rel="noopener"
>Get-DbaInstanceInstallDate&lt;/a> command&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-1.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="more-than-one-instance">More than one instance&lt;/h2>
&lt;p>If we want to get the installation date for more than one instance we can simply create an array of instances for the SqlInstance parameter&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE
&lt;/code>&lt;/pre>
&lt;h2 id="get-the-windows-installation-date-too">Get the Windows installation date too&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also get the windows installation date with the IncludeWindows switch&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE -IncludeWindows
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-3.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="gather-your-instances">Gather your instances&lt;/h2>
&lt;p>How you get the instances in your estate is going to be different per reader but here is an example using Registered Servers from my local registered servers list, you can also use a Central Management Server&lt;/p>
&lt;pre>&lt;code>Get-DbaRegisteredServer -Group local
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>So we can gather those instances into a variable and pass that to Get-DbaInstanceInstallDate&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-to-database">Add to database&lt;/h2>
&lt;p>To add the results of any PowerShell command to a database, you can pipe the results to &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDbTableData" target="_blank" rel="noopener"
>Write-DbaDbTableData&lt;/a>&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
$writeDbaDataTableSplat = @{
SqlInstance = 'localhost'
Table = 'InstallDate'
Database = 'tempdb'
Schema = 'dbo'
AutoCreateTable = $true
}
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances | Write-DbaDataTable @writeDbaDataTableSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>This will create a table called InstallDate and put the results of the Get-DbaInstanceInstallDate command. Note  If you want to try this code, I would advise using a different database than tempdb!!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>It is important to note that the table created may not have the most optimal data types and that you may want to pre-create the table.&lt;/p>
&lt;p>So there you go, all the installation dates for your estate in a database table. Hope that helps you Jonny.&lt;/p></description></item><item><title>MEAP MEAP  #dbatoolsMoL  Live Book edition</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</link><pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</guid><description>&lt;p>Its been a busy time!&lt;/p>
&lt;p>As well as many other things, the fantastical &lt;a class="link" href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life" target="_blank" rel="noopener"
>BDFL&lt;/a> of &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> Chrissy Lemaire&lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a> and myself have written enough of a chunk of&lt;em>&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> that our publisher&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Manning Publications&lt;/a> have agreed to release it as a MEAP. Not a text book, this book is written in a fun conversational style and split up into chapters that you can read in a lunch-time.&lt;/p>
&lt;p>It is impossible for me to hear MEAP and not think of this &lt;/p>
&lt;p>&lt;a class="link" href="https://tenor.com/view/hungry-coyote-looney-tunes-gif-5063446" target="_blank" rel="noopener"
>Roadrunner Speeding GIF&lt;/a> from &lt;a class="link" href="https://tenor.com/search/hungry-gifs" target="_blank" rel="noopener"
>Hungry GIFs&lt;/a>&lt;/p>
&lt;p>but I expect you are wondering what a MEAP is?&lt;/p>
&lt;blockquote>
&lt;p>What is MEAP?&lt;br>
A book can take a year or more to write, so how do you learn that hot new technology today? The answer is MEAP, the Manning Early Access Program. In MEAP, you read a book chapter-by-chapter while its being written and get the final eBook as soon as its finished. If you pre-order the pBook, youll get it long before its available in stores.&lt;/p>
&lt;p>&lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>https://www.manning.com/meap-program&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Basically, to make it easy to get and for those that like to get in early, you can order the book and get the first 4 chapters (three in reality) RIGHT NOW!! (It also means that Chrissy and I have to write the rest of book  dang still going to be busy!)&lt;/p>
&lt;p>Simply head over to &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a> and use the code mlsewell and you can get access to the book too.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/08/meap.png"
loading="lazy"
>](&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a>)&lt;/p>
&lt;p>This will also give you access to the live book.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/livebook.png"
loading="lazy"
>&lt;/p>
&lt;p>live book&lt;/p>
&lt;p>The live book is fantastic, you can read the whole book from within your browser. See the three icons that appear to the right of the book?&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/stuffage.png"
loading="lazy"
>&lt;/p>
&lt;p>3 little icons (no porridge)&lt;/p>
&lt;p>The left hand one enables you to bookmark an important part so that you can come back to it easily using the bookmarks link in the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/bookmark.png"
loading="lazy"
>&lt;/p>
&lt;p>bookmarks&lt;/p>
&lt;p>The middle icon enables you to write notes for yourself, maybe ways that you can use the information or maybe comments about an awesome Italian.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/satori.png"
loading="lazy"
>&lt;/p>
&lt;p>Shoes&lt;/p>
&lt;p>The last one is the way that you can make comments and engage us , the authors in conversation, ask questions, request clarification or wonder about Dutch data manglers&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/sander.png"
loading="lazy"
>&lt;/p>
&lt;p>I think its down to PII&lt;/p>
&lt;p>If you select a piece of text, another menu opens up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlight.png"
loading="lazy"
>&lt;/p>
&lt;p>The first icon lets you highlight the text, to make it easier to find later&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlightyellow.png"
loading="lazy"
>&lt;/p>
&lt;p>Hover over the highlight and you can choose different colours for different things.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/image.png"
loading="lazy"
>&lt;/p>
&lt;p>or even create pretty pictures for Mathias&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/pretty.png"
loading="lazy"
>&lt;/p>
&lt;p>Mathias  Why isnt he an MVP?&lt;/p>
&lt;p>You can choose to annotate, which is sort of like highlighting and writing a note with the next icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/other-users.png"
loading="lazy"
>&lt;/p>
&lt;p>When you want to share a link to a particular part of the book with someone else, you can highlight part of it and click the link icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/linkylinky.png"
loading="lazy"
>&lt;/p>
&lt;p>Its easy to start PowerShell as another user as long as you remember when to press SHIFT&lt;/p>
&lt;p>Which will highlight the paragraph and open a dialogue at the bottom where you can create and copy the link.&lt;/p>
&lt;p>By far the most important part for Chrissy and I is the last link. When you find something wrong you can mark it for our attention. Yes, even with Chrissy and I proof reading each others words, the fabulous proof reader Cludio Silva (&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>t&lt;/a>)and awesome tech editor Mike Shepard (&lt;a class="link" href="https://powershellstation.com/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/MikeShepard70" target="_blank" rel="noopener"
>t&lt;/a>) as well as many community reviewers there are still, and will continue to be, issues. So when you find them, highlight them and click the right hand most link&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/withwith.png"
loading="lazy"
>&lt;/p>
&lt;p>with with more more than than one one&lt;/p>
&lt;p>This will open up as shown so that you can fill in what was wrong (Please dont report this error again Shane &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>t&lt;/a> has beaten you to it!)&lt;/p>
&lt;p>You will have noticed on social media and elsewhere that we have left some easter eggs in the book&lt;/p>
&lt;blockquote>
&lt;p>Yup, we have some easter eggs in &lt;a class="link" href="https://twitter.com/hashtag/dbatoolsMol?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatoolsMol&lt;/a>&lt;/p>
&lt;p>We hope you enjoy them &lt;a class="link" href="https://t.co/iZa3u8iLPC" target="_blank" rel="noopener"
>https://t.co/iZa3u8iLPC&lt;/a>&lt;/p>
&lt;p> Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1167116661503266819?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>August 29, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you find them or whenever you want to talk about the book on social media, please use the hashtag #dbatoolsMoL  you never know what goodies may end up in your inbox.&lt;/p>
&lt;p>Oh and if you have got this far and dont know what dbatools in a Month of Lunches is, listen to the hair and read more &lt;a class="link" href="https://dbatools.io/meap/" target="_blank" rel="noopener"
>https://dbatools.io/meap/&lt;/a>&lt;/p></description></item><item><title>PowerShell in SQL Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</link><pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/07/image-4.png" alt="Featured image of post PowerShell in SQL Notebooks in Azure Data Studio" />&lt;p>I have done a lot of writing in the last few months but you see no blog posts! My wonderful friend Chrissy and I are writing dbatools in a Month of Lunches to be published by Manning. That has taken up a lot of my writing mojo. We have hit a little break whilst we have some reviews done ready for the &lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>MEAP&lt;/a> (For everyone who asks, the answer is the unfulfilling soon) so its time for a blog post!&lt;/p>
&lt;h2 id="sql-notebooks-are-cool">SQL Notebooks are cool&lt;/h2>
&lt;p>I have had a lot of fun with SQL Notebooks recently. I have presented a session about them at a couple of events this month &lt;a class="link" href="http://datagrillen.com" target="_blank" rel="noopener"
>DataGrillen&lt;/a> and SQL Saturday Cork. Here is a little snippet&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/hashtag/dbatools?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatools&lt;/a> in PowerShell in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> SQL Notebooks for creating the containers and restoring the &lt;a class="link" href="https://twitter.com/hashtag/dbachecks?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbachecks&lt;/a> historical database for running queries in &lt;br>
Getting ready for presentation for &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/wiQ41bblQV" target="_blank" rel="noopener"
>pic.twitter.com/wiQ41bblQV&lt;/a>&lt;/p>
&lt;p> Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1130871277449875456?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 21, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Yes, you can run PowerShell in a SQL Notebook in Azure Data Studio just by clicking a link in the markdown cell. This opens up a lot of excellent possibilities.&lt;/p>
&lt;p>I have had several discussions about how SQL Notebooks can be used by SQL DBAs within their normal everyday roles. (Mainly because I dont really understand what the sorcerers of data science do with notebooks!). I have helped clients to look at some of their processes and use SQL Notebooks to help with them. Creating Disaster Recovery or Change Run-books or Incident Response Templates or using them for product demonstrations. Of course, I needed to use PowerShell in that &lt;/p>
&lt;p>I have really enjoyed working out how to run PowerShell in the markdown in a SQL Notebook in Azure Data Studio and I think &lt;a class="link" href="http://www.centinosystems.com/blog/author/aencentinosystems-com/" target="_blank" rel="noopener"
>Anthony the kubernetes magician&lt;/a> did too!&lt;/p>
&lt;blockquote>
&lt;p>I think &lt;a class="link" href="https://twitter.com/sqldbawithbeard?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@sqldbawithbeard&lt;/a> is an actual wizard! You should see the things he can do with &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/KMeZR3CrPK" target="_blank" rel="noopener"
>pic.twitter.com/KMeZR3CrPK&lt;/a>&lt;/p>
&lt;p> Anthony E. Nocentino (@nocentino) &lt;a class="link" href="https://twitter.com/nocentino/status/1141709511700467712?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>June 20, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>OK enough magic puns lets talk about PowerShell in SQL Notebooks. You can read about &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>how to create a SQL Notebook and run T-SQL queries here&lt;/a>, (you no longer need the Insider Edition by the way)&lt;/p>
&lt;h2 id="powershell-in-markdown">PowerShell in Markdown!&lt;/h2>
&lt;p>First, before I go any further, I must say this. I was at the European PowerShell Conference when I was working this out and creating my sessions and I said the words&lt;/p>
&lt;blockquote>
&lt;p>Cool, I can click a link and run PowerShell, this is neat&lt;/p>
&lt;p>A Beardy fellow in Hannover&lt;/p>
&lt;/blockquote>
&lt;p>This stopped some red team friends of mine in their tracks and they said Show me. One of them was rubbing their hands with glee! You can imagine the sort of wicked, devious things that they were immediately considering doing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes, its funny but also it carries a serious warning. Without understanding what it is doing, please dont enable PowerShell to be run in a SQL Notebook that someone sent you in an email or you find on a GitHub. In the same way as you dont open the word document attachment which will get a thousand million trillion europounddollars into your bank account or run code you copy from the internet on production without understanding what it does, this could be a very dangerous thing to do.&lt;/p>
&lt;p>With that warning out of the way, there are loads of really useful and fantastic use cases for this. SQL Notebooks make great run-books or incident response recorders and PowerShell is an obvious tool for this. (If only we could save the PowerShell output in a SQL Notebook, this would be even better)&lt;/p>
&lt;h2 id="how-on-earth-did-you-work-this-out">How on earth did you work this out?&lt;/h2>
&lt;p>Someone asked me how I worked it out. I didnt! It began with Vicky Harp PM lead for the SQL Tools team at Microsoft&lt;/p>
&lt;blockquote>
&lt;p>Did you know you can add markdown links to open a terminal and paste in a command in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> notebooks? &lt;a class="link" href="https://t.co/YHX9pIVQco" target="_blank" rel="noopener"
>pic.twitter.com/YHX9pIVQco&lt;/a>&lt;/p>
&lt;p> Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1128359827128950784?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 14, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I then went and looked at &lt;a class="link" href="https://twitter.com/kevcunnane" target="_blank" rel="noopener"
>Kevin Cunnane&lt;/a>s notebook. Kevin is a member of the tools team working on Azure Data Studio. With SQL Notebooks, you can double click the markdown cell and see the code that is behind it. To understand how it is working, lets deviate a little.&lt;/p>
&lt;h2 id="keyboard-shortcuts">Keyboard Shortcuts&lt;/h2>
&lt;p>IF you click the cog at the bottom left of Azure Data Studio and choose Keyboard Shortcuts&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image.png"
loading="lazy"
>&lt;/p>
&lt;p>you can make Azure Data Studio (and Visual Studio Code) work exactly how you want it to. Typing in the top box will find a command and you can then set the shortcuts that you want to use to save yourself time.&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1" target="_blank" rel="noopener"
>https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This also enables you to see the command that is called when you use a keyboard shortcut. For example, you can see that for the focus terminal command it says &lt;code>workbench.action.terminal.focus&lt;/code>.&lt;/p>
&lt;p>It turns out that you can call this as a link in a Markdown document using HTML with &lt;code>&amp;lt;a href=&amp;quot;&amp;quot;&amp;gt;&lt;/code> and adding &lt;code>command:&lt;/code> prior to the command text. When the link is clicked the command will run. Cool &lt;/p>
&lt;p>For this to be able to work (you read the warning above?) you need to set the Notebook to be trusted by clicking this button.&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1" target="_blank" rel="noopener"
>https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This will allow any command to be run. Of course, people with beards will helpfully advise when this is required for a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/05%20-Working%20with%20dbachecks%20Validation%20Results.ipynb" target="_blank" rel="noopener"
>SQL Notebook&lt;/a>. (Safe to say people attempting nefarious actions will try the same with your users)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Now that we know how to run an Azure Data Studio command using a link in a markdown cell the next step is to run a PowerShell command. I headed to the &lt;a class="link" href="https://code.visualstudio.com/docs/editor/integrated-terminal" target="_blank" rel="noopener"
>Visual Studio Code documentation&lt;/a> and found&lt;/p>
&lt;blockquote>
&lt;p>Send text from a keybinding&lt;br>
The&lt;code>workbench.action.terminal.sendSequence&lt;/code>command can be used to send a specific sequence of text to the terminal, including escape sequence&lt;/p>
&lt;/blockquote>
&lt;p>Thats the command we need, however, we still need to craft the command so that it will work as a link. It needs to be converted into a URL.&lt;/p>
&lt;p>I started by using this website&lt;a class="link" href="https://www.url-encode-decode.com/" target="_blank" rel="noopener"
>https://www.url-encode-decode.com/&lt;/a>to do this. This is&lt;strong>how you can check the code in other peoples notebook, use the decode capability.&lt;/strong>&lt;/p>
&lt;p>Encoding &lt;code>Set-Location C:\dbachecks&lt;/code> gives `Set-Location+C%3A%5Cdbacheck``&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59567164-e5044300-9061-11e9-802b-7b28c3aee345.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can just put that code into the href link and bingo!&lt;/p>
&lt;p>If only it was that easy!!&lt;/p>
&lt;h2 id="some-replacing-is-required">Some Replacing is required&lt;/h2>
&lt;p>The + needs to be replaced with a space or &lt;code>%20&lt;/code>&lt;/p>
&lt;p>You also need to double the &lt;code>\&lt;/code> and replace the &lt;code>%3A&lt;/code> with a &lt;code>:&lt;/code>&lt;br>
The &lt;code>&amp;quot;&lt;/code> needs to be replaced with &lt;code>\u022&lt;/code>, the &lt;code>'&lt;/code> with &lt;code>\u027&lt;/code>, the curly braces wont work unless you remove the &lt;code>%0D%0A&lt;/code>. Got all that? Good!&lt;/p>
&lt;p>Once you have written your PowerShell, encoded it, performed the replacements, you add&lt;code>\u000D&lt;/code>at the end of the code to pass an enter to run the code and then place all of that into a link like this&lt;/p>
&lt;p>&lt;code>&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 PLACE THE ENCODED CODE HERE %22%7D&amp;quot;&amp;gt;Link Text&amp;lt;/a&amp;gt;&lt;/code>&lt;/p>
&lt;p>This means that if you want to add the PowerShell code to set a location and then list the files and folders in that location to a Markdown cell using PowerShell like this&lt;/p>
&lt;pre>&lt;code>Set-Location C:\dbachecks
Get-ChildItem
&lt;/code>&lt;/pre>
&lt;p>You would end up with a link like this&lt;/p>
&lt;p>&lt;code>`&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 Set-Location C:%5C%5Cdbachecks \u000D Get-ChildItem \u000D %22%7D&amp;quot;&amp;gt;Set Location and list files&amp;lt;/a`&lt;/code>&amp;gt;&lt;/p>
&lt;h2 id="doing-something-more-than-once">Doing something more than once?&lt;/h2>
&lt;p>I dont want to remember that all of the time so I wrote a PowerShell function. You can find it on GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1&lt;/a>&lt;/p>
&lt;p>This will take a PowerShell command and turn it into a link that will work in an Azure Data Studio markdown. Its not magic, its PowerShell. There is a &lt;code>ToClipboard&lt;/code> parameter which will copy the code to the clipboard ready for you to paste into the cell (On Windows machines only)&lt;/p>
&lt;h2 id="giants">Giants&lt;/h2>
&lt;p>There are many uses for this but heres one I think is cool.&lt;/p>
&lt;p>The link below will go to a notebook, which will show how you the giants upon whose shoulders I stand&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/GlennAlanBerry" target="_blank" rel="noopener"
>Glenn Berry&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Andr&lt;/a> &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Kamman&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/spaghettidba" target="_blank" rel="noopener"
>Gianluca Sartori&lt;/a>&lt;/p>
&lt;p>have enabled me to create a SQL Notebook with a link which will run some PowerShell to create a SQL Notebook which will have all of the Diagnostic Queries in it.&lt;/p>
&lt;p>You could possibly use something like it for your incident response SQL Notebook.&lt;/p>
&lt;p>Its also cool that GitHub renders the notebook in a browser (You cant run PowerShell or T-SQL from there though, you need Azure Data Studio!)&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-4.png"
loading="lazy"
>&lt;/p></description></item><item><title>Azure SQL Linux VM  configuring SQL, installing pwsh and connecting and interacting with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</link><pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-125.png" alt="Featured image of post Azure SQL Linux VM  configuring SQL, installing pwsh and connecting and interacting with dbatools" />&lt;p>In my posts about using Azure Devops to build Azure resources with Terraform, &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>I built a Linux SQL VM.&lt;/a> I used the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>Terraform in this GitHub&lt;/a> repository and created this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-mobaxterm">Connecting with MobaXterm&lt;/h2>
&lt;p>I had set the Network security rules to accept connections only from my static IP using variables in the Build Pipeline. I use &lt;a class="link" href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener"
>MobaXterm&lt;/a> as my SSH client. Its a free download. I click on sessions&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-120.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose a SSH session and fill in the remote host address from the portal&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-121.png"
loading="lazy"
>&lt;/p>
&lt;p>fill in the password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-122.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="configuring-sql">Configuring SQL&lt;/h2>
&lt;p>The next task is to configure the SQL installation. Following the instructions on the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sql/provision-sql-server-linux-virtual-machine?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft docs site&lt;/a> I run&lt;/p>
&lt;pre>&lt;code>sudo systemctl stop mssql-server
sudo /opt/mssql/bin/mssql-conf set-sa-password
&lt;/code>&lt;/pre>
&lt;p>enter the sa password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-123.png"
loading="lazy"
>&lt;/p>
&lt;p>Now to start SQL&lt;/p>
&lt;pre>&lt;code>sudo systemctl start mssql-server
&lt;/code>&lt;/pre>
&lt;h2 id="installing-pwsh">Installing pwsh&lt;/h2>
&lt;p>Installing PowerShell Core (pwsh) is easy with snap&lt;/p>
&lt;p>sudo snap install powershell &amp;ndash;classic&lt;/p>
&lt;p>A couple of minutes of downloads and install&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-124.png"
loading="lazy"
>&lt;/p>
&lt;p>and pwsh is ready for use&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-125.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-dbatools">Installing dbatools&lt;/h2>
&lt;p>To install &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbatools" target="_blank" rel="noopener"
>Powershell Gallery&lt;/a> simply run&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser&lt;/p>
&lt;p>This will prompt you to allow installing from an untrusted repository&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-126.png"
loading="lazy"
>&lt;/p>
&lt;p>and dbatools is ready to go&lt;/p>
&lt;pre>&lt;code>#Set a credential
$cred = Get-Credential
# Show the databases on the local instance
Get-DbaDatabase -SqlInstance localhost -SqlCredential $cred
&lt;/code>&lt;/pre>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-127.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-azure-data-studio">Connecting with Azure Data Studio&lt;/h2>
&lt;p>I can also connect with Azure Data Studio&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-128.png"
loading="lazy"
>&lt;/p>
&lt;p>and connect&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/p>
&lt;p>Just a quick little post explaining what I did &lt;/p>
&lt;p>Happy Linuxing!&lt;/p></description></item><item><title>Adding a Folder of Scripts to GitHub</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</link><pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</guid><description>&lt;p>Yesterday there was a tweet from Allen White.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/SQLRunr/status/1113862196201758720" target="_blank" rel="noopener"
>https://twitter.com/SQLRunr/status/1113862196201758720&lt;/a>&lt;/p>
&lt;p>Allen wanted to add his scripts folder to source control but didn&amp;rsquo;t have a how to do it handy. So I thought I would write one. Hopefully this will enable someone new to GitHub and to source control get a folder of scripts under source control&lt;/p>
&lt;h2 id="github-account">GitHub account&lt;/h2>
&lt;p>If you do not have a GitHub account go to &lt;a class="link" href="https://github.com" target="_blank" rel="noopener"
>https://github.com&lt;/a> and create a new account&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>There is a funky are you a human challenge&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-1.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then you can choose your subscription&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-2.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then answer some questions (Note - you probably want to choose different answers to the what are you interested in question! I&amp;rsquo;d suggest something technical)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-3.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You need to do the email verification&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-4.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Next is a very important step - Please do not skip this. You should set up 2 factor authentication. Yes even if &amp;ldquo;It&amp;rsquo;s just for me there is nothing special here&amp;rdquo;&lt;/p>
&lt;p>Click your user icon top right and then settings&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-5.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then click set up two factor authentication&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png?fit=630%2C365&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and either set up with an app or via SMS (I suggest the app is better)&lt;/p>
&lt;p>OK - Now you have your GitHub account set up. It should have taken you less time than reading this far.&lt;/p>
&lt;h2 id="add-a-scripts-folder-to-github">Add a Scripts Folder to GitHub&lt;/h2>
&lt;p>OK, Now to add a folder of scripts to a repository. Here is my folder of scripts. They can be any type of files. I would recommend copy the folder to a specific Git folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-7.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Open VS Code - If you don&amp;rsquo;t have VS Code, download it from
&lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>https://code.visualstudio.com/&lt;/a> From the welcome window choose open folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-8.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and open your scripts folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-9.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>In VS Code click the Source Control button&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-10.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and up at the top you will see a little icon - initialise repository&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-11.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click that and choose your folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-12.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Which will then show all of the changes to the repository (adding all the new files)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-13.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now we need to add a commit message for our changes. I generally try to write commit messages that are the reason why the change has been made as the what has been changed is made easy to see in VS Code (as well as other source control GUI tools)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-14.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click the tick or press CTRL + ENTER and this box will pop up&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-15.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I never click Always, I click yes, so that I can check if I am committing the correct files. Now we have created a local repository for our scripts folder. Our next step is to publish it to GitHub&lt;/p>
&lt;h2 id="create-a-new-repository-in-github">Create a New Repository in GitHub&lt;/h2>
&lt;p>In GitHub we need to create a remote repository. Click on the New Button. Give your repository a name and decide if you want it to be Public (available for anyone to search and find) or Private (only available to people you explicitly provide access to).&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-18.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This will give you a page that looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png?fit=630%2C499&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Copy the code after or push an existing repository from the command line&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># make sure prompt is at right place
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-Location C:\Git\MyScriptsFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Then paste the code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git remote add origin https://github.com/SQLDBAWithABeard-Test/TheBeardsFunkyScriptFolder.git
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git push -u origin master
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and paste it into PowerShell in VS Code. Make sure that your prompt is at the root of your scripts folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png?fit=630%2C340&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Fill in your username and password and your 2FA&lt;/p>
&lt;p>Then you will see a page like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png?fit=630%2C180&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and if you refresh your GitHub page you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png?fit=630%2C504&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Congratulations, your code is source controlled :-)&lt;/p>
&lt;h2 id="making-changes">Making Changes&lt;/h2>
&lt;p>Now you can make a change to a file&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-23.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-23.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Commit your change&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-24.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-24.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Hit the roundy-roundy icon (anyone know its proper name ?)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-25.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-25.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Press OK and your commit will be pushed to GitHub :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-26.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-26.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Yay - Source Control all the things&lt;/p></description></item><item><title>Generating a Workload against AdventureWorks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</link><pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-51.png" alt="Featured image of post Generating a Workload against AdventureWorks with PowerShell" />&lt;p>For a later blog post I have been trying to generate some workload against an AdventureWorks database.&lt;/p>
&lt;p>I found this excellent blog post by Pieter Vanhove &lt;a class="link" href="https://twitter.com/Pieter_Vanhove" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/&lt;/a> which references this 2011 post by Jonathan Kehayias &lt;a class="link" href="https://twitter.com/SQLPoolBoy" target="_blank" rel="noopener"
>t&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/" target="_blank" rel="noopener"
>https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/&lt;/a>&lt;/p>
&lt;p>Both of these run a random query in a single thread so I thought I would use &lt;a class="link" href="https://www.powershellgallery.com/packages/PoshRSJob/1.7.4.4" target="_blank" rel="noopener"
>PoshRSJob&lt;/a> by Boe Prox &lt;a class="link" href="https://learn-powershell.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>t&lt;/a> to run multiple queries at the same time &lt;/p>
&lt;p>To install PoshRSJob, like with any PowerShell module, you run&lt;/p>
&lt;pre>&lt;code>Install-Module -Name PoshRSJob
&lt;/code>&lt;/pre>
&lt;p>I downloaded AdventureWorksBOLWorkload zip from Pieters blog post and extracted to my &lt;code>C:\temp folder&lt;/code>. I created a &lt;code>Invoke-RandomWorkload&lt;/code> function which you can get from my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions" target="_blank" rel="noopener"
>functions repository in GitHub&lt;/a>. The guts of the function are&lt;/p>
&lt;pre>&lt;code> 1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
&lt;/code>&lt;/pre>
&lt;p>which will created $NumberOfJobs jobs and then run $Throttle number of jobs in the background until they have all completed. Each job will run a random query from the query file using Invoke-SqlCmd. Why did I use Invoke-SqlCmd and not Invoke-DbaQuery from dbatools? dbatools creates runspaces in the background to help with logging and creating runspaces inside background jobs causes errors&lt;/p>
&lt;p>Then I can run the function with&lt;/p>
&lt;pre>&lt;code>Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?resize=630%2C256&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and create a random workload. Creating lots of background jobs takes resources so when I wanted to run a longer workload I created a loop.&lt;/p>
&lt;pre>&lt;code>$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
&lt;/code>&lt;/pre>
&lt;p>You can get the function here. The full code is below&lt;/p>
&lt;pre>&lt;code># With thanks to Jonathan Kehayias and Pieter Vanhove
&amp;lt;#
.SYNOPSIS
Runs a random workload against a database using a sql file
.DESCRIPTION
Runs a random workload against a database using PoshRSJobs to create parallel jobs to run random
queries from a T-SQL file by default it uses the AdventureWorksBOLWorkload.sql from Pieter Vanhove
.PARAMETER SqlInstance
The SQL instance to run the queries against
.PARAMETER SqlCredential
The SQL Credential for the Instance if required
.PARAMETER Database
The name of the database to run the queries against
.PARAMETER NumberOfJobs
The number of jobs to create - default 10
.PARAMETER Delay
The delay in seconds for the output for the running jobs - default 10
.PARAMETER Throttle
The number of parallel jobs to run at a time - default 5
.PARAMETER PathToScript
The path to the T-SQL script holding the queries - default 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql'
.PARAMETER Delimiter
The delimiter in the T-SQL Script between the queries - default ------
.PARAMETER ShowOutput
Shows the output from the jobs
.EXAMPLE
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 100 -Delay 10 -Throttle 10
Runs 100 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23
.EXAMPLE
$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
Runs 1000 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23 10 times in a loop
.NOTES
With thanks to Pieter Vanhove
https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/
and
Jonathan Kehayias
https://www.sqlskills.com/blogs/jonathan/ the-adventureworks2008r2-books-online-random-workload-generator /
&amp;gt;
function Invoke-RandomWorkload {
#Requires -Module PoshRsJob
#Requires -Module SQLServer
Param(
[string]$SqlInstance,
[pscredential]$SqlCredential,
[string]$Database,
[int]$NumberOfJobs = 10,
[int]$Delay = 10,
[int]$Throttle = 5,
[string]$PathToScript = 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql',
[string]$Delimiter = &amp;quot;------&amp;quot;,
[switch]$ShowOutput
)
#Check if there are old Workload Jobs
$WorkloadJobs = Get-RSJob -Name Workload
if ($WorkloadJobs) {
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
$WorkloadJobs |Stop-RSJob
$WorkloadJobs | Remove-RSJob
}
Write-Output &amp;quot;Creating Background Jobs&amp;quot;
1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
$runningJobs = (Get-RSJob -Name WorkLoad -State Running). Count
While ($runningJobs -ne 0) {
$jobs = Get-RSJob -Name WorkLoad
$runningJobs = $Jobs.Where{$PSItem.State -eq 'Running'} .Count
$WaitingJobs = $Jobs.Where{$PSItem.State -eq 'NotStarted'}.Count
$CompletedJobs = $Jobs.Where{$PSItem.State -eq 'Completed'}.Count
Write-Output &amp;quot;$runningJobs jobs running - $WaitingJobs jobs waiting - $CompletedJobs -jobs finished&amp;quot;
Start-Sleep -Seconds $Delay
}
Write-Output &amp;quot;Jobs have finished&amp;quot;
if ($ShowOutput) {
Write-Output &amp;quot;WorkLoad Jobs Output below -&amp;quot;
Get-RSJob -Name WorkLoad | Receive-RSJob
}
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
Get-RSJob -Name WorkLoad | Remove-RSJob
Write-Output &amp;quot;Finished&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Whats a SQL Notebook in Azure Data Studio?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-7.png" alt="Featured image of post Whats a SQL Notebook in Azure Data Studio?" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-2017?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a cross-platform database tool for data professionals using the Microsoft family of on-premises and cloud data platforms on Windows, MacOS, and Linux.&lt;/p>
&lt;p>Recently Vicky Harp tweeted&lt;/p>
&lt;blockquote>
&lt;p>We&amp;rsquo;re getting very close to release of SQL Notebooks in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>! You can give the feature an early spin today with the insider build. &lt;a class="link" href="https://t.co/SEZp7ZdxCp" target="_blank" rel="noopener"
>pic.twitter.com/SEZp7ZdxCp&lt;/a>&lt;/p>
&lt;p> Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1104127412944551936?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 8, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>By the way, you can watch a recording from SQLBits of Vickys session&lt;/p>
&lt;blockquote>
&lt;p>If you missed &lt;a class="link" href="https://twitter.com/hashtag/sqlbits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#sqlbits&lt;/a>, you will definitely want to watch this demo by &lt;a class="link" href="https://twitter.com/vickyharp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@vickyharp&lt;/a> and &lt;a class="link" href="https://twitter.com/MGoCODE?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@MGoCODE&lt;/a> about &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>. Learn the latest about our cross-platform tool, including a new feature, SQL Notebooks &lt;a class="link" href="https://twitter.com/hashtag/SQLServer?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLServer&lt;/a> &lt;a class="link" href="https://t.co/diubYwQckn" target="_blank" rel="noopener"
>https://t.co/diubYwQckn&lt;/a>&lt;/p>
&lt;p> Azure Data Studio (@AzureDataStudio) &lt;a class="link" href="https://twitter.com/AzureDataStudio/status/1103806327065722880?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 7, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>So in the interest of learning about something new I decided to give it a try.&lt;/p>
&lt;h2 id="install-the-insiders-edition">Install The Insiders Edition&lt;/h2>
&lt;p>Unlike &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> which has a link to the insiders download on the front page, you will have to &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio#azure-data-studio" target="_blank" rel="noopener"
>visit the GitHub repository for the links to download the insiders release of Azure Data Studio&lt;/a>. Scroll down and you will see&lt;/p>
&lt;p>Try out the latest insiders build from&lt;code>master&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider" target="_blank" rel="noopener"
>Windows User Installer &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider" target="_blank" rel="noopener"
>Windows System Installer &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider" target="_blank" rel="noopener"
>Windows ZIP &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider" target="_blank" rel="noopener"
>macOS ZIP &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider" target="_blank" rel="noopener"
>Linux TAR.GZ &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See the&lt;a class="link" href="https://github.com/Microsoft/azuredatastudio/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>change log&lt;/a>for additional details of whats in this release.
Once you have installed you can connect to an instance, right click and choose New Notebook or you can use File  New Notebook
&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image.png"
loading="lazy"
>&lt;/p>
&lt;p>Incidentally, I use the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> to create the containers and I map &lt;code>C:\MSSQL\BACKUP\KEEP&lt;/code> on my local machine (where my backups are) to &lt;code>/var/opt/mssql/backups&lt;/code> on the containers on lines 10 and 17 of the docker-compose so change as required . If you want to follow along then put the ValidationResults.bak in the folder on your local machine.
The &lt;code>Create-Ag.ps1&lt;/code> shows the code and creates an AG with &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.&lt;/a> But I digress!&lt;/p>
&lt;h2 id="install-notebook-dependencies">Install Notebook Dependencies&lt;/h2>
&lt;p>Once you click New Notebook you will get a prompt to install the dependencies.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>It will show its output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and take a few minutes to run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>It took all but 11 minutes on my machine&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-notebook">Create a Notebook&lt;/h2>
&lt;p>OK, so now that we have the dependencies installed we can create a notebook. I decided to use the ValidationResults database that &lt;a class="link" href="https://blog.robsewell.com/dbachecks-save-the-results-to-a-database-for-historical-reporting/" target="_blank" rel="noopener"
>I use for my dbachecks demos and describe here&lt;/a>. I need to restore it from my local folder that I have mapped as a volume to my container. Of course, I use dbatools for this &lt;/p>
&lt;pre>&lt;code># U: sqladmin P: dbatools.IO
$cred = Get-Credential
$restoreDbaDatabaseSplat = @{
SqlInstance = $sqlinstance1
SqlCredential = $cred
UseDestinationDefaultDirectories = $true
Path = '/var/opt/mssql/backups/ValidationResults.bak'
}
Restore-DbaDatabase @restoreDbaDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>I had already got a connection saved to the instance in Azure Data Studio, you may need to create a new one using the new connection icon at the top left and filling in the details. The password is in the code above.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can start with my notebook. I am faced with this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I click on text and provide an intro&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I had written that and clicked out, I couldnt see what to do straight away!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I saw the code and text buttons at the top  Right, lets get on with it  I hit the code button and paste in the T-SQL to reset the dates in the database to simulate dbachecks having been run this morning.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-9.png"
loading="lazy"
>
Theres a run cell button on the right and when I press it&amp;gt;&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->
Cool &lt;/p>
&lt;p>If the SQL query has results then they are shown as well&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>This is fun and I can see plenty of uses for it. Go and have a play with SQL notebooks &lt;/p>
&lt;h2 id="source-control">Source Control&lt;/h2>
&lt;p>I used CTRL K, CTRL O to open a folder and saved my notebook in my local Presentations folder which is source controlled. When I opened the explorer CTRL + SHIFT + E I can see that the folder and the file are colour coded green and have a U next to them marking them as Untracked. I can also see that the source control icon has a 1 for the number of files with changes and in the bottom left that I am in the master branch.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>If I click on the source control icon (or CTRL + SHIFT + G) I can see the files with the changes and can enter a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>I then press CTRL + ENTER to commit my change and get this pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>As I only have one file and it has all the changes for this commit I click yes. If I had changed more than one file and only wanted to commit a single one at a time I would hover my mouse over the file and click the + to stage my change.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>If I make a further change to the notebook and save it, I can see that the source control provider recognises the change but this time the folder the file is in and the file are colour coded brown with an M to show that they have been modified.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Unlike Visual Studio Code, when you then click on the source control icon and click on the change it does not show the differences in the notebook although this works with SQL files.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>When I have made all my changes and committed them with good commit messages&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/imgs.xkcd.com/comics/git_commit.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can see that there are 3 local changes ready to be pushed to by remote repository (GitHub in this case) and 0 remote commits in this branch by looking at the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I can click on the roundy roundy icon (I don&amp;rsquo;t know its proper name ) and synchronise my changes. This comes with a pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Personally I never press OK, Dont Show Again because I like the double check and to think Is this really what I want to do right now. Once I press OK my changes will be synched with the remote repository. Explaining this means that you can find the notebook I have used in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/Notebooks" target="_blank" rel="noopener"
>Presentations GitHub Repository&lt;/a> which means that you can run the Notebook too using the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> and the instructions further up in the post.&lt;/p></description></item><item><title>#TSQL2sDay  NomNomNomNomNom</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-nomnomnomnomnom/</link><pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-nomnomnomnomnom/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/pille-riin-priske-1238490-unsplash.jpg" alt="Featured image of post #TSQL2sDay  NomNomNomNomNom" />&lt;p>&lt;a class="link" href="https://nocolumnname.blog/2019/03/05/t-sql-tuesday-112-dipping-into-your-cookie-jar/" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The topic for this months&lt;a class="link" href="https://nocolumnname.blog/2019/03/05/t-sql-tuesday-112-dipping-into-your-cookie-jar/" target="_blank" rel="noopener"
>T-SQL Tuesday #112&lt;/a>hosted by Shane ONeill (&lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>Blog&lt;/a>/&lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>Twitter&lt;/a>) is about dipping into your cookie jar. This reference means when times get tough how do you dip into your reserves to keep going. Shane asks the following:&lt;/p>
&lt;blockquote>
&lt;p>That is what I want from the contributors of this T-SQL Tuesday, those memories that they can think back on for sustenance. Like the humble cookie, I want a humble brag.&lt;/p>
&lt;/blockquote>
&lt;h2 id="mmmm-cookies">Mmmm Cookies&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/pille-riin-priske-1238490-unsplash.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Photo by&lt;a class="link" href="https://unsplash.com/photos/DM-KD1_fZrg?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Pille-Riin Priske&lt;/a>on&lt;a class="link" href="https://unsplash.com/search/photos/cookie?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>Im not good at bragging, &lt;a class="link" href="https://en.wikipedia.org/wiki/Impostor_syndrome" target="_blank" rel="noopener"
>Im generally convinced that all of you are better than me&lt;/a>. Yes, I am aware that it is irrational. This has made writing this post really hard. Sure, I get immense pleasure and satisfaction from solving a problem, thats a form of instant fulfillment. Certainly, I enjoy teaching people and passing over my knowledge for them to use.&lt;br>
I am not going to write about technical things that I have done because they dont give me sustenance in that way.&lt;/p>
&lt;p>So what does give me sustenance when times are hard?&lt;/p>
&lt;p>People.&lt;/p>
&lt;p>The things I am most proud of are the things other people do where I have played a small part. These are the things I look back at and help to energise me. Things like&lt;/p>
&lt;ul>
&lt;li>A couple of people who I suggested started writing blogs and then speaking who are now seen as experts in their niche.&lt;/li>
&lt;li>The people I mentored as new speakers who are now speaking all over the continent.&lt;/li>
&lt;/ul>
&lt;p>The most recent story was a DBA who sat in a full day pre-con at a SQL Saturday, took loads of notes and waited at the end to ask questions. We were looking at some code and she was telling me it wasnt very good and apologising for it. It was good, it performed the required actions over a large estate and I told her so. I asked about her job and with a big sigh, she told a story of being stuck in a rut, dealing with a lot of legacy systems, not enjoying it and not being able to move on. We had a long talk.&lt;/p>
&lt;p>Cut to this years SQL Bits and she came running up to me all energised. She has a new job, doing something Cool in the cloud, she said the things she had learned had helped her to land this role.&lt;/p>
&lt;p>In all of these cases, it is the person involved who has done all of the hard work but it is these things that keep me going. The thank yous and the smiles I see on those peoples faces as they do the thing that they love and enjoy their success and progression &lt;/p>
&lt;h2 id="cake-">Cake !!!!!&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/prince-abid-653931-unsplash.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Photo by&lt;a class="link" href="https://unsplash.com/photos/pEvPkPmuHzo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Prince Abid&lt;/a>on&lt;a class="link" href="https://unsplash.com/search/photos/cake?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>Hey, thats cake and not cookies Rob.&lt;/p>
&lt;p>I know. The biggest thing that keeps me going when times are tough though is the security I am able to provide. Nearly 20 years ago my life was very different. Without a job, Id had to give up a career, struggling dealing with my wifes serious illnesses, suddenly responsible for the entire household without the means to provide, I was in a very bleak place and saw no way out.&lt;/p>
&lt;p>So to have found a career that is my hobby, to be able to work and also to have fun, to have a social world that provides me with friends and entertainment in many countries and the opportunity to experience different cultures and still be able to live comfortably. Thats a blessing and what keeps me going.&lt;/p>
&lt;p>Also being able to pay my dad back for turning up with sacks of potatoes by taking him to football matches and comedy shows &lt;/p>
&lt;p>Acknowledge what you have got, tell your loved ones that you love them, enjoy life and use your cookies when you need them but dont forget the cake &lt;/p></description></item><item><title>#DataInDevon  Getting up to speed with PowerShell or spend a day with one of four other MVPs :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#dataindevon-getting-up-to-speed-with-powershell-or-spend-a-day-with-one-of-four-other-mvps-/</link><pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#dataindevon-getting-up-to-speed-with-powershell-or-spend-a-day-with-one-of-four-other-mvps-/</guid><description>&lt;p>Saturday 27th April is Global Azure Bootcamp day&lt;/p>
&lt;p>Whats Global Azure Bootcamp?&lt;/p>
&lt;p>The &lt;a class="link" href="https://global.azurebootcamp.net/" target="_blank" rel="noopener"
>website&lt;/a> says it best&lt;/p>
&lt;blockquote>
&lt;p>. communities will come together once again in the sixth great Global Azure Bootcamp event! Each user group will organize their own one day deep dive class on Azure the way they see fit and how it works for their members. The result is that thousands of people get to learn about Azure and join together online under the social hashtag &lt;a class="link" href="https://twitter.com/search?q=%23GlobalAzure" target="_blank" rel="noopener"
>#GlobalAzure&lt;/a>!&lt;/p>
&lt;/blockquote>
&lt;h2 id="saturday-is-free-learning">Saturday Is Free Learning&lt;/h2>
&lt;p>I am a part of the team organising the event in Exeter. Now there is a little story here. We had chosen this date by chance to hold an event we call Data In Devon giving people in the South West (of UK) the chance to access a whole day of high quality data and technical sessions for free on a Saturday.&lt;/p>
&lt;p>When the Global Azure Bootcamp was announced, we had a conversation with the organisers and they agreed that we could add Exeter as a venue as we had already decided to have a whole track dedicated to Azure. You can find our schedule here &lt;a class="link" href="https://sqlsouthwest.co.uk/data-in-devon-saturday-schedule/" target="_blank" rel="noopener"
>https://sqlsouthwest.co.uk/data-in-devon-saturday-schedule/&lt;/a> and you can register to attend &lt;a class="link" href="https://www.eventbrite.com/e/data-in-devon-registration-50262066193v" target="_blank" rel="noopener"
>via this form&lt;/a>&lt;/p>
&lt;p>Now, we have some costs obviously, not a lot but venues are not free and neither is food . We have a couple of sponsors (feel free to contact me if your company is interested in sponsoring the event) but we also have some paid training days on Friday 25th April.&lt;/p>
&lt;h2 id="friday-is-training-day">Friday Is Training Day&lt;/h2>
&lt;p>Its a great opportunity to get cheap high-quality training from some of the best in their areas of expertise. There are still some tickets for 175 and the price will rise only to 200. I think that 200 is fantastic value to be able to spend a day learning from&lt;/p>
&lt;p>Alex Whittles  Data Platform MVP  &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#BiinAzure" target="_blank" rel="noopener"
>Bi in Azure&lt;/a>&lt;br>
John Martin  Data Platform MVP  &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#InfrastructureAsCode" target="_blank" rel="noopener"
>Infrastructure as Code with Terraform&lt;/a>&lt;br>
Terry McCann  Data Platform MVP  &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#MachineLearning" target="_blank" rel="noopener"
>Machine Learning: From model to production using the cloud, containers and Dev Ops&lt;/a>&lt;br>
William Durkin  Data Platform MVP  &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Performance" target="_blank" rel="noopener"
>Performance Pain Reduction for Data Platform Projects&lt;/a>&lt;/p>
&lt;p>and myself  &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Powershell" target="_blank" rel="noopener"
>Getting up to speed with PowerShell&lt;/a>&lt;/p>
&lt;p>You can sign up for any of these sessions by following the instructions here &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Pricing" target="_blank" rel="noopener"
>https://sqlsouthwest.co.uk/training-day-schedule/#Pricing&lt;/a> We dont have a fancy website or booking system as we wanted to keep costs down.&lt;/p>
&lt;p>The details of my training day are below&lt;/p>
&lt;h1 id="getting-up-to-speed-with-powershells">Getting up to speed with PowerShell&lt;strong>S&lt;/strong>&lt;/h1>
&lt;p>PowerShell is cross-platform, it works exactly the same on Windows, on Linux and Mac. It is awesome for automation and amazing for administration.&lt;/p>
&lt;p>We will cover&lt;/p>
&lt;ul>
&lt;li>the basics about PowerShell, PowerShell security&lt;/li>
&lt;li>how to open PowerShell , how to install PowerShell .&lt;/li>
&lt;li>4 vital commands to enable you to be able to help yourself&lt;/li>
&lt;li>The PowerShell Gallery and how to find, install and use additional modules&lt;/li>
&lt;li>Reading the language&lt;/li>
&lt;li>Working with output&lt;/li>
&lt;li>Why Red text is a good thing and how to learn from the errors&lt;/li>
&lt;li>We will even delve into scripting with PowerShell and how to validate your environment&lt;/li>
&lt;/ul>
&lt;p>There will also be the opportunity to learn about any areas of PowerShell, Automation, CI/CD that you have questions about. This is a beginner level session in which I will teach you to be comfortable with PowerShell and confident in being able to use it in the future&lt;/p>
&lt;p>Attendees wanting to follow along should bring a laptop.&lt;/p></description></item><item><title>Using Docker to run Integration Tests for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</link><pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</guid><description>&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Andr Kamman&lt;/a> wrote a fantastic blog post this week &lt;a class="link" href="https://andrekamman.com/sql-server-container-instances-via-cloudshell/" target="_blank" rel="noopener"
>SQL Server Container Instances via Cloudshell&lt;/a> about how he uses containers in Azure to test code against different versions of SQL Server.&lt;/p>
&lt;p>It reminded me that I do something very similar to test &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> code changes. I thought this might make a good blog post. I will talk through how I do this locally as I merge a PR from another great friend &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>Cludio Silva&lt;/a> who has added &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/582" target="_blank" rel="noopener"
>agent job history checks.&lt;/a>&lt;/p>
&lt;h2 id="github-pr-vs-code-extension">GitHub PR VS Code Extension&lt;/h2>
&lt;p>I use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github" target="_blank" rel="noopener"
>GitHub Pull Requests extension for VS Code&lt;/a> to work with pull requests for &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pulls" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This enables me to see all of the information about the Pull Request, merge it, review it, comment on it all from VS Code&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/GitHub-Pull-Request-VsCode-Extension.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see which files have been changed and which changes have been made&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/viewing-a-change.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I am ready to test the pull request I perform a checkout using the extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/checkout-pull-request-checkout.png"
loading="lazy"
>&lt;/p>
&lt;p>This will update all of the files in my local repository with all of the changes in this pull request&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>You can see at the bottom left that the branch changes from development to the name of the PR.&lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-unit-tests">Running The Unit Tests&lt;/h2>
&lt;p>The first thing that I do is to run the Unit Tests for the module. These will test that the code is following all of the guidelines that we require and that the tests are formatted in the correct way for the Power Bi to parse. I have blogged about this &lt;a class="link" href="https://blog.robsewell.com/using-the-ast-in-pester-for-dbachecks/" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-the-powershell-ast-to-find-a-foreach-method/" target="_blank" rel="noopener"
>here&lt;/a> and we use this Pester in our CI process in Azure DevOps which I described &lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>here.&lt;/a>&lt;/p>
&lt;p>I navigate to the root of the dbachecks repository on my local machine and run&lt;/p>
&lt;pre>&lt;code> $testresults = Invoke-Pester .\tests -ExcludeTag Integration -Show Fails -PassThru
&lt;/code>&lt;/pre>
&lt;p>and after about a minute&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/pester-tests.png"
loading="lazy"
>&lt;/p>
&lt;p>Thank you Cludio, the code has passed the tests &lt;/p>
&lt;h2 id="running-some-integration-tests">Running Some Integration Tests&lt;/h2>
&lt;p>The difference between Unit tests and Integration tests in a nutshell is that the Unit tests are testing that the code is doing what is expected without any other external influences whilst the Integration tests are checking that the code is doing what is expected when running on an actual environment. In this scenario we know that the code is doing what is expected but we want to check what it does when it runs against a SQL Server and even when it runs against multiple SQL Servers of different versions.&lt;/p>
&lt;h2 id="multiple-versions-of-sql-server">Multiple Versions of SQL Server&lt;/h2>
&lt;p>As I have described &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>before&lt;/a> my friend and former colleague Andrew Pruski &lt;a class="link" href="http://dbafromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="http://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has many resources for running SQL in containers. This means that I can quickly and easily create fresh uncontaminated instances of SQL 2012, 2014, 2016 and 2017 really quickly.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/creating-contatiners.png"
loading="lazy"
>&lt;/p>
&lt;p>I can create 4 instances of different versions of SQL in (a tad over) 1 minute. How about you?&lt;/p>
&lt;p>Imagine how long it would take to run the installers for 4 versions of SQL and the pain you would have trying to uninstall them and make sure everything is clean. Even images that have been sysprepd wont be done in 1 minute.&lt;/p>
&lt;h2 id="docker-compose-up-">Docker Compose Up ?&lt;/h2>
&lt;p>So what is this magic command that has enabled me to do this? docker compose uses a YAML file to define multi-container applications. This means that with a file called docker-compose.yml like &lt;a class="link" href="https://gist.github.com/SQLDBAWithABeard/b589d499484af4ebfb7d637cb6b4efa3" target="_blank" rel="noopener"
>this&lt;/a>&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/ mssql-server-windows-developer:2017-latest
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and in that directory just run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>and 4 SQL containers are available to you. You can interact with them via SSMS if you wish with localhost comma PORTNUMBER. The port numbers in the above file are 15586, 15587,15588 and 15589&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?resize=630%2C188&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>Now it must be noted, as I &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>describe here&lt;/a> that first I pulled the images to my laptop. The first time you run docker compose will take significantly longer if you havent pulled the images already (pulling the images will take quite a while depending on your broadband speed)&lt;/p>
&lt;h2 id="credential">Credential&lt;/h2>
&lt;p>The next thing is to save a credential to make it easier to automate.&lt;del>I use the method described by my PowerShell friend Jaap Brasser &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/del>&lt;/p>
&lt;p>EDIT (September or is it March? 2020) - Nowadays I use the Secret Management Module&lt;/p>
&lt;p>I run this code&lt;/p>
&lt;pre>&lt;code> $CredentialPath = 'C:\MSSQL\BACKUP\KEEP\sacred.xml'
Get-Credential | Export-Clixml -Path $CredentialPath
&lt;/code>&lt;/pre>
&lt;p>and then I can create a credential object using&lt;/p>
&lt;pre>&lt;code>$cred = Import-Clixml $CredentialPath
&lt;/code>&lt;/pre>
&lt;h2 id="check-the-connections">Check The Connections&lt;/h2>
&lt;p>I ensure a clean session by removing the dbatools and dbachecks modules and then import the local version of dbachecks and set some variables&lt;/p>
&lt;pre>&lt;code>$dbacheckslocalpath = 'GIT:\dbachecks\'
Remove-Module dbatools, dbachecks -ErrorAction SilentlyContinue
Import-Module $dbacheckslocalpath\dbachecks.psd1
$cred = Import-Clixml $CredentialPath
$containers = 'localhost,15589', 'localhost,15588', 'localhost, 15587', 'localhost,15586'
&lt;/code>&lt;/pre>
&lt;p>Now I can start to run my Integration tests. First reset the dbachecks configuration and set some configuration values&lt;/p>
&lt;pre>&lt;code># run the checks against these instances
$null = Set-DbcConfig -Name app.sqlinstance $containers
# We are using SQL authentication
$null = Set-DbcConfig -Name policy.connection.authscheme -Value SQL
# sometimes its a bit slower than the default value
$null = Set-DbcConfig -Name policy.network.latencymaxms -Value 100 # because the containers run a bit slow!
&lt;/code>&lt;/pre>
&lt;p>Then I will run the dbachecks connectivity checks and save the results to a variable without showing any output&lt;/p>
&lt;pre>&lt;code>$ConnectivityTests = Invoke-DbcCheck -SqlCredential $cred -Check Connectivity -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>I can then use Pester to check that dbachecks has worked as expected by testing if the failedcount property returned is 0.&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;Testing the checks are running as expected&amp;quot; -Tag Integration {
Context &amp;quot;Connectivity Checks&amp;quot; {
It &amp;quot;All Tests should pass&amp;quot; {
$ConnectivityTests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default settings&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/check-connectivity.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="what-is-the-unit-test-for-this-pr">What is the Unit Test for this PR?&lt;/h2>
&lt;p>Next I think about what we need to be testing for the this PR. The Unit tests will help us.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/what-are-the-unit-tests.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="choose-some-integration-tests">Choose some Integration Tests&lt;/h2>
&lt;p>This check is checking the Agent job history settings and the unit tests are&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It Passes Check Correctly with Maximum History Rows disabled (-1)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It Fails Check Correctly with Maximum History Rows disabled (-1) but configured value is 1000&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It Passes Check Correctly with Maximum History Rows being 10000&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It Fails Check Correctly with Maximum History Rows being less than 10000&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It Passes Check Correctly with Maximum History Rows per job being 100&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It Fails Check Correctly with Maximum History Rows per job being less than 100&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So we will check the same things on real actual SQL Servers. First though we need to start the SQL Server Agent as it is not started by default. We can do this as follows&lt;/p>
&lt;pre>&lt;code>docker exec -ti integration_sql2012_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2014_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2016_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2017_1 powershell start-service SQLSERVERAGENT
&lt;/code>&lt;/pre>
&lt;p>Unfortunately, the agent service wont start in the SQL 2014 container so I cant run agent integration tests for that container but its better than no integration tests.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/agent-wont-start.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="this-is-what-we-will-test">This is What We Will Test&lt;/h2>
&lt;p>So we want to test if the check will pass with default settings. In general, dbachecks will pass for default instance, agent or database settings values by default.&lt;/p>
&lt;p>We also want the check to fail if the configured value for dbachecks is set to default but the value has been set on the instance.&lt;/p>
&lt;p>We want the check to pass if the configured value for the dbachecks configuration is set and the instance (agent, database) setting matches it.&lt;/p>
&lt;h2 id="if-you-are-doing-something-more-than-once-">If You Are Doing Something More Than Once &lt;/h2>
&lt;p>Lets automate that. We are going to be repeatedly running those three tests for each setting that we are running integration tests for. I have created 3 functions for this again checking that FailedCount or Passed Count is 0 depending on the test.&lt;/p>
&lt;pre>&lt;code>function Invoke-DefaultCheck {
It &amp;quot;All Checks should pass with default for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)default&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default setting (Yes we may set some values before but you get my drift)&amp;quot;
}
}
function Invoke-ConfigCheck {
It &amp;quot;All Checks should fail when config changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)configchanged&amp;quot; -ValueOnly
$Tests.PassedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and fail when we have changed the config values&amp;quot;
}
}
function Invoke-ValueCheck {
It &amp;quot;All Checks should pass when setting changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check) value changed&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass when we have changed the settings to match the config values&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Now I can use those functions inside a loop in my Integration Pester Test&lt;/p>
&lt;pre>&lt;code>$TestingTheChecks = @('errorlogscount','jobhistory')
Foreach ($Check in $TestingTheChecks) {
Context &amp;quot;$Check Checks&amp;quot; {
Invoke-DefaultCheck
Invoke-ConfigCheck
Invoke-ValueCheck
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="write-some-integration-tests">Write Some Integration Tests&lt;/h2>
&lt;p>So for this new test I have added a value to the TestingTheChecks array then I can test my checks. The default check I can check like this&lt;/p>
&lt;pre>&lt;code># run the checks against these instances (SQL2014 agent wont start :-( ))
$null = Set-DbcConfig -Name app.sqlinstance $containers.Where {$_ -ne 'localhost,15588'}
# by default all tests should pass on default instance settings
$jobhistorydefault = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Now I need to change the configurations so that they do not match the defaults and run the checks again&lt;/p>
&lt;pre>&lt;code>#Change the configuration to test that the checks fail
$null = Set-DbcConfig -Name agent.history. maximumjobhistoryrows -value 1000
$null = Set-DbcConfig -Name agent.history.maximumhistoryrows -value 10000
$jobhistoryconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Next we have to change the instance settings so that they match the dbachecks configuration and run the checks and test that they all pass.&lt;/p>
&lt;p>We will (of course) use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> for this. First we need to find the command that we need&lt;/p>
&lt;pre>&lt;code>Find-DbaCommand jobserver
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/find-dbacommand.png"
loading="lazy"
>&lt;/p>
&lt;p>and then work out how to use it&lt;/p>
&lt;pre>&lt;code>Get-Help Set-DbaAgentServer -Detailed
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/set-the-values.png"
loading="lazy"
>&lt;/p>
&lt;p>There is an example that does exactly what we want  So we can run this.&lt;/p>
&lt;pre>&lt;code>$setDbaAgentServerSplat = @{
MaximumJobHistoryRows = 1000
MaximumHistoryRows = 10000
SqlInstance = $containers.Where{$_ -ne 'localhost,15588'}
SqlCredential = $cred
}
Set-DbaAgentServer @setDbaAgentServerSplat
$jobhistoryvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;h2 id="run-the-integration-tests">Run the Integration Tests&lt;/h2>
&lt;p>And then we will check that all of the checks are passing and failing as expected&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\DockerTests.ps1
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/testing-the-checks.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="integration-test-for-error-log-counts">Integration Test For Error Log Counts&lt;/h2>
&lt;p>There is another integration test there for the error logs count. This works in the same way. Here is the code&lt;/p>
&lt;pre>&lt;code>#region error Log Count - PR 583
# default test
$errorlogscountdefault = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set a value and then it will fail
$null = Set-DbcConfig -Name policy.errorlog.logcount -Value 10
$errorlogscountconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set the value and then it will pass
$null = Set-DbaErrorLogConfig -SqlInstance $containers -SqlCredential $cred -LogCount 10
$errorlogscountvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
#endregion
&lt;/code>&lt;/pre>
&lt;h2 id="merge-the-changes">Merge the Changes&lt;/h2>
&lt;p>So with all the tests passing I can merge the PR into the development branch and Azure DevOps will start a build. Ultimately, I would like to add the integration to the build as well following &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Andr&lt;/a>s blog post but for now I used the GitHub Pull Request extension to merge the pull request into development which started a &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_build/results?buildId=365&amp;amp;view=results" target="_blank" rel="noopener"
>build&lt;/a> and then merged that into master which signed the code and deployed it to the PowerShell gallery as you can see &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=81&amp;amp;environmentId=81" target="_blank" rel="noopener"
>here&lt;/a> and the result is&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.164" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/dbachecks/1.1.164&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/powershell-gallery.png"
loading="lazy"
>&lt;/p></description></item><item><title>How I created PowerShell.cool using Flow, Azure SQL DB, Cognitive Services &amp; PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</link><pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</guid><description>&lt;p>Last weekend I was thinking about how to save the tweets for PowerShell Conference Europe. This annual event occurs in Hanover and this year it is onApril 17-20, 2018. The agenda has just been released and you can find it on the website&lt;a class="link" href="http://www.psconf.eu/" target="_blank" rel="noopener"
>http://www.psconf.eu/&lt;/a>&lt;/p>
&lt;p>I ended up creating an interactive PowerBi report to which my good friend and Data Platform MVP Paul Andrew &lt;a class="link" href="https://mrpaulandrew.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/mrpaulandrew" target="_blank" rel="noopener"
>t&lt;/a>added a bit of magic andI published it. The magnificent Tobias Weltner &lt;a class="link" href="http://www.powertheshell.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/TobiasPSP" target="_blank" rel="noopener"
>t&lt;/a> who organises PSConfEU pointed the domain name &lt;a class="link" href="http://powershell.cool" target="_blank" rel="noopener"
>http://powershell.cool&lt;/a> at the link. It looks like this.&lt;/p>
&lt;p>During the monthly &lt;a class="link" href="https://twitter.com/hashtag/PSTweetChat?src=hash" target="_blank" rel="noopener"
>#PSTweetChat&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Reminder that we do this chat the first Friday of every month from 1-2PM Eastern which I think is 6:00PM UTC &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p> Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959495635182477324?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I mentioned that I need to blog about how I created it and Jeff replied&lt;/p>
&lt;blockquote>
&lt;p>Yes, please. I&amp;rsquo;d love to setup something similiar for the PowerShell+DevOps Summit. &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p> Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959494450547511298?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>so here it is! Looking forward to seeing the comparison between the &lt;a class="link" href="https://powershell.org/summit/" target="_blank" rel="noopener"
>PowerShell and Devops Summi&lt;/a>t and the &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference Europe&lt;/a> &lt;/p>
&lt;p>This is an overview of how it works&lt;/p>
&lt;ul>
&lt;li>A &lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>Microsoft Flow&lt;/a> looks for tweets with the &lt;a class="link" href="https://twitter.com/search?q=%23PSConfEU&amp;amp;src=typd" target="_blank" rel="noopener"
>#PSConfEU&lt;/a> hashtag and then gets the information about the tweet&lt;/li>
&lt;li>&lt;a class="link" href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/" target="_blank" rel="noopener"
>Microsoft Cognitive Services Text Analysis API&lt;/a> analyses the sentiment of the tweet and provides a score between 0 (negative) and 1 (positive)&lt;/li>
&lt;li>Details about the tweet and the sentiment are saved in &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/sql-database/" target="_blank" rel="noopener"
>Azure SQL database&lt;/a>&lt;/li>
&lt;li>A &lt;a class="link" href="http://PowerBi.com" target="_blank" rel="noopener"
>PowerBi&lt;/a> report uses that data and provides the report&lt;/li>
&lt;/ul>
&lt;p>You will find all of the resources and the scripts to do all of the below in &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>the GitHub repo.&lt;/a> So clone it and navigate to the filepath&lt;/p>
&lt;h2 id="create-database">Create Database&lt;/h2>
&lt;p>First lets create a database. Connect to your Azure subscription&lt;/p>
&lt;pre>&lt;code>## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YourSubscriptionIDHere
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png"
loading="lazy"
alt="01 - subscription.png"
>&lt;/a>&lt;/p>
&lt;p>Then set some variables&lt;/p>
&lt;pre>&lt;code># The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
# The logical server name: Use a random value or replace with your own value (do not capitalize)
$servername = &amp;quot;server-$(Get-Random)&amp;quot;
# Set an admin login and password for your database
# The login information for the server You need to set these and uncomment them - Dont use these values
# $adminlogin = &amp;quot;ServerAdmin&amp;quot;
# $password = &amp;quot;ChangeYourAdminPassword1&amp;quot;
# The ip address range that you want to allow to access your server - change as appropriate
# $startip = &amp;quot;0.0.0.0&amp;quot;
# $endip = &amp;quot;0.0.0.0&amp;quot;
# To just add your own IP Address
$startip = $endip = (Invoke-WebRequest 'http:// myexternalip.com/raw').Content -replace &amp;quot;`n&amp;quot;
# The database name
$databasename = &amp;quot;tweets&amp;quot;
$AzureSQLServer = &amp;quot;$servername.database. windows.net,1433&amp;quot;
$Table = &amp;quot;table.sql&amp;quot;
$Proc = &amp;quot;InsertTweets.sql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>They should all make sense, take note that you need to set and uncomment the login and password and choose which IPs to allow through the firewall&lt;/p>
&lt;p>Create a Resource Group&lt;/p>
&lt;pre>&lt;code>## Create a resource group
New-AzureRmResourceGroup -Name $resourcegroupname -Location $location
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png"
loading="lazy"
alt="02 - resource group.png"
>&lt;/a>&lt;/p>
&lt;p>Create a SQL Server&lt;/p>
&lt;pre>&lt;code>## Create a Server
$newAzureRmSqlServerSplat = @{
SqlAdministratorCredentials = $SqlAdministratorCredentials
ResourceGroupName = $resourcegroupname
ServerName = $servername
Location = $location
}
New-AzureRmSqlServer @newAzureRmSqlServerSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png"
loading="lazy"
alt="03 - create server.png"
>&lt;/a>&lt;/p>
&lt;p>Create a firewall rule, I just use my own IP and add the allow azure IPs&lt;/p>
&lt;pre>&lt;code>$newAzureRmSqlServerFirewallRuleSplat = @{
EndIpAddress = $endip
StartIpAddress = $startip
ServerName = $servername
ResourceGroupName = $resourcegroupname
FirewallRuleName = &amp;quot;AllowSome&amp;quot;
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
# Allow Azure IPS
$newAzureRmSqlServerFirewallRuleSplat = @{
AllowAllAzureIPs = $true
ServerName = $servername
ResourceGroupName = $resourcegroupname
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png"
loading="lazy"
alt="03a - firewall rule.png"
>&lt;/a>&lt;/p>
&lt;p>Create a database&lt;/p>
&lt;pre>&lt;code># Create a database
$newAzureRmSqlDatabaseSplat = @{
ServerName = $servername
ResourceGroupName = $resourcegroupname
Edition = 'Basic'
DatabaseName = $databasename
}
New-AzureRmSqlDatabase @newAzureRmSqlDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png"
loading="lazy"
alt="04 - create database.png"
>&lt;/a>&lt;/p>
&lt;p>I have used the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>to run the scripts to create the database. You can get it using&lt;/p>
&lt;pre>&lt;code>Install-Module dbatools # -Scope CurrentUser # if not admin process
Run the scripts
# Create a credential
$newObjectSplat = @{
ArgumentList = $adminlogin, $ (ConvertTo-SecureString -String $password -AsPlainText -Force)
TypeName = 'System.Management.Automation. PSCredential'
}
$SqlAdministratorCredentials = New-Object @newObjectSplat
## Using dbatools module
$invokeDbaSqlCmdSplat = @{
SqlCredential = $SqlAdministratorCredentials
Database = $databasename
File = $Table,$Proc
SqlInstance = $AzureSQLServer
}
Invoke-DbaSqlCmd @invokeDbaSqlCmdSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png"
loading="lazy"
alt="05 - Create Table Sproc.png"
>&lt;/a>&lt;/p>
&lt;p>This will have created the following in Azure, you can see it in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/07-portal.png"
loading="lazy"
alt="07 - portal.png"
>&lt;/p>
&lt;p>You can connect to the database in SSMS and you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png"
loading="lazy"
alt="06 - show table.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-cognitive-services">Create Cognitive Services&lt;/h2>
&lt;p>Now you can create the Text Analysis Cognitive Services API&lt;/p>
&lt;p>First login (if you need to) and set some variables&lt;/p>
&lt;pre>&lt;code>## This creates cognitive services for analysing the tweets
## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YOUR SUBSCRIPTION ID HERE
#region variables
# The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
$APIName = 'TweetAnalysis'
#endregion
Then create the API and get the key
#Create the cognitive services
$newAzureRmCognitiveServicesAccountSplat = @{
ResourceGroupName = $resourcegroupname
Location = $location
SkuName = 'F0'
Name = $APIName
Type = 'TextAnalytics'
}
New-AzureRmCognitiveServicesAccount @newAzureRmCognitiveServicesAccountSplat
# Get the Key
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat
&lt;/code>&lt;/pre>
&lt;p>You will need to accept the prompt&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png"
loading="lazy"
alt="08 -cognitive service"
>&lt;/a>&lt;/p>
&lt;p>Copy the Endpoint URL as you will need it.Then save one of the keys for the next step!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png"
loading="lazy"
alt="09 cognitiveservice key"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow">Create the Flow&lt;/h2>
&lt;p>I have exported the Flow to a zip file and also the json for a PowerApp (no details about that in this post). Both are available in the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a>. I have submitted a template but it is not available yet.&lt;/p>
&lt;p>Navigate to&lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>https://flow.microsoft.com/&lt;/a>and sign in&lt;/p>
&lt;h2 id="creating-connections">Creating Connections&lt;/h2>
&lt;p>You will need to set up your connections. Click New Connection and search for Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png"
loading="lazy"
alt="16 - import step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add and fill in the Account Key and the Site URL from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png"
loading="lazy"
alt="17 import step 5.png"
>&lt;/a>&lt;/p>
&lt;p>click new connection and search for SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png"
loading="lazy"
alt="18 - import step 6.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the SQL Server Name (value of &lt;code>$AzureSQLServer&lt;/code>) , Database Name , User Name and Password from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png"
loading="lazy"
alt="19 - import step 7.png"
>&lt;/a>&lt;/p>
&lt;p>Click new Connection and search for Twitter and create a connection (the authorisation pop-up may be hidden behind other windows!)&lt;/p>
&lt;h2 id="import-the-flow">Import the Flow&lt;/h2>
&lt;p>If you have a premium account you can import the flow, click Import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png"
loading="lazy"
alt="11 - import flow.png"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png"
loading="lazy"
alt="12 - choose import.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the import.zip from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub Repo&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png"
loading="lazy"
alt="13 import step 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Create as new and choose a name&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png"
loading="lazy"
alt="14 - import step 2.png"
>&lt;/a>&lt;/p>
&lt;p>Click select during import next to Sentiment and choose the Sentiment connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png"
loading="lazy"
alt="15 impot step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Select during import for the SQL Server Connection and choose the SQL Server Connection and do the same for the Twitter Connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png"
loading="lazy"
alt="20 - import stpe 8.png"
>&lt;/a>&lt;/p>
&lt;p>Then click import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png"
loading="lazy"
alt="21 - imported.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow-without-import">Create the flow without import&lt;/h2>
&lt;p>If you do not have a premium account you can still create the flow using these steps. I have created a template but it is not available at the moment. Create the connections as above and then click Create from blank.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png"
loading="lazy"
alt="22 - importblank.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the trigger When a New Tweet is posted and add a search term. You may need to choose the connection to twitter by clicking the three dots&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png"
loading="lazy"
alt="23 - importblank 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add an action&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png"
loading="lazy"
alt="24 - add action.png"
>&lt;/a>&lt;/p>
&lt;p>search for detect and choose the Text Analytics Detect Sentiment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png"
loading="lazy"
alt="25 - choose sentuiment.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the name for the connection, the account key and the URL from the creation of the API above. If you forgot to copy them&lt;/p>
&lt;pre>&lt;code>#region Forgot the details
# Copy the URL if you forget to save it
$getAzureRmCognitiveServicesAccountSplat = @{
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccount @getAzureRmCognitiveServicesAccountSplat). Endpoint | Clip
# Copy the Key if you forgot
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat). Key1 | Clip
#endregion
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png"
loading="lazy"
alt="26 - enter details.png"
>&lt;/a>&lt;/p>
&lt;p>Click in the text box and choose Tweet Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png"
loading="lazy"
alt="27 - choose tweet text.png"
>&lt;/a>&lt;/p>
&lt;p>Click New Step and add an action. Search for SQL Server and choose SQL Server  Execute Stored Procedure&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png"
loading="lazy"
alt="28 - choose sql server execute stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the stored procedure[dbo].[InsertTweet]&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png"
loading="lazy"
alt="29 - choose stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in as follows&lt;/p>
&lt;ul>
&lt;li>__PowerAppsID__    0&lt;/li>
&lt;li>Date                Created At&lt;/li>
&lt;li>Sentiment           Score&lt;/li>
&lt;li>Tweet               Tweet Text&lt;/li>
&lt;li>UserLocation        Location&lt;/li>
&lt;li>UserName           Tweeted By&lt;/li>
&lt;/ul>
&lt;p>as shown below&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?resize=630%2C368&amp;amp;ssl=1"
loading="lazy"
alt="30 stored procedure info.png"
>&lt;/a>&lt;/p>
&lt;p>Give the flow a name at the top and click save flow&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png"
loading="lazy"
alt="31 flow created.png"
>&lt;/a>&lt;/p>
&lt;h2 id="connect-powerbi">Connect PowerBi&lt;/h2>
&lt;p>Open thePSConfEU Twitter Analysis Direct.pbix from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a> in PowerBi Desktop. Click the arrow next to Edit Queries and then change data source settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png"
loading="lazy"
alt="32 change data source.png"
>&lt;/a>&lt;/p>
&lt;p>Click Change source and enter the server(value of &lt;code>$AzureSQLServer&lt;/code>) and the database name. It will alert you to apply changes&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png"
loading="lazy"
alt="33 apply changes.png"
>&lt;/a>&lt;/p>
&lt;p>It will then pop-up with a prompt for the credentials. Choose Database and enter your credentials and click connect&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?resize=630%2C370&amp;amp;ssl=1"
loading="lazy"
alt="34 - creds.png"
>&lt;/a>&lt;/p>
&lt;p>and your PowerBi will be populated from the Azure SQL Database  This will fail if there are no records in the table because your flow hasnt run yet. If it does just wait until you see some tweets and then click apply changes again.&lt;/p>
&lt;p>You will probably want to alter the pictures and links etc and then yo can publish the report&lt;/p>
&lt;p>Happy Twitter Analysis&lt;/p>
&lt;p>Dont forget to keep an eye on your flow runs to make sure they have succeeded.&lt;/p></description></item><item><title>How to write a PowerShell function to use Confirm, Verbose and WhatIf</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/</link><pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/03-confirm.png" alt="Featured image of post How to write a PowerShell function to use Confirm, Verbose and WhatIf" />&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/" target="_blank" rel="noopener"
>my last blog post&lt;/a> I showed how to run a script with the WhatIf parameter. This assumes that the commands within the script have been written to use the common parameters Confirm, Verbose and WhatIf.&lt;/p>
&lt;p>Someone asked me how to make sure that any functions that they write will be able to do this.&lt;/p>
&lt;p>it is very easy&lt;/p>
&lt;p>When we define our function we are going to add &lt;code>[cmdletbinding(SupportsShouldProcess)]&lt;/code> at the top&lt;/p>
&lt;pre>&lt;code>function Set-FileContent {
[cmdletbinding(SupportsShouldProcess)]
Param()
&lt;/code>&lt;/pre>
&lt;p>and every time we perform an action that will change something we put that code inside a code block like this&lt;/p>
&lt;pre>&lt;code>if ($PSCmdlet.ShouldProcess(&amp;quot;The Item&amp;quot; , &amp;quot;The Change&amp;quot;)) {
# place code here
}
&lt;/code>&lt;/pre>
&lt;p>and alter The Item and The Change as appropriate.&lt;/p>
&lt;p>I have created a snippet for VS Code to make this quicker for me. To add it to your VS Code. Click the settings button bottom right, Click User Snippets, choose the powershell json and add the code below between the last two }s (Dont forget the comma)&lt;/p>
&lt;pre>&lt;code>,
&amp;quot;IfShouldProcess&amp;quot;: {
&amp;quot;prefix&amp;quot;: &amp;quot;IfShouldProcess&amp;quot;,
&amp;quot;body&amp;quot;: [
&amp;quot;if ($$PSCmdlet.ShouldProcess(\&amp;quot;The Item\&amp;quot; , \&amp;quot;The Change\&amp;quot;)) {&amp;quot;,
&amp;quot; # Place Code here&amp;quot;,
&amp;quot;}&amp;quot;
],
&amp;quot;description&amp;quot;: &amp;quot;Shows all the colour indexes for the Excel colours&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>and save the powershell.json file&lt;/p>
&lt;p>Then when you are writing your code you can simply type ifs and tab and the code will be generated for you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-VS-Code-Snippet.gif"
loading="lazy"
>&lt;/p>
&lt;p>As an example I shall create a function wrapped around Set-Content just so that you can see what happens.&lt;/p>
&lt;pre>&lt;code>function Set-FileContent {
[cmdletbinding(SupportsShouldProcess)]
Param(
[Parameter(Mandatory = $true)]
[ValidateNotNullOrEmpty()]
[string]$Content,
[Parameter(Mandatory = $true)]
[ValidateScript( {Test-Path $_ })]
[string]$File
)
if ($PSCmdlet.ShouldProcess(&amp;quot;$File&amp;quot; , &amp;quot;Adding $Content to &amp;quot;)) {
Set-Content -Path $File -Value $Content
}
}
&lt;/code>&lt;/pre>
&lt;p>I have done this before because if the file does not exist then &lt;code>Set-Content&lt;/code> will create a new file for you, but with this function I can check if the file exists first with the ValidateScript before running the rest of the function.&lt;/p>
&lt;p>As you can see I add variables from my PowerShell code into the The Item and The Change. If I need to add a property of an object I use &lt;code>$($Item.Property)&lt;/code>.&lt;/p>
&lt;p>So now, if I want to see what my new function would do if I ran it without actually making any changes I have -WhatIf added to my function automagically.&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -WhatIf
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-what-if.png"
loading="lazy"
>&lt;/p>
&lt;p>If I want to confirm any action I take before it happens I have &lt;code>-Confirm&lt;/code>&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -Confirm
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-confirm.png"
loading="lazy"
>&lt;/p>
&lt;p>As you can see it also give the confirm prompts for the &lt;code>Set-Content&lt;/code> command&lt;/p>
&lt;p>You can also see the verbose messages with&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -Verbose
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/04-verbose.png"
loading="lazy"
>&lt;/p>
&lt;p>So to summarise, it is really very simple to add Confirm, WhatIf and Verbose to your functions by placing &lt;code>[cmdletbinding(SupportsShouldProcess)]&lt;/code> at the top of the function and placing any code that makes a change inside&lt;/p>
&lt;pre>&lt;code>if ($PSCmdlet.ShouldProcess(&amp;quot;The Item&amp;quot; , &amp;quot;The Change&amp;quot;)) {
&lt;/code>&lt;/pre>
&lt;p>with some values that explain what the code is doing to the The Item and The Change.&lt;/p>
&lt;p>Bonus Number 1  This has added support for other common parameters as well  Debug, ErrorAction, ErrorVariable, WarningAction, WarningVariable, OutBuffer, PipelineVariable, and OutVariable.&lt;/p>
&lt;p>Bonus Number 2  This has automatically been added to your Help&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/05-get-help.png"
loading="lazy"
>&lt;/p>
&lt;p>Bonus Number 3  This has reduced the amount of comments you need to write and improved other peoples understanding of what your code is supposed to do  People can read your code and read what you have entered for the IfShouldProcess and that will tell them what the code is supposed to do &lt;/p>
&lt;p>Now you have seen how easy it is to write more professional PowerShell functions&lt;/p></description></item><item><title>How to run a PowerShell script file with Verbose, Confirm or WhatIf</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</link><pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Showing-the-results.png" alt="Featured image of post How to run a PowerShell script file with Verbose, Confirm or WhatIf" />&lt;p>Before you run a PowerShell command that makes a change to something you should check that it is going to do what you expect. You can do this by using the WhatIf parameter for commands that support it. For example, if you wanted to create a New SQL Agent Job Category you would use the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>awesome dbatools module&lt;/a> and write some code like this&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup'
&lt;/code>&lt;/pre>
&lt;p>before you run it, you can check what it is going to do using&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup' -WhatIf
&lt;/code>&lt;/pre>
&lt;p>which gives a result like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Whatif.png"
loading="lazy"
>&lt;/p>
&lt;p>This makes it easy to do at the command line but when we get confident with PowerShell we will want to write scripts to perform tasks using more than one command. So how can we ensure that we can check that those will do what we are expecting without actually running the script and see what happens? Of course, there are Unit and integration testing that should be performed using &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>Pester&lt;/a> when developing the script but there will still be occasions when we want to see what this script will do this time in this environment.&lt;/p>
&lt;p>Lets take an example. We want to place our SQL Agent jobs into specific custom categories depending on their name. We might write a script like this&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.SYNOPSIS
Adds SQL Agent Jobs to categories and creates the categories if needed
.DESCRIPTION
Adds SQL Agent Jobs to categories and creates the categories if needed. Creates
Backup', 'Index', 'TroubleShooting','General Info Gathering' categories and adds
the agent jobs depending on name to the category
.PARAMETER Instance
The Instance to run the script against
#&amp;gt;
Param(
[string]$Instance
)
$Categories = 'Backup', 'Index','DBCC', 'TroubleShooting', 'General Info Gathering'
$Categories.ForEach{
## Create Category if it doesnot exist
If (-not (Get-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem)) {
New-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem -CategoryType LocalJob
}
}
## Get the agent jobs and iterate through them
(Get-DbaAgentJob -SqlInstance $instance).ForEach{
## Depending on the name of the Job - Put it in a Job Category
switch -Wildcard ($PSItem.Name) {
'*DatabaseBackup*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Backup'
}
'*Index*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Index'
}
'*DatabaseIntegrity*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'DBCC'
}
'*Log SP_*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'TroubleShooting'
}
'*Collection*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'General Info Gathering'
}
## Otherwise put it in the uncategorised category
Default {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category '[Uncategorized (Local)]'
}
}
}
&lt;/code>&lt;/pre>
&lt;p>You can run this script against any SQL instance by calling it and passing an instance parameter from the command line like this&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>If you wanted to see what would happen, you could edit the script and add the WhatIf parameter to every changing command but thats not really a viable solution. What you can do is&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $true
&lt;/code>&lt;/pre>
&lt;p>this will set all commands that accept WhatIf to use the WhatIf parameter. This means that if you are using functions that you have written internally you must ensure that you write your functions to use the common parameters&lt;/p>
&lt;p>Once you have set the default value for WhatIf as above, you can simply call your script and see the WhatIf output&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>which will show the WhatIf output for the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Showing-the-results.png"
loading="lazy"
>&lt;/p>
&lt;p>Once you have checked that everything is as you expected then you can remove the default value for the WhatIf parameter and run the script&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $false
&amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>and get the expected output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-run-the-script-1.png"
loading="lazy"
>&lt;/p>
&lt;p>If you wish to see the verbose output or ask for confirmation before any change you can set those default parameters like this&lt;/p>
&lt;pre>&lt;code>## To Set Verbose output
$PSDefaultParameterValues['*:Verbose'] = $true
## To Set Confirm
$PSDefaultParameterValues['*:Confirm'] = $true
&lt;/code>&lt;/pre>
&lt;p>and set them back by setting to false&lt;/p></description></item><item><title>Pester 4.2.0 has a Because because :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</link><pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/01-Because-1.png" alt="Featured image of post Pester 4.2.0 has a Because because :-)" />&lt;p>I was going through my demo for the &lt;a class="link" href="http://meetu.ps/e/DdYV6/gHMdv/g" target="_blank" rel="noopener"
>South Coast User Group meeting&lt;/a> tonight and decided to add some details about the Because parameter available in the Pester pre-release version 4.2.0.&lt;/p>
&lt;p>To install a pre-release version you need to get the latest&lt;a class="link" href="https://go.microsoft.com/fwlink/?linkid=846259" target="_blank" rel="noopener"
>PowerShellGet&lt;/a>module. This is pre-installed with PowerShell v6 but for earlier versions open PowerShell as administrator and run&lt;/p>
&lt;pre>&lt;code>Install-Module PowerShellGet
&lt;/code>&lt;/pre>
&lt;p>You can try out the Pester pre-release version (once you have the latest PowerShellGet) by installing it from the &lt;a class="link" href="http://powershellgallery.com" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> with&lt;/p>
&lt;pre>&lt;code>Install-Module -Name Pester -AllowPrerelease -Force # -Scope CurrentUser # if not admin
&lt;/code>&lt;/pre>
&lt;p>There are a number of improvements as you can see in &lt;a class="link" href="https://github.com/pester/Pester/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>the change log&lt;/a>I particularly like the&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>Add -BeTrue to test for truthy values&lt;/li>
&lt;li>Add -BeFalse to test for falsy values&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>This release adds the Because parameter to the all assertions. This means that you can add a reason why the test has failed. As &lt;a class="link" href="http://jakubjares.com/2017/12/19/using-because/" target="_blank" rel="noopener"
>JAKUB JARE writes here&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Reasons force you think more&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons document your intent&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons make your TestCases clearer&lt;/p>
&lt;/li>
&lt;li>
&lt;p>So you can do something like this&lt;/p>
&lt;p>Describe &amp;ldquo;This shows the Because&amp;rdquo;{
It &amp;ldquo;Should be true&amp;rdquo; {
$false | Should -BeTrue -Because &amp;ldquo;The Beard said so&amp;rdquo;
}
}&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Which gives an error message like this &lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Because-1.png"
loading="lazy"
>&lt;/p>
&lt;p>As you can see the Expected gives the expected value and then your Because statement and then the actual result. Which means that you could write validation tests like&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;My System&amp;quot; {
Context &amp;quot;Server&amp;quot; {
It &amp;quot;Should be using XP SP3&amp;quot; {
(Get-CimInstance -ClassName win32_operatingsystem) .Version | Should -Be '5.1.2600' -Because &amp;quot;We have failed to bother to update the App and it only works on XP&amp;quot;
}
It &amp;quot;Should be running as rob-xps\\mrrob&amp;quot; {
whoami | Should -Be 'rob-xps\\mrrob' -Because &amp;quot;This is the user with the permissions&amp;quot;
}
It &amp;quot;Should have SMB1 enabled&amp;quot; {
(Get-SmbServerConfiguration).EnableSMB1Protocol | Should -BeTrue -Because &amp;quot;We don't care about the risk&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>and get a result like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Or if you were looking to validate your SQL Server you could write something like this&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_.Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG&amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>or maybe your security policies allow Windows Groups as logins on your SQL instances. You could easily link to the documentation and explain why this is important. This way you could build up a set of tests to validate your SQL Server is just so for your environment&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins). LoginType -contains 'WindowsUser' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>Just for fun, these would look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and the code looks like&lt;/p>
&lt;pre>&lt;code>$Instances = 'Rob-XPS', 'Rob-XPS\\Bolton'
foreach ($instance in $Instances) {
$Server, $InstanceName = $Instance.Split('/')
if ($InstanceName.Length -eq 0) {$InstanceName = 'MSSSQLSERVER'}
Describe &amp;quot;Testing the instance $instance&amp;quot; {
Context &amp;quot;SQL Agent Jobs&amp;quot; {
It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_. Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG &amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
Context &amp;quot;Logins&amp;quot; {
It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins).LoginType -contains 'WindowsUser' | Should @Should
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This will be a useful improvement to Pester when it is released and enable you to write validation checks with explanations.&lt;/p>
&lt;blockquote>
&lt;p>Come and Learn Some PowerShell Magic* at &lt;a class="link" href="https://twitter.com/hashtag/SQLBits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLBits&lt;/a> with &lt;a class="link" href="https://twitter.com/cl?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@cl&lt;/a> and I&lt;br>
Details &lt;a class="link" href="https://t.co/7OfK75e6Y1" target="_blank" rel="noopener"
>https://t.co/7OfK75e6Y1&lt;/a>&lt;br>
Registration &lt;a class="link" href="https://t.co/RDSkPlfMMx" target="_blank" rel="noopener"
>https://t.co/RDSkPlfMMx&lt;/a>&lt;br>
*PowerShell is not magic  it just might appear that way &lt;a class="link" href="https://t.co/5czPzYR3QD" target="_blank" rel="noopener"
>pic.twitter.com/5czPzYR3QD&lt;/a>&lt;/p>
&lt;p> Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/935143475418402816?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>November 27, 2017&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p></description></item><item><title>Using the AST in Pester for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</link><pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Pester-results-1.png" alt="Featured image of post Using the AST in Pester for dbachecks" />&lt;p>TagLine  My goal  Chrissy will appreciate Unit Tests one day &lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>Cludio Silva&lt;/a> has improved my &lt;a class="link" href="https://blog.robsewell.com/a-pretty-powerbi-pester-results-template-file/" target="_blank" rel="noopener"
>PowerBi For Pester&lt;/a>file and made it beautiful and whilst we were discussing this we found that if the Pester Tests were not formatted correctly the Power Bi looked  well rubbish to be honest! Chrissy asked if we could enforce some rules for writing our Pester tests.&lt;/p>
&lt;p>The rules were&lt;/p>
&lt;p>The Describe title should be in double quotes&lt;br>
The Describe should use the plural Tags parameter&lt;br>
The Tags should be singular&lt;br>
The first Tag should be a unique tag in Get-DbcConfig&lt;br>
The context title should end with $psitem&lt;br>
The code should use Get-SqlInstance or Get-ComputerName&lt;br>
The Code should use the forEach method&lt;br>
The code should not use $_&lt;br>
The code should contain a Context block&lt;/p>
&lt;p>She asked me if I could write the Pester Tests for it and this is how I did it. I needed to look at the Tags parameter for the Describe. It occurred to me that this was a job for the Abstract Syntax Tree (AST). I dont know very much about the this but I sort of remembered reading a blog post by &lt;a class="link" href="http://www.lazywinadmin.com/2016/08/powershellpester-make-sure-your.html" target="_blank" rel="noopener"
>Francois-Xavier Cat about using it with Pester&lt;/a> so I went and read that and &lt;a class="link" href="https://stackoverflow.com/questions/39909021/parsing-powershell-script-with-ast" target="_blank" rel="noopener"
>found an answer on Stack Overflow&lt;/a> as well. These looked just like what I needed so I made use of them. Thank you very much to Francois-Xavier and wOxxOm for sharing.&lt;/p>
&lt;p>The first thing I did was to get the Pester Tests which we have located in a checks folder and loop through them and get the content of the file with the Raw parameter&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Describes titles and tags&amp;quot; {
&lt;/code>&lt;/pre>
&lt;p>Then I decided to look at the Describes using the method thatwOxxOm (I know no more about this person!) showed.&lt;/p>
&lt;pre>&lt;code>$Describes = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\]\] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'describe'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
$tagIdx = $CE.IndexOf(($CE |Where ParameterName -eq'Tags') ) + 1
$tags = if ($tagIdx -and $tagIdx -lt $CE.Count) {
$CE\[$tagIdx\].Extent
}
New-Object PSCustomObject -Property @{
Name = $secondString
Tags = $tags
}
}
&lt;/code>&lt;/pre>
&lt;p>As I understand it, this code is using the Parser on the $check (which contains the code from the file) and finding all of the Describe commands and creating an object of the title of the Describe with the StaticType equal to String and values from the Tag parameter.&lt;/p>
&lt;p>When I ran this against the database tests file I got the following results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-describes-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Then it was a simple case of writing some tests for the values&lt;/p>
&lt;pre>&lt;code>@($describes).Foreach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$title Should Use a double quote after the Describe&amp;quot; {
$PSItem.Name.ToString().Startswith('&amp;quot;')| Should be $true
$PSItem.Name.ToString().Endswith('&amp;quot;')| Should be $true
}
It &amp;quot;$title should use a plural for tags&amp;quot; {
$PsItem.Tags| Should Not BeNullOrEmpty
}
# a simple test for no esses apart from statistics and Access!!
if ($null -ne $PSItem.Tags) {
$PSItem.Tags.Text.Split(',').Trim().Where{($_ -ne '$filename') -and ($_ -notlike '\*statistics\*') -and ($_ -notlike '\*BackupPathAccess\*') }.ForEach{
It &amp;quot;$PsItem Should Be Singular&amp;quot; {
$_.ToString().Endswith('s')| Should Be $False
}
}
It &amp;quot;The first Tag Should Be in the unique Tags returned from Get-DbcCheck&amp;quot; {
$UniqueTags -contains $PSItem.Tags.Text.Split(',') \[0\].ToString()| Should Be $true
}
}
else {
It &amp;quot;You haven't used the Tags Parameter so we can't check the tags&amp;quot; {
$false| Should be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The Describes variable is inside @() so that if there is only one the ForEach Method will still work. The unique tags are returned from our command Get-DbcCheck which shows all of the checks. We will have a unique tag for each test so that they can be run individually.&lt;/p>
&lt;p>Yes, I have tried to ensure that the tags are singular by ensuring that they do not end with an s (apart from statistics) and so had to not check BackupPathAccess and statistics. Filename is a variable that we add to each Describe Tags so that we can run all of the tests in one file. I added a little if block to the Pester as well so that the error if the Tags parameter was not passed was more obvious&lt;/p>
&lt;p>I did the same with the context blocks as well&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Contexts&amp;quot; {
## Find the Contexts
$Contexts = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\] \] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'Context'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
New-Object PSCustomObject -Property @{
Name = $secondString
}
}
@($Contexts).ForEach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$Title Should end with `$psitem So that the PowerBi will work correctly&amp;quot; {
$PSItem.Name.ToString().Endswith('psitem&amp;quot;')| Should Be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This time we look for the Context command and ensure that the string value ends with psitem as the PowerBi parses the last value when creating columns&lt;/p>
&lt;p>Finally I got all of the code and check if it matches some coding standards&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Code&amp;quot; {
## This just grabs all the code
$AST = \[System.Management.Automation.Language.Parser\] ::ParseInput($Check, \[ref\]$null, \[ref\]$null)
$Statements = $AST.EndBlock.statements.Extent
## Ignore the filename line
@($Statements.Where{$_.StartLineNumber -ne 1}).ForEach{
$title = \[regex\]::matches($PSItem.text, &amp;quot;Describe(. *)-Tag&amp;quot;).groups\[1\].value.Replace('&amp;quot;', '').Replace ('''', '').trim()
It &amp;quot;$title Should Use Get-SqlInstance or Get-ComputerName&amp;quot; {
($PSItem.text -Match 'Get-SqlInstance') -or ($psitem.text -match 'Get-ComputerName')| Should be $true
}
It &amp;quot;$title Should use the ForEach Method&amp;quot; {
($Psitem.text -match 'Get-SqlInstance\\).ForEach {') -or ($Psitem.text -match 'Get-ComputerName\\). ForEach{')| Should Be $true# use the \ to escape the )
}
It &amp;quot;$title Should not use `$_&amp;quot; {
($Psitem.text -match '$_')| Should Be $false
}
It &amp;quot;$title Should Contain a Context Block&amp;quot; {
$Psitem.text -match 'Context'| Should Be $True
}
}
&lt;/code>&lt;/pre>
&lt;p>I trim the title from the Describe block so that it is easy to see where the failures (or passes) are with some regex and then loop through each statement apart from the first line to ensure that the code is using our internal commands Get-SQLInstance or Get-ComputerName to get information, that we are looping through each of those arrays using the ForEach method rather than ForEach-Object and using $psitem rather than $_ to reference the This Item in the array and that each Describe block has a context block.&lt;/p>
&lt;p>This should ensure that any new tests that are added to the module follow the guidance we have set up on the Wiki and ensure that the Power Bi results still look beautiful!&lt;/p>
&lt;p>Anyone can run the tests using&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\\tests\\Unit.Tests.ps1 -show Fails
&lt;/code>&lt;/pre>
&lt;p>before they create a Pull request and it looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Pester-results-1.png"
loading="lazy"
>&lt;/p>
&lt;p>if everything is Green then they can submit their Pull Request  If not they can see quickly that something needs to be fixed. (fail early  )&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-fails.png"
loading="lazy"
alt="03 fails.png"
>&lt;/p></description></item><item><title>TSQL2sday #94 Lets get all Posh!</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</link><pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</guid><description>&lt;p>Write-Output &amp;ldquo;What are you going to automate today?&amp;rdquo;&lt;/p>
&lt;p>&lt;/p>
&lt;p>Welcome to T-SQL Tuesday for September 2017!&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/08/tsql2sday.jpg"
loading="lazy"
alt="tsql2sday"
>
&lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>T-SQL Tuesday&lt;/a> is a chance for you to join in the SQL Server community and write a blog post on a suggested topic. It makes for a great way to find a bunch of blog posts showing the same subject from many different viewpoints. Please join in and write a blog post, maybe it&amp;rsquo;s your first ever, maybe you haven&amp;rsquo;t blogged for a while but even if you blog every day come and join the party and share your knowledge.&lt;/p>
&lt;p>To participate:&lt;/p>
&lt;ol>
&lt;li>Write a post on the topic below&lt;/li>
&lt;li>Schedule the post to go live on Tuesday, September 12th (between zero am and midnight, UTC)&lt;/li>
&lt;li>Include the &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2010/06/01/t-sql-tuesday-007-and-t-sql-tuesday-has-a-logo.aspx" target="_blank" rel="noopener"
>TSQL Tuesday logo&lt;/a> in the top of your post&lt;/li>
&lt;li>Link the post back to this one (its easier if you comment on this post and link it)&lt;/li>
&lt;li>Optional: Tweet a link to your post using the &lt;a class="link" href="https://twitter.com/hashtag/TSQL2sday?src=hash" target="_blank" rel="noopener"
>#tsql2sday hash tag on Twitter&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Extra credit: if youd like to host your own TSQL Tuesday in the future, &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2017/01/03/t-sql-tuesday-rules-of-engagement.aspx" target="_blank" rel="noopener"
>read the full rules for info on how to sign up&lt;/a>. Just like I did but don&amp;rsquo;t forget its your month!!&lt;/p>
&lt;h2 id="this-months-topic-lets-get-all-posh---what-are-you-going-to-automate-today">This months topic: Let&amp;rsquo;s get all Posh - What are you going to automate today?&lt;/h2>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/PowerShell.png"
loading="lazy"
alt="PowerShell"
>
It is no surprise to those that know me that I will choose PowerShell as the topic for this month. I am passionate about PowerShell because it has enabled me to have the career I have today and to visit numerous countries all around the world, meet people and talk about PowerShell. By my reckoning &lt;a class="link" href="http://tsqltuesday.com/?s=PowerShell" target="_blank" rel="noopener"
>searching the TSQL Tuesday website&lt;/a> it has been over 3 years since we had a topic specific to PowerShell. So I would like you to blog about PowerShell and SQL Server (or other interesting data platform products)&lt;/p>
&lt;p>If you don&amp;rsquo;t know or use PowerShell GREAT! That&amp;rsquo;s awesome.&lt;/p>
&lt;p>Please spend an hour or so with it and tell us how you got on and what and how you learned. Just like &lt;a class="link" href="https://www.brentozar.com/archive/2017/07/live-blogging-erik-vs-PowerShell/" target="_blank" rel="noopener"
>Erik and Brent did&lt;/a>. You could install one of the community modules like &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>, &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> , &lt;a class="link" href="https://www.PowerShellgallery.com/packages/SQLDiagAPI" target="_blank" rel="noopener"
>SQLDiagAPI&lt;/a> or the Microsoft ones &lt;a class="link" href="https://www.PowerShellgallery.com/packages/Sqlserver" target="_blank" rel="noopener"
>sqlserver&lt;/a> or &lt;a class="link" href="https://github.com/Microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>SSRS&lt;/a> and try them out and tell us what you learned.&lt;/p>
&lt;p>If you want help whilst doing this please make use of the #PowerShellhelp channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a>&lt;/p>
&lt;p>This will be of so much benefit to all people who don&amp;rsquo;t use PowerShell and want to start to learn about it.&lt;/p>
&lt;p>If you do use PowerShell and SQL then either tell the tale of the best thing you have automated or a beginners post to show people how to start using PowerShell. I have heard many stories and am looking forward to tales of&lt;/p>
&lt;ul>
&lt;li>testing backups&lt;/li>
&lt;li>doing migrations&lt;/li>
&lt;li>resetting log shipping&lt;/li>
&lt;li>creating things in the cloud and on premises&lt;/li>
&lt;li>SQL on Linux with PowerShell on Linux&lt;/li>
&lt;li>using Pester for testing&lt;/li>
&lt;li>automating manual tasks&lt;/li>
&lt;li>automating incident knowledge gathering&lt;/li>
&lt;li>continuous integration and delivery&lt;/li>
&lt;/ul>
&lt;p>and many more. I will read all of them and do a write up of them later next week.&lt;/p>
&lt;p>Invoke-Coffee&lt;/p>
&lt;p>Start-BlogWriting -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Get-BlogProofRead&lt;/p>
&lt;p>Post-Blog -Date September 12th 2017 -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Write-Tweet -Hashtag TSQL2sday -Message &amp;lsquo;This is my cool blogpost&amp;rsquo;&lt;/p>
&lt;p>&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/keep-calm-and-PowerShell.jpg"
loading="lazy"
alt="keep calm and PowerShell.jpg"
>&lt;/p></description></item><item><title>PSConfAsia 2016</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/psconfasia-2016/</link><pubDate>Mon, 24 Oct 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/psconfasia-2016/</guid><description>&lt;p>I have just got back to the UK from Singapore following the amazing &lt;a class="link" href="http://www.psconf.asia/" target="_blank" rel="noopener"
>PSConfAsia&lt;/a> conference. I must say that Matt, Milton, Sebastian and Ben did a fantastic job organising this conference and were proud that there was anotable increase in attendees from last year.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5csebastians-photo.jpg"
loading="lazy"
alt="sebastians-photo"
>&lt;/p>
&lt;p>&lt;/p>
&lt;p>The conference began (unofficially) with a PowerShell User group session in the Microsoft Offices on Wednesday where &lt;a class="link" href="http://www.ravichaganti.com/blog/" target="_blank" rel="noopener"
>Ravi Chaganti&lt;/a> spoke about DSC&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161019_19_56_07_pro-2.jpg"
loading="lazy"
alt="WP_20161019_19_56_07_Pro (2).jpg"
>&lt;/p>
&lt;p>and then Desmond Lee lead a Q and A session. In the end we decided that all the answers were&lt;/p>
&lt;blockquote>
&lt;p>It Depends and Test in your Environment&lt;/p>
&lt;/blockquote>
&lt;p>That evening, I even managed to jump on the PASS PowerShell Virtual Chapter session by Scott Sutherland &lt;a class="link" href="https://www.youtube.com/watch?v=npoORzfP7rw" target="_blank" rel="noopener"
>Hacking SQL Servers on Scale using PowerShell the recording of which is here&lt;/a>Asession organised and managed onlinein three different time zones by Aaron Chrissy and myself :-).&lt;/p>
&lt;p>On Thursday the conference proper started with a pre-con day at the Amazon Web Services office. Yes, you read that right. This conference really highlighted the cross-platformdirectionand adoption of open-source that Microsoft is taking.&lt;a class="link" href="http://twitter.com/@JasonYoder_MCT" target="_blank" rel="noopener"
>Jason Yoder&lt;/a> spent all day teaching a group &amp;ldquo;PowerShell for Beginners&amp;rdquo; in one room&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_09_24_43_pro.jpg"
loading="lazy"
alt="WP_20161020_09_24_43_Pro.jpg"
>&lt;/p>
&lt;p>while The Amazon Web Services Team showed DevOps on AWS with PowerShell in the morning and &lt;a class="link" href="https://twitter.com/juneb_get_help" target="_blank" rel="noopener"
>June Blender&lt;/a> gave a SAPIEN Toolmaking Seminar.fter this we went back to the Microsoft Offices for another User Group where Jason Yoder gave a (nother) session with &lt;a class="link" href="https://twitter.com/jaap_brasser" target="_blank" rel="noopener"
>Jaap Brasser&lt;/a> on PowerShell Tips and Tricks (&lt;a class="link" href="https://onedrive.live.com/?authkey=%21AJyNBdDeTNtAS18&amp;amp;id=4B0EFD9B34E1210E%2124928&amp;amp;cid=4B0EFD9B34E1210E" target="_blank" rel="noopener"
>Demo&lt;/a>)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_19_26_24_pro-2.jpg"
loading="lazy"
alt="WP_20161020_19_26_24_Pro (2).jpg"
>&lt;/p>
&lt;p>Friday started with The PowerShell Team represented by &lt;a class="link" href="https://twitter.com/khansenhansen" target="_blank" rel="noopener"
>Kenneth Hansen&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/angelcalvos" target="_blank" rel="noopener"
>Angel Calvo&lt;/a> talking about PowerShell Past, Present and Future. It was really good that there was such great access to the product team at the conference and I saw lots of interaction around the conference as well, in addition to the sessions they provided.&lt;/p>
&lt;p>Next up for me was anothersession from the PowerShell Team, this time &lt;a class="link" href="https://twitter.com/hemanmahawar" target="_blank" rel="noopener"
>Hemant Mahawar&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/lzybkr" target="_blank" rel="noopener"
>Jason Shirk&lt;/a> taking us ona Journey Through the Ages of PowerShell Security&lt;/p>
&lt;blockquote>
&lt;p>Execution Policy is not a security feature&lt;/p>
&lt;/blockquote>
&lt;p>That took us to lunch, we were treated to excellent lunches at this conference&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_12_07_14_pro-2.jpg"
loading="lazy"
alt="WP_20161020_12_07_14_Pro (2).jpg"
>&lt;/p>
&lt;p>After lunch I sat in the PowerShell Teams Ask Us Anything session although I was mainly preparing for my own session PowerShell Profile Prepares Perfect Production Purlieu which followed. There were excellent sessions on JEA, Nano Server, Chef and DSC, Containers, ETS and securing PowerShell against malware whilst I attended &lt;a class="link" href="http://flynnbundy.com" target="_blank" rel="noopener"
>Flynn Bundy&amp;rsquo;s&lt;/a> session about Windows Containers and Building GUIs with XAML with &lt;a class="link" href="https://twitter.com/david_das_neves" target="_blank" rel="noopener"
>David Das Neves&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161021_15_58_12_pro-2.jpg"
loading="lazy"
alt="WP_20161021_15_58_12_Pro (2).jpg"
>&lt;/p>
&lt;p>That evening, organisers, speakers and attendees all went to the Penny Black pub on Marina Bay and enjoyed some food, refreshments and networking&lt;/p>
&lt;p>Saturday started slowly after the rain (another impressive &amp;lsquo;feature&amp;rsquo; of Singapore) but the first session was a brilliant one with &lt;a class="link" href="https://twitter.com/hemanmahawar" target="_blank" rel="noopener"
>Hemant Mahawar&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/lzybkr" target="_blank" rel="noopener"
>Jason Shirk&lt;/a> talking Pragmatic PowerShell and answering questions. I am glad Jason used &lt;a class="link" href="https://github.com/Code52/carnac" target="_blank" rel="noopener"
>Carnac&lt;/a>to show what he was typing so that people could (just about:-) ) keep up. I then attended the excellent session about contribution with Microsoft.&lt;/p>
&lt;p>The rest of the day had amazing sessions on Azure Automation, IoT, AWS Cloud Formation, Centralised Repository Server, Chef, Puppet, Professional Help, Nano Server, Docker, DSC, Release Pipeline and of course some bearded fella talking about Installing SQL Scripts and creating Pester Tests for them and combining PowerShell, SQL, SSRS, PowerBi and Cortana :-)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cjason-yoders-photo.jpg"
loading="lazy"
alt="Jason Yoder&amp;rsquo;s photo.jpg"
>&lt;/p>
&lt;p>My takeaways from the conference were that Microsoft is very open to all members of the open source community, DevOps is a very important topicand also the following points from the PowerShell team&lt;/p>
&lt;blockquote>
&lt;p>PowerShell Team want YOU to contribute. Interact with them File bugs Feature Requests Documentation Tests Code&lt;/p>
&lt;/blockquote>
&lt;p>and&lt;/p>
&lt;blockquote>
&lt;p>Fixing is better than complaining :-) &lt;a class="link" href="https://twitter.com/@HemanMahawar" target="_blank" rel="noopener"
>@HemanMahawar&lt;/a> &lt;a class="link" href="https://twitter.com/search?q=%23psconfasia" target="_blank" rel="noopener"
>#psconfasia&lt;/a> You can help fix the documentation. Use the contribute button on the doc&lt;/p>
&lt;/blockquote>
&lt;p>and&lt;/p>
&lt;blockquote>
&lt;p>If you are thinking of starting or runa PowerShell usergroup Microsoft would like help. Tag1 of the team such as &lt;a class="link" href="https://twitter.com/@ANGELCALVOS" target="_blank" rel="noopener"
>@ANGELCALVOS&lt;/a> &lt;a class="link" href="https://twitter.com/search?q=%23psconfasia" target="_blank" rel="noopener"
>#psconfasia&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Special thanks and congratulations must go to Matt, Milton, Sebastian and Ben for their excellent organisation and for creating an awesome event. I am looking forward to seeing how they can better it next year and also hoping that seeing all the fabulous speakers and sessions will inspire some attendees from this years event to share their own knowledge and experience at local user groups and even next years conference.&lt;/p></description></item><item><title>PowerShell CMDLets added for SQL2016 Always Encrypted</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-cmdlets-added-for-sql2016-always-encrypted/</link><pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-cmdlets-added-for-sql2016-always-encrypted/</guid><description>&lt;p>&lt;a class="link" href="https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/30/sql-PowerShell-july-2016-update/" target="_blank" rel="noopener"
>The post on the SQLServer blog at TechNet by the SQL Server Tools Team today&lt;/a> made me jump out of my seat.&lt;/p>
&lt;blockquote>
&lt;p>The July update for SSMS includes the first substantial improvement in SQL PowerShell in many years. We owe a lot of thanks for this effort to the great collaboration with our community. We have several new CMDLETs to share with you&lt;/p>
&lt;/blockquote>
&lt;p>In one release there are &lt;strong>twenty-five&lt;/strong> new CMDLets for the new sqlserver module&lt;/p>
&lt;blockquote>
&lt;p>This means that if you have a PowerShell script doing &lt;em>Import-Module SQLPS&lt;/em>, it will need to be changed to be &lt;em>Import-Module SqlServer&lt;/em> in order to take advantage of the new provider functionality and new CMDLETs. The new module will be installed to &lt;em>%Program Files\WindowsPowerShell\Modules\SqlServer&lt;/em> and hence no update to $env:PSModulePath is required.&lt;/p>
&lt;/blockquote>
&lt;p>So SQLPS will still continue to work but will not be updated and will not contain the new CMDlets or the future new CMDlets.&lt;/p>
&lt;h2 id="so-what-new-things-do-we-have">So what new things do we have?&lt;/h2>
&lt;blockquote>
&lt;p>This month we introduce CMDLETs for the following areas:&lt;/p>
&lt;ul>
&lt;li>Always Encrypted&lt;/li>
&lt;li>SQL Agent&lt;/li>
&lt;li>SQL Error Logs&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Chrissy LeMaire has written about the &lt;a class="link" href="https://blog.netnerds.net/2016/06/the-sql-server-PowerShell-module-formerly-known-as-sqlps/" target="_blank" rel="noopener"
>new SQL Agent cmdlets&lt;/a>&lt;/p>
&lt;p>Aaron Nelson has written about the &lt;a class="link" href="http://sqlvariant.com/2016/06/webinar-on-25-new-PowerShell-cmdlets-for-sql-server-and-more/" target="_blank" rel="noopener"
>new Get-SqlErrorLog cmdlet&lt;/a>&lt;/p>
&lt;p>Laerte Junior has written about &lt;a class="link" href="https://www.simple-talk.com/blogs/2016/06/30/invoke-sqlcmd-just-got-better/" target="_blank" rel="noopener"
>Invoke-SQLCmd&lt;/a>&lt;/p>
&lt;p>All four of us will be presenting a webinar on the new CMDlets via the &lt;a class="link" href="http://PowerShell.sqlpass.org/" target="_blank" rel="noopener"
>PowerShell Virtual Chapter&lt;/a>Wed, Jul 06 2016 12:00 Eastern Daylight Time If you cant make ita recordingwill be made available on YouTube on the VC Channel &lt;a class="link" href="https://sqlps.io/video" target="_blank" rel="noopener"
>https://sqlps.io/video&lt;/a>&lt;/p>
&lt;h2 id="always-encrypted-cmdlets">Always Encrypted CMDlets&lt;/h2>
&lt;p>That leaves the Always Encrypted CMDLets and there are 17 of those!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;/p>
&lt;p>That seems to cover setting up Always Encrypted with PowerShell , removing it and getting information about it. When the new SSMS update is dropped you will be able to start using all of this new functionality.&lt;/p>
&lt;p>Just remember Import-Module sqlserver&lt;/p>
&lt;h2 id="call-to-action">CALL TO ACTION&lt;/h2>
&lt;p>Microsoft are engaging with the community to improve the tools we all use in our day to day work. There is are two Trello boards set up for &lt;strong>YOU&lt;/strong> to use to contribute&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/vote" target="_blank" rel="noopener"
>https://sqlps.io/vote&lt;/a> for SQLPS sqlserver PowerShell module&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/ssms" target="_blank" rel="noopener"
>https://sqlps.io/ssms&lt;/a> for SSMS&lt;/p>
&lt;p>Go and join them and upvote &lt;strong>YOUR&lt;/strong> preferred choice of the next lot of CMDlets&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/trellocount.png"
loading="lazy"
alt="trellocount"
>&lt;/p>
&lt;p>&lt;/p>
&lt;p>We have also set up a SQL Community Slack for anyone in the community to discuss all things related to SQL including the Trello board items and already it seems a good place for people to get help with 150+ members in a few days. You can get an invite here &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;/p>
&lt;p>Come and join us&lt;/p></description></item><item><title>PowerShell Pester Testing for Parameter Validation</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-testing-for-parameter-validation/</link><pubDate>Sun, 31 Jan 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-testing-for-parameter-validation/</guid><description>&lt;p>This error caught me out. I am putting this post here firstly to remind me if I do it again adn also to help others who may hit the same issue.&lt;/p>
&lt;p>Today I am rewriting a function to create a Hyper-V VM so that I can properly script the creation of my labs for demos and other things. I am doing this because I want to use DSC to create an availability group and want to be able to tear down and recreate the machines (but thats for another day)&lt;/p>
&lt;p>I also have been looking at &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> which is a framework for running unit tests within PowerShell&lt;/p>
&lt;p>You will find some good blog posts about starting with Pester &lt;a class="link" href="https://www.google.co.uk/search?q=PowerShell&amp;#43;pester&amp;#43;tutorial&amp;amp;ie=&amp;amp;oe=" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>Here is the start of the function. I validate the VMName parameter to ensure that there a VM with that name does not already exist&lt;/p>
&lt;p>function Create-HyperVMFromBase {
[cmdletbinding()]
param (
[Parameter(Mandatory = $true,HelpMessage=&amp;ldquo;Enter a VMName for the VM that does not exist&amp;rdquo;)] [ValidateScript({(!(Get-VM -Name $_))})]
[string]$VMName,&lt;/p>
&lt;p>and my Pester test looks like this&lt;/p>
&lt;p>$here = Split-Path -Parent $MyInvocation.MyCommand.Path
$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;quot;.Tests.&amp;quot;, &amp;ldquo;.&amp;rdquo;)
. {&amp;rsquo;$here$sut'}&lt;/p>
&lt;p>Describe &amp;ldquo;Create Hyper V from Base Tests&amp;rdquo; {
Context &amp;ldquo;Parameter Values,Validations and Errors&amp;rdquo; {
It exists {
test-path function:\create-hypervmfrombase | should be $true
}
It &amp;ldquo;Should error when VMName exists&amp;rdquo; {
$VMName = (Get-VM|Select -First 1 Name).Name
create-hypervmfrombase -VMName $VMName |should throw
}&lt;/p>
&lt;p>I thought that what I was testing was that the function threw an error when an incorrect parameter was passed. The should throw should be true but what I got was&lt;/p>
&lt;p>&lt;a class="link" href="../assets/uploads/2016/01/pester-error3.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error3_thumb.jpg"
loading="lazy"
alt="pester error3"
>&lt;/a>&lt;/p>
&lt;p>So I was getting the correct error but not passing the test. It was a simple fix. Simply adding curly braces around the call to the function&lt;/p>
&lt;p>$here = Split-Path -Parent $MyInvocation.MyCommand.Path
$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;quot;.Tests.&amp;quot;, &amp;ldquo;.&amp;rdquo;)
. &amp;ldquo;$here$sut&amp;rdquo;
Describe &amp;ldquo;Create Hyper V from Base Tests&amp;rdquo; {
Context &amp;ldquo;Parameter Values,Validations and Errors&amp;rdquo; {
It exists {
test-path function:\create-hypervmfrombase | should be $true
}
It &amp;ldquo;Should error when VMName exists&amp;rdquo; {
$VMName = (Get-VM|Select -First 1 Name).Name
{create-hypervmfrombase -VMName $VMName} |should throw
}
}
}&lt;/p>
&lt;p>and we pass the test.&lt;/p>
&lt;p>&lt;a class="link" href="../assets/uploads/2016/01/pester-success2.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-success2_thumb.jpg"
loading="lazy"
alt="pester success2"
>&lt;/a>&lt;/p></description></item><item><title>Power Bi, PowerShell and SQL Agent Jobs</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/power-bi-powershell-and-sql-agent-jobs/</link><pubDate>Mon, 28 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/power-bi-powershell-and-sql-agent-jobs/</guid><description>&lt;p>Continuing &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>my series on using Power Bi with my DBA Database&lt;/a> I am going to show in this post how I create the most useful daily report for DBAs - The SQL Agent Job report. &lt;a class="link" href="https://1drv.ms/f/s!Ah9eXQJC3wLIh8BKfjiXBs7g6m7hfw" target="_blank" rel="noopener"
>You can get the scripts and reports here&lt;/a>&lt;/p>
&lt;p>Please note this project became &lt;a class="link" href="http://dbareports.io" target="_blank" rel="noopener"
>dbareports.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag1.jpg?w=300"
loading="lazy"
alt="AG1"
>&lt;/a>&lt;/p>
&lt;p>This gives a quick overview of the status of the Agent Jobs across the estate and also quickly identifies recent failed jobs enabling the DBA to understand their focus and prioritise their morning efforts.&lt;/p>
&lt;p>I gather the information into 2 tables AgentJobDetail&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[AgentJobDetail](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgetnJobDetailID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Date] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Category] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[JobName] [nvarchar](250) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Description] [nvarchar](750) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[IsEnabled] [bit] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Status] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[LastRunTime] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Outcome] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_info.AgentJobDetail] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgetnJobDetailID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and AgentJobServer&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[AgentJobServer](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgentJobServerID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Date] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[NumberOfJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[SuccessfulJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[FailedJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DisabledJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[UnknownJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_Info.AgentJobServer] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgentJobServerID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Detail table holds the results of every Agent Job and the Server table holds a roll up for each server. The script to gather this information is based on the script I used to put the information into an Excel Sheet as described in my post &lt;a class="link" href="https://blog.robsewell.com/blog/how-i-check-hundreds-of-sql-agent-jobs-in-60-seconds-with-powershell/" target="_blank" rel="noopener"
>How I Check Hundreds of Agent Jobs in 60 Seconds with PowerShell&lt;/a> which I also altered to send an HTML email to the DBA team each morning. This however is a much better solution and allows for better monitoring and trending.&lt;/p>
&lt;p>As I have explained &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>in my previous posts&lt;/a> I use an Instance List table to hold the information about each instance in the estate and a series of PowerShell scripts which run via Agent Jobs to gather the information into various tables. These posts describe the use of the Write-Log function and the methodology of gathering the required information and looping through each instance so I wont repeat that here. There is an extra check I do however for Express Edition as this does not contain the Agent service&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$edition = $srv.Edition
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Edition -eq &amp;#39;Express&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Log -Path $LogFile -Message &amp;#34;No Information gathered as this Connection $Connection is Express&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Agent Job information can be found in SMO by exploring the &lt;code>$srv.JobServer.Jobs&lt;/code> object and I gather the information by iterating through each job and setting the values we require to variables&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JobCount = $srv.JobServer.jobs.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $successCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $failedCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $UnknownCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JobsDisabled = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #For each job on the server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($jobin$srv.JobServer.Jobs)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobName = $job.Name;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobEnabled = $job.IsEnabled;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobLastRunOutcome = $job.LastRunOutcome;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Category = $Job.Category;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $RunStatus = $Job.CurrentRunStatus;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Time = $job.LastRunDate;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Time -eq &amp;#39;01/01/000100:00:00&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$Time = &amp;#39;&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Description = $Job.Description;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Counts for jobs Outcome
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($jobEnabled -eq $False)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$JobsDisabled += 1}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Failed&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$failedCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Succeeded&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$successCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$UnknownCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I found that some Jobs had names and descriptions that had &amp;rsquo; in them which would cause the SQL update or insert statement to fail so I use the replacemethod to replace the &amp;rsquo; with ''&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($Description -eq $null) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Description = &amp;#39; &amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Description.replace(&amp;#39;&amp;#39;&amp;#39;&amp;#39;, &amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($jobName -eq $Null) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobName = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobName = $JobName.replace(&amp;#39;&amp;#39;&amp;#39;&amp;#39;, &amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then insert the data per job after checking that it does not already exist which allows me to re-run the job should a number of servers be uncontactable at the time of the job running without any additional work&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">IF NOT EXISTS (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SELECT [AgetnJobDetailID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[Info].[AgentJobDetail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">where jobname = &amp;#39;$jobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and InstanceID = (SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and lastruntime = &amp;#39;$Time&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INSERT INTO [Info].[AgentJobDetail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">([Date]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Category]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[JobName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Description]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[IsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Status]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[LastRunTime]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Outcome])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,(SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Category&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Description&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobEnabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$RunStatus&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Time&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobLastRunOutcome&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I put this in a here-string variable and pass it to Invoke-SQLCmd I do the same with the roll up using this query&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">INSERT INTO [Info].[AgentJobServer]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">([Date]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[NumberOfJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[SuccessfulJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[FailedJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[DisabledJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[UnknownJobs])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,(SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$JobCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$successCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$failedCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$JobsDisabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$UnknownCount&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This job runs as a SQL Agent Job every morning a half an hour or so beforethe DBA arrives for the morning shift vastly improving the ability of the DBA to prioritise their morning routine.&lt;/p>
&lt;p>To create the report open Power Bi Desktop and click Get Data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag2.jpg?w=300"
loading="lazy"
alt="ag2"
>&lt;/a>&lt;/p>
&lt;p>Then choose SQL Server and click connect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag3.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag3.jpg?w=274"
loading="lazy"
alt="ag3"
>&lt;/a>&lt;/p>
&lt;p>Enter the Connection string, the database and the query to gather the data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag5.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag5.jpg?w=300"
loading="lazy"
alt="ag5"
>&lt;/a>&lt;/p>
&lt;p>The query is&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Select IL.InstanceID,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.InstanceName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.Environment,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.Location,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Category,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Date,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Description,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.IsEnabled,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.JobName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.LastRunTime,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Outcome,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [dbo].[InstanceList] IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN [Info].[AgentJobDetail] AJD
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ON IL.InstanceID = AJD.InstanceID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE LastRunTime &amp;gt; DATEADD(Day,-31,GETDATE())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once we have gathered the data we then create some extra columns and measures for the reports. First I create a date column from the datetime Date Column&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayDate = DATE(YEAR(&amp;#39;Agent Job Detail&amp;#39;[Date]),MONTH(&amp;#39;Agent Job Detail&amp;#39;[Date]),DAY(&amp;#39;Agent Job Detail&amp;#39;[Date]))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also do the same for the LastRuntime. I create a day of the week column so that I can report on jobs outcome by day&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayyOfWeek = CONCATENATE(WEEKDAY(&amp;#39;Agent Job Detail&amp;#39;[Date],2),FORMAT(&amp;#39;Agent Job Detail&amp;#39;[Date],&amp;#34; -dddd&amp;#34;))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>My friend Terry McCann &lt;a class="link" href="http://hyperbi.co.uk" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/@sqlshark" target="_blank" rel="noopener"
>t&lt;/a> helped me create a column thatreturns true if the last run time is within 24 hours of the current time to help identify the recent jobs that have failed NOTE - On a Monday morning you will need to change this if you do not check your jobs on the weekend.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Last Run Relative Hour = ((1.0\*(NOW()-&amp;#39;Agent Job Detail&amp;#39;[LastRunTime]))\*24)&amp;lt;24
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a measure for Succeeded, Failed and Unknown&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Succeeded = IF(&amp;#39;Agent Job Detail&amp;#39;[Outcome] = &amp;#34;Succeeded&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, 0)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Next we have to create somemeasures for the sum of failed jobs and the averagesThis is the code for 7 day sum&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Failed7Days = CALCULATE(SUM(&amp;#39;Agent Job Detail&amp;#39;[Failed]),FILTER (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALL ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ),
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#39;Agent Job Detail&amp;#39;[Last Run Date] &amp;gt; ( MAX ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ) - 7 )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;amp;&amp;amp; &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] &amp;lt;= MAX ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ) ) )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and for the 7 Day average&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Failed7DayAverage = DIVIDE([Failed7Days],7)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I did the same for 30 days. I used the&lt;a class="link" href="http://social.technet.microsoft.com/wiki/contents/articles/680.powerpivot-dax-filter-functions.aspx" target="_blank" rel="noopener"
>TechNet reference for DAX expressions&lt;/a> and got ideas from &lt;a class="link" href="http://blog.crossjoin.co.uk/category/dax/" target="_blank" rel="noopener"
>Chris Webbs blog&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag6.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag6.jpg?w=83"
loading="lazy"
alt="ag6"
>&lt;/a> First I created the 30 day historical trend chart using a Line and Clustered column chart using the last run date as the axis and the succeed measure as the column and the Failed, Failed 7 Day Average and failed 30 day average as the lines&lt;/p>
&lt;p>I then formatted the lines and title and column&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag7.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag7.jpg?w=300"
loading="lazy"
alt="ag7"
>&lt;/a>&lt;/p>
&lt;p>To create the gauge which shows how well we have done today I created a measure to quickly identify todays jobs&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">LastRun Relative Date Offset = INT(&amp;#39;Agent Job Detail&amp;#39;[LastRunTime] - TODAY())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which I use as a filter for the gauge as shown below. I also create two measures zero and twenty for the minimum and maximum for the gauge&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag8.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag8.jpg?w=300"
loading="lazy"
alt="ag8"
>&lt;/a>&lt;/p>
&lt;p>The rest of the report is measures for 7 day average and 30 day average, a slicer for environment and two tables, one to show the historical job counts and one to show the jobs that have failed in the last 24 hours using the Last Run Relative Hour measure from above&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag9.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag9.jpg?w=300"
loading="lazy"
alt="ag9"
>&lt;/a>&lt;/p>
&lt;p>There are many other reports that you can or may want to create maybe by day of the week or by category depending on your needs. Once you have the data gathered you are free to play with the data as you see fit. Please add any further examples of reports you can run or would like to run in the comments below.&lt;/p>
&lt;p>Once you have your report written you can publish it to PowerBi.com and create a dashboard and query it with natural language. I have explained the process &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>in previous posts&lt;/a>&lt;/p>
&lt;p>For example - How many Jobs failed today&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag110.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag110.jpg?w=300"
loading="lazy"
alt="ag110"
>&lt;/a>&lt;/p>
&lt;p>Which server had most failed jobs&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag11.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag11.jpg?w=300"
loading="lazy"
alt="ag11"
>&lt;/a>&lt;/p>
&lt;p>or using the category field which database maintenance jobs failed today&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag13.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag13.jpg?w=300"
loading="lazy"
alt="ag13"
>&lt;/a>&lt;/p>
&lt;p>I hope these posts have given you ideas about how you can use PowerShell, a DBA Database and Power Bi to help you to manage and report on your environment.&lt;/p>
&lt;p>&lt;a class="link" href="https://1drv.ms/f/s!Ah9eXQJC3wLIh8BKfjiXBs7g6m7hfw" target="_blank" rel="noopener"
>You can get the scripts and reports here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - Databases</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-databases/</link><pubDate>Tue, 22 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-databases/</guid><description>&lt;p>Following my post about &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db1.png?w=300"
loading="lazy"
alt="db1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db2.png?w=300"
loading="lazy"
alt="db2"
>&lt;/a>&lt;/p>
&lt;p>Although you will find so many items of data that I expect that you will want to create different reports for your own requirements. You will also want to put the report onto PowerBi.com and explore the natural language querying as I show at the end of this post&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts and PowerShell scripts here.&lt;/a>&lt;/p>
&lt;p>The SQLInfo table is created using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[Databases](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DatabaseID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Name] [nvarchar](256) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateAdded] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateChecked] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoClose] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoCreateStatisticsEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoShrink] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoUpdateStatisticsEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AvailabilityDatabaseSynchronizationState] [nvarchar](16) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AvailabilityGroupName] [nvarchar](128) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CaseSensitive] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Collation] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CompatibilityLevel] [nvarchar](15) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CreateDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DataSpaceUsageKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [EncryptionEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IndexSpaceUsageKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsAccessible] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsFullTextEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsMirroringEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsParameterizationForced] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsReadCommittedSnapshotOn] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsSystemObject] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsUpdateable] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastDifferentialBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastLogBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Owner] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PageVerify] [nvarchar](17) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ReadOnly] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [RecoveryModel] [nvarchar](10) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ReplicationOptions] [nvarchar](40) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SizeMB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SnapshotIsolationState] [nvarchar](10) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SpaceAvailableKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Status] [nvarchar](35) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TargetRecoveryTime] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK_Databases] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DatabaseID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName = &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get the script &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>from here&lt;/a> or you can read on to see how it works and how to create the report and publish it to powerbi.com and query it with natural langauge&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible.I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called $ServerNames holding the server name, instance name and port&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and create a $Connection variable for my SMO connection string and connect to the server&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Even though I place the creation of the SMO server object in a try block you still need to an additional check to ensure that you can connect and populate the object as the code above creates an empty SMO Server object with the name property set to the $Connection variable if you can&amp;rsquo;t connect to that server and doesnt error as you may expect The way I have always validated an SMO Server object is to check the version property. There is no justifiable reason for choosing that property, you could choose any one but thats the one I have always used. I use an if statement to do this ( &lt;a class="link" href="https://blog.robsewell.com/blog/powershell-snippets-a-great-learning-tool/" target="_blank" rel="noopener"
>This post about Snippets will show you the best way to learn PowerShell code&lt;/a>) The reference I use for exiting a loop in the way that you want is &lt;a class="link" href="http://ss64.com/ps/break.html" target="_blank" rel="noopener"
>this one&lt;/a> In this case we use a continue to carry on iterating the loop&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Catch-Block &amp;#34; Failed to Connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the user databases&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach($db in $srv.databases|Where-Object {$_.IsSystemObject -eq $false })
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Name = $db.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Parent = $db.Parent.Name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To gather information on all databases just remove everything after the pipe symbol or if you wish to exclude certain databases from the collection gathering, maybe the database you keep &lt;a class="link" href="https://blog.robsewell.com/blog/making-a-change-log-easier-with-powershell/" target="_blank" rel="noopener"
>your Change log table&lt;/a> and DBA Team info in you can do that as well here&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Name = $db.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Parent = $db.Parent.Name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you wish to view all of the different properties that you can gather information on in this way you can use this code to take a look. (This is something you should get used to doing when writing new PowerShell scripts)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Connection = &amp;#39;SERVERNAMEHERE&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv.databases | Get-Member
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>An alternative method of doing this is to set a variable to a $db and then to select all of the properties so that you can see the values and identify the ones you want. Again this a good thing to do when exploring new objects&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$db = $srv.databases[&amp;#39;DBNAMEHERE&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db| Select *
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can see from the screen shot below that there are 170 properties available to you on a SQL2014 instance. You can gather any or all of that information as long as you ensure that you have the columns with the correct data types in your table and that your script has the logic to deal with properties that do not exist although I have had less issue with this for the database object than the server object&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db3.png?w=300"
loading="lazy"
alt="db3"
>&lt;/a>&lt;/p>
&lt;p>You can look for the property that you want by using the Get-Member cmdlet as shown above or use MSDN to find it &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.database%28v=sql.120%29.aspx" target="_blank" rel="noopener"
>starting from here&lt;/a> or by GoogleBingDuckDuckGo ing &amp;ldquo;PowerShell SMO&amp;rdquo; and the property you wish to find.&lt;/p>
&lt;p>The rest of the script follows exactly the same pattern as &lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>the previous post&lt;/a> by checking the SQL Info table for an entry for that instance and updating the table if it exists and inserting if it does not.&lt;/p>
&lt;p>This is how I created the reports shown above.&lt;/p>
&lt;p>Connect to the DBA Database and run these queries to gather the data for the report.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Environment
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Inactive
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.NotContactable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DatabaseID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Name]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DateAdded]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoClose]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoCreateStatisticsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoShrink]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoUpdateStatisticsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AvailabilityDatabaseSynchronizationState]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AvailabilityGroupName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CaseSensitive]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Collation]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CompatibilityLevel]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CreateDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DataSpaceUsageKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[EncryptionEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IndexSpaceUsageKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsAccessible]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsFullTextEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsMirroringEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsParameterizationForced]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsReadCommittedSnapshotOn]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsUpdateable]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastDifferentialBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastLogBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Owner]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[PageVerify]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[ReadOnly]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[RecoveryModel]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[ReplicationOptions]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SizeMB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SnapshotIsolationState]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SpaceAvailableKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Status]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[TargetRecoveryTime]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[Info].[Databases] as D
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN [DBADatabase].[dbo].[InstanceList] as IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ON IL.InstanceID =D.InstanceID
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To get all the database and instance information and&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT C.ClientName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DatabaseID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Notes]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[ClientDatabaseLookup] as CDL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> JOIN [DBADatabase].[dbo].[Clients] as C
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON CDL.clientid = c.clientid
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To get the client information. The client information needs to be manually added to the table as this (in general) needs a human bean to understand. When the script runs every night it will pick up new databases and I add a default value of &amp;ldquo;Not Entered&amp;rdquo; to the table which makes it easier to identify the databases that need this additional work. (This also means that as a Team Leader I can monitor that my team are doing this) It can also be added to any scripts which create new databases for deployment.&lt;/p>
&lt;p>Then we need to create some measures and calculated columns for our report. I did this as I realised that I needed it when making the report rather than all up front.&lt;/p>
&lt;p>I created two calculated columns for size for the databases one for Gb and one for Tb by clicking on the data icon on the left and then new measure&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SizeGb = Query1[SizeMB]/1024
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SizeTb = Query1[SizeGb]/1024
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Some measures for count of Databases, Instances and Servers&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Databases = COUNT(Query1[DatabaseID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Instances = DISTINCTCOUNT(Query1[InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Servers = DISTINCTCOUNT(Query1[ServerName])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also wanted to be able to differentiate between &amp;lsquo;External&amp;rsquo; and &amp;lsquo;Internal&amp;rsquo; customers. So I created a calculated column for this value using a switch statement.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">External = SWITCH(Clients[ClientName],&amp;#34;Not Entered&amp;#34;, 0 , &amp;#34;Dev Team&amp;#34;,0,&amp;#34;Mi Team&amp;#34;,0,&amp;#34;DBA Team&amp;#34;,0,&amp;#34;Finance Department&amp;#34;,0,&amp;#34;HR&amp;#34;,0,&amp;#34;Operations&amp;#34;,0,&amp;#34;Payroll&amp;#34;,0,&amp;#34;Test Team&amp;#34;,0,&amp;#34;Systems Team&amp;#34;,0,&amp;#34;Unknown&amp;#34;,0,1)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a donut chart to show the size of the database in Gb by client (and no, my real clients are not rock bands :-) ) as shown below. I formatted the title, legend and background by clicking on the paintbrush in the visualisation pane. I would encourage you to investigate the options here.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db4.png?w=300"
loading="lazy"
alt="db4"
>&lt;/a> The other donut chart is number of clients per location (and those are SQL User group locations in the UK and my hometown Bolton)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db5.png?w=300"
loading="lazy"
alt="db5"
>&lt;/a>&lt;/p>
&lt;p>The rest of the visualisations on that report are cards and tables which I am sure that you can work out.&lt;/p>
&lt;p>I created a map to show the location of the databases&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db6.png?w=300"
loading="lazy"
alt="db6"
>&lt;/a>&lt;/p>
&lt;p>And after reading this post &lt;a class="link" href="http://sqldusty.com/2015/08/03/power-bi-tip-use-the-treemap-chart-as-a-colorful-slicer/" target="_blank" rel="noopener"
>http://sqldusty.com/2015/08/03/power-bi-tip-use-the-treemap-chart-as-a-colorful-slicer/&lt;/a> by Dustin Ryan I created a colourful slicer for environment and the client and then added some other information. The important thing here is to pick the information that the person looking at the report needs to see. So if it is recovery model, compatibility level, collation, page verify setting, mirroring, replication, size and number of databases then this report is correct but I doubt thats what you want :-)&lt;/p>
&lt;p>You can slice this report by location, client or environment. For example, I can easily see which clients have data in Exeter and the size and number of databases&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db7.png?w=300"
loading="lazy"
alt="db7"
>&lt;/a>&lt;/p>
&lt;p>Or if Metallica ring me up I can quickly see that they have 4 databases, just under 69Gb of data in Exeter and it isn&amp;rsquo;t mirrored. You will notice that it is not easy to see the recovery model or the compatibility level. If you hover over the results you get a highlight figure which shows the data is filtered but it is not shown visually very well as there are over a thousand databases using full recovery model.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db8.png?w=300"
loading="lazy"
alt="db8"
>&lt;/a>&lt;/p>
&lt;p>If we are asked about the Integration environment we can see that it is hosted in Bolton, Manchester, Southampton and Exeter and comprises of 394 databases and 739 Gb of data. It is also easier to see the compatibility level and recovery model as the ratios are larger&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db9.png?w=300"
loading="lazy"
alt="db9"
>&lt;/a>&lt;/p>
&lt;p>Once we have created the report in the way that we want we can then publish it to powerbi.com and share it with others if we wish. Publishing is as easy as pressing the publish button and entering your powerbi credentials but if you want your data to automatically refresh (and this is the point of the exercise to remove manual work) then you will need to install and configure the PowerBi gateway and schedule a refresh I will post about this later.&lt;/p>
&lt;p>Once the report is published you can access it in the browser and create a dashboard by clicking the pin in the top right of a visualisation and a pop up will ask you which dashboard you wish to pin it to (Another recent update to Power Bi)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db10.png?w=300"
loading="lazy"
alt="db10"
>&lt;/a>&lt;/p>
&lt;p>Once you have a dashboard you can then perform some natural language question and answer on it. This can be quite interesting and not always quite what you (or your report readers) might expect but it is getting better all the time&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db11.png?w=300"
loading="lazy"
alt="db11"
>&lt;/a>&lt;/p>
&lt;p>You have to remember to use the names of the columns correctly&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db12.png?w=300"
loading="lazy"
alt="db12"
>&lt;/a>&lt;/p>
&lt;p>But once you have the query correct you can alter it by adding &amp;ldquo;as a VISUALISATION&amp;rdquo; and choose the visualisation&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db13.png?w=300"
loading="lazy"
alt="db13"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db14.png?w=300"
loading="lazy"
alt="db14"
>&lt;/a>&lt;/p>
&lt;p>And once you have the visualisation you can pin it to the dashboard&lt;/p>
&lt;p>I think you can see how useful it can be&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db15.png?w=263"
loading="lazy"
alt="db15"
>&lt;/a>&lt;/p>
&lt;p>This doesnt work quite as you expect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db16.png?w=300"
loading="lazy"
alt="db16"
>&lt;/a>&lt;/p>
&lt;p>But this does&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db17.png?w=275"
loading="lazy"
alt="db17"
>&lt;/a>&lt;/p>
&lt;p>How about this (and yes it felt wrong to type!)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db18.png?w=300"
loading="lazy"
alt="db18"
>&lt;/a>&lt;/p>
&lt;p>And the auditors would love to be able to do this. (This is an old copy of the database in case The Eagles people are reading this - your database is backed up every 15 minutes)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db19.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db19.png?w=300"
loading="lazy"
alt="db19"
>&lt;/a>&lt;/p>
&lt;p>Or this for a DBA ( Yes, my obfuscation script database naming convention is a bit bland)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db20.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db20.png?w=300"
loading="lazy"
alt="db20"
>&lt;/a>&lt;/p>
&lt;p>Or the DBA team manager might choose this one&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db21.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db21.png?w=300"
loading="lazy"
alt="db21"
>&lt;/a>&lt;/p>
&lt;p>The advantage that I cannot show via static pictures is that the data, visualisation and the suggestions alter in real time as you type&lt;/p>
&lt;p>I hope that you have found this useful and that you can see the benefits and advantages of using a DBA Database and empowering people to use self-service to answer their own questions leaving the DBA time to do more important things like drinking coffee :-)&lt;/p>
&lt;p>As always if you have any questions or comments please feel free to post them on the blog.&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Enterprise Strategies - A #TSQL2sDay post</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/enterprise-strategies-a-#tsql2sday-post/</link><pubDate>Tue, 08 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/enterprise-strategies-a-#tsql2sday-post/</guid><description>&lt;p>&lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/time-for-t-sql-tuesday-70/" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/TSQL2sDay150x150.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This months TSQL2sDay blog post party is hosted by &lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/time-for-t-sql-tuesday-70/" target="_blank" rel="noopener"
>Jen McCown&lt;/a> and is about Enterprise Strategy.&lt;/p>
&lt;p>Adam Mechanic started &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2009/11/30/invitation-to-participate-in-t-sql-tuesday-001-date-time-tricks.aspx" target="_blank" rel="noopener"
>TSQL Tuesdays over 5 years ago&lt;/a> and you will find many brilliant posts under that heading if &lt;a class="link" href="https://www.google.co.uk/#q=tsql2sday" target="_blank" rel="noopener"
>you search for them&lt;/a>&lt;/p>
&lt;p>Managing SQL servers at enterprise scale is not a straightforward task. Your aim as a DBA should be to simplify it as much as possible and to automate everything that you possibly can. &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>This post by John Sansom&lt;/a> could have been written for this months party and I recommend that you read it.&lt;/p>
&lt;p>So here are a few points that I think you should consider if you look after SQL in an Enterprise environment.&lt;/p>
&lt;ul>
&lt;li>Enterprise Strategy will undoubtedly garner a whole host of excellent posts and Jen will provide a round up post which will I am certain will be an excellent resource. &lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/the-tsql2sday-70-roundup/" target="_blank" rel="noopener"
>Take a look here&lt;/a>&lt;/li>
&lt;li>Know where your instances are and have a single place that you can reference them from. Some people recommend a &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/bb895144.aspx?f=255&amp;amp;MSPPError=-2147217396" target="_blank" rel="noopener"
>Central Management Server&lt;/a> but I find this too restrictive for my needs. I use an InstanceList table in my DBA Database with the following columns [ServerName], [InstanceName] , [Port] , [AG] , [Inactive] , [Environment] and [Location]. This enables me to target instances not just by name but by environment (Dev, Test, Pre-Prod, Live etc), by location or by joining the InstanceList table with another table I can target by the application or any number of other factors. I also capture information about the servers at windows and SQL level to this database so I can target the SQL 2012 servers specifically if need be or any other metric. This is very powerful and enables far greater flexibility than the CMS in my opinion.&lt;/li>
&lt;li>Use PowerShell (no surprise I would mention this!) PowerShell is a brilliant tool for automation and I use it all of the time&lt;/li>
&lt;li>Get used to using this piece of PowerShell code&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName],[InstanceName],[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0 AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice the query variable above, this is where the power lies as it enables you to gather all the instances that you need for your task as described in the bullet post above. Once you get used to doing this you can do things like this identify all the instances with Remote DAC disabled using a query against the DBA Database and then enable it on all servers by adding this code to the loop above&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$srv.RemoteDacEnabled = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.alter()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Very quick very simple and very very powerful. You can also use this to run TSQL scripts against the instances you target but there are some &lt;a class="link" href="https://www.bing.com/search?q=issues%20with%20invoke-sqlcmd&amp;amp;form=EDGEAR&amp;amp;qs=PF&amp;amp;cvid=bafe07c6afd54a6cb0ce7a1583300a79&amp;amp;pq=issues%20with%20invoke-sqlcmd&amp;amp;elv=AF!A!XC!KoOyC2FxnVd!deIwlgRcylR4EqUAG2rfVDNS" target="_blank" rel="noopener"
>added complications with Invoke-SQLCmd&lt;/a> that you need to be aware of&lt;/p>
&lt;ul>
&lt;li>BE CAREFUL. Test and understand and test before you run any script on a live system especially using a script like this which enables you to target ALL of your servers. You must definitely check that your $ServerNames array contains only the instances you need before you make any changes. You need to be ultra-cautious when it is possible to do great damage&lt;/li>
&lt;li>Write scripts that are robust and handle errors gracefully. I use Jason Wasser @wasserja Write-Log function to write to a text file and wrap my commands in a try catch block.&lt;/li>
&lt;li>Include comments in your scripts to assist either the future you or the folks in your position in 5 years time. I would also add one of my bug bears - Use the description block in Agent Jobs. The first place any DBA is going to go to when that job fails is to open the properties of the job. Please fill in that block so that anyone troubleshooting knows some information about what the job does or at the very least a link to some documentation about it&lt;/li>
&lt;li>Finally in my list, don&amp;rsquo;t overdo the alerts. Alerting is vital for any DBA it is a brilliant way to ensure that you quickly know about any issues affecting your estate but &lt;a class="link" href="http://thomaslarock.com/2012/02/the-minimalist-guide-to-database-administration/" target="_blank" rel="noopener"
>all alerts should be actionable&lt;/a> and in some cases you can automate the action that you can take but the message here is don&amp;rsquo;t send messages to the DBA team email for every single tiny thing or they will get swamped and ignore the vital one. This holds for whichever alerting or monitoring system that you use&lt;/li>
&lt;/ul>
&lt;p>This is but a small sub-section of things that you need to consider when responsible for a large SQL estate but if you need help and advice or just moral support and you dont already interact with the SQL community then make today the day you start. Maybe &lt;a class="link" href="http://thomaslarock.com/sql-family/" target="_blank" rel="noopener"
>this post by Thomas La Rock&lt;/a> is a good place to start or &lt;a class="link" href="http://www.sqlpass.org/PASSChapters.aspx" target="_blank" rel="noopener"
>your nearest User Group/Chapter&lt;/a> or the &lt;a class="link" href="https://twitter.com/hashtag/sqlfamily" target="_blank" rel="noopener"
>#sqlfamily hashtag&lt;/a> or give me a shout and I will gladly help.&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - SQL Info</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-sql-info/</link><pubDate>Mon, 07 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-sql-info/</guid><description>&lt;p>Following my post about &lt;a class="link" href="http://wp.me/p3aio8-gj" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/2.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>Although you will find so many items of data that I expect that you will want to create different reports for your own requirements. You will also want to put the report onto PowerBi.com and explore the natural language querying as I show at the end of this post&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts and PowerShell scripts here.&lt;/a>&lt;/p>
&lt;p>The SQLInfo table is created using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[SQLInfo](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLInfoID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateChecked] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateAdded] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServerName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLVersionString] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLVersion] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServicePack] [nvarchar](3) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Edition] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServerType] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Collation] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsHADREnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLServiceAccount] [nvarchar](35) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLService] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLServiceStartMode] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BAckupDirectory] [nvarchar](256) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BrowserAccount] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BrowserStartMode] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsSQLClustered] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterName] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterQuorumstate] [nvarchar](20) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterQuorumType] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [C2AuditMode] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CostThresholdForParallelism] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MaxDegreeOfParallelism] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DBMailEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultBackupCComp] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FillFactor] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MaxMem] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MinMem] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [RemoteDacEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [XPCmdShellEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CommonCriteriaComplianceEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultFile] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultLog] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [HADREndpointPort] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ErrorLogPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstallDataDirectory] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstallSharedDirectory] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsCaseSensitive] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsFullTextInstalled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LinkedServer] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LoginMode] [nvarchar](20) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MasterDBLogPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MasterDBPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [NamedPipesEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [OptimizeAdhocWorkloads] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceID] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AGListener] [nvarchar](150) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AGs] [nvarchar](150) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK__SQL__50A5926BC7005F29] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLInfoID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [Info].[SQLInfo] WITH CHECK ADD CONSTRAINT [FK_SQLInfo_InstanceList] FOREIGN KEY([InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">REFERENCES [dbo].[InstanceList] ([InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [Info].[SQLInfo] CHECK CONSTRAINT [FK_SQLInfo_InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName = &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>the script from here&lt;/a> or you can read on to see how it works and how to create the report and publish it to powerbi.com&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Catch-Block
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ([string]$Additional)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34; On $Connection &amp;#34; + $Additional + $_.Exception.Message + $_.Exception.InnerException.InnerException.message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Message = &amp;#34; This message came from the Automated PowerShell script updating the DBA Database with Server Information&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Msg = $Additional + $ErrorMessage + &amp;#34; &amp;#34; + $Message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message $ErrorMessage -Level Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-EventLog -LogName SQLAutoScript -Source &amp;#34;SQLAUTOSCRIPT&amp;#34; -EventId 1 -EntryType Error -Message $Msg
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the function an additional parameter which will hold each custom error message which I write to both the event log and a text message to enable easy troubleshooting and include the message from the $Error variable by accessing it with $_. I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called $ServerNames holding the server name, instance name and port&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and create a &lt;code>$Connection&lt;/code> variable for my SMO connection string and connect to the server&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Even though I place the creation of the SMO server object in a try block you still need to an additional check to ensure that you can connect and populate the object as the code above creates an empty SMO Server object with the name property set to the $Connection variable if you can&amp;rsquo;t connect to that server and doesnt error as you may expect The way I have always validated an SMO Server object is to check the version property. There is no justifiable reason for choosing that property, you could choose any one but thats the one I have always used. I use an if statement to do this ( &lt;a class="link" href="http://wp.me/p3aio8-cL" target="_blank" rel="noopener"
>This post about Snippets will show you the best way to learn PowerShell code&lt;/a>) The reference I use for exiting a loop in the way that you want is &lt;a class="link" href="http://ss64.com/ps/break.html" target="_blank" rel="noopener"
>this one&lt;/a> In this case we use a continue to carry on iterating the loop&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Catch-Block &amp;#34; Failed to Connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you wish to view all of the different properties that you can gather information on in this way you can use this code to take a look. (This is something you should get used to doing when writing new PowerShell scripts)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv | Get-Member
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>As you can see from the screenshot below on my SQL2014 server there are 184 properties. I havent chosen to gather all of them, only the ones that are of interest to me, our team or others who request information from our team such as auditors and project managers etc&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>You can choose to use any or all of these properties as long as you ensure you have the columns in your table with the correct data type and that you have the correct knowledge and logic to stop the script from erroring if/when the property is not available. Here is an example&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($srv.IsHadrEnabled -eq $True)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$IsHADREnabled = $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGs = $srv.AvailabilityGroups|Select Name -ExpandProperty Name|Out-String
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Expression = @{Name = &amp;#39;ListenerPort&amp;#39; ; Expression = {$_.Name + &amp;#39;,&amp;#39; + $_.PortNumber }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGListener = $srv.AvailabilityGroups.AvailabilityGroupListeners|select $Expression|select ListenerPort -ExpandProperty ListenerPort
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IsHADREnabled = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGs = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGListener = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $BackupDirectory = $srv.BackupDirectory
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I check if the property &lt;code>IsHADREnabled&lt;/code> is true and if it is I then gather the information about the Availability Group names and the listener port and if it doesnt exist I set the values to None.&lt;/p>
&lt;p>You will find that not all of the properties that you want are at the root of the Server SMO object. If you want you max and min memory values and you want to know if &lt;code>remote admin connections&lt;/code> or &lt;code>xp_cmdshell&lt;/code> are enabled you will need to look at the &lt;code>$Srv.Configuration&lt;/code> object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $MaxMem = $srv.Configuration.MaxServerMemory.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $MinMem = $srv.Configuration.MinServerMemory.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $RemoteDacEnabled = $srv.Configuration.RemoteDacConnectionsEnabled.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XPCmdShellEnabled = $srv.Configuration.XPCmdShellEnabled.ConfigValue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can look for the property that you want by using the Get-Member cmdlet as shown above or use MSDN to find it &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.server.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>starting from here&lt;/a> or by GoogleBingDuckDuckGo ing &amp;ldquo;PowerShell SMO&amp;rdquo; and the property you wish to find.&lt;/p>
&lt;p>The rest of the script follows exactly the same pattern &lt;a class="link" href="http://sqldbawithabeard.com/2015/08/31/populating-my-dba-database-for-power-bi-with-PowerShell-server-info/" target="_blank" rel="noopener"
>as the previous post&lt;/a> by checking the SQL Info table for an entry for that instance and updating the table if it exists and inserting if it does not.&lt;/p>
&lt;p>There are other uses for gathering this information than just for reporting on it. You can target different versions of SQL for different scripts. You can identify values that are outside what is expected and change them. If xp_cmdshell should not be enabled, write the TSQL to gather the connection string of all of the servers from the DBADatabase where the SQLInfo table has &lt;code>XPCMDShellenabled = 1&lt;/code> and loop through them exactly as above and change the value of &lt;code>$srv.Configuration.XPCmdShellEnabled.ConfigValue&lt;/code> to 0 and then &lt;code>$Srv.Alter()&lt;/code>&lt;/p>
&lt;p>It is a very powerful way of dynamically targeting your estate if you are looking after many instances and with great power comes great responsibility.&lt;/p>
&lt;p>ALWAYS TEST THESE AND ANY SCRIPTS YOU FIND OR SCRIPTS YOU WRITE BEFORE YOU RUN THEM IN YOUR PRODUCTION ENVIRONMENT&lt;/p>
&lt;p>Yeah, I shouted and some people thought it was rude. But its important, it needs to be repeated and drilled in so that it becomes habitual. You can do great damage to your estate with only a few lines of PowerShell and a DBA Database so please be very careful and ensure that you have a suitable test subset of servers that you can use to test&lt;/p>
&lt;p>The other thing we can do is report on the data and with Power Bi we can create self service reports and dashboards and also make use of the natural language query at powerbi.com so that when your systems team ask &amp;ldquo;What are all the servers in X data center?&amp;rdquo; you can enable them to answer it themselves or when the compliance officer asks how many SQL 2005 instances do we have and which clients do they serve you can give them a dashboard they can query themselves.&lt;/p>
&lt;p>This is how I create the two reports you see at the top. I start by connecting to the data source, my DBA Database&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>And I use this query&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Environment
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Inactive
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.NotContactable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLInfoID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DateAdded]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLVersionString]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLVersion]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServicePack]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[Edition]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServerType]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[Collation]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsHADREnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLServiceAccount]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLService]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLServiceStartMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BAckupDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BrowserAccount]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BrowserStartMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsSQLClustered]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterQuorumstate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterQuorumType]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[C2AuditMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[CostThresholdForParallelism]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MaxDegreeOfParallelism]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DBMailEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultBackupCComp]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[FillFactor]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MaxMem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MinMem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[RemoteDacEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[XPCmdShellEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[CommonCriteriaComplianceEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultFile]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultLog]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[HADREndpointPort]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ErrorLogPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstallDataDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstallSharedDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsCaseSensitive]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsFullTextInstalled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[LinkedServer]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[LoginMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MasterDBLogPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MasterDBPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[NamedPipesEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[OptimizeAdhocWorkloads]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[AGListener]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[AGs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[Info].[SQLInfo] as SI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> JOIN [DBADatabase].[dbo].[InstanceList] as IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON IL.InstanceID = SI.InstanceID
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So that I can easily add any and all the data to the reports if I choose or query using them in powerbi.com&lt;/p>
&lt;p>First I created 3 measures.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> AG = DISTINCTCOUNT(Query1[AGs]) Instances = DISTINCTCOUNT(Query1[InstanceID]) Servers = DISTINCTCOUNT(Query1[ServerName])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I click on map&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/5.png?w=300"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>And drag the location column to location and the Instances measure to both the Values and Color Saturation&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I then click on edit and format the title and change the colours for the data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>Next I created I heat map for Instances by Edition. The picture shows the details&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>And a column chart for Instances by Version&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/9.png?w=300"
loading="lazy"
alt="9"
>&lt;/a>&lt;/p>
&lt;p>I also add a table showing the number of instances in each location and a slicer for environment.&lt;/p>
&lt;p>Even though you have added one slicer, you are able to slice the data by clicking on the charts. If I click on Developer Edition I can quickly see which versions and locations they are in&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/10.png?w=300"
loading="lazy"
alt="10"
>&lt;/a>&lt;/p>
&lt;p>This works for the map and the column chart as well. This has all been created using live data as a base with all identifying information altered, Bolton is where I was born and the other locations are chosen at random, all other figures and rollups have also been altered.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/11.png?w=300"
loading="lazy"
alt="11"
>&lt;/a>&lt;/p>
&lt;p>To create the other report I create two donut charts for Instances by version and by location using steps similar to my previous post and then add some tables for location, edition and xp_cmdshell enabled as well as some cards showing total numbers of Servers, Instances and Availability Groups and a slicer for environment to create a report like this, you can use the donut charts to slice the data as well&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/12.png?w=300"
loading="lazy"
alt="12"
>&lt;/a>&lt;/p>
&lt;p>But there are so many different points of information gathered by this script that you get extra value using the natural language query on powerbi.com.&lt;/p>
&lt;p>Click Publish and enter your powerbi.com credentials and then log into powerbi.com in a browser and you will see your report and your dataset. (Note, you can easily filter to find your dashboards, reports and data sets)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/13.png?w=173"
loading="lazy"
alt="13"
>&lt;/a>&lt;/p>
&lt;p>Click the plus sign to create a new dashboard and click the pin on any of the objects in your report to pin them to the dashboard&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/14.png?w=300"
loading="lazy"
alt="14"
>&lt;/a>&lt;/p>
&lt;p>Then you can view (and share) your dashboard&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/15.png?w=300"
loading="lazy"
alt="15"
>&lt;/a>&lt;/p>
&lt;p>Once you have done this you can query your data using natural language. It will cope with spelling mistakes and expects the column names so you may want to think about renaming them in your report by right clicking on them after you get your data.&lt;/p>
&lt;p>You can ask it questions and build up information on the fly and alter it as you need it. As a DBA doing this and imagining enabling others to be able to ask these questions whenever they want from a browser and as many times as they like, it was very cool!&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/16.png?w=300"
loading="lazy"
alt="16"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/17.png?w=300"
loading="lazy"
alt="17"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/18.png?w=300"
loading="lazy"
alt="18"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/19.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/19.png?w=300"
loading="lazy"
alt="19"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/20.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/20.png?w=300"
loading="lazy"
alt="20"
>&lt;/a>&lt;/p>
&lt;p>Pretty cool, I think you and any of your &amp;lsquo;requestors&amp;rsquo; would agree&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You can get all of the scripts here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Use Twitter to get #PowerShell help</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-twitter-to-get-#powershell-help/</link><pubDate>Sun, 06 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-twitter-to-get-#powershell-help/</guid><description>&lt;p>A quick post today just to add some weight to something that Mike Fal &lt;a class="link" href="http://www.mikefal.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/Mike_Fal" target="_blank" rel="noopener"
>t&lt;/a>has kicked off. The &lt;a class="link" href="https://twitter.com/hashtag/sqlhelp" target="_blank" rel="noopener"
>#SQLHelp hashtag&lt;/a> is well known and well used with in the SQL world. It is a fantastic resource and one that I recommend to all SQL folk I meet who are not aware of it. &lt;a class="link" href="https://www.brentozar.com/archive/2009/12/i-need-sqlhelp/" target="_blank" rel="noopener"
>Heres how it started&lt;/a>&lt;/p>
&lt;p>Mike has suggested that there should be a similar resource for PowerShell questions &lt;a class="link" href="https://twitter.com/search?q=%23PoShHelp" target="_blank" rel="noopener"
>#PoSHHelp&lt;/a>. We want to create a useful and positive place for people to go with their PowerShell queries and some good folks like Mike, &lt;a class="link" href="http://t.co/NfvkfJXMjp" target="_blank" rel="noopener"
>Shawn Melton&lt;/a>(&lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>), &lt;a class="link" href="http://t.co/K8jsx6WHcc" target="_blank" rel="noopener"
>Adam Bertram&lt;/a>(&lt;a class="link" href="https://twitter.com/adbertram" target="_blank" rel="noopener"
>@adbertram&lt;/a>), &lt;a class="link" href="http://t.co/U5LLtwWDPI" target="_blank" rel="noopener"
>Derik Hammer&lt;/a>(&lt;a class="link" href="https://twitter.com/SQLHammer" target="_blank" rel="noopener"
>@SQLHammer&lt;/a>), &lt;a class="link" href="http://learn-PowerShell.net/" target="_blank" rel="noopener"
>Boe Prox&lt;/a>(&lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>@proxb&lt;/a>), myself and others will be looking for your PowerShell problems and try to assist you over Twitter with the same care and grace as Sqlhelp.&lt;/p>
&lt;p>As with Sqlhelp we would like there to be a few rules that we all can follow to ensure that this remains a brilliant resource. Mike has suggested the following&lt;/p>
&lt;ol>
&lt;li>Questions should fit into 140 characters.&lt;/li>
&lt;li>If they dont, put your question and information on another site (like &lt;a class="link" href="http://serverfault.com/" target="_blank" rel="noopener"
>ServerFault.com&lt;/a>) and link to it.&lt;/li>
&lt;li>DO NOT SPAM THE HASH TAG. This is important, because in order to make it useful it needs to be kept clean. Dont use it to advertise your blog posts or articles, but only for Q&amp;amp;A.&lt;/li>
&lt;li>Dont be a dick, a.k.a. &lt;a class="link" href="http://knowyourmeme.com/memes/wheatons-law" target="_blank" rel="noopener"
>Wheatons Law&lt;/a>. Its all too easy to let the anonymity of the internet get the better of us. Be polite and respectful to those using and accidentally mis-using the hash tag.&lt;/li>
&lt;/ol>
&lt;p>I notice that &lt;a class="link" href="http://sqlvariant.com/2010/07/please-join-us-for-poshhelp/" target="_blank" rel="noopener"
>Aaron Nelson had already suggested this a few years ago&lt;/a> but it seems like it has fallen by the wayside. I would like to see this grow for all PowerShell folk so I ask you all to do two things.&lt;/p>
&lt;p>Firstly, please add #PoSHHelp to your Tweetdeck column list or pin it to Tweetium (like I have) If you see a question you can help with then jump in and give your answer and help the community.&lt;/p>
&lt;p>Secondly, let people know, if you see or hear a question about PowerShell then advise them to make use of the hashtag. If you blog about PowerShell then write a quick blog post like this one and let your readers know.&lt;/p>
&lt;p>Pass on the word&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/nRhfnZ0.png"
loading="lazy"
>&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - Server Info</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-server-info/</link><pubDate>Mon, 31 Aug 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-server-info/</guid><description>&lt;p>Following my last post about &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database. They are the secondary part to my DBADatabase which I also use to automate the installation and upgrade of all of my DBA scripts as I started to blog about in this post &lt;a class="link" href="https://blog.robsewell.com/powershell/sql%20server/installing-and-upgrading-default-scripts-automation-part-one-introduction/" target="_blank" rel="noopener"
>Installing and upgrading default scripts automation - part one - Introduction&lt;/a> which is a series I will continue later.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/18.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts here&lt;/a>.&lt;/p>
&lt;p>I create the following tables&lt;/p>
&lt;ul>
&lt;li>dbo.ClientDatabaseLookup&lt;/li>
&lt;li>dbo.Clients&lt;/li>
&lt;li>dbo.InstanceList&lt;/li>
&lt;li>dbo.InstanceScriptLookup&lt;/li>
&lt;li>dbo.ScriptList&lt;/li>
&lt;li>Info.AgentJobDetail&lt;/li>
&lt;li>Info.AgentJobServer&lt;/li>
&lt;li>Info.Databases&lt;/li>
&lt;li>Info.Scriptinstall&lt;/li>
&lt;li>Info.ServerOSInfo&lt;/li>
&lt;li>Info.SQLInfo&lt;/li>
&lt;/ul>
&lt;p>By adding Server name, Instance Name , Port, Environment, NotContactable, and Location into the InstanceList table I can gather all of the information that I need and also easily add more information to other tables as I need to.&lt;/p>
&lt;p>The not contactable column is so that I am able to add instances that I am not able to contact due to permission or environment issues. I can still gather information about them manually and add it to the table. I use the same script and change it to generate the SQL query rather than run it, save the query and then run the query manually to insert the data. This is why I have the DateAdded and Date Checked column so that I know how recent the data is. I dont go as far as recording the change however as that will be added to a DBA-Admin database on every instance which stores every change to the instance.&lt;/p>
&lt;p>The ServerOSInfo table is created like so&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\*\*\*\*\*\* Object: Table [Info].[ServerOSInfo] Script Date: 26/08/2015 19:50:38 \*\*\*\*\*\*
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SET ANSI_NULLS ON
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SET QUOTED_IDENTIFIER ON
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[ServerOSInfo](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerOSInfoID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DateAdded] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DateChecked] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DNSHostName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Domain] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[OperatingSystem] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[NoProcessors] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[IPAddress] [nvarchar](15) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[RAM] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK__ServerOS__50A5926BC7005F29] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerOSInfoID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName= &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get the &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>script from here&lt;/a> or you can read on to see how it works and how to create the report&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Catch-Block{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ([string]$Additional)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34; On $Connection &amp;#34; + $Additional + $_.Exception.Message + $_.Exception.InnerException.InnerException.message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Message = &amp;#34; This message came from the Automated PowerShell script updating the
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DBA Database with Server Information&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Msg = $Additional + $ErrorMessage + &amp;#34; &amp;#34; + $Message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message $ErrorMessage -Level Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-EventLog -LogName SQLAutoScript -Source &amp;#34;SQLAUTOSCRIPT&amp;#34; -EventId 1 -EntryType Error -Message $Msg
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the function an additional parameter which will hold each custom error message which I write to both the event log and a text message to enable easy troubleshooting and include the message from the &lt;code>$Error&lt;/code> variable by accessing it with &lt;code>$_&lt;/code>. I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called &lt;code>$Servers&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$AlltheServers = Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query &amp;#34;SELECT DISTINCT [ServerName] FROM [DBADatabase].[dbo].[InstanceList] WHERE Inactive = 0 OR NotContactable = 1&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Servers = $AlltheServers| Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and gather the information with three WMI queries.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;Gathering Info for $Server &amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach($Server in $Servers)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;Gathering Info for $Servers&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DNSHostName = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Domain = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$OperatingSystem = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$IP = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Info = get-wmiobject win32_computersystem -ComputerName $Server -ErrorAction Stop|select DNSHostName,Domain,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">@{Name=&amp;#34;RAM&amp;#34;;Expression={&amp;#34;{0:n0}&amp;#34; -f($_.TotalPhysicalMemory/1gb)}},NumberOfLogicalProcessors
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the variables some default values in case they are not picked up and set the error action for the command to Stop to exit the try and the first query gathers the DNSHostName, Domain Name, the amount of RAM in GB and the number of logical processors, the second gathers the Operating System version but the third was the most interesting to do. There are many methods of gathering the IP Address using PowerShell and I tried a few of them before finding one that would work with all of the server versions that I had in my estate but the one that worked remotely the best for me and this is a good point to say that this works in my lab and in my shop but may not necessarily work in yours, so understand, check and test this and any other script that you find on the internet before you let them anywhere near your production environment.&lt;/p>
&lt;p>Unfortunately the one that worked everywhere remotely errored with the local server so I added a check to see if the server name in the variable matches the global environment variable of Computer Name&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$OS = gwmi Win32_OperatingSystem -ComputerName $Server| select @{name=&amp;#39;Name&amp;#39;;Expression={($_.caption)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Server -eq $env:COMPUTERNAME)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{$IP = (Get-WmiObject -ComputerName $Server -class win32_NetworkAdapterConfiguration -Filter &amp;#39;ipenabled = &amp;#34;true&amp;#34;&amp;#39; -ErrorAction Stop).ipaddress[0] }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else {$IP = [System.Net.Dns]::GetHostAddresses($Server).IPAddressToString }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;WMI Info gathered for $Server &amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once I have all of the information I check if the server already exists in the ServerOs table and choose to either insert or update.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Exists = Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query &amp;#34;SELECT [ServerName] FROM [DBADatabase].[Info].[ServerOSInfo] WHERE ServerName = &amp;#39;$Server&amp;#39;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Exists)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> UPDATE [Info].[ServerOSInfo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SET [DateChecked] = GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[ServerName] = &amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DNSHostName] = &amp;#39;$DNSHostName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Domain] = &amp;#39;$Domain&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[OperatingSystem] = &amp;#39;$OperatingSystem&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[NoProcessors] = &amp;#39;$NOProcessors&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[IPAddress] = &amp;#39;$IP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[RAM] = &amp;#39;$RAM&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WHERE ServerName = &amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> INSERT INTO [Info].[ServerOSInfo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ([DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DateAdded
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DNSHostName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Domain]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[OperatingSystem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[NoProcessors]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[IPAddress]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[RAM])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ( GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$DNSHostName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$Domain&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$OperatingSystem&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$NoProcessors&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$IP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$RAM&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $Query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ```
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">And thats it. Now if you wish to gather different data about your servers then you can examine the data available to you by
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>get-wmiobject Win32_OperatingSystem -ComputerName $Server | Get-Member
get-wmiobject win32_computersystem -ComputerName $Server | Get-Member&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">If you find something that you want to gather you can then add the property to the script and gather that information as well, make sure that you add the column to the table and to both the insert and update statements in the PowerShell Script
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">**Creating the report in Power Bi**
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">All data shown in the examples below has been generated from real-life data but all identifiable data has been altered or removed. I was born in Bolton and [SQL SouthWest](http://sqlsouthwest.co.uk/) is based in Exeter :-)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Open Power Bi Desktop and click get data. Add the connection details for your DBA Database server and database and add the query
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>SELECT SOI.[ServerOSInfoID]
,SOI.[DateChecked]
,SOI.[ServerName]
,SOI.[DNSHostName]
,SOI.[Domain]
,SOI.[OperatingSystem]
,SOI.[NoProcessors]
,SOI.[IPAddress]
,SOI.[RAM]
,IL.ServerName
,IL.InstanceName
,IL.Location
,IL.Environment
,IL.Inactive
,IL.NotContactable
FROM [DBADatabase].[Info].[ServerOSInfo] as SOI
JOIN [dbo].[InstanceList] as IL
ON IL.ServerName = SOI.[ServerName]
```
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/21.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/21.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>Create a new column for the Operating Edition by clicking data on the left and using this code as described &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>in my previous post&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Edition = SWITCH([OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 Enterprise&amp;#34;,&amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And one for OS Version using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">OS Version = SWITCH([OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;Server 2012 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 Standard&amp;#34;, &amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 Enterprise&amp;#34;,&amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also created a new measure to count the distinct number of servers and instances as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Servers = DISTINCTCOUNT(Query1[Servers Name])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Instances = COUNT(Query1[Instance])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then in the report area I start by creating a new text box and adding a title to the report and setting the page level filter to InActive is false so that all decommissioned servers are not included&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/31.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/31.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>I then create a donut chart for the number of servers by Operating System by clicking the donut chart in the visualisations and then dragging the OS version to the Details and the Servers Name to the Values&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/41.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/41.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>I then click the format button and added a proper title and the background colour&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/51.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/51.png?w=90"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>Then create the server numbers by location in the same way by clicking donut chart and adding location and count of server names and adding the formatting in the same way as the previous donut&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/61.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/61.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I created a number of charts to hold single values for Domain, Instance, Server, RAM, Processors and the number of Not Contactable to provide a quick easy view of those figures, especially when you filter the report by clicking on a value within the donut chart. I find that managers really like this feature. They are all created in the same way by clicking the card in the visualisation and choosing the value&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/71.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/71.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>I also add a table for the number of servers by operating system and the number of servers by location by dragging those values to a table visualisation. I find that slicers are very useful ways of enabling information to be displayed as required, use the live visualisation to do this, I add the environment column to slice so that I can easily see values for the live environment or the development environment&lt;/p>
&lt;p>I create a separate page in the report to display all of the server data as this can be useful for other teams such as the systems (server admin) team. I give them a lot of different slicers : - Domain, Location, Environment, OS Version, Edition and NotContactable with a table holding all of the relevant values to enable them to quickly see details&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/81.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/81.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You can get all of the scripts here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell  Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Setting Up and Using Azure VM SQL Automated Backup (and Restore)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</link><pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</guid><description>&lt;p>This weekend I was creating some Azure VMs to test and was required to use the GUI for some screenshots. I have always used my PowerShell scripts &lt;a class="link" href="http://sqldbawithabeard.com/2013/05/14/spinning-up-and-shutting-down-windows-azure-lab-with-PowerShell/" target="_blank" rel="noopener"
>described here&lt;/a> to create my test systems and with a new job taking up a lot of my time had missed the &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>announcement about Azure SQL Automated Backup and Azure SQL Automated Patching&lt;/a> so was surprised to see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>I read the announcement and also the details on MSDN &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx&lt;/a> which show that this requires the SQL Server IaaS Agent. This is a default option on new virtual machines.&lt;/p>
&lt;p>There are some other considerations too. It is only supported for SQL Server 2014 and Windows Server 2012 and 2012R2 at present and you can set a retention period to a maximum of 30 days but it is automated. You do not have to decide upon the backup strategy Azure will decide the frequency and type of backups dependent upon the workload of the database and some other factors such as&lt;/p>
&lt;p>A full backup is taken  when an instance is added to use Managed backup  When transaction log growth is 1Gb or more  At least once a week  If the log chain is broken  When a database is created&lt;/p>
&lt;p>A transaction log backup is taken - If no log backup is found - Transaction log space used is 5Mb or larger - At least once every two hours - Any time the transaction log backup is lagging behind a full database backup. The goal is to keep the log chain ahead of full backup.&lt;/p>
&lt;p>From &lt;a class="link" href="https://msdn.microsoft.com/en-gb/library/dn449496%28v=sql.120%29.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-gb/library/dn449496(v=sql.120).aspx&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>There are some restrictions - Only database backups are supported - System databases are not supported so you need to back those up yourself - You can only back up to Azure storage - Maximum backup size is 1Tb as this is the maximum size for a blob in Azure storage - Simple recovery is not supported - Maximum retention is 30 days - if you are required to keep your backups for longer than 30 days for regulatory or other reasons you could simply use Azure Automation to copy the files to another storage account in Azure)&lt;/p>
&lt;/blockquote>
&lt;p>How to set it up.&lt;/p>
&lt;p>If you are using the GUI then you will find SQL Automated Backup in the optional config blade of the set up. You can follow the steps &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here to set it up&lt;/a>. If (like me) you want to use PowerShell then use the following code after you have created your Virtual Machine&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$storageaccount = &amp;#34;&amp;lt;storageaccountname&amp;gt;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storageaccountkey = (Get-AzureStorageKey -StorageAccountName $storageaccount).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storagecontext = New-AzureStorageContext -StorageAccountName $storageaccount -StorageAccountKey $storageaccountkey
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$encryptionpassword = (Get-Credential -message &amp;#39;Backup Encryption Password&amp;#39; -User &amp;#39;IGNOREUSER&amp;#39;).password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$autobackupconfig = New-AzureVMSqlServerAutoBackupConfig -StorageContext $storagecontext -Enable -RetentionPeriod 10 -EnableEncryption -CertificatePassword $encryptionpassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-AzureVM -ServiceName &amp;lt;vmservicename&amp;gt; -Name &amp;lt;vmname&amp;gt; | Set-AzureVMSqlServerExtension -AutoBackupSettings $autobackupconfig | Update-AzureVM
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once you have run the code, Azure will take care of the rest. Add a couple of databases to your instance and look in the storage account and you will see this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>And in the automaticbackup container you will find the Certificates and master key backups&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>It will also create a credential&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/5.png"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>You can use the same credential to back up your system databases. If like me you use &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>Ola Hallengrens excellent Maintenance Solution&lt;/a> then simply change your systems backup job as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [msdb]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EXEC msdb.dbo.sp_update_jobstep @job_name = &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL&amp;#39;, @step_id=1 ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @command=N&amp;#39;sqlcmd -E -S $(ESCAPE_SQUOTE(SRVR)) -d master -Q &amp;#34;EXECUTE [dbo].[DatabaseBackup] @Databases = &amp;#39;&amp;#39;SYSTEM_DATABASES&amp;#39;&amp;#39;, &amp;#34;https://myaccount.blob.core.windows.net/mycontainer&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> , @Credential = &amp;#39;&amp;#39;AutoBackup_Credential&amp;#39;&amp;#39;, @BackupType = &amp;#39;&amp;#39;FULL&amp;#39;&amp;#39;, @Verify = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @CleanupTime = NULL, @CheckSum = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @LogToTable = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;&amp;#34; -b&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you need to restore your database then you can use the GUI and when you choose restore you will see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>Enter your storage account and the key which you can get from the Azure portal. You will notice that the credential has already been selected, click connect and&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>There are all of your backups ready to restore to any point in time that you choose. By clicking script the T-SQL is generated which looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [master]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BACKUP LOG [Test] TO URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_LogBackup_2015-07-16_06-21-26.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOFORMAT, NOINIT, NAME = N&amp;#39;Test_LogBackup_2015-07-16_06-21-26&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOSKIP, NOREWIND, NOUNLOAD, NORECOVERY , STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE DATABASE [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714201240+00.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714202740+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714224241+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715005741+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715031242+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715052742+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715074243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715095743+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715121243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150716060004+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is an important note. Remember this when you have just set it up so that you dont think that you have done it wrong (which is what I did!)&lt;/p>
&lt;p>When you enable Automated Patching for the first time, Azure configures the SQL Server IaaS Agent in the background. During this time, the portal will not show that Automated Patching is configured. Wait several minutes for the agent to be installed, configured. After that the portal will reflect the new settings.&lt;/p>
&lt;p>From &amp;lt;&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx&lt;/a>&amp;gt;&lt;/p>
&lt;p>And also look out for this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>The password I had chosen was not complex enough but the PowerShell script had succeeded and not given me the warning&lt;/p>
&lt;p>To set up SQL Automated Patching you follow a similar steps. The setting is again on the OS Config blade and click enable and then you can choose the frequency and duration of the patching.&lt;/p>
&lt;p>It is important to remember to choose your maintenance window correctly. If you have set up your SQL VMs correctly you will have them in an availability set and be using either mirroring or Availability Groups and have the VMs set up in the same availability set to ensure availability during the underlying host patching but I had it confirmed by Principal Software Engineering Manager Sethu Srinivasan &lt;a class="link" href="http://twitter.com/sethusrinivasan" target="_blank" rel="noopener"
>t&lt;/a> via Microsoft PFE Arvind Shyamsundar &lt;a class="link" href="http://blogs.msdn.com/b/arvindsh/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/arvisam" target="_blank" rel="noopener"
>t&lt;/a> that the SQL Automated Patching is not HA aware so you will need to ensure that you set the maintenance windows on each VM to ensure that they do not overlap&lt;/p></description></item><item><title>Installing and upgrading default scripts automation - part one - Introduction</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/installing-and-upgrading-default-scripts-automation-part-one-introduction/</link><pubDate>Mon, 08 Jun 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/installing-and-upgrading-default-scripts-automation-part-one-introduction/</guid><description>&lt;p>First I must say thank you to all of the wonderful people who have put time and effort into providing free tools and scripts to enable not only myself but all SQL DBAs to ease their work. For this series I especially thank&lt;/p>
&lt;ul>
&lt;li>Brent Ozar - &lt;a class="link" href="http://www.brentozar.com/" target="_blank" rel="noopener"
>w&lt;/a>|&lt;a class="link" href="https://twitter.com/BrentO" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;li>Ola Hallengren - &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>w&lt;/a>&lt;/li>
&lt;li>Adam Mechanic - &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/adammachanic" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;li>Jared Zagelbaum - &lt;a class="link" href="https://jaredzagelbaum.wordpress.com/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/JaredZagelbaum" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The aim of this series is to share the methodology and the scripts that I have used to resolve this issue.&lt;/p>
&lt;p>How can I automate the deployment and update of backup, integrity ,index maintenance and troubleshooting scripts as well as other default required scripts to all of the instances under my control and easily target any instances by OS version, SQL version, Environment, System or any other configuration of my choosing&lt;/p>
&lt;p>This is Part 1 - Introduction I will link to the further posts here as I write them&lt;/p>
&lt;p>So the scenario that lead to this series is a varied estate of SQL servers and instances where I wanted an automated method of deploying the scripts and being able to target different servers. It needed to be easy to maintain, easy to use and easy to alter. I wanted to be able to update all of the scripts easily when required. I also wanted to automate the install of new instances and ensure that I could ensure that all required scripts were installed and documented.&lt;/p>
&lt;p>The method of doing this that I chose is just that - Its the way that I chose, whether it will work for you and your estate I don&amp;rsquo;t know but I hope you will find it of benefit. Of course you must test it first. Ensure that you understand what is happening, what it is doing and that that is what you want it to do. If you implement this methodology of installing scripts you will easily be able to start by targeting your Development Server and then gradually rolling it out to any other environments&amp;rsquo; whilst always making sure that you test, monitor and validate prior to moving to the next.&lt;/p>
&lt;p>I decided that I needed to have a DBA Database to start with. The role of the DBA Database is to be the single source of truth for the instances that are under my control, a source for the location of the scripts that I need to deploy and a place to hold the information that I gather from the servers. It is from this database that I will be able to target the instances as required and set the flags to update the scripts as and when I need to&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/06/agentjob1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/06/agentjob1.png?w=300"
loading="lazy"
alt="agentjob"
>&lt;/a>&lt;/p>
&lt;p>On that instance I also chose to put the SQL Agent Job that will deploy all of the scripts. This is an important point. The account that you use to run that job whether it is the Agent Service Account or a proxy account will need to have privileges on every instance that you target. It will need to be able to run every script that you wish to target your servers. The privileges it requires are defined by the scripts that you want to run. How that is set up is unique to your environment and your system. I will only say that all errors are logged to the log files and will enable you to resolve these issues. You should always use the principle of least privilege required to get the job done. Domain and Sys Admin are not really the best answer here :-)&lt;/p>
&lt;p>I also created 2 further Agent Jobs to gather Windows and SQL Information from the servers. These jobs target all the instances and servers in the DBA Database and gather information centrally about Windows and SQL configurations making it easy to provide that information to any other teams that require it. I am always looking for methods to reduce the workload on DBAs and enabling people (using the correct permissions) to gather the information that they require by self-service is very beneficial&lt;/p>
&lt;p>Documentation and logging about the scripts are provided by the log files stored as text files to troubleshoot the script and also documented in the Change log table in a DBA database on each instance which I blogged about &lt;a class="link" href="http://sqldbawithabeard.com/2014/12/08/making-a-change-log-easier-with-PowerShell/" target="_blank" rel="noopener"
>previously here&lt;/a>&lt;/p>
&lt;p>The last thing was the script which needed to be modular and easy to add to and amend.&lt;/p>
&lt;p>Throughout this series of blog posts I will share and expand on the methods I used to do this. If you have any questions at any point please feel free to ask either by commenting on the post or by contacting me using the methods on my About Me page&lt;/p></description></item><item><title>Scheduling Ola Hallengrens Maintenance Solution Default Jobs with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/scheduling-ola-hallengrens-maintenance-solution-default-jobs-with-powershell/</link><pubDate>Wed, 06 May 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/scheduling-ola-hallengrens-maintenance-solution-default-jobs-with-powershell/</guid><description>&lt;p>If you are a SQL Server DBA you should know about Ola Hallengren and will probably have investigated his Maintenance Solution.&lt;/p>
&lt;p>If you haven&amp;rsquo;t please start here &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>https://ola.hallengren.com/&lt;/a>&lt;/p>
&lt;p>You can also watch his presentation at SQLBits at this link&lt;/p>
&lt;p>&lt;a class="link" href="http://sqlbits.com/Sessions/Event9/Inside_Ola_Hallengrens_Maintenance_Solution" target="_blank" rel="noopener"
>http://sqlbits.com/Sessions/Event9/Inside_Ola_Hallengrens_Maintenance_Solution&lt;/a>&lt;/p>
&lt;p>where he talks about and demonstrates the solution.&lt;/p>
&lt;p>It is possible to just run his script to install the solution and schedule the jobs and know that you have made a good start in keeping your databases safe. You should be more proactive than that and set specific jobs for your own special requirements but you can and should find that information in other places including the FAQ on Ola&amp;rsquo;s site&lt;/p>
&lt;p>I particularly like the parameter @ChangeBackupType which when running the transaction logor differential backup will change the backup type to full if the backup type cannot be taken. This is excellent for picking up new databases and backing them up soon after creation&lt;/p>
&lt;p>When you run the script the jobs are created but not scheduled and it is for this reason I created this function. All it does it schedule the jobs so that I know that they will be run when a new server is created and all the databases will be backed up. I can then go back at a later date and schedule them correctly for the servers workload or tweak them according to specific needs but this allows me that fuzzy feeling of knowing that the backups and other maintenance will be performed.&lt;/p>
&lt;p>To accomplish this I pass a single parameter $Server to the function this is the connection string and should be in the format of &lt;code>SERVERNAME&lt;/code>, &lt;code>SERVERNAME\INSTANCENAME &lt;/code>or &lt;code>SERVERNAME\INSTANCENAME,Port&lt;/code>&lt;/p>
&lt;p>I then create a &lt;code>$srv&lt;/code> SMO object as usual&lt;/p>
&lt;p>&lt;code>$srv = New-Object Microsoft.SQLServer.Management.SMO.Server $Server&lt;/code>&lt;/p>
&lt;p>Create a JobServer object and a Jobs array which holds the Jobs&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$JobServer = $srv.JobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs = $JobServer.Jobs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And set the schedule for each job. I pick each Job using the Where-Object Cmdlet and break out if the job does not exist&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Job = $Jobs|Where-Object {$_.Name -eq &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Job -eq $Null)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Output &amp;#34;No Job with that name&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> break}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then I create a Schedule object and set its properties and create the schedule&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Schedule = new-object Microsoft.SqlServer.Management.Smo.Agent.JobSchedule ($job, &amp;#39;Daily - Midnight ++ Not Sunday&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveEndDate = Get-Date -Month 12 -Day 31 -Year 9999
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveEndTimeOfDay = &amp;#39;23:59:59&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyTypes = &amp;#34;Weekly&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyRecurrenceFactor = 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencySubDayTypes = &amp;#34;Once&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyInterval = 126 # Weekdays 62 + Saturdays 64 - &amp;lt;a href=&amp;#34;https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx&amp;#34;&amp;gt;https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx&amp;lt;/a&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveStartDate = get-date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$schedule.ActiveStartTimeOfDay = &amp;#39;00:16:00&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.IsEnabled = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.Create()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have picked this example for the blog as it shows some of the less obvious gotchas. Setting the active end date could only be achieved by using the Get-Date Cmdlet and defining the date. The schedule frequency interval above is for every day except Sundays. This achieved by using the following table from &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>MSDN&lt;/a> which is always my first port of call when writing these scripts&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>WeekDays.Sunday = 1&lt;/li>
&lt;li>WeekDays.Monday = 2&lt;/li>
&lt;li>WeekDays.Tuesday = 4&lt;/li>
&lt;li>WeekDays.Wednesday = 8&lt;/li>
&lt;li>WeekDays.Thursday = 16&lt;/li>
&lt;li>WeekDays.Friday = 32&lt;/li>
&lt;li>WeekDays.Saturday = 64&lt;/li>
&lt;li>WeekDays.WeekDays = 62&lt;/li>
&lt;li>WeekDays.WeekEnds = 65&lt;/li>
&lt;li>WeekDays.EveryDay = 127&lt;/li>
&lt;/ul>
&lt;p>Combine values using an OR logical operator to set more than a single day. For example, combine WeekDays.Monday and WeekDays.Friday (FrequencyInterval = 2 + 32 = 34) to schedule an activity for Monday and Friday.&lt;/p>
&lt;/blockquote>
&lt;p>It is easy using this to set up whichever schedule you wish by combining the numbers. I would advise commenting it in the script so that your future self or following DBAs can understand what is happening.&lt;/p>
&lt;p>You can tweak this script or use the code to work with any Agent Jobs and set the schedules accordingly and you can check that you have set the schedules correctly with this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JObserver = $srv.JobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JObs = $JObserver.Jobs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ActiveStartTimeOfDay = @{Name = &amp;#34;ActiveStartTimeOfDay&amp;#34;; Expression = {$_.JobSchedules.ActiveStartTimeOfDay}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $FrequencyInterval = @{Name = &amp;#34;FrequencyInterval&amp;#34;; Expression = {$_.JobSchedules.FrequencyInterval}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $FrequencyTypes = @{Name = &amp;#34;FrequencyTypes&amp;#34;; Expression = {$_.JobSchedules.FrequencyTypes}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IsEnabled = @{Name = &amp;#34;IsEnabled&amp;#34;; Expression = {$_.JobSchedules.IsEnabled}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Jobs|Where-Object{$_.Category -eq &amp;#39;Database Maintenance&amp;#39;}|select name,$IsEnabled,$FrequencyTypes,$FrequencyInterval,$ActiveStartTimeOfDay|Format-Table -AutoSize
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can get the script from Script Center via the link below or by searching for &amp;ldquo;Ola&amp;rdquo; using the &lt;a class="link" href="http://www.microsoft.com/en-us/download/details.aspx?id=42525?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>script browser add-in&lt;/a> straight from ISE&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/05/browser.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/05/browser.jpg?w=300"
loading="lazy"
alt="browser"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Schedule-Ola-Hallengrens-a66a3c89?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://gallery.technet.microsoft.com/scriptcenter/Schedule-Ola-Hallengrens-a66a3c89&lt;/a>&lt;/p></description></item><item><title>Instances and Ports with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/instances-and-ports-with-powershell/</link><pubDate>Wed, 22 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/instances-and-ports-with-powershell/</guid><description>&lt;p>Just a quick post and a day late for &lt;a class="link" href="https://twitter.com/hashtag/sqlnewblogger" target="_blank" rel="noopener"
>#SQLNewBlogger&lt;/a> There are some excellent posts on that hashtag and I recommend that you read them&lt;/p>
&lt;p>When you know a server name but not the name of the instances or the ports that they are using this function will be of use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.SYNOPSIS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Shows the Instances and the Port Numbers on a SQL Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.DESCRIPTION
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">This function will show the Instances and the Port Numbers on a SQL Server using WMI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.PARAMETER Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The Server Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.EXAMPLE
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-SQLInstancesPort Fade2Black
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">This will display the instances and the port numbers on the server Fade2Black
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.NOTES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AUTHOR: Rob Sewell sqldbawithabeard.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DATE: 22/04/2015
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">function Get-SQLInstancesPort {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ([string]$Server)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [system.reflection.assembly]::LoadWithPartialName(&amp;#34;Microsoft.SqlServer.Smo&amp;#34;)|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [system.reflection.assembly]::LoadWithPartialName(&amp;#34;Microsoft.SqlServer.SqlWmiManagement&amp;#34;)|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $mc = new-object Microsoft.SqlServer.Management.Smo.Wmi.ManagedComputer $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances = $mc.ServerInstances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($Instance in $Instances) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $port = @{Name = &amp;#34;Port&amp;#34;; Expression = {$_.ServerProtocols[&amp;#39;Tcp&amp;#39;].IPAddresses[&amp;#39;IPAll&amp;#39;].IPAddressProperties[&amp;#39;TcpPort&amp;#39;].Value}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Parent = @{Name = &amp;#34;Parent&amp;#34;; Expression = {$_.Parent.Name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instance|Select $Parent, Name, $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>PowerShelling SQL Saturday Sessions to the Guidebook app</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershelling-sql-saturday-sessions-to-the-guidebook-app/</link><pubDate>Tue, 07 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershelling-sql-saturday-sessions-to-the-guidebook-app/</guid><description>&lt;p>Following on from my &lt;a class="link" href="http://sqldbawithabeard.com/2015/03/21/parsing-xml-child-nodes-and-converting-to-datetime-with-PowerShell/" title="Parsing XML Child Nodes and Converting to DateTime with PowerShell"
target="_blank" rel="noopener"
>previous pos&lt;/a>t about parsing XML where I used the information from &lt;a class="link" href="https://voiceofthedba.wordpress.com/2015/01/26/downloading-sql-saturday-data/" target="_blank" rel="noopener"
>Steve Jones blog post&lt;/a> to get information from the &lt;a class="link" href="https://www.sqlsaturday.com/" target="_blank" rel="noopener"
>SQL Saturday web site&lt;/a> I thought that this information and script may be useful for others performing the same task.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Edit - This post was written prior to the updates to the SQL Saturday website over the weekend. When it can back up the script worked perfectly but the website is unavailable at the moment again so I will check and update as needed once it is back.&lt;/p>
&lt;p>We are looking at using &lt;a class="link" href="https://guidebook.com/" target="_blank" rel="noopener"
>the Guidebook app&lt;/a> to provide an app for our attendees with all the session details for &lt;a class="link" href="https://www.sqlsaturday.com/372" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>&lt;/p>
&lt;p>The Guidebook admin website requires the data for the sessions in a certain format. You can choose CSV or XLS.&lt;/p>
&lt;p>In the admin portal you can download the template&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/down.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/down.jpg?w=300"
loading="lazy"
alt="down"
>&lt;/a>&lt;/p>
&lt;p>which gives an Excel file like this&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/excel.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/excel.jpg?w=300"
loading="lazy"
alt="-excel"
>&lt;/a>&lt;/p>
&lt;p>&lt;/p>
&lt;p>So now all we need to do is to fill it with data.&lt;/p>
&lt;p>I have an Excel Object Snippet which I use to create new Excel Objects when using PowerShell to manipulate Excel. Here it is for you. Once you have run the code you will be able to press CTRL + J and be able to choose the New Excel Object Snippet any time.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$snippet = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Title = &amp;#34;New Excel Object&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Description = &amp;#34;Creates a New Excel Object&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Text = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a .com object for Excel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl = new-object -comobject excel.application
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl.Visible = \`$true # Set this to False when you run in production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$wb = \`$xl.Workbooks.Add() # Add a workbook
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$ws = \`$wb.Worksheets.Item(1) # Add a worksheet
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells=\`$ws.Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Do Some Stuff
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">perhaps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells.item(\`$row,\`$col)=&amp;#34;Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells.item(\`$row,\`$col).font.size=16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$Cells.item(\`$row,\`$col).Columnwidth = 10
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$wb.Saveas(&amp;#34;C:\temp\Test\`$filename.xlsx&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl.quit()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-IseSnippet @snippet
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I needed to change this to open the existing file by using&lt;/p>
&lt;p>&lt;code>$wb = $xl.Workbooks.Open($GuideBookPath)&lt;/code>&lt;/p>
&lt;p>In the more help tab of the Excel workbook it says&lt;/p>
&lt;blockquote>
&lt;!-- raw HTML omitted -->
&lt;/blockquote>
&lt;p>So we need to do some manipulation of the data we gather. As before I selected the information from the XML as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Endtime = @{Name =&amp;#34;EndTime&amp;#34;; Expression = {[datetime]($_.EndTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Talks = $Sessions.event|Where-Object {$_.title -ne &amp;#39;Coffee Break&amp;#39; -and $_.title -ne &amp;#39;Room Change&amp;#39; -and $_.title -ne &amp;#39;Lunch Break&amp;#39; -and $_.title -ne &amp;#39;Raffle and Cream Tea&amp;#39;}| select $Speaker,$Room,$Starttime,$Endtime,Title,Description |Sort-Object StartTime
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then looped through the $Talks array and wrote each line to Excel like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($Talk in $Talks)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = $Talk.StartTime.ToString(&amp;#39;MM/dd/yyyy&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Start = $talk.StartTime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$End = $Talk.Endtime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Title = $Talk.Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Talk.Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = $Talk.Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Start
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $End
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I know that I converted the String to DateTime and then back to a String again but that was the easiest (quickest) way to obtain the correct format for the Excel file&lt;/p>
&lt;p>Then to finish save the file and quit Excel&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$wb.Save()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.quit()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then you upload the file in the Guidebook admin area &lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/import.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/import.jpg?w=300"
loading="lazy"
alt="import"
>&lt;/a>&lt;/p>
&lt;p>wait for the email confirmation and all your sessions are available in the guidebook&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/sched.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/sched.jpg?w=300"
loading="lazy"
alt="sched"
>&lt;/a>&lt;/p>
&lt;p>I hope that is useful to others. The full script is below&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## From http://www.sqlservercentral.com/blogs/steve_jones/2015/01/26/downloading-sql-saturday-data/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$i = 372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$baseURL = http://www.sqlsaturday.com/eventxml.aspx?sat=
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DestinationFile = E:\SQLSatData\SQLSat + $i + .xml
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$GuideBookPath = &amp;#39;C:\temp\Guidebook_Schedule_Template.xls&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sourceURL = $baseURL + $i
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc = New-Object System.Xml.XmlDocument
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Load($sourceURL)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Save($DestinationFile)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Endtime = @{Name =&amp;#34;EndTime&amp;#34;; Expression = {[datetime]($_.EndTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Talks = $Sessions.event|Where-Object {$_.title -ne &amp;#39;Coffee Break&amp;#39; -and $_.title -ne &amp;#39;Room Change&amp;#39; -and $_.title -ne &amp;#39;Lunch Break&amp;#39; -and $_.title -ne &amp;#39;Raffle and Cream Tea&amp;#39;}| select $Speaker,$Room,$Starttime,$Endtime,Title,Description |Sort-Object StartTime
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a .com object for Excel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl = new-object -comobject excel.application
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.Visible = $true # Set this to False when you run in production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb = $xl.Workbooks.Open($GuideBookPath)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ws = $wb.Worksheets.item(1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells=$ws.Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(2,1) = &amp;#39;&amp;#39; # To clear that entry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(3,1) = &amp;#39;&amp;#39; # To clear that entry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($Talk in $Talks)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = $Talk.StartTime.ToString(&amp;#39;MM/dd/yyyy&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Start = $talk.StartTime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$End = $Talk.Endtime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Title = $Talk.Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Talk.Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = $Talk.Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Start
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $End
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb.Save()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.quit()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Parsing XML Child Nodes and Converting to DateTime with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/parsing-xml-child-nodes-and-converting-to-datetime-with-powershell/</link><pubDate>Sat, 21 Mar 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/parsing-xml-child-nodes-and-converting-to-datetime-with-powershell/</guid><description>&lt;p>As part of my organiser role for SQLSaturday Exeter (&lt;a class="link" href="http://sqlsatexeter.azurewebsites.net" target="_blank" rel="noopener"
>Training Day Information here&lt;/a> and &lt;a class="link" href="https://www.sqlsaturday.com/372/" target="_blank" rel="noopener"
>Saturday Information here&lt;/a>) I needed to get some schedule information to input into a database.&lt;/p>
&lt;p>I had read &lt;a class="link" href="https://voiceofthedba.wordpress.com/2015/01/26/downloading-sql-saturday-data/" target="_blank" rel="noopener"
>Steve Jones blog posts on DownloadingSQL Saturday Data&lt;/a>and followed the steps there to download the data from the SQL Saturday website for our event.&lt;/p>
&lt;p>A typical session is held in the XML like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;event&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;importID&amp;gt;27608&amp;lt;/importID&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;speakers&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;speaker&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;id&amp;gt;27608&amp;lt;/id&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;name&amp;gt;William Durkin&amp;lt;/name&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/speaker&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/speakers&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;track&amp;gt;Track 2&amp;lt;/track&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;location&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;name&amp;gt;Buccaneer&amp;#39;s Refuge &amp;lt;/name&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/location&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;title&amp;gt;Stories from the Trenches: Upgrading SQL with Minimal Downtime&amp;lt;/title&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;description&amp;gt;SQL Server has come a long way in the last few years, with Microsoft investing heavily in High Availability features. This session will show you how to use these features to enable you to safely upgrade a SQL Server, while ensuring you have a return path if things should go wrong. You will leave the session knowing what features you can use to upgrade either the OS, Hardware or SQL Server version while keeping your maintenance window to a minimum. The session will apply to Standard Edition as well as Enterprise Edition, so doesn&amp;#39;t only apply to &amp;#39;High Rollers&amp;#39;!&amp;lt;/description&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;startTime&amp;gt;4/25/2015 3:20:00 PM&amp;lt;/startTime&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;endTime&amp;gt;4/25/2015 4:10:00 PM&amp;lt;/endTime&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;/event&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;/p>
&lt;p>I needed to output the following details -Speaker Name , Room , Start time,Duration and Title&lt;/p>
&lt;p>To accomplish this I examined the node for Williams session&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$i = 372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$baseURL = http://www.sqlsaturday.com/eventxml.aspx?sat=
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DestinationFile = E:\SQLSatData\SQLSat + $i + .xml
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sourceURL = $baseURL + $i
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc = New-Object System.Xml.XmlDocument
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Load($sourceURL)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Save($DestinationFile)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then established that to get the speakers name I had to obtain the value from the child node which I accomplished as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $Speaker #To check that it worked
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is an easy way to obtain sub(or child) properties within a select in PowerShell and I would recommend that you practice and understand that syntax of @{Name=&amp;quot;&amp;quot;; Expression = {} } which will enable you to perform all kinds of manipulation on those objects. You are not just limited to obtaining child properties but can perform calculations as well&lt;/p>
&lt;p>I did the same thing to get the room and the start time&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {$_.StartTime}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $Speaker,$Room,$StartTime #To check that it worked
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then needed duration and thought that I could use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Duration = @{Name =&amp;#34;Duration&amp;#34;; Expression = {($_.EndTime) - ($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $duration
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>However that just gave me a blank result so to troubleshoot I ran&lt;/p>
&lt;p>&lt;code>$Sessions.event[39].endtime - $sessions.event[39].startTime&lt;/code>&lt;/p>
&lt;p>Which errored with the (obvious when I thought about it) message&lt;/p>
&lt;blockquote>
&lt;p>Cannot convert value &amp;ldquo;4/25/2015 4:10:00 PM&amp;rdquo; to type &amp;ldquo;System.Int32&amp;rdquo;. Error: &amp;ldquo;Input string was not in a correct format.&amp;rdquo; At line:1 char:1 + $Sessions.event[39].endtime - $sessions.event[39].startTime + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidArgument: (:) [], RuntimeException + FullyQualifiedErrorId : InvalidCastFromStringToInteger&lt;/p>
&lt;/blockquote>
&lt;p>The value was stored as a string&lt;/p>
&lt;p>Running&lt;/p>
&lt;p>&lt;code>$Sessions.event[39].endtime |Get-Member&lt;/code>&lt;/p>
&lt;p>showed me that there was a method called ToDateTime but there is an easier way.By defining the datatype of an object PowerShell will convert it for you so the resulting code looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Duration = @{Name =&amp;#34;Duration&amp;#34;; Expression = {[datetime]($_.EndTime) - [datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event|select $Speaker,$Room,$Starttime,$Duration,Title |Format-Table -AutoSize -Wrap
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and the resulting entry is finally as I required it. I believe that this will use the regional settings from the installation on the machine that you are using but I have not verified that. If anyone in a different region would like to run this code and check that that is the case I will update the post accordingly&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/zzcapture.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/zzcapture.jpg?w=300"
loading="lazy"
alt="zzCapture"
>&lt;/a>&lt;/p>
&lt;p>Hopefully you have learnt from this how you can extend select from the pipeline and how defining the datatype can be beneficial. Any questions please comment below&lt;/p></description></item><item><title>Triggering a System Center Configuration Manager deployment task</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/triggering-a-system-center-configuration-manager-deployment-task/</link><pubDate>Wed, 18 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/triggering-a-system-center-configuration-manager-deployment-task/</guid><description>&lt;p>A slightly different topic today.&lt;/p>
&lt;p>Once you have built up knowledge, you become the person that people ask to solve things. This is something I really enjoy, taking a problem and solving it for people and in the process teaching them and enabling them to automate more things.&lt;/p>
&lt;p>A colleague was performing a new deployment of a product via SCCM and wanted to trigger the clients to update and receive the new update instead of waiting for it to be scheduled.&lt;/p>
&lt;p>They had found some code that would do this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>They had the idea of using this command and a text file containing the machines and PS Remote.&lt;/p>
&lt;p>I looked at it a different way and gave them a function so that they could provide the Collection Name (In SCCM a collection is a list of machines for a specific purpose) and the function would import the SCCM module, connect to the Site get the names of the machines in the collection and run the command on each one&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Trigger-DeploymentCycle
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CollectionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># PS script to run
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## import SCCM module
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module (Join-Path $(Split-Path $env:SMS_ADMIN_UI_PATH) ConfigurationManager.psd1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#open drive for SCCM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cd &amp;lt;Site Code&amp;gt;:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#### cd &amp;lt;Site Code&amp;gt;:\ replace with Site Code or add param $SiteCOde and use cd ${$SiteCode}:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get Computer names in collection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PCs = (Get-CMDeviceCollectionDirectMembershipRule -CollectionName $CollectionName).rulename
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Count = $PCs.count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;Total number of PCs = $Count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-Command ComputerName $PCs ScriptBlock $scriptblock ThrottleLimit 50
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This would work very well but they wanted some error checking to enable them to identify machines they were unable to connect to following the deployment so the final solution which will run a little slower&lt;/p>
&lt;p>Set up function and parameters and create log files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Trigger-DeploymentCycle
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CollectionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create log file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartTime = Get-Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = Get-Date -Format ddMMyyHHss
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Errorlogpath = &amp;#34;C:\temp\SCCMError&amp;#34; + $Date + &amp;#34;.txt&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Successlogpath = &amp;#34;C:\temp\SCCMSuccess&amp;#34; + $Date + &amp;#34;.txt&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path $Errorlogpath -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path $Successlogpath -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartLog = &amp;#34;Script Started at $StartTime&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartLog | Out-File -FilePath $Successlogpath -Append
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Create the script block, import the SCCM module, connect to the SCCM site and get the machines in the collection. Note that you will have to change &lt;code>&amp;lt;Site Code&amp;gt;&lt;/code> with your own site code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## import SCCM module
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module (Join-Path $(Split-Path $env:SMS_ADMIN_UI_PATH) ConfigurationManager.psd1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#open drive for SCCM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cd &amp;lt;Site Code&amp;gt;:\ #### cd &amp;lt;Site Code&amp;gt;:\ replace with Site Code or add param $SiteCOde and use cd ${$SiteCode}:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get Computer names in collection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PCs = (Get-CMDeviceCollectionDirectMembershipRule -CollectionName $CollectionName).rulename
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Count = $PCs.count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;Total number of PCs = $Count&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I wanted to give them a progress output so I needed to be able to identify the number of machines in the collection by using the count property. I then needed to output the number of the item within the array which I did with&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$a= [array]::IndexOf($PCs, $PC) + 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34; Connecting to PC - $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then pinged the machine,ran the script block and wrote to the log files and finally opened the log files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if (Test-Connection $PC -Quiet -Count 1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run command on PC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-Command -ComputerName $PC -scriptblock $scriptblock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Success = &amp;#34;SUCCESS - finished - $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Success | Out-File -FilePath $Successlogpath -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output $Success
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34;ERROR - $PC is not available -- $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage| Out-File -FilePath $Errorlogpath -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output $ErrorMessage
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad $Errorlogpath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad $Successlogpath
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now they can load the function into their PowerShell sessions and type&lt;/p>
&lt;p>&lt;code>TriggerDeplyment COLLECTIONNAME&lt;/code>&lt;/p>
&lt;p>and they will be able to manually trigger the tasks. This function will trigger the following tasks for a list of PCs in a collection.&lt;/p>
&lt;ul>
&lt;li>Machine Policy Assignment Request &amp;ndash; {00000000-0000-0000-0000-000000000021}&lt;/li>
&lt;li>Machine Policy Evaluation &amp;ndash; {00000000-0000-0000-0000-000000000022}&lt;/li>
&lt;li>Software Inventory &amp;ndash; {00000000-0000-0000-0000-000000000002}&lt;/li>
&lt;li>Application Deployment Evaluation Cycle: {00000000-0000-0000-0000-000000000121}&lt;/li>
&lt;/ul>
&lt;p>Here is the list of other tasks you can trigger:&lt;/p>
&lt;ul>
&lt;li>Discovery Data Collection Cycle: {00000000-0000-0000-0000-000000000003}&lt;/li>
&lt;li>Hardware Inventory Cycle: {00000000-0000-0000-0000-000000000001}&lt;/li>
&lt;li>Machine Policy Retrieval and Evaluation Cycle: {00000000-0000-0000-0000-000000000021}&lt;/li>
&lt;li>Software Metering Usage Report Cycle: {00000000-0000-0000-0000-000000000031}&lt;/li>
&lt;li>Software Updates Deployment Evaluation Cycle: {00000000-0000-0000-0000-000000000108}&lt;/li>
&lt;li>Software Updates Scan Cycle: {00000000-0000-0000-0000-000000000113}&lt;/li>
&lt;li>Windows Installer Source List Update Cycle: {00000000-0000-0000-0000-000000000032}&lt;/li>
&lt;li>Hardware Inventory={00000000-0000-0000-0000-000000000001}&lt;/li>
&lt;li>Software Update Scan={00000000-0000-0000-0000-000000000113}&lt;/li>
&lt;li>Software Update Deployment Re-eval={00000000-0000-0000-0000-000000000114}&lt;/li>
&lt;li>Data Discovery={00000000-0000-0000-0000-000000000003}&lt;/li>
&lt;li>Refresh Default Management Point={00000000-0000-0000-0000-000000000023}&lt;/li>
&lt;li>Refresh Location (AD site or Subnet)={00000000-0000-0000-0000-000000000024}&lt;/li>
&lt;li>Software Metering Usage Reporting={00000000-0000-0000-0000-000000000031}&lt;/li>
&lt;li>Sourcelist Update Cycle={00000000-0000-0000-0000-000000000032}&lt;/li>
&lt;li>Cleanup policy={00000000-0000-0000-0000-000000000040}&lt;/li>
&lt;li>Validate assignments={00000000-0000-0000-0000-000000000042}&lt;/li>
&lt;li>Certificate Maintenance={00000000-0000-0000-0000-000000000051}&lt;/li>
&lt;li>Branch DP Scheduled Maintenance={00000000-0000-0000-0000-000000000061}&lt;/li>
&lt;li>Branch DP Provisioning Status Reporting={00000000-0000-0000-0000-000000000062}&lt;/li>
&lt;li>Refresh proxy management point={00000000-0000-0000-0000-000000000037}&lt;/li>
&lt;li>Software Update Deployment={00000000-0000-0000-0000-000000000108}&lt;/li>
&lt;li>State Message Upload={00000000-0000-0000-0000-000000000111}&lt;/li>
&lt;li>State Message Cache Cleanup={00000000-0000-0000-0000-000000000112}&lt;/li>
&lt;/ul>
&lt;p>You can find the function here&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Trigger-DeploymentCycle-c27f7b9d?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Trigger-Deployment&lt;/a>&lt;/p>
&lt;p>and all of &lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/site/search?f%5B0%5D.Type=User&amp;amp;f%5B0%5D.Value=Rob%20Sewell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>my Script Center Submissions&lt;/a> are here&lt;/p>
&lt;p>As always  The internet lies, fibs and deceives and everything you read including this post should be taken with a pinch of salt and examined carefully. All code should be understood and tested prior to running in a live environment.&lt;/p></description></item><item><title>Show AutoGrowth Events with PowerShell to CSV</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-autogrowth-events-with-powershell-to-csv/</link><pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-autogrowth-events-with-powershell-to-csv/</guid><description>&lt;p>This week I was reading Pinal Daves post about Autogrowth Events&lt;/p>
&lt;p>&lt;a class="link" href="http://blog.sqlauthority.com/2015/02/03/sql-server-script-whenwho-did-auto-grow-for-the-database/" target="_blank" rel="noopener"
>http://blog.sqlauthority.com/2015/02/03/sql-server-script-whenwho-did-auto-grow-for-the-database/&lt;/a>&lt;/p>
&lt;p>as it happened I had a requirement to make use of the script only a few days later. I was asked to provide the information in a CSV so that the person who required the information could manipulate it in Excel.&lt;/p>
&lt;p>I am a great believer in Automation. If you are going to do something more than once then automate it so I wrote two functions, added them to TFS and now they will be available to all of my team members next time they load PowerShell.&lt;/p>
&lt;p>Why two functions? Well Pinal Daves script gets the information from the default trace for a single database but there may be times when you need to know the autogrowth events that happened on a server with multiple databases.&lt;/p>
&lt;p>I use a very simplemethod for doing this as I have not found the correct way to parse the default trace with PowerShell.The functions rely on &lt;a class="link" href="https://github.com/RamblingCookieMonster/PowerShell/blob/master/Invoke-Sqlcmd2.ps1" target="_blank" rel="noopener"
>Invoke-SQLCMD2&lt;/a>which I also have in my functions folder and pass the query from Pinal Daves Blog post as a here string&lt;/p>
&lt;p>&lt;code>$Results = Invoke-Sqlcmd2 -ServerInstance $Server -Database master -Query $Query&lt;/code>&lt;/p>
&lt;p>To output to CSV I use the &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849932.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Export-CSV cmdlet&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if($CSV)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Results| Export-Csv -Path $CSV
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And to open the CSV I add a &lt;code>[switch]&lt;/code> parameter. You can find out more about parameters &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh847743.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>or by&lt;/p>
&lt;p>&lt;code>Get-Help about_Functions_Advanced_Parameters&lt;/code>&lt;/p>
&lt;p>so the parameter block of my function looks like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$Server,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$Database,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$false)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CSV,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$false)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[switch]$ShowCSV
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now when I am asked again to provide this information it is as easy as typing&lt;/p>
&lt;p>&lt;code>Show-AutogrowthServer -Server SQL2014Ser12R2&lt;/code>&lt;/p>
&lt;p>or&lt;/p>
&lt;p>&lt;code>Show-AutogrowthDatabase -Server SQL2014Ser12R2 -Database Autogrowth&lt;/code>&lt;/p>
&lt;p>and the results will be displayed as below&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/02/autogrowth.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/02/autogrowth.jpg?w=660"
loading="lazy"
alt="autogrowth"
>&lt;/a>&lt;/p>
&lt;p>just a side note. Pinal Daves script uses @@servername in the where clause and if you have renamed your host the script will be blank. The resolution to this is to runt he following T-SQL&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">sp_dropserver &amp;#39;OLDSERVERNAME&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sp_addserver NEWSERVERNAME, local;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can find the scripts here&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Show-Autogrowth-Events-for-8798a8b0?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Show-AutoGrowthServer&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Show-Autogrowth-Events-and-f4833cc8?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Show-AutoGrowthDatabase&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/site/search?f%5B0%5D.Type=User&amp;amp;f%5B0%5D.Value=Rob%20Sewell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>and all of my Script Center Submissions are here&lt;/a>&lt;/p>
&lt;p>As always - The internet lies, fibs and deceives and everything you read including this post should be taken with a pinch of salt and examined carefully. All code should be understood and tested prior to running in a live environment.&lt;/p></description></item><item><title>Uploading a Source Folder to Azure File Storage</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</link><pubDate>Sun, 01 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</guid><description>&lt;p>Azure File Storage enables you to present an Azure Storage Account to your IaaS VMs as a share using SMB. You can fid out further details here&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/%c2%a0" title="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/ "
target="_blank" rel="noopener"
>http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/&lt;/a>&lt;/p>
&lt;p>Once you have created your Azure File Storage Account and connected your Azure Virtual Machines to it, you may need to upload data from your premises into the storage to enable it to be accessed by the Virtual Machines&lt;/p>
&lt;p>To accomplish this I wrote a function and called it Upload-ToAzureFileStorage&lt;/p>
&lt;p>I started by creating a source folder and files to test&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\b -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\c -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\d -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we needed to connect to the subscription, get the storage account access key and create a context to store them&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#Select Azure Subscription
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Select-AzureSubscription -SubscriptionName $AzureSubscriptionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get the Storage Account Key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StorageAccountKey = (Get-AzureStorageKey -StorageAccountName $StorageAccountName).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># create a context for account and key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ctx=New-AzureStorageContext $StorageAccountName $StorageAccountKey
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806403.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Get-AzureStorageShare cmdlet&lt;/a>shows the shares available for the context so we can check if the share exists&lt;/p>
&lt;p>&lt;code>$S = Get-AzureStorageShare -Context $ctx -ErrorAction SilentlyContinue|Where-Object {$\_.Name -eq $AzureShare}&lt;/code>&lt;/p>
&lt;p>and if it doesnt exist create it using&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806378.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageShare&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$s = New-AzureStorageShare $AzureShare -Context $ctx
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>For the sake only of doing it a different way wecan check for existence of the directory in Azure File Storage that we are going to upload the files to like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = Get-AzureStorageFile -Share $s -ErrorAction SilentlyContinue|select Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($d.Name -notcontains $AzureDirectory)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and if it doesnt exist create it using&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = New-AzureStorageDirectory -Share $s -Path $AzureDirectory
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now that we have the directory created in the storage account we need to create any subfolders. First get the folders&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\# get all the folders in the source directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Folders = Get-ChildItem -Path $Source -Directory -Recurse
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can then iterate through them using a foreach loop. If we do this and select the FullName property the results will be&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">C:\\temp\\TestUpload\\New1 C:\\temp\\TestUpload\\New2 C:\\temp\\TestUpload\\New3 C:\\temp\\TestUpload\\New4 C:\\temp\\TestUpload\\New5 C:\\temp\\TestUpload\\New1\\list C:\\temp\\TestUpload\\New1\\list\\a C:\\temp\\TestUpload\\New1\\list\\b C:\\temp\\TestUpload\\New1\\list\\c C:\\temp\\TestUpload\\New1\\list\\d C:\\temp\\TestUpload\\New1\\list\\a\\1 C:\\temp\\TestUpload\\New1\\list\\a\\2 C:\\temp\\TestUpload\\New1\\list\\a\\3 C:\\temp\\TestUpload\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>but to create new folders we need to remove the &lt;code>&amp;quot;C:\\temp\\TestUpload&amp;quot;&lt;/code> and replace it with the Directory name in Azure. I chose to do this as follows using the substring method and the length of the source folder path.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach($Folder in $Folders)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($Folder.FullName).Substring(($source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and tested that the results came out as I wanted&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">AppName\\New1 AppName\\New2 AppName\\New3 AppName\\New4 AppName\\New5 AppName\\New1\\list AppName\\New1\\list\\a AppName\\New1\\list\\b AppName\\New1\\list\\c AppName\\New1\\list\\d AppName\\New1\\list\\a\\1 AppName\\New1\\list\\a\\2 AppName\\New1\\list\\a\\3 AppName\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I could then create the new folders in azure using&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a> again&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-AzureStorageDirectory -Share $s -Path $Path -ErrorAction SilentlyContinue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I followed the same process with the files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$files = Get-ChildItem -Path $Source -Recurse -File&amp;lt;/pre&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;pre&amp;gt;foreach($File in $Files)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($file.FullName).Substring(($Source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then created the files using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806404.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Set-AzureStorageFileContent&lt;/a> this has a -Force and a -Confirm switch and I added those into my function by using a [switch] Parameter&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#upload the files to the storage
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Confirm)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Confirm
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Force
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can download the function from the Script Center&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe&lt;/a>&lt;/p>
&lt;p>As also, any comments or queries are welcome and obviously the internet lies so please understand and test all code you find before using it in production&lt;/p></description></item><item><title>Refreshing A SQL Mirrored Database Using Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</link><pubDate>Mon, 25 Aug 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</guid><description>&lt;p>SQL mirroring is a means of providing high availability for your SQL database. It is available in Standard Edition and although the feature is deprecated it is still widely utilised. &lt;a class="link" href="http://msdn.microsoft.com/en-gb/library/ms189852.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>You can read more about it on MSDN here&lt;/a> and &lt;a class="link" href="http://www.brentozar.com/archive/2013/07/database-mirroring-faq/" target="_blank" rel="noopener"
>Jes Borland wrote a useful post answering many questions here&lt;/a>&lt;/p>
&lt;p>There are situations where you may need to refresh these databases. Disaster Recovery is an obvious one but also during development to provide testing or development environments to test your High Availability implementations, run through disaster scenarios, create run books or ensure that the code changes still work with mirroring. There are other scenarios but this post covers the automation of restoring a mirrored database from a backup.&lt;/p>
&lt;p>I have mentioned before and no doubt I shall again, &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>John Sansom wrote a great post about automation&lt;/a> and I am a strong follower of that principle.&lt;/p>
&lt;p>To refresh a SQL mirror the following steps are required, there are some gotchas that you need to be aware of which I will discuss later&lt;/p>
&lt;ul>
&lt;li>remove mirroring&lt;/li>
&lt;li>restore principle database from backup&lt;/li>
&lt;li>perform a transaction log backup of the principle database&lt;/li>
&lt;li>restore both backups on the mirror server with no recovery&lt;/li>
&lt;li>recreate mirroring&lt;/li>
&lt;li>resolve orphaned users&lt;/li>
&lt;li>check mirroring status&lt;/li>
&lt;/ul>
&lt;p>Regular blog followers will know that I prefer to use Powershell when I can (and where it is relevant to do so) and so I have used Powershell to automate all of the steps above&lt;/p>
&lt;p>The script requires some variables to be set up at the beginning. You can easily change this and make the script into a function and call it if you desire, but for this post I shall consider the script as a standalone. The reasoning for this is that I imagine that it will be placed into a run book or stored for use in a repository for specific use and therefore reduces any pre-requisites for using it.&lt;/p>
&lt;p>Set variables as follows, the last three variables set the types for the backup action type and device type and do not need to be altered.&lt;/p>
&lt;pre>&lt;code>\# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
&lt;/code>&lt;/pre>
&lt;p>After some error checking the first thing is to create server and database SMO objects&lt;/p>
&lt;pre>&lt;code>\# Create Server objects $Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer $Mirror = New-Object Microsoft.SQLServer.Management.Smo. server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
&lt;/code>&lt;/pre>
&lt;p>(Added Extra  Use New-ISESnippet to create a SMO Server Snippet and use CTRL + J to find it&lt;/p>
&lt;pre>&lt;code>New-IseSnippet -Title SMO-Server -Description &amp;quot;Create A SQL Server SMO Object&amp;quot; -Text &amp;quot;`$srv = New-Object Microsoft.SqlServer.Management.Smo.Server `$server&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="remove-mirroring">Remove Mirroring&lt;/h4>
&lt;p>Before we can restore the database we need to remove mirroring&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
&lt;/code>&lt;/pre>
&lt;h4 id="restore-principle-database-from-backup">restore principle database from backup&lt;/h4>
&lt;p>Once mirroring has been removed we can restore the database. &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>Stuart Moores Great Series&lt;/a> provides all the code you need to backup and restore databases with Powershell. There is however a bug which can catch you out. Heres the code&lt;/p>
&lt;pre>&lt;code>$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;p>The bug is as follows, if your restore is going to take longer than 10 minutes and you are using an earlier version of SQL than SQL 2012 SP1 CU8 then you will find that the restore fails after 10 minutes. This is the default timeout. You may try to set the&lt;/p>
&lt;pre>&lt;code>$srv.ConnectionContext.StatementTimeout
&lt;/code>&lt;/pre>
&lt;p>Value to a larger value or 0 and this will work after SQL 2012 SP1 CU8 but prior to that you will still face the same error. The simple workaround is to use &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/7985b7ef-ed89-4dfd-b02a-433cc4e30894" target="_blank" rel="noopener"
>Invoke-SQLCmd2&lt;/a> and to script the restore as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="perform-a-transaction-backup-of-the-principle-database">perform a transaction backup of the principle database&lt;/h4>
&lt;p>We need to have a full and transaction log backup to set up mirroring. Again you may need to use the script method if your backup will take longer than 600 seconds.&lt;/p>
&lt;pre>&lt;code>#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = Log Backup of  + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 ServerInstance $PrincipalServer Database master Query $query ConnectionTimeout 0 # comment out if not used
&lt;/code>&lt;/pre>
&lt;h4 id="restore-both-backups-on-the-mirror-server-with-no-recovery">Restore both backups on the mirror server with no recovery&lt;/h4>
&lt;p>To complete the mirroring set up we need to restore the backups onto the mirror server with no recovery as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="recreate-mirroring">Recreate mirroring&lt;/h4>
&lt;p>You recreate mirroring in the same way as you would if you were using T-SQL simply add the principal endpoint to the mirror, and the mirror and witness endpoints to the principal&lt;/p>
&lt;pre>&lt;code>#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
&lt;/code>&lt;/pre>
&lt;h4 id="resolve-orphaned-users">Resolve orphaned users&lt;/h4>
&lt;p>You will need to resolve any users and permissions on your destination servers. I do not know a way to do this with PowerShell and would be interested if anyone has found a way to replace the password or the SID on a user object, please contact me if you know.&lt;/p>
&lt;p>Many people do this with the &lt;a class="link" href="http://support.microsoft.com/kb/918992" target="_blank" rel="noopener"
>sp_rev_logins stored procedure&lt;/a> which will create the T-SQL for recreating the logins. However, Powershell cannot read the outputs of the message window where the script prints the script. If you know that your logins are staying static then run sp_rev_logins and store the output in a sql file and call it with Invoke-SQLCmd2&lt;/p>
&lt;pre>&lt;code>$SQL =  #Path to File
Invoke-Sqlcmd2 ServerInstance $Server Database master InputFile $SQL
&lt;/code>&lt;/pre>
&lt;p>The other option is to &lt;a class="link" href="http://dbadiaries.com/how-to-transfer-logins-to-another-sql-server-or-instance" target="_blank" rel="noopener"
>set up a SSIS package following this blog post&lt;/a> and call it from Powershell as follows&lt;/p>
&lt;p>**2020 Edit ** - You should use &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> to do this&lt;/p>
&lt;pre>&lt;code>Invoke-Command ComputerName $Server scriptblock {DTExec.exe /File PATHTOPackage.dtsx}
&lt;/code>&lt;/pre>
&lt;p>This requires &lt;a class="link" href="http://technet.microsoft.com/en-us/magazine/ff700227.aspx" target="_blank" rel="noopener"
>Powershell Remoting&lt;/a> to have been set up on the server which may or may not be available to you in your environment.&lt;/p>
&lt;p>IMPORTANT NOTE  The script does not include any methods for resolving orphaned users so you will need to test and then add your own solution to the script.&lt;/p>
&lt;h4 id="check-mirroring-status">check mirroring status&lt;/h4>
&lt;p>Lastly you want to check that the script has run successfully and that mirroring is synchronised (I am from the UK!!) To do this I check that time and file used for the last database backup &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/1860/identify-when-a-sql-server-database-was-restored-the-source-and-backup-date/" target="_blank" rel="noopener"
>using this script&lt;/a>&lt;/p>
&lt;pre>&lt;code>#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 1 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize Wrap
&lt;/code>&lt;/pre>
&lt;p>and that mirroring has synchronised using the following Powershell command&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>Depending on your needs you may add some error checking using the results of the above scripts. As I said at the top of the post, you can turn this script into a function and call it at will or add it to an Agent Job for regular scheduling or just kept in a folder ready to be run when required. The choice is yours but all usual rules apply. Dont believe anything you read on this blog post, dont run any scripts on production, test before running any scripts, understand what the code is doing before you run it or I am not responsible if you break anything&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: Refresh Mirrored Database
Author: Rob Sewell https://blog.robsewell.com
Requires: Invoke-SQLCMD2 (included)
Version History:
1.2 22/08/2014
.SYNOPSIS
Refreshes a mirrored database
.DESCRIPTION
This script will refresh a mirrored database, recreate mirroring and chekc status of mirroring.
Further details on the website
Requires the variables at the top of the script to be filled in
IMPORTANT - Orpahaned users are not resolved with this acript without additions. See blog post for options
#&amp;gt;
# Load Invoke-SQLCMD2
#Load the assemblies the script requires
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Management.Common&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoEnum&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Smo&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoExtended &amp;quot; );
[void][System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;Microsoft.SqlServer.ConnectionInfo&amp;quot;)
[System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;System.Windows.Forms&amp;quot;)|Out-Null
# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationFUll = $FileShare + $DBName + 'formirroring.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
######################
&amp;lt;#
.SYNOPSIS
Runs a T-SQL script.
.DESCRIPTION
Runs a T-SQL script. Invoke-Sqlcmd2 only returns message output, such as the output of PRINT statements when -verbose parameter is specified
.INPUTS
None
You cannot pipe objects to Invoke-Sqlcmd2
.OUTPUTS
System.Data.DataTable
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;SELECT login_time AS 'StartTime' FROM sysprocesses WHERE spid = 1&amp;quot;
This example connects to a named instance of the Database Engine on a computer and runs a basic T-SQL query.
StartTime
-----------
2010-08-12 21:21:03.593
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -InputFile &amp;quot;C:\MyFolder\tsqlscript.sql&amp;quot; | Out-File -filePath &amp;quot;C:\MyFolder\tsqlscript.rpt&amp;quot;
This example reads a file containing T-SQL statements, runs the file, and writes the output to another file.
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;PRINT 'hello world'&amp;quot; -Verbose
This example uses the PowerShell -Verbose parameter to return the message output of the PRINT command.
VERBOSE: hello world
.NOTES
Version History
v1.0 - Chad Miller - Initial release
v1.1 - Chad Miller - Fixed Issue with connection closing
v1.2 - Chad Miller - Added inputfile, SQL auth support, connectiontimeout and output message handling. Updated help documentation
v1.3 - Chad Miller - Added As parameter to control DataSet, DataTable or array of DataRow Output type
#&amp;gt;
function Invoke-Sqlcmd2 {
[CmdletBinding()]
param(
[Parameter(Position = 0, Mandatory = $true)] [string]$ServerInstance,
[Parameter(Position = 1, Mandatory = $false)] [string]$Database,
[Parameter(Position = 2, Mandatory = $false)] [string]$Query,
[Parameter(Position = 3, Mandatory = $false)] [string]$Username,
[Parameter(Position = 4, Mandatory = $false)] [string]$Password,
[Parameter(Position = 5, Mandatory = $false)] [Int32]$QueryTimeout = 600,
[Parameter(Position = 6, Mandatory = $false)] [Int32]$ConnectionTimeout = 15,
[Parameter(Position = 7, Mandatory = $false)] [ValidateScript( {test-path $_})] [string]$InputFile,
[Parameter(Position = 8, Mandatory = $false)] [ValidateSet(&amp;quot;DataSet&amp;quot;, &amp;quot;DataTable&amp;quot;, &amp;quot;DataRow&amp;quot;)] [string]$As = &amp;quot;DataRow&amp;quot;
)
if ($InputFile) {
$filePath = $(resolve-path $InputFile).path
$Query = [System.IO.File]::ReadAllText(&amp;quot;$filePath&amp;quot;)
}
$conn = new-object System.Data.SqlClient.SQLConnection
if ($Username)
{ $ConnectionString = &amp;quot;Server={0};Database={1};User ID={2};Password={3};Trusted_Connection=False;Connect Timeout={4}&amp;quot; -f $ServerInstance, $Database, $Username, $Password, $ConnectionTimeout }
else
{ $ConnectionString = &amp;quot;Server={0};Database={1};Integrated Security=True;Connect Timeout={2}&amp;quot; -f $ServerInstance, $Database, $ConnectionTimeout }
&amp;amp;amp;n bsp; $conn.ConnectionString = $ConnectionString
#Following EventHandler is used for PRINT and RAISERROR T-SQL statements. Executed when -Verbose parameter specified by caller
if ($PSBoundParameters.Verbose) {
$conn.FireInfoMessageEventOnUserErrors = $true
$handler = [System.Data.SqlClient.SqlInfoMessageEventHandler] {Write-Verbose &amp;quot;$($_)&amp;quot;}
$conn.add_InfoMessage($handler)
}
$conn.Open()
$cmd = new-object system.Data.SqlClient.SqlCommand($Query, $conn)
$cmd.CommandTimeout = $QueryTimeout
$ds = New-Object system.Data.DataSet
$da = New-Object system.Data.SqlClient.SqlDataAdapter($cmd)
[void]$da.fill($ds)
$conn.Close()
switch ($As) {
'DataSet' { Write-Output ($ds) }
'DataTable' { Write-Output ($ds.Tables) }
'DataRow' { Write-Output ($ds.Tables[0]) }
}
} #Invoke-Sqlcmd2
# Check for existence of Backup file with correct name
If (!(Test-Path $LocationReplace)) {
Write-Output &amp;quot; There is no file called &amp;quot;
Write-Output $LocationReplace
Write-Output &amp;quot;Please correct and re-run&amp;quot;
break
}
# Remove Old Backups
if (Test-Path $locationFull) {
Remove-Item $LocationFUll -Force
}
if (Test-Path $locationTran) {
Remove-Item $LocationTran -Force
}
# Create Server objects
$Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer
$Mirror = New-Object Microsoft.SQLServer.Management.Smo.server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
# If database is on Mirror server fail it over to Principal
if ($DatabasePrincipal.IsAccessible -eq $False) {
$DatabaseMirror.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Failover)
}
# remove mirroring
$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Full Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup
$Backup.Action = $Full
$Backup.BackupSetDescription = &amp;quot;Full Backup of &amp;quot; + $DBName
$Backup.Database = $DatabasePrincipal.Name
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFull, $File)
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = &amp;quot;Log Backup of &amp;quot; + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFUll, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
# Resolve Orphaned Users if needed
#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 20 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize -Wrap
$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre></description></item><item><title>Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</link><pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</guid><description>&lt;p>There is a newer &lt;a class="link" href="https://blog.robsewell.com/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/" target="_blank" rel="noopener"
>up to date version of this post here&lt;/a> using the &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> and the sqlserver module&lt;/p>
&lt;p>But if you want to continue with this way read on!!&lt;/p>
&lt;p>Having created &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Windows Users&lt;/a> or &lt;a class="link" href="https://blog.robsewell.com/creating-sql-user-and-adding-to-server-role-with-powershell/" target="_blank" rel="noopener"
>SQL Users&lt;/a> using the last two days posts, today we shall add them to a role on a database.&lt;/p>
&lt;p>As I discussed &lt;a class="link" href="https://blog.robsewell.com/checking-sql-server-user-role-membership-with-powershell/" target="_blank" rel="noopener"
>previously&lt;/a> I believe that to follow good practice I try to ensure that database permissions are granted by role membership and each role is created with the minimum amount of permissions required for successful execution of the task involved.&lt;/p>
&lt;p>So with each database having the correct roles created and the users created we just need to add the user to the database and to the role. This is easily done with PowerShell.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image70.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image70.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The &lt;code>Add-UserToRole&lt;/code> function takes four parameters Server,Database,User and Role and does a series of error checks.&lt;/p>
&lt;p>With these functions you can easily create a number of Users and add them to database roles quickly and easily and repeatedly.&lt;/p>
&lt;p>If the test team come to you and require 10 Test Users and 3 Test Administrators adding to the test database. I create 2 notepad files&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image71.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image71.png"
loading="lazy"
alt="image"
>&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image72.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image72.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and use them with the &lt;code>Add-SQLAccountToSQLRole&lt;/code> and &lt;code>Add-UserToRole&lt;/code> functions to create the users&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image73.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image73.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Here are the results in PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image74.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image74.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and in SSMS&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image75.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image75.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The Code is here&lt;/p>
&lt;pre>&lt;code>############################################################# ################################
#
# NAME: Add-UserToRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to add user or group to a role on a database
#
# USAGE: Add-UserToRole fade2black Aerosmith Test db_owner
#
Function Add-UserToRole ([string] $server, [String] $Database , [string]$User, [string]$Role)
{
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
#Check Database Name entered correctly
$db = $svr.Databases[$Database]
if($db -eq $null)
{
Write-Output &amp;quot; $Database is not a valid database on $Server&amp;quot;
Write-Output &amp;quot; Databases on $Server are :&amp;quot;
$svr.Databases|select name
break
}
#Check Role exists on Database
$Rol = $db.Roles[$Role]
if($Rol -eq $null)
{
Write-Output &amp;quot; $Role is not a valid Role on $Database on $Server &amp;quot;
Write-Output &amp;quot; Roles on $Database are:&amp;quot;
$db.roles|select name
break
}
if(!($svr.Logins.Contains($User)))
{
Write-Output &amp;quot;$User not a login on $server create it first&amp;quot;
break
}
if (!($db.Users.Contains($User)))
{
# Add user to database
$usr = New-Object ('Microsoft.SqlServer.Management. Smo.User') ($db, $User)
$usr.Login = $User
$usr.Create()
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User was not a login on $Database on $server&amp;quot;
Write-Output &amp;quot;$User added to $Database on $Server and $Role Role&amp;quot;
}
else
{
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User added to $Role Role in $Database on $Server &amp;quot;
}
}
&lt;/code>&lt;/pre></description></item></channel></rss>