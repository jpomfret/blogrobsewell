<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>azure on Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/tags/azure/</link><description>Recent content in azure on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 28 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/tags/azure/index.xml" rel="self" type="application/rss+xml"/><item><title>How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</guid><description>&lt;img src="https://images.unsplash.com/photo-1614791962365-7590111b1b1c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80" alt="Featured image of post How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error" />&lt;p>There are a number of methods to import PowerShell modules into Azure automation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>as described in the documentation here&lt;/a>&lt;/p>
&lt;p>You may however miss an important piece of information hidden in that documentation if you are uploading a module from a GitHub release instead of via the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. The name that you refer to the module must match the module name and module folder name in the zip file.&lt;/p>
&lt;h1 id="method-one---from-gallery">Method one - from Gallery&lt;/h1>
&lt;p>This is my preferred method for importing modules into Azure Automation accounts, the only bothersome part is remembering to do it twice, once for 5.1 and once for 7.1 as I am sure that if I forget that will be the one module that I will need!&lt;/p>
&lt;h2 id="find-the-module">Find the module&lt;/h2>
&lt;p>Go to the Module page for the automation account and then Add module and browse the gallery and search for &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> (other modules are available!) and install it&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550108-e6096986-3392-4585-a57a-5c515c2890bf.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>It will take a few moments to install but you will see it in the list with a green tick once it has imported.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181548887-0ec695e4-41b9-45b3-8ab3-a004968c2323.png"
loading="lazy"
alt="image"
>#&lt;/p>
&lt;p>Then it is available in all of my PowerShell 7.1 runbooks in my automation account - Here I have just run &lt;code>Get-DbaToolsConfig&lt;/code> in a test runbook to prove that the module has imported&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550937-7e89c7b3-31e8-4af1-b965-c82f2f63562f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="method-two---using-the-zip-file-from-a-github-release">Method two - using the zip file from a GitHub Release&lt;/h1>
&lt;p>Sometimes you may wish to not use the PowerShell Gallery to import the modules, maybe you have a custom module that you are not ready to upload to the gallery or maybe the module is just internally developed and not available on the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. In this scenario, you can still import hte module so that it can be used by your runbooks.&lt;/p>
&lt;p>To demonstrate, I will remove the dbatools module from the Automation Account&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181553061-9be2da4d-344d-4027-aa7f-902445cee12b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and download the latest release from GitHub directly&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/dataplat/dbatools/releases/tag/v1.1.118" target="_blank" rel="noopener"
>https://github.com/dataplat/dbatools/releases/tag/v1.1.118&lt;/a>&lt;/p>
&lt;p>If you are unable to use the PowerShell Gallery to get the latest dbatools release, I would always use the official signed release.&lt;/p>
&lt;p>You can then upload the zip from the same Modules page using the Browse for file but here is the &lt;em>important bit&lt;/em> You must update the name of the module. By default Azure will set the name to match the name of the zip file as that is what is expected and indeed mentioned in the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules#author-modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft documentation here &lt;/a>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181561112-6aecd5e3-efaa-4b2a-84d7-f7e521035d04.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and once it is imported successfully and I have a green tick&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181564377-df8c707e-24ec-43eb-8d57-702fcb39400b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>I can run the test - Again I just ran &lt;code>Get-DbaToolsConfig&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181569077-2b2e59e2-4bf1-46b6-851f-2e624cf9c43c.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>This method will work with both PowerShell 5.1 and PowerShell 7.1, you will just have to upload the zip (and remember to rename the module entry) twice.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571123-8acb8ff5-7b36-4b62-91f7-34b3df36a1d8.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571518-909ecc6f-9270-45d2-a7b5-0de4406c88c4.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="when-it-goes-wrong">When it goes wrong&lt;/h1>
&lt;p>If you do not rename the module correctly but leave it as the name of file &lt;code>dbatools-signed&lt;/code> in this example&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571939-b881b4bc-4449-4569-b71a-66142436158a.png"
loading="lazy"
alt="image"
>
.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181572041-2fe18929-cc14-40ae-b654-62653206903f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;blockquote>
&lt;p>Error importing the module dbatools-signed. Import failed with the following error:&lt;br>
Orchestrator.Shared.AsyncModuleImport.ModuleImportException: Cannot import the module of name dbatools-signed, as the module structure was invalid. at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.ExecuteInternal(CodeActivityContext context, Byte[] moduleContent, String moduleName, ModuleLanguage moduleLanguage) at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.Execute(CodeActivityContext context) at&lt;br>
System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)&lt;/p>
&lt;/blockquote>
&lt;p>If you get that, just re-upload the zip file and use the correct name in the form.&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Deploying a Bicep Module from a private repository without a connection to the repository</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-bicep-module-from-a-private-repository-without-a-connection-to-the-repository/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-bicep-module-from-a-private-repository-without-a-connection-to-the-repository/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Deploying a Bicep Module from a private repository without a connection to the repository" />&lt;h1 id="using-a-private-module-repository">Using a private module repository&lt;/h1>
&lt;p>From Bicep version 0.4.1008 you can save and version your Bicep modules in repositories. &lt;a class="link" href="https://msftplayground.com/2021/11/using-private-repositories-for-bicep-modules/" target="_blank" rel="noopener"
>You can read more about how to do it here&lt;/a>. This is really useful for reusing modules and modularising large corporate infrastructure environments.&lt;/p>
&lt;p>You can control how a single resource (think of a storage account) is deployed across your environment and ensure that all requirements are followed (the storage account must have public access disabled, must have private endpoints and must have the one production network allowed). This is really useful and since it has been available we have used this to deploy infrastructure.&lt;/p>
&lt;h1 id="so-whats-the-problem-">So whats the problem ?&lt;/h1>
&lt;p>When you need to use a module from the repository, you refer to the repository when you define the module path.&lt;/p>
&lt;p>&lt;code>module storage 'br:bearddemoacr.azurecr.io/bicep/storage/storagev2:0.0.2' = {&lt;/code>&lt;/p>
&lt;p>This says I want to deploy something we will call &lt;code>storage&lt;/code> and you can find the definition called &lt;code>bicep/storage/storagev2&lt;/code> in a Bicep Repository (&lt;code>br&lt;/code>) at &lt;code>bearddemoacr.azurecr.io&lt;/code> and we will use the tag &lt;code>0.0.2&lt;/code>. The rest of the properties will then be written.&lt;/p>
&lt;p>On the client that you use to do the deployment, Bicep will &lt;code>restore&lt;/code> the required information from the Bicep Repository and use that to perform the deployments. By default, it uses the path &lt;code>~/.bicep&lt;/code> on Linux/Mac and &lt;code>$HOME\.bicep&lt;/code> on Windows.&lt;/p>
&lt;p>If you take a look in that directory, you will see the files that have been restored for use.&lt;/p>
&lt;p>![cachecontents]({{ &amp;ldquo;/assets/uploads/2021/Bicep/cachecontents.png&amp;rdquo; | relative_url }})&lt;/p>
&lt;p>But this relies on the client that is performing the deployment having connectivity and being able to authenticate to the Azure Container Registry (ACR) that is holding the Bicep Modules.&lt;/p>
&lt;h1 id="why-would-the-client-not-have-access">Why would the client not have access?&lt;/h1>
&lt;p>There are a number of situations where the deployment client (a workstation, a devops pipeline agent) may not have access to the ACR. The development and testing of the Bicep Modules may take place in a development Azure subscription which has no connectivity to the production Azure subscription. The production environment may be in Azure Government Cloud or it may be in a customers Azure subscription and opening a connection to an ACR in another subscription in another network may be prohibitively complicated and time consuming due to the process required to gain approvals and perform the actions to open the required paths or (more likely) is simply not allowed.&lt;/p>
&lt;h1 id="bicep_cache_directory-environment-variable-to-the-rescue">BICEP_CACHE_DIRECTORY environment variable to the rescue&lt;/h1>
&lt;p>There is an environment variable called BICEP_CACHE_DIRECTORY that defines the path that is used to hold the restored bicep artifacts. This means that we can do two things to enable us to continue to use a Bicep Repository with all of the benefits but still be able to deploy the infrastructure.&lt;/p>
&lt;h1 id="cache-the-files">Cache the files&lt;/h1>
&lt;p>Firstly, as part of the build process we can set the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> path and perform a &lt;code>bicep restore&lt;/code> on the Bicep Resource file. This will restore all of the referenced modules to the path. We can then package this directory with our deployment bicep file and transfer them to the deployment environment.&lt;/p>
&lt;h1 id="deploy-the-bicep">Deploy the Bicep&lt;/h1>
&lt;p>Then when we extract the package we can set the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> to the directory holding the cached files and deploy our bicep as we would normally. Even though the files reference the Bicep Repository by name, the deployment will use the cache. I even tested it by deleting the images from the Bicep Repository completely (after I had run &lt;code>bicep restore&lt;/code> of course) and I was able to deploy from the cache without issue.&lt;/p>
&lt;p>Hopefully, this wil help someone somewhere as the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> variable is not wildly known or documented.&lt;/p>
&lt;p>Happy automating&lt;/p></description></item><item><title>When you REALLY want to see your Azure DevOps Secret Variable Values</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/when-you-really-want-to-see-your-azure-devops-secret-variable-values/</link><pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/when-you-really-want-to-see-your-azure-devops-secret-variable-values/</guid><description>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/michael-dziedzic-1bjsASjhfkE-unsplash.jpg" alt="Featured image of post When you REALLY want to see your Azure DevOps Secret Variable Values" />&lt;h1 id="i-really-needed-to-see-the-values">I REALLY needed to see the values&lt;/h1>
&lt;p>The problem was that I had code in an Azure DevOps PowerShell task which was using a Service Principal to do some things in Azure and it was failing.&lt;/p>
&lt;p>The pipeline had some things a little like this, it got a number of values from a key vault, set them to variables and used them in a custom function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$somevalue = (Get-AzKeyVaultSecret -vaultName $KeyVaultName -name &amp;#39;AGeneratedName&amp;#39;).SecretValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$somecredential = New-Object System.Management.Automation.PSCredential (&amp;#39;dummy&amp;#39;, $somevalue )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$something = $somecredential.GetNetworkCredential().Password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Do-SomethingSpecial -MyThing $something
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I was getting an error saying &amp;ldquo;forbidden - *** does not have access&amp;rdquo; or similar&lt;/p>
&lt;p>Thing is, I knew that &lt;code>$something&lt;/code> did have access as I could run the same code from my workstation and it did the logging in for &lt;code>$something&lt;/code> so the error must be in the values that I was passing into the function. (there were more values than this but that is not important)&lt;/p>
&lt;p>All I needed to do was to see what values had been passed to the function and I could resolve this little issue. But these were secret variables. Helpfully kept out of the logs by Azure DevOps hence the *** so what to do?&lt;/p>
&lt;p>I thought - I know what I will do, I will write the Parameter values from the function out as Verbose, call the function with &lt;code>-Verbose&lt;/code> and then delete the run to clear up the logs.&lt;/p>
&lt;p>I added&lt;/p>
&lt;p>&lt;code>Write-Verbose ($PSBoundParameters | Out-String)&lt;/code>&lt;/p>
&lt;p>to my function, called it with verbose in the pipeline and got&lt;/p>
&lt;blockquote>
&lt;p>Name       Value&lt;br>
- -         - -&lt;br>
MyThing       ***&lt;/p>
&lt;/blockquote>
&lt;p>Awesome.&lt;/p>
&lt;p>Write it to a file and read it back. This is a tactic that you can read about that works but it puts the secrets on disk on the agent and I did not want to do that.&lt;/p>
&lt;p>I thought I would be even cleverer and this time I added to my function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$WhatsMyThing = $MyThing + &amp;#39;-1&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Verbose &amp;#34;My thing is $WhatsMyThing&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Thats bound to work.&lt;/p>
&lt;p>My how I laughed when in the logs I had&lt;/p>
&lt;blockquote>
&lt;p>My Thing is  ***-1&lt;/p>
&lt;/blockquote>
&lt;p>Right. I thought.&lt;/p>
&lt;p>This IS IT.&lt;/p>
&lt;p>I WILL SHOW YOU AZURE DEVOPS&lt;/p>
&lt;p>I added to my function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$WhatsMyThing =[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($$MyThing ))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Verbose &amp;#34;My thing is $WhatsMyThing&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This converted the value of MyThing into a base64 encoded value which I could see in the logs.&lt;/p>
&lt;blockquote>
&lt;p>My Thing is VGhlIEJlYXJkIGlzIExhdWdoaW5nIGF0IHlvdS4gWW91IHRoaW5rIEkgd291bGQgcHV0IHNvbWV0aGluZyByZWFsIGluIGhlcmU/IEdvb2QgdHJ5Lg==&lt;/p>
&lt;/blockquote>
&lt;p>and then I could decode it on my workstation with&lt;/p>
&lt;p>&lt;code>[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String('ValueFromLogs'))&lt;/code>&lt;/p>
&lt;p>and learn that despite two people looking at the values we couldnt tell the difference between AGeneratedName and AnotherGeneratedName and they were the wrong way around!!!!&lt;/p>
&lt;p>But at least I know now a good way to get those secret values.&lt;/p>
&lt;p>If you do this, dont forget to delete the pipeline run from Azure DevOps so that the encoded value is not left in the logs for anyone to read.&lt;/p>
&lt;p>Every day is a learning day.&lt;/p></description></item><item><title>How to deploy an Azure Arc Enabled SQL Managed Instance in AKS</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-deploy-an-azure-arc-enabled-sql-managed-instance-in-aks/</link><pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-deploy-an-azure-arc-enabled-sql-managed-instance-in-aks/</guid><description>&lt;img src="https://raw.githubusercontent.com/SQLDBAWithABeard/Beard-Aks-AEDS/main/images/connecteddc.png" alt="Featured image of post How to deploy an Azure Arc Enabled SQL Managed Instance in AKS" />&lt;h1 id="want-to-play-before-ga-">Want to play before GA ?&lt;/h1>
&lt;p>Azure SQL enabled by Azure Arc will be generally available at the end of the month following the announcement &lt;a class="link" href="https://azure.microsoft.com/en-us/blog/bring-cloud-experiences-to-data-workloads-anywhere-with-azure-sql-enabled-by-azure-arc?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can read more about &lt;a class="link" href="https://azure.microsoft.com/en-us/services/azure-arc/hybrid-data-services?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Arc-enabled Data Services &lt;/a>&lt;/p>
&lt;p>I have been playing with it for a few months, mainly in a Kubernetes cluster running on my NUCs in my office but Azure Arc is available in so many places, all the public clouds, your own data center (or NUCs in your office :-) ) so if you want to try it out and you do not want to build your own Kubernetes cluster then you can use &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/kubernetes-service?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>AKS&lt;/a> in Azure.&lt;/p>
&lt;h1 id="how-can-i-do-that-">How can I do that ?&lt;/h1>
&lt;p>One way is to use the &lt;a class="link" href="https://azurearcjumpstart.io/azure_arc_jumpstart/azure_arc_data?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Arc Jumpstart website&lt;/a> which has many templates for many scenarios.&lt;/p>
&lt;p>I like playing with &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Bicep&lt;/a> which is a domain-specific language or DSL for deploying Azure resources.&lt;/p>
&lt;p>I have &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Beard-Aks-AEDS" target="_blank" rel="noopener"
>created a repository on GitHub &lt;/a> which you can use to create your own AKS cluster with an Azure Arc Enabled directly connected Data Controller and SQL Managed Instance either 1 node replica or 3 node replica.&lt;/p>
&lt;p>There is even the code to create an Azure Virtual Machine and install the required tooling if you need it.&lt;/p>
&lt;p>All of the details and instructions are in the read me file so feel free to go and make use of it and you can have a resource group that looks like this&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/SQLDBAWithABeard/Beard-Aks-AEDS/main/images/portalresources.png"
loading="lazy"
alt="portal"
>&lt;/p>
&lt;p>Just dont forget to delete the Resource Group once you have finished!!&lt;/p>
&lt;p>You can create it any time you like with the code :-)&lt;/p>
&lt;p>Happy Azure Arc SQL Managed Instance playing!&lt;/p></description></item><item><title>Flexing My Bicep - Reusable code with modules for deploying an Azure SQL Server</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-reusable-code-with-modules-for-deploying-an-azure-sql-server/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-reusable-code-with-modules-for-deploying-an-azure-sql-server/</guid><description>&lt;img src="https://datasaturdays.com/assets/design/twitter/c.twitter%201r.png" alt="Featured image of post Flexing My Bicep - Reusable code with modules for deploying an Azure SQL Server" />&lt;h1 id="reusable-code">Reusable code&lt;/h1>
&lt;p>We looked at a simple deployment of an Azure SQL Server and a database in the last blog post. You would like to reuse this code though, you will want to create more SQL Instances and SQL databases in the future. With Bicep, you can use modules and parameters to do this.&lt;/p>
&lt;p>You can create a module for your SQL Instance. I look up &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers/databases?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>the resource information from the documentation&lt;/a> and create a file named SQLInstance.bicep. I put it in a Resources directory.&lt;/p>
&lt;h1 id="parameters">Parameters&lt;/h1>
&lt;p>At the top of the file you need to define parameters to enabled you to pass in different values for the deployment. You can find information about &lt;a class="link" href="https://github.com/Azure/bicep/blob/main/docs/spec/parameters.md" target="_blank" rel="noopener"
>Bicep parameters in the docs on GitHub&lt;/a>.&lt;/p>
&lt;p>You define a parameter using the keyword &lt;code>param&lt;/code>. At a minimum you need a name and a datatype. An obvious one for this usecase would be the name of the SQL Instance which could be defined as&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param SqlInstanceName string
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Perhaps your organisation has a requirement for all of the data to be stored in a particular region. You might want to have a default value for your location parameter. You can define a default parameter by assigning it with an equals sign.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param location string = &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Some parameters that you would like to use will only allow certain values. You can define those as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">@allowed([
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#39;Disabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param transparentDataEncryption string = &amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">targetScope = &amp;#39;resourceGroup&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param SqlInstanceName string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param location string = &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param tags object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param administratorLogin string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param administratorLoginPassword string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param minimalTlsVersion string = &amp;#39;1.0&amp;#39; // 1.0,1.1,1.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param publicNetworkAccess string = &amp;#39;Disabled&amp;#39; // &amp;#39;Disabled&amp;#39;,&amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ActiveDirectoryAdminUser string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ActiveDirectoryAdminUserSid string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param tenantid string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param azureADOnlyAuthentication bool = false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ExternalAdministratorPrincipalType string // User Application Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param sqlauditActionsAndGroups array //BATCH_COMPLETED_GROUP,,SUCCESSFUL_DATABASE_AUTHENTICATION_GROUP,FAILED_DATABASE_AUTHENTICATION_GROUP maybe some of these too but the logs will get large,APPLICATION_ROLE_CHANGE_PASSWORD_GROUP,BACKUP_RESTORE_GROUP,DATABASE_LOGOUT_GROUP,DATABASE_OBJECT_CHANGE_GROUP,DATABASE_OBJECT_OWNERSHIP_CHANGE_GROUP,DATABASE_OBJECT_PERMISSION_CHANGE_GROUP,DATABASE_OPERATION_GROUP,DATABASE_PERMISSION_CHANGE_GROUP,DATABASE_PRINCIPAL_CHANGE_GROUP,DATABASE_PRINCIPAL_IMPERSONATION_GROUP,DATABASE_ROLE_MEMBER_CHANGE_GROUP,FAILED_DATABASE_AUTHENTICATION_GROUP,SCHEMA_OBJECT_ACCESS_GROUP,SCHEMA_OBJECT_CHANGE_GROUP,SCHEMA_OBJECT_OWNERSHIP_CHANGE_GROUP,SCHEMA_OBJECT_PERMISSION_CHANGE_GROUP,SUCCESSFUL_DATABASE_AUTHENTICATION_GROUP,USER_CHANGE_PASSWORD_GROUP,BATCH_STARTED_GROUP,BATCH_COMPLETED_GROUP
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param SqldatabaseNames array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param dbSkuName string // for example GP_Gen5_2, BC_Gen5_10, HS_Gen5_8, P5, S0 etc
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param collation string = &amp;#39;SQL_Latin1_General_CP1_CI_AS&amp;#39; //
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param maxSizeBytes int // The max size of the database expressed in bytes.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param zoneRedundant bool = false // Whether or not this database is zone redundant, which means the replicas of this database will be spread across multiple availability zones.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param licenseType string = &amp;#39;LicenseIncluded&amp;#39; // The license type to apply for this database. LicenseIncluded if you need a license, or BasePrice if you have a license and are eligible for the Azure Hybrid Benefit. - LicenseIncluded or BasePrice
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: SqlInstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: tags
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> identity: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> type: &amp;#39;SystemAssigned&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: administratorLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: administratorLoginPassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> minimalTlsVersion: minimalTlsVersion
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: publicNetworkAccess
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administrators: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorType: &amp;#39;ActiveDirectory&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> login: ActiveDirectoryAdminUser
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sid: ActiveDirectoryAdminUserSid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tenantId: tenantid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureADOnlyAuthentication: azureADOnlyAuthentication
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> principalType: ExternalAdministratorPrincipalType
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// SQL Databases
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">resource symbolicname &amp;#39;Microsoft.Sql/servers/databases@2020-11-01-preview&amp;#39; = [for item in SqldatabaseNames:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> parent: sql
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: tags
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sku: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: dbSkuName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> collation: collation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> maxSizeBytes: maxSizeBytes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> zoneRedundant: zoneRedundant
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> licenseType: licenseType
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Invalid Template Deployment with my Bicep</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/invalid-template-deployment-with-my-bicep/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/invalid-template-deployment-with-my-bicep/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Invalid Template Deployment with my Bicep" />&lt;h1 id="an-error">An Error&lt;/h1>
&lt;p>Did I tear my bicep? No but I got an error. Whilst trying to deploy a network with Bicep using Azure DevOps I received the error&lt;/p>
&lt;blockquote>
&lt;p>Error: Code=InvalidTemplateDeployment; Message=The template deployment &amp;lsquo;deploy_bicep003_20210505094331&amp;rsquo; is not valid according to the validation procedure. The tracking id is &amp;lsquo;4bdec1fe-915d-4735-a1c1-7b56fbba0dc2&amp;rsquo;. See inner errors for details.&lt;/p>
&lt;/blockquote>
&lt;p>Unfortunately that was all that I had. I had to find the inner error for details&lt;/p>
&lt;h1 id="try-the-deployment-log-on-the-resource-group">Try the deployment log on the Resource Group&lt;/h1>
&lt;p>As I know that the Bicep deployments are logged in Azure under the Resource Groups deployment I looked there first but there were no entries (obviously Rob, there had been no deployment)&lt;/p>
&lt;p>So I navigated to the home page of the Azure Portal and searched for Activity log.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylog.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylog.png"
loading="lazy"
alt="activitylog"
>&lt;/a>&lt;/p>
&lt;p>I searched for the name of the deployment &lt;code>deploy_bicep003_20210505094331&lt;/code> and saw&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogsearch.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogsearch.png"
loading="lazy"
alt="activitylogsearch"
>&lt;/a>&lt;/p>
&lt;p>clicking on the link showed me this with the relevant information hidden in the JSON&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogdetails.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogdetails.png"
loading="lazy"
alt="activitylogdetails"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Resource name {&amp;rsquo;name&amp;rsquo;:&amp;lsquo;subnet1&amp;rsquo;,&amp;lsquo;addressPrefix&amp;rsquo;:&amp;lsquo;10.0.0.0/24&amp;rsquo;}.name is invalid.&lt;/p>
&lt;/blockquote>
&lt;p>Bingo.&lt;/p>
&lt;p>I had made a mistake in my resource definition for the subnets. I had used&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">subnets: [for item in subnets:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item}.name&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addressPrefix: &amp;#39;${item}.addressPrefix&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>where I should have used&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">subnets: [for item in subnets:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item.name}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addressPrefix: &amp;#39;${item.addressPrefix}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Every day is a learning day.&lt;/p></description></item><item><title>Flexing My Bicep - Deploy an Azure SQL Database -Intro to Azure Bicep IaC</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-deploy-an-azure-sql-database-intro-to-azure-bicep-iac/</link><pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-deploy-an-azure-sql-database-intro-to-azure-bicep-iac/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Flexing My Bicep - Deploy an Azure SQL Database -Intro to Azure Bicep IaC" />&lt;h1 id="starting-working-out">Starting working out?&lt;/h1>
&lt;p>It is important to keep a healthy body and mind, especially when my life is so sedentary these days. Getting exercise is good for both. This blog post has nothing to do with exercise though (apart from maybe exercising the mind)&lt;/p>
&lt;h1 id="project-bicep">Project Bicep&lt;/h1>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/bicep-overview?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Bicep&lt;/a> is a language for declaring and deploying Azure Resources. Like &lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>Terraform&lt;/a> it enables you to define your infrastructure as code.&lt;/p>
&lt;h2 id="why-use-bicep-instead">WHy use Bicep instead?&lt;/h2>
&lt;p>I really like being able to control infrastructure with code. I have used &lt;a class="link" href="https://blog.robsewell.com/tags/#terraform" target="_blank" rel="noopener"
>Terraform to deploy infrastructure&lt;/a> and almost exclusively on Azure. I have created and altered many environments for clients over the past couple of years using Terraform. I have also used ARM templates but found them confusing and unwieldly to use.&lt;/p>
&lt;h2 id="existing-state">Existing State&lt;/h2>
&lt;p>Terraform will deploy the required changes to your infrastructure by comparing the existing state which is stored in a state file with the expected state which is created by running the plan command. If someone alters the Azure resource via the portal, Azure CLI or Azure PowerShell all kinds of mayhem can occur normally failure in deployment and time spent troubleshooting. It is possible to use the &lt;a class="link" href="https://www.terraform.io/docs/cli/commands/import.html" target="_blank" rel="noopener"
>&lt;code>import&lt;/code> command in Terraform&lt;/a> to get the existing resource state into the state file so that the comparison is performed against the existing state of the resource but this requires a lot of manual intervention.&lt;/p>
&lt;p>Bicep deploys the changes by comparing the existing state of the Azure resources with the expected state in the code. This, for me, is a super benefit and reduces the complications of those type of errors.&lt;/p>
&lt;h2 id="latest-api-support">Latest API support&lt;/h2>
&lt;p>Terraform resources have a lag between features or properties from Azure being made available and those features or properties being incorporated into the Terraform resource. This has lead to me requiring my deployments to have additional Azure CLI, Azure PowerShell or worse both steps to achieve what I need.&lt;/p>
&lt;p>Bicep immediately supports all preview and GA versions for Azure Services, I don&amp;rsquo;t have to wait and all the things I can do are available to me.&lt;/p>
&lt;h2 id="authoring">Authoring&lt;/h2>
&lt;p>I love &lt;a class="link" href="https://code.visualstudio.com" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> and there is a &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-bicep&amp;amp;WT.mc_id=devops-13338-abewan" target="_blank" rel="noopener"
>super extension&lt;/a> that makes authoring a joy.&lt;/p>
&lt;h2 id="what-if-support">What If Support&lt;/h2>
&lt;p>I have written before about the &lt;a class="link" href="https://blog.robsewell.com/blog/powershell/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/" target="_blank" rel="noopener"
>importance of WhatIf for PowerShell functions and how to implement it&lt;/a> and Bicep has &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-deploy-what-if?tabs=azure-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>What If for deployments&lt;/a> so that you can validate that the code you have written will perform the tasks that you expect.&lt;/p>
&lt;h2 id="deployments-recorded-in-azure">Deployments recorded in Azure&lt;/h2>
&lt;p>The changes that I make with Bicep are recorded in Azure and I can find them in the deployments for the Resource Group&lt;/p>
&lt;h2 id="cost">Cost&lt;/h2>
&lt;p>Bicep is free :-)&lt;/p>
&lt;h1 id="deploy-an-azure-sql-database-rob">Deploy an Azure SQL Database Rob&lt;/h1>
&lt;p>OK, let&amp;rsquo;s see an example. I would like to deploy an Azure SQL Database into a Resource Group. I will need an Azure SQL Server resource and an Azure SQL Database resource. The &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Templates site&lt;/a> has the examples that I need. The &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure SQL Server page&lt;/a> shows the Bicep code I need and the explanations of the expected values.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource symbolicname &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> identity: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> type: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> minimalTlsVersion: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> encryptionIdentityId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> keyId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administrators: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorType: &amp;#39;ActiveDirectory&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> principalType: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> login: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sid: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tenantId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureADOnlyAuthentication: bool
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a file with a &lt;code>.bicep&lt;/code> extension in VS Code&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/bicepfile.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/bicepfile.png"
loading="lazy"
alt="bicepfile"
>&lt;/a>&lt;/p>
&lt;p>and add only the required values. (NOTE - this is just an example and I would never recommend that you would put the password for anything in a file in plain text, we will cover how to handle secrets later. )&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;beardsqlrand01&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;sysadmin&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;dbatools.IO&amp;#39; // DON&amp;#39;T DO THIS - EVER
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="validate-the-deployment-with-whatif">Validate the deployment with WhatIf&lt;/h2>
&lt;p>I created an empty Resource Group for my test&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-AzResourceGroup -Name &amp;#39;BicepTest&amp;#39; -Location &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Next, I am going to check that the code that I have written will perform the actions that I expect. I am hoping to get&lt;/p>
&lt;ul>
&lt;li>An Azure SQL Instance called beardsqlrand01&lt;/li>
&lt;li>In the location North Europe&lt;/li>
&lt;li>With an admin login and password as stated in the file (NO Don&amp;rsquo;t ever do this in Production)&lt;/li>
&lt;/ul>
&lt;p>I do this using the Azure PowerShell command &lt;code>New-AzResourceGroupDeployment&lt;/code> and give it the Resource Group Name and the path to the file&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Validate the deployment with Whatif
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The first thing this does is check the status of the resources in the resource group&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatif.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatif.png"
loading="lazy"
alt="whatif"
>&lt;/a>&lt;/p>
&lt;p>then it provides a list of what it will do. In this example there is only one resource.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifresult.png"
loading="lazy"
alt="whatifresult"
>&lt;/a>&lt;/p>
&lt;p>This tells us that there will be a creation of 1 resource and that the values are as I expect them. As I am happy with that I can then deploy the infrastructure by changing the &lt;code>WhatIf&lt;/code> value to false&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Deploy the changes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="deployment-can-be-seen-in-the-azure-portal">Deployment can be seen in the Azure Portal&lt;/h1>
&lt;p>If I look in the Azure Portal, I can see the deployment is happening.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploying.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploying.png"
loading="lazy"
alt="portaldeploying"
>&lt;/a>&lt;/p>
&lt;p>Once it has finished I get an output on the screen&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/deploymentresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/deploymentresult.png"
loading="lazy"
alt="deploymentresult"
>&lt;/a>&lt;/p>
&lt;p>and when I look in the portal at the deployment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploymentresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploymentresult.png"
loading="lazy"
alt="portaldeploymentresult"
>&lt;/a>&lt;/p>
&lt;p>and my resource has been created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portalsqlresource.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portalsqlresource.png"
loading="lazy"
alt="portalsqlresource"
>&lt;/a>&lt;/p>
&lt;h2 id="add-a-database">Add a database&lt;/h2>
&lt;p>I have my Azure SQL Instance, next I need a database. I look up &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers/databases?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>the resource information&lt;/a> and add the required information to my bicep file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;beardsqlrand01&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;sysadmin&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;dbatools.IO&amp;#39; // DON&amp;#39;T DO THIS - EVER
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: &amp;#39;Disabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> resource bearddatabase &amp;#39;databases@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;BicepDatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sku: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;Basic&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is a super simple example. The database resource is defined within the SQL Instance resource with a name and a SKU.&lt;/p>
&lt;p>We validate it in exactly the same way as before. This time we will see that we can incrementally add or change resources to our deployment and validate what will happen.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Validate the deployment with Whatif
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This time the result looks a little different as we already have a resource in the Resource Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifdatabase.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifdatabase.png"
loading="lazy"
alt="whatifdatabase"
>&lt;/a>&lt;/p>
&lt;p>At the top it gives you three types of changes&lt;/p>
&lt;ul>
&lt;li>Create&lt;/li>
&lt;li>NoChange&lt;/li>
&lt;li>Ignore&lt;/li>
&lt;/ul>
&lt;p>It shows at the bottom that the changes are&lt;/p>
&lt;blockquote>
&lt;p>Resource changes: 1 to create, 1 no change, 1 to ignore.&lt;/p>
&lt;/blockquote>
&lt;p>This tells you that it will create the Azure SQL Database, it will not change the Azure SQL Server and there is no change to the master database.&lt;/p>
&lt;p>I am happy with that validation, so I deploy the changes, again using the same code as before.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Deploy the changes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If I look in the portal I can see the deployment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployment.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployment.png"
loading="lazy"
alt="databasedeployment"
>&lt;/a>&lt;/p>
&lt;p>and once it has completed I can see the database in the Portal&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployed.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployed.png"
loading="lazy"
alt="databasedeployed"
>&lt;/a>&lt;/p>
&lt;p>Thats all there is to Bicep.&lt;/p>
&lt;ul>
&lt;li>Find the resource information in the docs&lt;/li>
&lt;li>Define your deployment in code&lt;/li>
&lt;li>Validate your deployment with WhatIf&lt;/li>
&lt;li>Deploy your changes&lt;/li>
&lt;/ul>
&lt;h1 id="remove-the-resource-group">Remove the Resource Group&lt;/h1>
&lt;p>Now that my test has finished I will remove the Resource Group. If you are following along, this is how to do that&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Remove-AzResourceGroup -Name BicepTest -Force
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="all-of-the-code">All of the code&lt;/h1>
&lt;p>I have added all of the code for this blog post to my GitHub here &lt;a class="link" href="https://github.com/SQLDBAWithABeard/BeardBicep/tree/main/SimpleSqlDatabase" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/BeardBicep/tree/main/SimpleSqlDatabase&lt;/a> so that you can follow along.&lt;/p>
&lt;h1 id="next-steps">Next steps&lt;/h1>
&lt;p>Now that you have an introduction to Bicep and can see how useful and powerful it can be, we will expand on this in the following blog posts.&lt;/p></description></item><item><title>Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/08/image-16.png" alt="Featured image of post Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools" />&lt;p>Following on from my posts about using Secret Management &lt;a class="link" href="https://blog.robsewell.com/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>Good bye Import-CliXml&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/" target="_blank" rel="noopener"
>running programmes as a different user&lt;/a>, I have another use case.&lt;/p>
&lt;p>After creating Azure SQL Databases in an Elastic Pool using a process pretty similar to this one &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>I blogged about last year&lt;/a>, I needed to be able to programmatically create users and assign permissions.&lt;/p>
&lt;h2 id="i-need-a-user-to-login-with">I need a user to login with&lt;/h2>
&lt;p>When I created my Azure SQL Server with Terraform, I set the Azure Admin to be a SPN as you can see in the image from the portal and set it to have an identity using the documentation for &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_server.html" target="_blank" rel="noopener"
>azurerm_mssql_server&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-18.png"
loading="lazy"
>
This allows this user to manage the access for the SQL Server as long as the SQL Server Azure AD identity has Directory Reader privileges. The SQL Server is called temp-beard-sqls and as you can see the identity is assigned to the role.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-11.png"
loading="lazy"
>
The privileges required to do this for a single identity are quite high&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>so now, you can assign an Azure Active Directory Group to that Role and allow less-privileged users to add the identity to this group . The documentation is &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> and there is a tutorial &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal-tutorial?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> explaining the steps you need to take.&lt;/p>
&lt;h2 id="what-is-an-azure-spn">What is an Azure SPN?&lt;/h2>
&lt;blockquote>
&lt;p>An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest&lt;/a>&lt;/p>
&lt;p>I created the SPN using Azure CLI straight from the Azure Portal by clicking this button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and running&lt;/p>
&lt;pre>&lt;code>az ad sp create-for-rbac --name ServicePrincipalName
&lt;/code>&lt;/pre>
&lt;p>This will quickly create a SPN for you and return the password&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes I have deleted this one&lt;/p>
&lt;h2 id="add-azure-key-vault-to-secret-management">Add Azure Key Vault to Secret Management&lt;/h2>
&lt;p>In my previous posts, I have been using the Default Key Vault which is limited to your local machine and the user that is running the code. It would be better to use Azure Key Vault to store the details for the SPN so that it safely stored in the cloud and not on my machine and also so that anyone (or app) that has permissions to the vault can use it.&lt;/p>
&lt;p>First you need to login to Azure in PowerShell (You will need to have the AZ* modules installed)&lt;/p>
&lt;pre>&lt;code>Connect-AzAccount
&lt;/code>&lt;/pre>
&lt;p>Be aware, the login box can appear behind the VS Code or Azure Data Studio window!&lt;/p>
&lt;p>Once connected, if you have several Azure subscriptions, you can list them with&lt;/p>
&lt;pre>&lt;code>Get-AzSubscription
&lt;/code>&lt;/pre>
&lt;p>You can choose your subscription with&lt;/p>
&lt;pre>&lt;code>$AzureSubscription = Set-AzContext -SubscriptionName &amp;quot;NAME OF SUBSCRIPTION&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>For the Secret Management Module to manage the Azure Key Vault, you first need to register it.&lt;/p>
&lt;p>Ensure that you have permissions to connect by following the details in the network security documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/network-security?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/network-security&lt;/a> and the secure access documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault&lt;/a>&lt;/p>
&lt;p>Then you can run &lt;code>Register-SecretVault&lt;/code> . You need to provide the local name for the key vault, the module name &lt;code>Az.KeyVault&lt;/code>, and a &lt;code>VaultParameters&lt;/code> hashtable with the KeyVault name and the Azure Subscription ID. You can register other types of Key Vaults to the Secret Management module in this way and they will require different values for the &lt;code>VaultParameters&lt;/code> parameter.&lt;/p>
&lt;pre>&lt;code>$KeyVaultName = 'beard-key-vault'
Register-SecretVault -Name BeardKeyVault -ModuleName Az.KeyVault -VaultParameters @{ AZKVaultName = $KeyVaultName; SubscriptionId = $AzureSubscription.Subscription.Id }
&lt;/code>&lt;/pre>
&lt;h2 id="adding-the-spn-details-to-the-azure-key-vault">Adding the SPN details to the Azure Key Vault&lt;/h2>
&lt;p>Using the values for AppID – (Note NOT the display name) and the values for the password from the Azure CLI output or by creating a new secret for the SPN with PowerShell or via the portal. You can use the following code to add the SPN details and the tenantid to the Azure Key Vault using the Secret Management module&lt;/p>
&lt;pre>&lt;code>$ClientId = Read-Host &amp;quot;Enter ClientID&amp;quot; -AsSecureString
$SecretFromPortal = Read-Host &amp;quot;Enter Client Secret&amp;quot; -AsSecureString
$tenantid = Read-Host &amp;quot;Enter TenantId&amp;quot; -AsSecureString
Set-Secret -Vault BeardKeyVault -Name service-principal-guid -Secret $ClientId
Set-Secret -Vault BeardKeyVault -Name service-principal-secret -SecureStringSecret $SecretFromPortal
Set-Secret -Vault BeardKeyVault -Name Tenant-Id -Secret $tenantid
&lt;/code>&lt;/pre>
&lt;p>You can also do this with the Az.KeyVault module by following the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can see the secrets in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>and also at the command line with the Secret Management module using&lt;/p>
&lt;pre>&lt;code>Get-SecretInfo -Vault RegisteredNameOfVault
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="can-my-user-connect">Can my user connect?&lt;/h2>
&lt;p>If I try to connect in Azure Data Studio to my Azure SQL Database with my AAD account to the temp-sql-db-beard database. It fails.&lt;/p>
&lt;p>By the way a great resource for troubleshooting the SQL error 18456 failure states can be found here &lt;a class="link" href="https://sqlblog.org/2020/07/28/troubleshooting-error-18456" target="_blank" rel="noopener"
>https://sqlblog.org/2020/07/28/troubleshooting-error-18456&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-13.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="dbatools-to-the-rescue-">dbatools to the rescue 🙂&lt;/h2>
&lt;p>dbatools is an open source community collaboration PowerShell module for administrating SQL Server. You can find more about it at &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.io&lt;/a> and get the book that Chrissy and I are writing about dbatools at &lt;a class="link" href="http://dbatools.io%5Cbook" target="_blank" rel="noopener"
>dbatools.io\book&lt;/a>&lt;/p>
&lt;p>You can connect to Azure SQL Database with an Azure SPN using the following code. It will get the secrets from the Azure Key Vault that have been set above and create a connection. Lets see if I can run a query as the SPN.&lt;/p>
&lt;pre>&lt;code>$SqlInstance = 'temp-beard-sqls.database.windows.net'
$databasename = 'master'
$appid = Get-Secret -Vault BeardKeyVault -Name service-principal-guid -AsPlainText
$Clientsecret = Get-Secret -Vault BeardKeyVault -Name service-principal-secret
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = Get-Secret -Vault BeardKeyVault -Name Sewells-Tenant-Id -AsPlainText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
Invoke-DbaQuery -SqlInstance $AzureSql -Database master -SqlCredential $credential -Query &amp;quot;Select SUSER_NAME() as 'username'&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Excellent 🙂&lt;/p>
&lt;h2 id="add-a-user-to-the-user-database">Add a user to the user database&lt;/h2>
&lt;p>I can then add my user to the temp-sql-db-beard Database. I need to create a new connection to the user database as you cannot use the &lt;code>USE [DatabaseName]&lt;/code> statement&lt;/p>
&lt;pre>&lt;code>$Userdatabasename = 'temp-sql-db-beard'
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $Userdatabasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre>
&lt;p>Whilst you can use dbatools to create new users in Azure SQL Database at present you cant create AAD users. You can run a T-SQL Script to do this though. This script will create a contained database user in the database. I have added the role membership also but this can also be done with &lt;a class="link" href="https://docs.dbatools.io/#Add-DbaDbRoleMember" target="_blank" rel="noopener"
>Add-DbaDbRoleMember&lt;/a> from dbatools&lt;/p>
&lt;pre>&lt;code>$Query = @&amp;quot;
CREATE USER [rob@sewells-consulting.co.uk] FROM EXTERNAL PROVIDER
ALTER ROLE db_datareader ADD MEMBER [rob@sewells-consulting.co.uk]
&amp;quot;@
Invoke-DbaQuery -SqlInstance $AzureSql -Database $Userdatabasename -SqlCredential $credential -Query $Query
&lt;/code>&lt;/pre>
&lt;p>Lets check the users on the database with dbatools&lt;/p>
&lt;pre>&lt;code>Get-DbaDbUser -SqlInstance $AzureSql -Database $Userdatabasename |Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>I have my user and it is of type External user. Lets see if I can connect&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Bingo 🙂&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>Because I dont like to see awesome people struggling with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Here is the same code using just the Az.KeyVault module&lt;/p>
&lt;pre>&lt;code>$appid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-guid&amp;quot;).SecretValueText
$Clientsecret = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-secret&amp;quot;).SecretValue
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;Sewells-Tenant-Id&amp;quot;).SecretValueText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre></description></item><item><title>Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</link><pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-125.png" alt="Featured image of post Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools" />&lt;p>In my posts about using Azure Devops to build Azure resources with Terraform, &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>I built a Linux SQL VM.&lt;/a> I used the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>Terraform in this GitHub&lt;/a> repository and created this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-mobaxterm">Connecting with MobaXterm&lt;/h2>
&lt;p>I had set the Network security rules to accept connections only from my static IP using variables in the Build Pipeline. I use &lt;a class="link" href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener"
>MobaXterm&lt;/a> as my SSH client. Its a free download. I click on sessions&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-120.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose a SSH session and fill in the remote host address from the portal&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-121.png"
loading="lazy"
>&lt;/p>
&lt;p>fill in the password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-122.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="configuring-sql">Configuring SQL&lt;/h2>
&lt;p>The next task is to configure the SQL installation. Following the instructions on the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sql/provision-sql-server-linux-virtual-machine?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft docs site&lt;/a> I run&lt;/p>
&lt;pre>&lt;code>sudo systemctl stop mssql-server
sudo /opt/mssql/bin/mssql-conf set-sa-password
&lt;/code>&lt;/pre>
&lt;p>enter the sa password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-123.png"
loading="lazy"
>&lt;/p>
&lt;p>Now to start SQL&lt;/p>
&lt;pre>&lt;code>sudo systemctl start mssql-server
&lt;/code>&lt;/pre>
&lt;h2 id="installing-pwsh">Installing pwsh&lt;/h2>
&lt;p>Installing PowerShell Core (pwsh) is easy with snap&lt;/p>
&lt;p>sudo snap install powershell &amp;ndash;classic&lt;/p>
&lt;p>A couple of minutes of downloads and install&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-124.png"
loading="lazy"
>&lt;/p>
&lt;p>and pwsh is ready for use&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-125.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-dbatools">Installing dbatools&lt;/h2>
&lt;p>To install &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbatools" target="_blank" rel="noopener"
>Powershell Gallery&lt;/a> simply run&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser&lt;/p>
&lt;p>This will prompt you to allow installing from an untrusted repository&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-126.png"
loading="lazy"
>&lt;/p>
&lt;p>and dbatools is ready to go&lt;/p>
&lt;pre>&lt;code>#Set a credential
$cred = Get-Credential
# Show the databases on the local instance
Get-DbaDatabase -SqlInstance localhost -SqlCredential $cred
&lt;/code>&lt;/pre>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-127.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-azure-data-studio">Connecting with Azure Data Studio&lt;/h2>
&lt;p>I can also connect with Azure Data Studio&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-128.png"
loading="lazy"
>&lt;/p>
&lt;p>and connect&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/p>
&lt;p>Just a quick little post explaining what I did 🙂&lt;/p>
&lt;p>Happy Linuxing!&lt;/p></description></item><item><title>Using Azure DevOps Build Pipeline Templates with Terraform to build an AKS cluster</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/</link><pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-151.png" alt="Featured image of post Using Azure DevOps Build Pipeline Templates with Terraform to build an AKS cluster" />&lt;p>In the last few posts I have moved from &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>building an Azure SQL DB with Terraform using VS Code&lt;/a> to &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>automating the build process for the Azure SQL DB using Azure DevOps Build Pipelines&lt;/a> to &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>using Task Groups in Azure DevOps to reuse the same Build Process and build an Azure Linux SQL VM and Network Security Group&lt;/a>. This evolution is fantastic but Task Groups can only be used in the same Azure DevOps repository. It would be brilliant if I could use Configuration as Code for the Azure Build Pipeline and store that in a separate source control repository which can be used from any Azure DevOps Project.&lt;/p>
&lt;p>Luckily, you can 😉 You can use &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure DevOps Job Templates&lt;/a> to achieve this. There is a limitation at present, you can only use them for Build Pipelines and not Release Pipelines.&lt;/p>
&lt;p>The aim of this little blog series was to have a single Build Pipeline stored as code which I can use to build any infrastructure that I want with Terraform in Azure and be able to use it anywhere&lt;/p>
&lt;h2 id="creating-a-build-pipeline-template">Creating a Build Pipeline Template&lt;/h2>
&lt;p>I created a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-BuildTemplates" target="_blank" rel="noopener"
>GitHub repository&lt;/a> to hold my Build Templates, feel free to use them as a base for your own but please don’t try and use the repo for your own builds.&lt;/p>
&lt;p>The easiest way to create a Build Template is to already have a Build Pipeline. This cannot be done from a Task Group but I still have the Build Pipeline from my &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>automating the build process for the Azure SQL DB using Azure DevOps Build Pipelines&lt;/a> blog post.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-132.png"
loading="lazy"
>&lt;/p>
&lt;p>There is a View YAML button. I can click this to view the YAML definition of the Build Pipeline&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-133.png"
loading="lazy"
>&lt;/p>
&lt;p>I copy that and paste it into a new file in my BuildTemplates repository. (I have replaced my Azure Subscription information in the public repository)&lt;/p>
&lt;pre>&lt;code> jobs:
- job: Build
pool:
name: Hosted VS2017
demands: azureps
steps:
- task: AzureCLI@1
displayName: 'Azure CLI to deploy azure storage for backend'
inputs:
azureSubscription: 'PUTYOURAZURESUBNAMEHERE'
scriptLocation: inlineScript
inlineScript: |
# the following script will create Azure resource group, Storage account and a Storage container which will be used to store terraform state
call az group create --location $(location) --name $(TerraformStorageRG)
call az storage account create --name $(TerraformStorageAccount) --resource-group $(TerraformStorageRG) --location $(location) --sku Standard_LRS
call az storage container create --name terraform --account-name $(TerraformStorageAccount)
- task: AzurePowerShell@3
displayName: 'Azure PowerShell script to get the storage key'
inputs:
azureSubscription: 'PUTYOURAZURESUBNAMEHERE'
ScriptType: InlineScript
Inline: |
# Using this script we will fetch storage key which is required in terraform file to authenticate backend stoarge account
$key=(Get-AzureRmStorageAccountKey -ResourceGroupName $(TerraformStorageRG) -AccountName $(TerraformStorageAccount)).Value[0]
Write-Host &amp;quot;##vso[task.setvariable variable=TerraformStorageKey]$key&amp;quot;
azurePowerShellVersion: LatestVersion
- task: qetza.replacetokens.replacetokens-task.replacetokens@3
displayName: 'Replace tokens in terraform file'
inputs:
rootDirectory: Build
targetFiles: |
**/*.tf
**/*.tfvars
tokenPrefix: '__'
tokenSuffix: '__'
- powershell: |
Get-ChildItem .\Build -Recurse
Get-Content .\Build\*.tf
Get-Content .\Build\*.tfvars
Get-ChildItem Env: | select Name
displayName: 'Check values in files'
enabled: false
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Initialise Terraform'
inputs:
TemplatePath: Build
Arguments: 'init -backend-config=&amp;quot;0-backend-config.tfvars&amp;quot;'
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Plan Terraform execution'
inputs:
TemplatePath: Build
Arguments: plan
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Apply Terraform'
inputs:
TemplatePath: Build
Arguments: 'apply -auto-approve'
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
&lt;/code>&lt;/pre>
&lt;p>Now I can use this yaml as configuration as code for my Build Pipeline 🙂 It can be used from any Azure DevOps project. Once you start looking at the code and the &lt;a class="link" href="https://docs.microsoft.com/en-gb/azure/devops/pipelines/yaml-schema?view=azure-devops&amp;amp;tabs=schema?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>documentation for the yaml&lt;/a> schema you can begin to write your pipelines as YAML, but sometimes it is easier to just create build pipeline or even just a job step in the browser and click the view yaml button!&lt;/p>
&lt;h2 id="create-an-aks-cluster-with-a-sql-2019-container-using-terraform-and-build-templates">Create an AKS Cluster with a SQL 2019 container using Terraform and Build templates&lt;/h2>
&lt;p>I have a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AKS" target="_blank" rel="noopener"
>GitHub Repository with the Terraform code to build a simple AKS cluster&lt;/a>. This could not have been achieved without &lt;a class="link" href="https://azurecitadel.com/automation/terraform/lab8/" target="_blank" rel="noopener"
>Richard Cheney’s article&lt;/a> I am not going to explain how it all works for this blog post or some of the negatives of doing it this way. Instead lets build an Azure DevOps Build Pipeline to build it with Terraform using Configuration as Code (the yaml file)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-134.png"
loading="lazy"
>&lt;/p>
&lt;p>I am going to create a new Azure DevOps Build Pipeline and as in the previous posts connect it to the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AKS" target="_blank" rel="noopener"
>GitHub Repository holding the Terraform code&lt;/a>.&lt;/p>
&lt;p>This time I am going to choose the Configuration as code template&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-135.png"
loading="lazy"
>&lt;/p>
&lt;p>I am going to give it a name and it will show me that it needs the path to the yaml file containing the build definition in the current repository.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-136.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the 3 ellipses will pop-up a file chooser and I pick the build.yaml file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-137.png"
loading="lazy"
>&lt;/p>
&lt;p>The build.yaml file looks like this. The name is the USER/Repository Name and the endpoint is the name of the endpoint for the GitHub service connection in Azure DevOps. The template value is the name of the build yaml file @ the name given for the repository value.&lt;/p>
&lt;pre>&lt;code> resources:
repositories:
- repository: templates
type: GitHub
name: SQLDBAWithABeard/Presentations-BuildTemplates-Private
endpoint: SQLDBAWithABeardGitHub
jobs:
- template: AzureTerraform.yaml@templates # Template reference
&lt;/code>&lt;/pre>
&lt;p>You can find (and change) your GitHub service connection name by clicking on the cog bottom left in Azure DevOps and clicking service connections&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-140.png"
loading="lazy"
>&lt;/p>
&lt;p>I still need to create my variables for my Terraform template (perhaps I can now just leave those in my code?) For the AKS Cluster build right now I have to add presentation, location, ResourceGroupName, AgentPoolName, ServiceName, VMSize, agent_count&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-139.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I click save and queue and the job starts running&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-141.png"
loading="lazy"
>&lt;/p>
&lt;p>If I want to edit the pipeline it looks a little different&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-152.png"
loading="lazy"
>&lt;/p>
&lt;p>The variables and triggers can be found under the 3 ellipses on the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-153.png"
loading="lazy"
>&lt;/p>
&lt;p>It also defaults the trigger to automatic deployment.&lt;/p>
&lt;p>It takes a bit longer to build&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-142.png"
loading="lazy"
>&lt;/p>
&lt;p>and when I get the Terraform code wrong and the build fails, I can just alter the code, commit it, push and a new build will start and the Terraform will work out what is built and what needs to be built!&lt;/p>
&lt;p>but eventually the job finishes successfully&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-143.png"
loading="lazy"
>&lt;/p>
&lt;p>and the resources are built&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-144.png"
loading="lazy"
>&lt;/p>
&lt;p>and in Visual Studio Code with the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-kubernetes-tools.vscode-kubernetes-tools" target="_blank" rel="noopener"
>Kubernetes extension&lt;/a> installed I can connect to the cluster by clicking the 3 ellipses and Add Existing Cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-145.png"
loading="lazy"
>&lt;/p>
&lt;p>I choose Azure Kubernetes Services and click next&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-146.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose my subscription and then add the cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-147.png"
loading="lazy"
>&lt;/p>
&lt;p>and then I can explore my cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-148.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see the dashboard by right clicking on the cluster name and Open Dashboard&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-150.png"
loading="lazy"
>&lt;/p>
&lt;p>Right clicking on the service name and choosing describe&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-149.png"
loading="lazy"
>&lt;/p>
&lt;p>shows the external IP address, which I can put into Azure Data Studio and connect to my container&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-151.png"
loading="lazy"
>&lt;/p>
&lt;p>So I now I can source control my Build Job Steps and hold them in a central repository. I can make use of them in any project. This gives me much more control and saves me from repeating myself repeating myself. The disadvantage is that there is no handy warning when I change the underlying Build Repository that I will be affecting other Build Pipelines and there is no easy method to see which Build Pipelines are dependent on the build yaml file&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Building Azure SQL Db with Terraform with Visual Studio Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-with-visual-studio-code/</link><pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-with-visual-studio-code/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-42.png" alt="Featured image of post Building Azure SQL Db with Terraform with Visual Studio Code" />&lt;p>I have been using &lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>Terraform&lt;/a> for the last week or so to create some infrastructure and decided to bring that knowledge back to a problem that I and others suffer from – building environments for presentations, all for the sake of doing some learning.&lt;/p>
&lt;h2 id="what-is-terraform">What is Terraform?&lt;/h2>
&lt;p>According to the website&lt;/p>
&lt;blockquote>
&lt;p>HashiCorp Terraform enables you to safely and predictably create, change, and improve infrastructure. It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned&lt;/p>
&lt;p>&lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>https://www.terraform.io/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This means that I can define my infrastructure as code. If I can do that then I can reliably do the same thing again and again, at work to create environments that have the same configuration or outside of work to repeatedly build the environment I need.&lt;/p>
&lt;h2 id="building-an-azure-sql-database-with-terraform">Building an Azure SQL Database with Terraform&lt;/h2>
&lt;p>To understand how to build a thing the best place to start is the documentation &lt;a class="link" href="https://www.terraform.io/docs" target="_blank" rel="noopener"
>https://www.terraform.io/docs&lt;/a> . For an &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_database.html" target="_blank" rel="noopener"
>Azure SQL Db in the docs&lt;/a> you will find a block of code that looks like this&lt;/p>
&lt;pre>&lt;code> resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;acceptanceTestResourceGroup1&amp;quot;
location = &amp;quot;West US&amp;quot;
}
resource &amp;quot;azurerm_sql_server&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;mysqlserver&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group.test.name}&amp;quot;
location = &amp;quot;West US&amp;quot;
version = &amp;quot;12.0&amp;quot;
administrator_login = &amp;quot;4dm1n157r470r&amp;quot;
administrator_login_password = &amp;quot;4-v3ry-53cr37-p455w0rd&amp;quot;
}
resource &amp;quot;azurerm_sql_database&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;mysqldatabase&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group.test.name}&amp;quot;
location = &amp;quot;West US&amp;quot;
server_name = &amp;quot;${azurerm_sql_server.test.name}&amp;quot;
tags = {
environment = &amp;quot;production&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>If you read the code, you can see that there are key value pairs defining information about the resource that is being created. Anything inside a ${} is a dynamic reference. So&lt;/p>
&lt;p>resource_group_name = &amp;ldquo;${azurerm_resource_group.test.name}&amp;rdquo;
refers to the name property in the azure_resource_group block called test (or the name of the resource group 🙂 )&lt;/p>
&lt;h2 id="infrastructure-as-code">Infrastructure As Code&lt;/h2>
&lt;p>So I can put that code into a file (name it main.tf) and alter it with the values and “run Terraform” and what I want will be created. Lets take it a step further though because I want to be able to reuse this code. Instead of hard-coding all of the values I am going to use variables. I can do this by creating another file called variables.tf which looks like&lt;/p>
&lt;pre>&lt;code> variable &amp;quot;presentation&amp;quot; {
description = &amp;quot;The name of the presentation - used for tagging Azure resources so I know what they belong to&amp;quot;
default = &amp;quot;dataindevon&amp;quot;
}
variable &amp;quot;ResourceGroupName&amp;quot; {
description = &amp;quot;The Resource Group Name&amp;quot;
default = &amp;quot;beardrules&amp;quot;
}
variable &amp;quot;location&amp;quot; {
description = &amp;quot;The Azure Region in which the resources in this example should exist&amp;quot;
default = &amp;quot;uksouth&amp;quot;
}
variable &amp;quot;SqlServerName&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server to be created or to have the database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;jeremy&amp;quot;
}
variable &amp;quot;SQLServerAdminUser&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server Admin user for the Azure SQL Database&amp;quot;
default = &amp;quot;Beard&amp;quot;
}
variable &amp;quot;SQLServerAdminPassword&amp;quot; {
description = &amp;quot;The Azure SQL Database users password&amp;quot;
default = &amp;quot;JonathanlovesR3ge%&amp;quot;
}
variable &amp;quot;SqlDatabaseName&amp;quot; {
description = &amp;quot;The name of the Azure SQL database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;jsdb&amp;quot;
}
variable &amp;quot;Edition&amp;quot; {
description = &amp;quot;The Edition of the Database - Basic, Standard, Premium, or DataWarehouse&amp;quot;
default = &amp;quot;Standard&amp;quot;
}
variable &amp;quot;ServiceObjective&amp;quot; {
description = &amp;quot;The Service Tier S0, S1, S2, S3, P1, P2, P4, P6, P11 and ElasticPool&amp;quot;
default = &amp;quot;S0&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>and my main.tf then looks like this.&lt;/p>
&lt;pre>&lt;code>provider &amp;quot;azurerm&amp;quot; {
version = &amp;quot;=1.24.0&amp;quot;
}
resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.ResourceGroupName}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_server&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlServerName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group. presentation.name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
version = &amp;quot;12.0&amp;quot;
administrator_login = &amp;quot;${var.SQLServerAdminUser}&amp;quot;
administrator_login_password = &amp;quot;${var.SQLServerAdminPassword} &amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_database&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlDatabaseName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_sql_server.presentation. resource_group_name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
server_name = &amp;quot;${azurerm_sql_server.presentation. name}&amp;quot;
edition = &amp;quot;${var.Edition}&amp;quot;
requested_service_objective_name = &amp;quot;${var.ServiceObjective}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>You can find these files in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLDB/tree/master/Manual" target="_blank" rel="noopener"
>GitHub Repository&lt;/a> here.&lt;/p>
&lt;h2 id="alright--deploy-something">Alright – deploy something&lt;/h2>
&lt;p>To deploy the code that I have written I need to download Terraform from &lt;a class="link" href="https://www.terraform.io/downloads.html" target="_blank" rel="noopener"
>https://www.terraform.io/downloads.html&lt;/a> and then extract the exe to a folder in my PATH. (I chose C:\Windows). Then in Visual Studio Code I installed two extensions The &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=mauve.terraform" target="_blank" rel="noopener"
>Terraform Extension by Mikael Olenfalk&lt;/a> which enables syntax highlighting and auto-completion for the tf files and the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azureterraform" target="_blank" rel="noopener"
>Azure Terraform&lt;/a> extension. You will need also need &lt;a class="link" href="https://nodejs.org/en/" target="_blank" rel="noopener"
>Node.js from here&lt;/a>.&lt;/p>
&lt;p>With those in place I navigated to the directory holding my files in Visual Studio Code and pressed F1 and started typing azure terraform and chose Azure Terraform Init&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-39.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-39.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I was then prompted to use Cloud Shell and a browser opened to login. Once I had logged in I waited until I saw this&lt;/p>
&lt;p>&lt;a class="link" href="blob:https://blog.robsewell.com/787b935b-930a-45c4-ac43-18a18193e01f" >&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-40.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I press F1 again and this time choose Azure Terraform plan. This is going to show me what Terraform is going to do if it applies this configuration.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-41.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-41.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see the what is going to be created. It is going to create 3 things&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-42.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-42.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Once you have checked that the plan is what you want, press F1 again and choose Azure Terraform Apply&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-43.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-43.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You are then asked to confirm that this is what you want. Only “yes” will be accepted. Then you will see the infrastructure being created&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-44.png"
loading="lazy"
>&lt;/p>
&lt;p>and a minute later&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-45.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-45.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and Jeremy exists in the beardrules resource group&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then once I have finished with using the sqlinstance. I can press F1 again and choose Azure Terraform Destroy. Again there is a confirmation required.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-47.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-47.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and you will see the progress for 46 seconds&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-50.png"
loading="lazy"
>&lt;/p>
&lt;p>and all of the resources have gone.&lt;/p>
&lt;p>Thats a good start. This enables me to create resources quickly and easily and keep the configuration for them safely in source control and easy to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>In my next post I will create an Azure DevOps pipeline to deploy an AZure SQL Db withTerraform&lt;/a>.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>The post after will show how to use Azure DevOps Task Groups to use the same build steps in multiple pipelines and build an Azure Linux SQL Server VM&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/" target="_blank" rel="noopener"
>The post after that will show how to use Azure DevOps templates to use the same build steps across many projects and build pipelines and will build a simple AKS cluster&lt;/a>&lt;/p></description></item><item><title>Deploying a Windows Data Science Virtual Machine to Azure with PowerShell easily</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-windows-data-science-virtual-machine-to-azure-with-powershell-easily/</link><pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-windows-data-science-virtual-machine-to-azure-with-powershell-easily/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png" alt="Featured image of post Deploying a Windows Data Science Virtual Machine to Azure with PowerShell easily" />&lt;p>This weekend (10 December 2016), I went to Slovenia for a &lt;a class="link" href="http://www.sqlsaturday.com/567/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday&lt;/a>. As always, it was an amazing event well organised by &lt;a class="link" href="https://twitter.com/MladenPrajdic" target="_blank" rel="noopener"
>Mladen Prajdic&lt;/a>, &lt;a class="link" href="http://sqlblog.com/blogs/dejan_sarka/default.aspx" target="_blank" rel="noopener"
>Dejan Sarka&lt;/a>, and &lt;a class="link" href="https://twitter.com/MatijaLah" target="_blank" rel="noopener"
>Matija Lah&lt;/a> in a fabulous setting amongst fabulous scenery. I highly recommend it and, also, &lt;a class="link" href="https://en.wikipedia.org/wiki/Ljubljana" target="_blank" rel="noopener"
>Ljubljana&lt;/a>  is a wonderful place to be in December with all the lights and markets.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/wp_20161209_19_21_06_pro.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/wp_20161209_19_21_06_pro.jpg"
loading="lazy"
alt="WP_20161209_19_21_06_Pro.jpg"
>&lt;/a>&lt;/p>
&lt;p>Whilst I was there I was asked by someone if you could deploy data science virtual machines in Azure with PowerShell. I said I was sure that it could be done and agreed I would write a blog post, so here it is.&lt;/p>
&lt;p>According to the &lt;a class="link" href="https://azure.microsoft.com/en-gb/marketplace/partners/microsoft-ads/standard-data-science-vm/" target="_blank" rel="noopener"
>Azure documentation&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>The Data Science Virtual Machine running on a Windows Server 2012 contains popular tools for data exploration, modeling and development activities. The main tools include Microsoft R Server Developer Edition (An enterprise ready scalable R framework) , Anaconda Python distribution, Jupyter notebooks for Python and R, Visual Studio Community Edition with Python, R and node.js tools, Power BI desktop, SQL Server 2016 Developer edition including support In-Database analytics using Microsoft R Server. It also includes open source deep learning tools like Microsoft Cognitive Toolkit (CNTK 2.0) and mxnet; ML algorithms like xgboost, Vowpal Wabbit. The Azure SDK and libraries on the VM allows you to build your applications using various services in the cloud that are part of the Cortana Analytics Suite which includes Azure Machine Learning, Azure data factory, Stream Analytics and SQL Datawarehouse, Hadoop, Data Lake, Spark and more.&lt;/p>
&lt;/blockquote>
&lt;p>I have created a function to wrap around the process to make it easier for none PowerShell  people to do this. There are a series of steps to follow below and you should be able to create a machine in about 10 minutes once you have completed the pre-requisites.&lt;/p>
&lt;h2 id="enable-programmatically-deployment">Enable Programmatically Deployment&lt;/h2>
&lt;p>First, an annoyance. To be able to deploy Data Science virtual machines in Azure programmatically  you first have to login to the portal and click some buttons.&lt;/p>
&lt;p>In the &lt;a class="link" href="https://portal.aure.com" target="_blank" rel="noopener"
>Portal&lt;/a> click new and then marketplace and then search for data science. Choose the Windows Data Science Machine and under the blue Create button you will see a link which says “Want to deploy programmatically? Get started” Clicking this will lead to the following blade.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/set-up-programmatically1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/set-up-programmatically1.png"
loading="lazy"
alt="set-up-programmatically"
>&lt;/a>&lt;/p>
&lt;p>Click Enable and then save and you then move to PowerShell 🙂&lt;/p>
&lt;h2 id="azure-powershell-cmdlets">Azure PowerShell Cmdlets&lt;/h2>
&lt;p>Follow the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/azureps-cmdlets-docs/" target="_blank" rel="noopener"
>here&lt;/a> to install the Azure PowerShell modules. In the examples you see here I am using Windows 10 and PowerShell version 5.1.14393.479 and I installed the Azure modules using the Install-Module method&lt;/p>
&lt;h2 id="get-the-script">Get the script&lt;/h2>
&lt;p>To install a data science VM, we’ll use the &lt;code>New-WindowsDataScienceVM.ps1&lt;/code> script. In this script, I’m using version 1.2, but any version of this script published in PowerShell Gallery is fine.&lt;/p>
&lt;p>To install the &lt;code>New-WindowsDataScienceVM&lt;/code> script from the PowerShell gallery, type:&lt;/p>
&lt;p>&lt;code>Install-Script New-WindowsDataScienceVM&lt;/code>&lt;/p>
&lt;p>For  more information about using the PowerShellGet cmdlets to install scripts and modules from PowerShell Gallery, &lt;a class="link" href="https://msdn.microsoft.com/powershell/gallery/readme" target="_blank" rel="noopener"
>read this page&lt;/a>. The PowerShellGet modules is included in PowerShell 5.0 and later on Windows 10, but you can install PowerShellGet for PowerShell 3.0 and 4.0. If you cannot connect to the gallery or prefer not to install the module, you can also find the &lt;a class="link" href="https://raw.githubusercontent.com/SQLDBAWithABeard/DataScienceVM/master/New-WindowsDataScienceVM.ps1" target="_blank" rel="noopener"
>script on GitHub&lt;/a>.&lt;/p>
&lt;h2 id="login-to-azure">Login to Azure&lt;/h2>
&lt;p>You can login to Azure using the command&lt;/p>
&lt;p>&lt;code>Login-AzureRMAccount&lt;/code>&lt;/p>
&lt;p>which will pop-up a prompt for you to log into Azure&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login.png"
loading="lazy"
alt="login"
>&lt;/a>&lt;/p>
&lt;h2 id="enable-simple-mode">Enable Simple Mode&lt;/h2>
&lt;p>The &lt;code>New-WindowsDataScienceVM&lt;/code> function comes with a &lt;strong>Simple&lt;/strong> switch parameter.&lt;/p>
&lt;p>If you use &lt;strong>-Simple&lt;/strong>, the function prompts you only for the admin username and password for the virtual machine. It creates a randomly-named, standard_DS1_v2-sized machine in the ukwest data centre with standard, locally redundant storage in a randomly named Resource Group. All of the required objects have random names, too. If that is not what you want, there is more information at the end of this post. I am considering offering a pop-up to choose location in Simple Mode. Let me know here if that would be something you would like&lt;/p>
&lt;p>To create a simple data science VM, run:&lt;/p>
&lt;p>&lt;code>New-WindowsDataScienceVM -Simple&lt;/code>&lt;/p>
&lt;h2 id="enter-local-admin-password">Enter Local Admin Password&lt;/h2>
&lt;p>When you run the function, it prompts for a local admin username and password to log into the virtual machine. The password must have 3 of the following 1 Upper case, 1 lower case, I special character and 1 number. Don’t lose it, you will need it.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/local-admin.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/local-admin.png"
loading="lazy"
alt="Local Admin.PNG"
>&lt;/a>&lt;/p>
&lt;p>Grab a cuppa, creating your VM and its resources will take 5 – 10 minutes. (In my testing it reliably took between 7 and 8 minutes)  The screen will look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/deploying.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/deploying.png"
loading="lazy"
alt="deploying.PNG"
>&lt;/a>&lt;/p>
&lt;p>When the script has finished running you will have deployed a set of resources like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/portal.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/portal.png"
loading="lazy"
alt="portal"
>&lt;/a>&lt;/p>
&lt;h2 id="login-to-the-virtual-machine">Login to the Virtual Machine&lt;/h2>
&lt;p>Copy and paste the correct code from the output at the end of the script to launch the RDP session and save the RDP file to your documents folder for later use.&lt;/p>
&lt;p>Or you can find the Virtual machine name in the portal or by running&lt;/p>
&lt;p>&lt;code>Get-AzureRmVM -ResourceGroupName &amp;lt;ResourceGroup&amp;gt; | Where-Object {$_.Name -like 'DSVM*'}&lt;/code>&lt;/p>
&lt;p>You can then use the code below to download a RDP file and log into the virtual machine using this code&lt;/p>
&lt;p>&lt;code>Get-AzureRmRemoteDesktopFile -ResourceGroupName &amp;lt;ResourceGroup&amp;gt; -Name &amp;lt;VMName&amp;gt;  -LocalPath C:\WIP\DataScienceVM.rdp -Launch&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png"
loading="lazy"
alt="rdp file.PNG"
>&lt;/a>&lt;/p>
&lt;p>You will need to login with the local admin account you set up previously, which means that you will need to click on more choices and then the &lt;code>machinename\Username&lt;/code>. In this case the machine name is &lt;code>DSVMZIAgd&lt;/code>&lt;/p>
&lt;p>You can copy the correct Virtual Machine name and Username from the output at the end of the script.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login-screen.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login-screen.png"
loading="lazy"
alt="login screen.PNG"
>&lt;/a>&lt;/p>
&lt;p>If you have forgotten your password, you can reset it in the Portal.&lt;/p>
&lt;h2 id="enjoy-the-data-science-virtual-machine">Enjoy the Data Science Virtual Machine&lt;/h2>
&lt;p>You are then logged in and can carry on. Once the Azure PowerShell modules and script are installed you would be able to have a machine up and running within 10 minutes.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/vm-desktop.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/vm-desktop.png"
loading="lazy"
alt="vm-desktop"
>&lt;/a>&lt;/p>
&lt;h2 id="cleaning-up">Cleaning Up&lt;/h2>
&lt;p>To remove the resource group and ALL resources in the resource group, including the data science VM, run:&lt;/p>
&lt;p>&lt;code>Remove-AzureRmResourceGroup -Name &amp;lt;ResourceGroup&amp;gt;  -Force&lt;/code>&lt;/p>
&lt;p>This will remove ALL resources in that resource group, so be careful if you have deployed anything else.&lt;/p>
&lt;h2 id="customising-the-deployment">Customising the Deployment&lt;/h2>
&lt;p>If you want to use different settings for the deployment or want to script the creation of a number of machines, you can run&lt;/p>
&lt;p>&lt;code>Get-Help New-WindowsDataScienceVM -Full&lt;/code>&lt;/p>
&lt;p>and see all the options and further examples. Any questions please feel free to comment&lt;/p></description></item><item><title>Backing up to URL container name – case is important</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-to-url-container-name-case-is-important/</link><pubDate>Thu, 03 Mar 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-to-url-container-name-case-is-important/</guid><description>&lt;p>If you use &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn435916.aspx" target="_blank" rel="noopener"
>SQL Backup to URL&lt;/a> to backup your databases to Azure blob storage remember that for the container name case is important&lt;/p>
&lt;p>So&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">BACKUP LOG [DatabaseName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TO URL = N&amp;#39;https://storageaccountname.blob.core.windows.net/containername/databasename_log_dmmyyhhss.trn&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CHECKSUM, NO_COMPRESSION, CREDENTIAL = N&amp;#39;credential&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>will work but&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">BACKUP LOG [DatabaseName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TO URL = N&amp;#39;https://storageaccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CHECKSUM, NO_COMPRESSION, CREDENTIAL = N&amp;#39;credential&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>will give an (400) Bad Request Error which may not be easy to diagnose&lt;/p>
&lt;blockquote>
&lt;p>Msg 3271, Level 16, State 1, Line 1
A nonrecoverable I/O error occurred on file &amp;ldquo;&lt;a class="link" href="https://storageacccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn%27:%22" target="_blank" rel="noopener"
>https://storageacccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn':"&lt;/a> Backup to URL received an exception from the remote endpoint.
Exception Message: The remote server returned an error: (400) Bad Request..
Msg 3013, Level 16, State 1, Line 1
BACKUP LOG is terminating abnormally.&lt;/p>
&lt;/blockquote>
&lt;p>If you are using Ola Hallengrens jobs to perform your backup then your job step will look like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">sqlcmd -E -S $(ESCAPE_SQUOTE(SRVR)) -d DBA-Admin -Q &amp;#34;EXECUTE [dbo].[DatabaseBackup] @Databases = &amp;#39;USER_DATABASES&amp;#39;,&amp;amp;nbsp; @URL = &amp;#39;https://storageaccountname.blob.core.windows.net/containername&amp;#39;, @Credential = &amp;#39;credential&amp;#39;, @BackupType = &amp;#39;LOG&amp;#39;, @ChangeBackupType = &amp;#39;Y&amp;#39;, @Verify = &amp;#39;Y&amp;#39;, @CheckSum = &amp;#39;Y&amp;#39;, @LogToTable = &amp;#39;Y&amp;#39;&amp;#34; -b
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Note the &lt;code>@ChangeBackupType = ‘Y’&lt;/code> parameter which is not created by default but I think is very useful. If you have just created a database and take log backups every 15 minutes but differential (or full) every night the log backup will fail until a full backup has been taken. This parameter will check if a log backup is possible and if not take a full backup meaning that you still can keep to your RTO/RPO requirements even for newly created databases&lt;/p></description></item><item><title>Using Power Bi with my DBA Database</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-power-bi-with-my-dba-database/</link><pubDate>Sun, 16 Aug 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-power-bi-with-my-dba-database/</guid><description>&lt;p>Every good DBA should have a DBA database. A place to store information about all of their instances and databases.&lt;/p>
&lt;p>I have an InstanceList table which looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbo].[InstanceList](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerName] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceName] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Port] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AG] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Inactive] [bit] NULL CONSTRAINT [DF_InstanceList_Inactive] DEFAULT ((0)),
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Environment] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Location] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_InstanceList_ID] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I use this as the basis for all of my information gathering. By adding Server name, Instance Name , Port, Environment and Location to the table I use overnight Agent jobs to run PowerShell scripts to gather information about all of the instances. This way the information is dynamic and gathered from the server, so when we add RAM and change Max memory this is updated the next time the script runs. You can also automate your installation and decommission procedures (using PowerShell scripts) to add the information to the DBA database automatically&lt;/p>
&lt;p>I have 4 scripts&lt;/p>
&lt;ul>
&lt;li>ServerInfo which gathers Windows OS information such as Version and edition of the operating system, number of processors,amount of RAM, IP address, domain name etc&lt;/li>
&lt;li>SQLInfo which gathers information about the instance such as SQL version, edition, collation, max and min memory, MAXDOP , service accounts and start modes, default file locations etc&lt;/li>
&lt;li>Database information such as size, data usage, index usage, last backup dates, owner and many more&lt;/li>
&lt;li>Agent Job which gathers the outcome of the jobs that have run, their names, category into two tables one for a server rollup and one for details about each job&lt;/li>
&lt;/ul>
&lt;p>Recently I have received a lot of requests for information from various sources, auditors asking about encryption and backup policies, Project managers asking about database and sql versions, compliance asking about numbers of Windows 2003 servers or SQL 2005 servers, system teams asking which serves in a particular location can be turned off at which time dependant on which system they are supporting for a power down&lt;/p>
&lt;p>Before we had the DBA database holding all of the information about the instances we would have struggled to be able to compile this information and when I saw Power Bi was released to GA I thought that it would be a good place to start to learn about it. By using data that I understood and answering questions that I knew the format of the answer I could be more confident about experimenting - ie. if I know I have 100 servers then any result for servers that exceeds that is incorrect&lt;/p>
&lt;p>I have never been a BI guy, I claim no expertise in the correct methods of manipulating the data. There may very well be better methods of achieving these results and if there please feel free to comment below so that I can improve my knowledge and keep on learning&lt;/p>
&lt;p>All data shown in the examples below has been generated from real-life data but all identifiable data has been altered or removed. I have no servers in Bolton, it is where I am from originally!!&lt;/p>
&lt;p>I downloaded Power BI Desktop from powerbi.com and ran the installer and the first screen you see is this one&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>I then clicked on Get Data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/2.png?w=276"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>And then SQL Server and filled in the details for my DBA Database and clicked connect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>I used my current Windows credentials&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>It then asked me which tables I wanted to load so I said all of them :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/5.png?w=195"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>Once I had loaded the data I looked at the queries and renamed some of the columns to make more sense to me. I also created some calculated columns by clicking New Column&lt;/p>
&lt;p>I created a relative date column using this code from Chris Webb &lt;a class="link" href="http://blog.crossjoin.co.uk/2013/01/24/building-relative-date-reports-in-powerpivot/" target="_blank" rel="noopener"
>http://blog.crossjoin.co.uk/2013/01/24/building-relative-date-reports-in-powerpivot/&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Relative Date Offset=INT([Date] – TODAY()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Relative Date=IF([Relative Date Offset]=0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, &amp;#34;Today&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, &amp;#34;Today &amp;#34; &amp;amp; IF([Relative Date Offset]&amp;gt;0, &amp;#34;+&amp;#34;, &amp;#34;&amp;#34;) &amp;amp; [Relative Date Offset])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This will enable me to show data for the last day&lt;/p>
&lt;p>I also did the same for days of the week&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayOfWeek = CONCATENATE(WEEKDAY(&amp;#39;Info AgentJobDetail&amp;#39;[LastRunTime],2),FORMAT(&amp;#39;InfoAgentJobDetail&amp;#39;[LastRunTime],&amp;#34; -dddd&amp;#34;))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Because I struggled to show the information about the Operating system I also created two columns for OS name and OS edition by adding columns as shown below&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Version = SWITCH(&amp;#39;Info ServerOSInfo&amp;#39;[OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;Server 2012 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Edition = SWITCH(&amp;#39;Info ServerOSInfo&amp;#39;[OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then I started to play with the data.&lt;/p>
&lt;p>This is probably not how a professional would phrase it but I would say that if you don&amp;rsquo;t know how to use a new application be brave and give it a try.&lt;/p>
&lt;p>&lt;strong>OBVIOUSLY&lt;/strong> you are a &lt;strong>PROFESSIONAL DBA&lt;/strong> and will not do anything that would endanger production, use a backup of your database and work locally if you need to.&lt;/p>
&lt;p>The first thing I wanted to know was how many servers I had by operating system, how many by SQL version and the location of them so that I could answer the questions I had been asked. I had already written a query to get the correct information to give to the requestors so I knew the correct answers which was also an advantage. I did this like this&lt;/p>
&lt;p>I expanded the Info ServerOSInfo query and dragged the ServerName field to the report which created a table of names&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I then changed the ServerName values to Count&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>I then dragged the calculated column Operating System Version to the table&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>If I click on the table and then donut chart in the visualisations it changes to&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/9.png?w=300"
loading="lazy"
alt="9"
>&lt;/a>&lt;/p>
&lt;p>So you can quickly see how you want the data displayed&lt;/p>
&lt;p>I then decided to look at the number of SQL 2005 instances that I had and as I had relationships between SQLInfo and Instancelist and Clients I could build a more dynamic report.&lt;/p>
&lt;p>I created a donut chart with SQLVersion as the legend and InstanceID as the values and a table of SQLVersion, ServerName and Instance Name. I also created a card that was count of InstanceID&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/10.png?w=300"
loading="lazy"
alt="10"
>&lt;/a>&lt;/p>
&lt;p>Now it starts getting really useful. If I want to know how many SQL 2005 instances I have I simply click on SQL2005 in the donut chart and the rest of the report changes&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/11.png?w=300"
loading="lazy"
alt="11"
>&lt;/a>&lt;/p>
&lt;p>This is very cool and I hope you can see how useful this could be and how brilliant it would be to enable relevant people within the organisation the ability to look at that report and answer their own questions.&lt;/p>
&lt;p>Lets take it to the next step. I have a location column in the InstanceList table which comprises of town names. If I choose a map and drag that column to the Location field and set Values and Color Saturation to the Count of InstanceID&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/12.png?w=166"
loading="lazy"
alt="12"
>&lt;/a>&lt;/p>
&lt;p>and create two tables one of client with a count of instanceid and one location with a count of instance id I can do this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/13.png?w=300"
loading="lazy"
alt="13"
>&lt;/a>&lt;/p>
&lt;p>Look at how it dynamically changes as you click on the data labels - This is very cool and makes me smile every time!! I altered the colour saturation colours to make it easier to see. Now if I am asked about SQL 2005 servers I can quickly click on SQL 2005 and&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/14.png?w=300"
loading="lazy"
alt="14"
>&lt;/a>&lt;/p>
&lt;p>I can see that there are 32 instances, most are in Southampton, and which clients they support&lt;/p>
&lt;p>If I click a location rather than SQL version the report alters like so&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/15.png?w=300"
loading="lazy"
alt="15"
>&lt;/a>&lt;/p>
&lt;p>So you can simply pass the report file to your colleagues to enable them to use it or you can publish it to Powerbi.com. &lt;a class="link" href="https://support.powerbi.com/knowledgebase/articles/685479-power-bi-pro-content-what-is-it?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>I am not going to go into any detail about the costs or licensing etc&lt;/a> I will just say it is as easy as clicking publish. If you wish to have the information automatically refreshed there are some &lt;a class="link" href="http://biinsight.com/power-bi-personal-gateway-five-things-you-must-know/" target="_blank" rel="noopener"
>more steps that you would need to go through which are detailed here which enable you to connect your on-premise database to Powerbi using the data management gateway&lt;/a>, alternatively you can simply refresh the data in the report and then publish it and replace the existing report.&lt;/p>
&lt;p>Once the report is in powerbi.com you can enable Q and A on the data. This is some kind of supernatural mystical magical query language which enables you to query your data with natural language and will alter the results as you type and even cope with (deliberate for screenshot) spelling mistakes :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/16.png?w=300"
loading="lazy"
alt="16"
>&lt;/a>&lt;/p>
&lt;p>I also created a report for my Agent Jobs to enable me to quickly and easily see which Jobs have failed in the last day&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/17.png?w=300"
loading="lazy"
alt="17"
>&lt;/a>&lt;/p>
&lt;p>I did this by filtering the report by Relative Date Offset greater than -1 (today) and &lt;code>isenabled = True&lt;/code> and &lt;code>Outcome = Failed&lt;/code>&lt;/p>
&lt;p>There are many many more ways I can see this being useful and I hope I have given you some ideas and encouraged you to try for yourself and find out more&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Setting Up and Using Azure VM SQL Automated Backup (and Restore)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</link><pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</guid><description>&lt;p>This weekend I was creating some Azure VMs to test and was required to use the GUI for some screenshots. I have always used my PowerShell scripts &lt;a class="link" href="http://sqldbawithabeard.com/2013/05/14/spinning-up-and-shutting-down-windows-azure-lab-with-PowerShell/" target="_blank" rel="noopener"
>described here&lt;/a> to create my test systems and with a new job taking up a lot of my time had missed the &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>announcement about Azure SQL Automated Backup and Azure SQL Automated Patching&lt;/a> so was surprised to see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>I read the announcement and also the details on MSDN &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx&lt;/a> which show that this requires the SQL Server IaaS Agent. This is a default option on new virtual machines.&lt;/p>
&lt;p>There are some other considerations too. It is only supported for SQL Server 2014 and Windows Server 2012 and 2012R2 at present and you can set a retention period to a maximum of 30 days but it is automated. You do not have to decide upon the backup strategy Azure will decide the frequency and type of backups dependent upon the workload of the database and some other factors such as&lt;/p>
&lt;p>A full backup is taken ○ when an instance is added to use Managed backup ○ When transaction log growth is 1Gb or more ○ At least once a week ○ If the log chain is broken ○ When a database is created&lt;/p>
&lt;p>A transaction log backup is taken - If no log backup is found - Transaction log space used is 5Mb or larger - At least once every two hours - Any time the transaction log backup is lagging behind a full database backup. The goal is to keep the log chain ahead of full backup.&lt;/p>
&lt;p>From &lt;a class="link" href="https://msdn.microsoft.com/en-gb/library/dn449496%28v=sql.120%29.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-gb/library/dn449496(v=sql.120).aspx&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>There are some restrictions - Only database backups are supported - System databases are not supported so you need to back those up yourself - You can only back up to Azure storage - Maximum backup size is 1Tb as this is the maximum size for a blob in Azure storage - Simple recovery is not supported - Maximum retention is 30 days - if you are required to keep your backups for longer than 30 days for regulatory or other reasons you could simply use Azure Automation to copy the files to another storage account in Azure)&lt;/p>
&lt;/blockquote>
&lt;p>How to set it up.&lt;/p>
&lt;p>If you are using the GUI then you will find SQL Automated Backup in the optional config blade of the set up. You can follow the steps &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here to set it up&lt;/a>. If (like me) you want to use PowerShell then use the following code after you have created your Virtual Machine&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$storageaccount = &amp;#34;&amp;lt;storageaccountname&amp;gt;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storageaccountkey = (Get-AzureStorageKey -StorageAccountName $storageaccount).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storagecontext = New-AzureStorageContext -StorageAccountName $storageaccount -StorageAccountKey $storageaccountkey
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$encryptionpassword = (Get-Credential -message &amp;#39;Backup Encryption Password&amp;#39; -User &amp;#39;IGNOREUSER&amp;#39;).password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$autobackupconfig = New-AzureVMSqlServerAutoBackupConfig -StorageContext $storagecontext -Enable -RetentionPeriod 10 -EnableEncryption -CertificatePassword $encryptionpassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-AzureVM -ServiceName &amp;lt;vmservicename&amp;gt; -Name &amp;lt;vmname&amp;gt; | Set-AzureVMSqlServerExtension -AutoBackupSettings $autobackupconfig | Update-AzureVM
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once you have run the code, Azure will take care of the rest. Add a couple of databases to your instance and look in the storage account and you will see this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>And in the automaticbackup container you will find the Certificates and master key backups&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>It will also create a credential&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/5.png"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>You can use the same credential to back up your system databases. If like me you use &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>Ola Hallengrens excellent Maintenance Solution&lt;/a> then simply change your systems backup job as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [msdb]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EXEC msdb.dbo.sp_update_jobstep @job_name = &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL&amp;#39;, @step_id=1 ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @command=N&amp;#39;sqlcmd -E -S $(ESCAPE_SQUOTE(SRVR)) -d master -Q &amp;#34;EXECUTE [dbo].[DatabaseBackup] @Databases = &amp;#39;&amp;#39;SYSTEM_DATABASES&amp;#39;&amp;#39;, &amp;#34;https://myaccount.blob.core.windows.net/mycontainer&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> , @Credential = &amp;#39;&amp;#39;AutoBackup_Credential&amp;#39;&amp;#39;, @BackupType = &amp;#39;&amp;#39;FULL&amp;#39;&amp;#39;, @Verify = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @CleanupTime = NULL, @CheckSum = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @LogToTable = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;&amp;#34; -b&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you need to restore your database then you can use the GUI and when you choose restore you will see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>Enter your storage account and the key which you can get from the Azure portal. You will notice that the credential has already been selected, click connect and&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>There are all of your backups ready to restore to any point in time that you choose. By clicking script the T-SQL is generated which looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [master]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BACKUP LOG [Test] TO URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_LogBackup_2015-07-16_06-21-26.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOFORMAT, NOINIT, NAME = N&amp;#39;Test_LogBackup_2015-07-16_06-21-26&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOSKIP, NOREWIND, NOUNLOAD, NORECOVERY , STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE DATABASE [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714201240+00.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714202740+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714224241+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715005741+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715031242+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715052742+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715074243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715095743+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715121243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150716060004+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is an important note. Remember this when you have just set it up so that you don’t think that you have done it wrong (which is what I did!)&lt;/p>
&lt;p>When you enable Automated Patching for the first time, Azure configures the SQL Server IaaS Agent in the background. During this time, the portal will not show that Automated Patching is configured. Wait several minutes for the agent to be installed, configured. After that the portal will reflect the new settings.&lt;/p>
&lt;p>From &amp;lt;&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx&lt;/a>&amp;gt;&lt;/p>
&lt;p>And also look out for this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>The password I had chosen was not complex enough but the PowerShell script had succeeded and not given me the warning&lt;/p>
&lt;p>To set up SQL Automated Patching you follow a similar steps. The setting is again on the OS Config blade and click enable and then you can choose the frequency and duration of the patching.&lt;/p>
&lt;p>It is important to remember to choose your maintenance window correctly. If you have set up your SQL VMs correctly you will have them in an availability set and be using either mirroring or Availability Groups and have the VMs set up in the same availability set to ensure availability during the underlying host patching but I had it confirmed by Principal Software Engineering Manager Sethu Srinivasan &lt;a class="link" href="http://twitter.com/sethusrinivasan" target="_blank" rel="noopener"
>t&lt;/a> via Microsoft PFE Arvind Shyamsundar &lt;a class="link" href="http://blogs.msdn.com/b/arvindsh/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/arvisam" target="_blank" rel="noopener"
>t&lt;/a> that the SQL Automated Patching is not HA aware so you will need to ensure that you set the maintenance windows on each VM to ensure that they do not overlap&lt;/p></description></item><item><title>Uploading a Source Folder to Azure File Storage</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</link><pubDate>Sun, 01 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</guid><description>&lt;p>Azure File Storage enables you to present an Azure Storage Account to your IaaS VMs as a share using SMB. You can fid out further details here&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/%c2%a0" title="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/ "
target="_blank" rel="noopener"
>http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/&lt;/a> &lt;/p>
&lt;p>Once you have created your Azure File Storage Account and connected your Azure Virtual Machines to it, you may need to upload data from your premises into the storage to enable it to be accessed by the Virtual Machines&lt;/p>
&lt;p>To accomplish this I wrote a function and called it Upload-ToAzureFileStorage&lt;/p>
&lt;p>I started by creating a source folder and files to test&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\b -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\c -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\d -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we needed to connect to the subscription, get the storage account access key and create a context to store them&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#Select Azure Subscription
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Select-AzureSubscription -SubscriptionName $AzureSubscriptionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get the Storage Account Key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StorageAccountKey = (Get-AzureStorageKey -StorageAccountName $StorageAccountName).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># create a context for account and key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ctx=New-AzureStorageContext $StorageAccountName $StorageAccountKey
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806403.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Get-AzureStorageShare  cmdlet&lt;/a> shows the shares available for the context so we can check if the share exists&lt;/p>
&lt;p>&lt;code>$S = Get-AzureStorageShare -Context $ctx -ErrorAction SilentlyContinue|Where-Object {$\_.Name -eq $AzureShare}&lt;/code>&lt;/p>
&lt;p>and if it doesnt exist create it using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806378.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageShare&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$s = New-AzureStorageShare $AzureShare -Context $ctx
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>For the sake only of doing it a different way we can check for existence of the directory in Azure File Storage that we are going to upload the files to like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = Get-AzureStorageFile -Share $s -ErrorAction SilentlyContinue|select Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($d.Name -notcontains $AzureDirectory)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and if it doesnt exist create it using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = New-AzureStorageDirectory -Share $s -Path $AzureDirectory
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now that we have the directory created in the storage account we need to create any subfolders. First get the folders&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\# get all the folders in the source directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Folders = Get-ChildItem -Path $Source -Directory -Recurse
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can then iterate through them using a foreach loop. If we do this and select the FullName property the results will be&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">C:\\temp\\TestUpload\\New1 C:\\temp\\TestUpload\\New2 C:\\temp\\TestUpload\\New3 C:\\temp\\TestUpload\\New4 C:\\temp\\TestUpload\\New5 C:\\temp\\TestUpload\\New1\\list C:\\temp\\TestUpload\\New1\\list\\a C:\\temp\\TestUpload\\New1\\list\\b C:\\temp\\TestUpload\\New1\\list\\c C:\\temp\\TestUpload\\New1\\list\\d C:\\temp\\TestUpload\\New1\\list\\a\\1 C:\\temp\\TestUpload\\New1\\list\\a\\2 C:\\temp\\TestUpload\\New1\\list\\a\\3 C:\\temp\\TestUpload\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>but to create new folders we need to remove the &lt;code>&amp;quot;C:\\temp\\TestUpload&amp;quot;&lt;/code> and replace it with the Directory name in Azure. I chose to do this as follows using the substring method and the length of the source folder path.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach($Folder in $Folders)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($Folder.FullName).Substring(($source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and tested that the results came out as I wanted&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">AppName\\New1 AppName\\New2 AppName\\New3 AppName\\New4 AppName\\New5 AppName\\New1\\list AppName\\New1\\list\\a AppName\\New1\\list\\b AppName\\New1\\list\\c AppName\\New1\\list\\d AppName\\New1\\list\\a\\1 AppName\\New1\\list\\a\\2 AppName\\New1\\list\\a\\3 AppName\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I could then create the new folders in azure using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a> again&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-AzureStorageDirectory -Share $s -Path $Path -ErrorAction SilentlyContinue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I followed the same process with the files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$files = Get-ChildItem -Path $Source -Recurse -File&amp;lt;/pre&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;pre&amp;gt;foreach($File in $Files)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($file.FullName).Substring(($Source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then created the files using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806404.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Set-AzureStorageFileContent&lt;/a> this has a -Force and a -Confirm switch and I added those into my function by using a [switch] Parameter&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#upload the files to the storage
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Confirm)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Confirm
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Force
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can download the function from the Script Center&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe&lt;/a>&lt;/p>
&lt;p>As also, any comments or queries are welcome and obviously the internet lies so please understand and test all code you find before using it in production&lt;/p></description></item><item><title>A look at the SQL Assessment Intelligence Pack in Operational Insights</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-look-at-the-sql-assessment-intelligence-pack-in-operational-insights/</link><pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-look-at-the-sql-assessment-intelligence-pack-in-operational-insights/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/11/opsman1.jpg" alt="Featured image of post A look at the SQL Assessment Intelligence Pack in Operational Insights" />&lt;p>Operational Insights is a service that has been added in preview to Azure. It enables you to collect, combine, correlate and visualize all your machine data in one place. It can collect data from all of your machines either via SCOM or by using an agent. Once the data is collected Operational Insights has a number of Intelligence Packs which have pre-configured rules and algorithms to provide analysis in various areas including for SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-gb/services/operational-insights/" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-gb/services/operational-insights/&lt;/a>&lt;/p>
&lt;p>I thought I would take a look. I have an installation of SCOM in my lab on my laptop and I read the instructions to see how to connect it to Operational Insights. (You don’t have to have a SCOM installation to use Operational insights you can make use of an agent as well just follow the steps from the page below)&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-us/trial/operational-insights-get-started/" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-us/trial/operational-insights-get-started/&lt;/a>&lt;/p>
&lt;p>It really is very simple&lt;/p>
&lt;p>If you have an Azure subscription already you can sign into the portal and join the preview program by clicking&lt;/p>
&lt;p>New –&amp;gt; App Services –&amp;gt; Operational Insights&lt;/p>
&lt;p>and create a new Operational Insights Workspace.&lt;/p>
&lt;p>Once you have done that, if you have an installation of SCOM 2012 you need to be running Service Pack 1 and download and install the System Center Operational Insights Connector for Operations Manager and import the MPB files into SCOM.&lt;/p>
&lt;p>If you have SCOM 2012R2 the connector is already installed and to connect your SCOM to Operational Insights is very very easy as you can see on&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-us/trial/operational-insights-get-started/?step2=withaccount&amp;amp;step3=SCOMcustomer" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-us/trial/operational-insights-get-started/?step2=withaccount&amp;amp;step3=SCOMcustomer&lt;/a>&lt;/p>
&lt;ol>
&lt;li>In the Operations Manager Console, click Administration.&lt;/li>
&lt;li>Under Administration, select System Center Advisor, and then click Advisor Connection.&lt;/li>
&lt;li>Click Register to Advisor Service.&lt;/li>
&lt;li>Sign in with your Microsoft or Organizational account.&lt;/li>
&lt;li>Choose an existing Operational Insights workspace from the drop down menu&lt;/li>
&lt;li>Confirm your changes.&lt;/li>
&lt;li>In the System Center Advisor Overview page, Under Actions, click Add a Computer/Group.&lt;/li>
&lt;li>Under Options, select Windows Server or All Instance Groups, and then search and add servers that you want data&lt;/li>
&lt;/ol>
&lt;p>That is it. No really, that is it. I was amazed how quickly I was able to get this done in my lab and it would not take very long in a large implementation of SCOM either as you will have your groups of computers defined which will make it easy to decide which groups to use. You could use a separate workspace for each type of server or split up the information per service. It really is very customisable.&lt;/p>
&lt;p>Once you have done that, go and add some of the Intelligence Packs. Each intelligence pack will change the amount  and type of data that is collected. At November 23rd there are&lt;/p>
&lt;ul>
&lt;li>Alert Management – for your SCOM Alerts&lt;/li>
&lt;li>Change Tracking – Tracking Configuration Changes&lt;/li>
&lt;li>Log Management – for event log collection and interrogation&lt;/li>
&lt;li>System Update Assessment – Missing Security Updates&lt;/li>
&lt;li>Malware Assessment – Status of Anti-Malware and Anti-Virus scans&lt;/li>
&lt;li>Capacity Planning – Identify Capacity and Utilisation bottlenecks&lt;/li>
&lt;li>SQL Assessment – The risk and health of SQL Server Environment&lt;/li>
&lt;/ul>
&lt;p>There are also two ‘coming soon’ Intelligence packs&lt;/p>
&lt;ul>
&lt;li>AD Assessment – Risk and health of Active Directory&lt;/li>
&lt;li>Security – Explore security related data and help identify security breaches&lt;/li>
&lt;/ul>
&lt;p>You then (if you are like me) have a period of frustration whilst you wait for all of the data to be uploaded and aggregated but once it is you sign into the Operational Insights Portal&lt;/p>
&lt;p>&lt;a class="link" href="https://preview.opinsights.azure.com" target="_blank" rel="noopener"
>https://preview.opinsights.azure.com&lt;/a> and it will look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman1.jpg"
loading="lazy"
alt="opsman1"
>&lt;/a>&lt;/p>
&lt;p>There is a lot of information there. As it is on my laptop and the lab is not running all of the time and is not connected to the internet most of the time I am not surprised that there are some red parts to my assessment!!&lt;/p>
&lt;p>Obviously I was interested in the SQL Assessment and I explored it a bit further&lt;/p>
&lt;p>Clicking on the SQL Assessment tile takes you to a screen which shows the SQL Assessment broken down into 6 Focus areas&lt;/p>
&lt;p>Security and Compliance, Availability and Business Continuity, Performance and Scalability, Upgrade, Migration and  Deployment, Operations and Monitoring and Change and Configuration Management. MSDN &lt;a class="link" href="http://msdn.microsoft.com/en-us/library/azure/dn873967.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/en-us/library/azure/dn873967.aspx&lt;/a> gives some more information about each one&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Security and Compliance&lt;/strong> – Safeguard the reputation of your organization by defending yourself from security threats and breaches, enforcing corporate policies, and meeting - technical, legal and regulatory compliance requirements.&lt;/li>
&lt;li>&lt;strong>Availability and Business Continuity&lt;/strong> – Keep your services available and your business profitable by ensuring the resiliency of your infrastructure and by having the right - level of business protection in the event of a disaster.&lt;/li>
&lt;li>&lt;strong>Performance and Scalability&lt;/strong> – Help your organization to grow and innovate by ensuring that your IT environment can meet current performance requirements and can respond - quickly to changing business needs.&lt;/li>
&lt;li>&lt;strong>Upgrade, Migration and Deployment&lt;/strong> – Position your IT department to be the key driver of change and innovation, by taking full advantage of new enabling technologies to - unlock more business value for organizational units, workforce and customers.&lt;/li>
&lt;li>&lt;strong>Operations and Monitoring&lt;/strong> – Lower your IT maintenance budget by streamlining your IT operations and implementing a comprehensive preventative maintenance program to - maximize business performance.&lt;/li>
&lt;li>&lt;strong>Change and Configuration Management&lt;/strong> – Protect the day-to-day operations of your organization and ensure that changes won’t negatively affect the business by establishing change control procedures and by tracking and auditing system configurations.&lt;/li>
&lt;/ul>
&lt;p>You will be able to see some dials showing you how well you are doing in each area for the servers whose data has been collected.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman2.jpg"
loading="lazy"
alt="opsman2"
>&lt;/a>&lt;/p>
&lt;p>Each area will have the High Priority Recommendations shown below the dial and you can click on them to see more information about those recommendations&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman3.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman3.jpg"
loading="lazy"
alt="opsman3"
>&lt;/a>&lt;/p>
&lt;p>You can also click the dial or the see all link to enter the search area where you can customise how you wish to see the data that has been collected, this looks a bit confusing at first&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman4.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman4.jpg"
loading="lazy"
alt="opsman4"
>&lt;/a>&lt;/p>
&lt;p>The top bar contains the search , the timescale and some buttons to save the search, view the saved searches and view the search history, all of which will be shown in the right hand column below&lt;/p>
&lt;p>The left column contains a bar graph for the search and all of the filters. The middle column contains the results of the search and can be viewed in list or tabular format and exported to CSV using the button below. A little bit of experimentation will give you a better understanding of how the filtering works and how you can make use of that for your environment&lt;/p>
&lt;p>By looking at the search for the Operations and Monitoring Focus Area shown above&lt;/p>
&lt;blockquote>
&lt;p>Type:SQLAssessmentRecommendation IsRollup=true RecommendationPeriod=2014-11 FocusArea=”Operations and Monitoring” RecommendationResult=Failed | sort RecommendationWeight desc&lt;/p>
&lt;/blockquote>
&lt;p>I saw that &lt;code>RecommendationResult=Failed&lt;/code> and changed it to &lt;code>RecommendationResult=Passed&lt;/code>. This enabled me to see all of the Recommendations that had been passed in the Focus Area and clicking the export button downloaded a csv file. I deleted &lt;code>RecommendationResult=Passed&lt;/code> from the search and that gave me all of the recommendations that made up that Focus Area&lt;/p>
&lt;ul>
&lt;li>Operations and Monitoring Focus Area&lt;/li>
&lt;li>Recommendation&lt;/li>
&lt;li>Enable Remote Desktop on servers.&lt;/li>
&lt;li>Enable Remote Desktop on virtual machines.&lt;/li>
&lt;li>Ensure computers are able to download updates.&lt;/li>
&lt;li>Configure event logs to overwrite or archive old events automatically.&lt;/li>
&lt;li>Review event log configuration to ensure event data is retained automatically. This relates to System Logs&lt;/li>
&lt;li>Review event log configuration to ensure event data is retained automatically. This relates to Application Logs&lt;/li>
&lt;/ul>
&lt;p>I decided then to do the same for each of the Focus Areas for the SQL Assessment Intelligence Pack&lt;/p>
&lt;p>Security and Compliance Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Change passwords that are the same as the login name.&lt;/li>
&lt;li>Remove logins with blank passwords.&lt;/li>
&lt;li>LAN Manager Hash for Passwords Stored&lt;/li>
&lt;li>Investigate why unsigned kernel modules were loaded.&lt;/li>
&lt;li>Apply security best practices to contained databases.&lt;/li>
&lt;li>Enable User Account control on all computers.&lt;/li>
&lt;li>Consider disabling the xp_cmdshell extended stored procedure.&lt;/li>
&lt;li>Implement Windows authentication on Microsoft Azure-hosted SQL Server deployments.&lt;/li>
&lt;li>Avoid using the Local System account to run the SQL Server service.&lt;/li>
&lt;li>Avoid adding users to the db_owner database role.&lt;/li>
&lt;li>Ensure only essential users are added to the SQL Server sysadmin server role.&lt;/li>
&lt;li>Disable SQL Server guest user in all user databases.&lt;/li>
&lt;li>Avoid running SQL Server Agent jobs using highly-privileged accounts.&lt;/li>
&lt;li>Configure the SQL Server Agent service to use a recommended account.&lt;/li>
&lt;li>Apply Windows password policies to SQL Server logins.&lt;/li>
&lt;li>Investigate failures to validate the integrity of protected files.&lt;/li>
&lt;li>Investigate failures to validate kernel modules.&lt;/li>
&lt;/ul>
&lt;p>Availability and Business Continuity Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Schedule full database backups at least weekly.&lt;/li>
&lt;li>Optimize your backup strategy with Microsoft Azure Blob Storage.&lt;/li>
&lt;li>Avoid using the Simple database recovery model.&lt;/li>
&lt;li>Ensure all installations of Windows are activated.&lt;/li>
&lt;li>Investigate logical disk errors.&lt;/li>
&lt;li>Reduce the maximum Kerberos access token size.&lt;/li>
&lt;li>Investigate connection failures due to SSPI context errors.&lt;/li>
&lt;li>Set the PAGE_VERIFY database option to CHECKSUM.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate a write error on a disk.&lt;/li>
&lt;li>Check the network access to Active Directory domain controllers.&lt;/li>
&lt;li>Review DNS configuration on non-DNS servers.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate memory dumps.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate why the computer shut down unexpectedly.&lt;/li>
&lt;li>Enable dynamic DNS registration for domain-joined servers.&lt;/li>
&lt;/ul>
&lt;p>Performance and Scalability Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Increase the number of tempdb database files.&lt;/li>
&lt;li>Configure the tempdb database to reduce page allocation contention.&lt;/li>
&lt;li>Ensure all tempdb database files have identical initial sizes and growth increments.&lt;/li>
&lt;li>Set autogrowth increments for database files and log files to fixed values rather than percentage values.&lt;/li>
&lt;li>Set autogrowth increments for transaction log files to less than 1GB.&lt;/li>
&lt;li>Modify auto-grow settings to use a fixed size growth increment of less than 1GB and consider enabling Instant File Initialization.&lt;/li>
&lt;li>Change your Affinity Mask and Affinity I/O MASK settings to prevent conflicts.&lt;/li>
&lt;li>Resolve issues caused by excessive virtual log files.&lt;/li>
&lt;li>Modify the database file layout for databases larger than 1TB.&lt;/li>
&lt;li>Set the AUTO_CLOSE option to OFF for frequently accessed databases.&lt;/li>
&lt;li>Review memory requirements on servers with less than 4GB of physical memory installed.&lt;/li>
&lt;li>Configure system SiteName properties to be dynamic.&lt;/li>
&lt;li>Align the Max Degree of Parallelism option to the number of logical processors.&lt;/li>
&lt;li>Align the Max Degree of Parallelism option to the number of logical processors.&lt;/li>
&lt;li>Consider disabling the AUTO_SHRINK database option.&lt;/li>
&lt;li>Review memory requirements on computers with high paging file use.&lt;/li>
&lt;li>Ensure SQL Server does not consume memory required by other applications and system components.&lt;/li>
&lt;li>Consider changing your power saving settings to optimize performance.&lt;/li>
&lt;li>Increase the initial size of the tempdb database.&lt;/li>
&lt;li>Review the configuration of Maximum Transfer Unit (MTU) size.&lt;/li>
&lt;li>Review your paging file settings.&lt;/li>
&lt;li>Review and optimize memory cache configuration.&lt;/li>
&lt;li>Review the configuration of Maximum Transfer Unit (MTU) size.&lt;/li>
&lt;li>Review the system processor scheduling mode.&lt;/li>
&lt;li>Review network provider ordering settings.&lt;/li>
&lt;li>Remove invalid entries from the PATH environment variable.&lt;/li>
&lt;li>Remove network entries from the PATH environment variable.&lt;/li>
&lt;li>Investigate processes that use a large number of threads.&lt;/li>
&lt;li>Avoid hosting user database files on the same disk volume as tempdb database files.&lt;/li>
&lt;li>Review processes with large working set sizes.&lt;/li>
&lt;li>Reduce the length of the PATH environment variable.&lt;/li>
&lt;li>Reduce the number of entries in the PATH environment variable.&lt;/li>
&lt;li>Ensure SQL Server does not consume memory required by other applications and system components.&lt;/li>
&lt;li>Enable the backup compression default configuration option.&lt;/li>
&lt;li>Ensure the DNS Client service is running and is set to start automatically.&lt;/li>
&lt;li>Consider compressing database tables and indexes.&lt;/li>
&lt;/ul>
&lt;p>Upgrade, Migration and Deployment Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Ensure all devices run supported operating system versions.&lt;/li>
&lt;li>Ensure that the guest user is enabled in the msdb database.&lt;/li>
&lt;li>Avoid using the Affinity64 Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Affinity Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Affinity I/O Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Allow Updates configuration option in SQL Server.&lt;/li>
&lt;li>Avoid using the Allow Updates configuration option in SQL Server.&lt;/li>
&lt;li>Avoid using the Affinity64 I/O Mask configuration setting in new development work.&lt;/li>
&lt;li>Configure SQL Server to accept incoming connections.&lt;/li>
&lt;li>Configure SQL Server instances and firewalls to allow communication over TCP/IP.&lt;/li>
&lt;/ul>
&lt;p>As I have no data for Change and Configuration Management I was not able to see the recommendations in my Operation Insights Workspace.&lt;/p>
&lt;p>Edit: Daniele Muscetta has said in the comments that this is a bug which is being tracked&lt;/p>
&lt;p>As you can see from the type and description of the recommendations above these are all areas that a DBA will be concerned about and the benefit of having all of this information gathered, pre-sorted, prioritised and presented to you in this manner will enable you to work towards a better SQL environment and track your progress. You can read more about the SQL Assessment Intelligence Pack here&lt;/p>
&lt;p>&lt;a class="link" href="http://msdn.microsoft.com/en-us/library/azure/dn873958.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/en-us/library/azure/dn873958.aspx&lt;/a>&lt;/p>
&lt;p>As well as the pre-determined queries that are built into the Intelligence pack you can search your data in any way that you require enabling you to present information about the health and risk of your SQL Environment to your team or your management with ease. The “with ease” bit is dependent on you understanding the language and structure of the search queries.&lt;/p>
&lt;p>You will need to put this page into your bookmarks&lt;/p>
&lt;p>&lt;a class="link" href="http://msdn.microsoft.com/library/azure/dn873997.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/library/azure/dn873997.aspx&lt;/a>&lt;/p>
&lt;p>As it contains the syntax and definitions to search your data&lt;/p>
&lt;p>A very useful page for a starter like me is&lt;/p>
&lt;p>&lt;a class="link" href="http://blogs.msdn.com/b/dmuscett/archive/2014/10/19/advisor-searches-collection.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.msdn.com/b/dmuscett/archive/2014/10/19/advisor-searches-collection.aspx&lt;/a>&lt;/p>
&lt;p>by Daniele Muscetta which has a list of useful Operational Insights search queries such as&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>SQL Recommendation by Computer&lt;/strong>&lt;/p>
&lt;p>Type=SQLAssessmentRecommendation IsRollup=false RecommendationResult=Failed | measure count() by Computer&lt;/p>
&lt;/blockquote>
&lt;p>If you click the star to the right of the search box you will find the saved searches. For the SQL Assessment Intelligence Pack there are&lt;/p>
&lt;p>Did the agent pass the prerequisite check (if not, SQL Assessment data won’t be complete)&lt;/p>
&lt;p>Focus Areas&lt;/p>
&lt;ul>
&lt;li>How many SQL Recommendation are affecting a Computer a SQL Instance or a - Database?&lt;/li>
&lt;li>How many times did each unique SQL Recommendation trigger?&lt;/li>
&lt;li>SQL Assesments passed by Server&lt;/li>
&lt;li>SQL Recommendation by Computer&lt;/li>
&lt;li>SQL Recommendation by Database&lt;/li>
&lt;li>SQL Recommendation by Instance&lt;/li>
&lt;/ul>
&lt;p>You can use these and you can save your own searches which show the data in a way that is valuable to you.&lt;/p>
&lt;p>Overall I am impressed with this tool and can see how it can be beneficial for a DBA as well as for System Administrators. I was amazed how easy it was to set up and how quickly I was able to start manipulating the data once it had been uploaded.&lt;/p></description></item><item><title>Using PowerShell to get Azure Endpoint Ports</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-get-azure-endpoint-ports/</link><pubDate>Mon, 02 Dec 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-get-azure-endpoint-ports/</guid><description>&lt;p>A quick blog today. I was reading &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/3076/how-to-read-the-sql-server-database-transaction-log/" target="_blank" rel="noopener"
>this blog post about How to read the SQL Error Log&lt;/a> and I thought I would try some of the examples. I started my Azure VM using &lt;a class="link" href="https://blog.robsewell.com/?p=534" target="_blank" rel="noopener"
>the steps in my previous post&lt;/a>&lt;/p>
&lt;p>I ran&lt;/p>
&lt;pre>&lt;code>Get-AzureVM -ServiceName TheBestBeard -Name Fade2black
&lt;/code>&lt;/pre>
&lt;p>and then&lt;/p>
&lt;pre>&lt;code> Get-AzureVM -ServiceName TheBestBeard -Name Fade2black|Get-AzureEndpoint |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>and bingo I had my SQL Port to put in SSMS and can go and play some more with SQL&lt;/p></description></item><item><title>Starting My Azure SQL Server VMs with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/starting-my-azure-sql-server-vms-with-powershell/</link><pubDate>Wed, 27 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/starting-my-azure-sql-server-vms-with-powershell/</guid><description>&lt;p>The last post about &lt;a class="link" href="https://blog.robsewell.com/?p=505" target="_blank" rel="noopener"
>Launching Azure VMs with PowerShell&lt;/a> made someone ask me to explain how I start my Azure VMs normally so here goes.&lt;/p>
&lt;p>When I decide to write a blog post or develop and test a script or run through demos from a presentation or blog post I fire up my Azure Virtual machines with PowerShell. This is how I do it&lt;/p>
&lt;p>Open PowerShell and check that I am connected to my default subscription by running &lt;code>Get-AzureSubscription&lt;/code>&lt;/p>
&lt;p>Note – You must have installed Windows Azure PowerShell and installed the PublishSettingsFile or used &lt;code>Add-AzureAccount&lt;/code> for your subscription following the steps here&lt;/p>
&lt;p>&lt;a class="link" href="http://www.windowsazure.com/en-us/manage/install-and-configure-windows-powershell/" target="_blank" rel="noopener"
>http://www.windowsazure.com/en-us/manage/install-and-configure-windows-powershell/&lt;/a>&lt;/p>
&lt;p>Then I run the following three Cmdlets&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-AzureVM&lt;/code> shows me the VMs associated with that subscription.&lt;/p>
&lt;p>I then pipe to &lt;code>Start-AzureVM&lt;/code> as I want to start both machines. If I only wanted one I would check that&lt;/p>
&lt;pre>&lt;code>Get-AzureVM -name Fade2Black -ServiceName TheBestBeard
&lt;/code>&lt;/pre>
&lt;p>returned the correct machine and then pipe that to &lt;code>Start-AzureVM&lt;/code>&lt;/p>
&lt;p>Once the VMs have started I use &lt;code>Get-AzureRemoteDesktopFile&lt;/code> giving a local path for the rdp file and specifying &lt;code>–Launch&lt;/code> to run the RDP session&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and away we go 🙂&lt;/p>
&lt;p>Once I have finished simply run&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and my machines are stopped and no longer running my credit down.&lt;/p></description></item><item><title>#TSQL2sDay Why My Head is Always in The Cloud</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-why-my-head-is-always-in-the-cloud/</link><pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-why-my-head-is-always-in-the-cloud/</guid><description>&lt;p>&lt;a class="link" href="http://www.sqlchicken.com/2013/11/t-sql-tuesday-48-cloud-atlas/" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/www.sqlchicken.com/wp-content/uploads/2013/11/20121003200545_thumb.jpg?resize=175%2C175"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Todays post is my first for the TSQL2sDay series. For those not familiar this is rotating blog party that was started by Adam Machanic &lt;a class="link" href="http://twitter.com/adammachanic" target="_blank" rel="noopener"
>(@AdamMachanic&lt;/a> &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>blog&lt;/a>) back in 2009. If you want to catch up on all the fun to date check out this nice archive (&lt;a class="link" href="http://t.co/g3tzA9nP27" target="_blank" rel="noopener"
>link&lt;/a>) put together by Steve Jones &lt;a class="link" href="http://twitter.com/way0utwest" target="_blank" rel="noopener"
>(@way0utwest&lt;/a> &lt;a class="link" href="http://voiceofthedba.com/" target="_blank" rel="noopener"
>blog&lt;/a>). Thank you Steve!!!&lt;/p>
&lt;p>&lt;a class="link" href="http://owenrichardson.com/2011/07/07/cloud-computing/" target="_blank" rel="noopener"
>&lt;img src="https://owenrichardson.files.wordpress.com/2011/07/wpid-photo-jul-7-2011-1738.jpg?w=432&amp;amp;h=650&amp;amp;resize=207%2C310"
loading="lazy"
alt="Azure Ballon - Credit http://owenrichardson.com/"
>&lt;/a>&lt;/p>
&lt;p>This one is hosted by Jorge Segarra &lt;a class="link" href="https://twitter.com/SQLChicken" target="_blank" rel="noopener"
>@SQLChicken:&lt;/a>  &lt;a class="link" href="http://www.sqlchicken.com/2013/11/t-sql-tuesday-48-cloud-atlas/" target="_blank" rel="noopener"
>who said&lt;/a> This month’s topic is all about the cloud. What’s your take on it? Have you used it? If so, let’s hear your experiences. Haven’t used it? Let’s hear why or why not? Do you like/dislike recent changes made to cloud services? It’s clear skies for writing! So let’s hear it folks, where do you stand with the cloud?&lt;/p>
&lt;p>My wife would tell you that my head is always in the cloud and she’s right (she usually is) just not like that picture! I would love to float gracefully above the land and gaze upon the view but its the landing that bothers me and will always stop me from trying it&lt;/p>
&lt;p>Credit &lt;a class="link" href="http://owenrichardson.com/" target="_blank" rel="noopener"
>http://owenrichardson.com/&lt;/a>&lt;/p>
&lt;p>She’s right, pedantically and literally too, because this year I have spent a lot of time with my head and my fingers and my thinking in &lt;a class="link" href="http://www.windowsazure.com/" target="_blank" rel="noopener"
>Virtual Machines using Windows Azure&lt;/a>. That is where I have learnt a lot of my SQL and Powershell this year. After &lt;a class="link" href="http://sqlsouthwest.co.uk/sqlsat269/" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/12-things-i-learnt-at-sqlbits-xi/" target="_blank" rel="noopener"
>SQL Bits in Nottingham&lt;/a> this year I have needed a place to practice and learn, an environment to try things and break things and mend them again and experiment.&lt;/p>
&lt;p>I learn just as well by doing things as I do reading about them. Stuart Moore  &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a> has a great post called &lt;a class="link" href="http://stuart-moore.com/learning-play-sql-server/" title="http://stuart-moore.com/learning-play-sql-server/"
target="_blank" rel="noopener"
>Learning to Play with SQL Server&lt;/a> and whist I haven’t been as rough with my Azure SQL instances as he suggests I have been able to practice at will without worry and thanks to my MSDN subscription without cost. I have taken examples from blog posts and demos from User Group Sessions and run them on my Windows Azure VMs&lt;/p>
&lt;p>Every single blog post I have written this year that has examples has been written in Azure and screen shots from Azure. Whilst some of my Powershell scripts in the &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a> series had already been written to solve one particular problem or another at MyWork, every single one was refined and demo’d and all the screen shots were from Azure and several were developed on Azure too&lt;/p>
&lt;p>My first ever session to the SQL South West user group was about &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>Spinning up and Shutting Down VMS in Azure&lt;/a> was about Azure and was an interesting experience in &lt;a class="link" href="http://en.wikipedia.org/wiki/Murphy%27s_law" target="_blank" rel="noopener"
>Murphys Law&lt;/a> which meant I &lt;a class="link" href="https://blog.robsewell.com/lessons-learnt-from-my-first-talk-at-sql-southwest/" target="_blank" rel="noopener"
>ended up having to deliver it  on Azure&lt;/a>.&lt;/p>
&lt;p>The second time I have talked was about the PowerShell Box of Tricks series to the Cardiff User Group. Having learnt my lesson from the first time I had bought a mini HDMI to VGA converter and I had tested it using a couple of monitors at home and it worked wonderfully. However, when I got to Cardiff my little Asus convertible didn’t provide enough grunt to power the funky presentation screen. Luckily thanks to Stuart Moore &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a> who was also there doing his &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>excellent PowerShell Back Up and Restore Sessio&lt;/a>n who let me use his Mac I was able to deliver the session using Office Web App to run the PowerPoint from my SkyDrive whilst all the demos were on ………Yup you guessed it Windows Azure !!!&lt;/p>
&lt;p>So I feel qualified to answer Jorge’s questions and take part in T-SQL Tuesday this time round.&lt;/p>
&lt;p>I like Azure. I like the ease I can spin up and down machines or any PaaS services at will. I love that I can do it with PowerShell because I really enjoy using PowerShell in my day to day work and at home too. Living as I do in a beautifully convenient bungalow in the country, I still enjoy the frustration of watching that spinning ring as my videos buffer on our 1.8Mbs at best internet connection. Whilst that does have an impact on using Azure it is a damn sight better than waiting many days trying to download one single file. Something like an ISO file for the latest SQL Server CTP for example.&lt;/p>
&lt;p>There is no way I would have got a look at SQL Server 2014 if it wasn’t for Azure. I was able to spin up a SQL Server 2014 machine in only a few minutes and log in and have a play and then delete it. I have done the same with Server 2012 and 2012 R2. It has enabled me to try setting up Availability Groups and other technologies not yet implemented at MyWork&lt;/p>
&lt;p>I wouldn’t have been able to do any of that on my machines at home as I don’t have anything capable of running Hyper-V whilst this 8 year old desktop still keeps hanging on despite the odd noises. (Negotiations are currently in place to replace it with something shiny and new. &lt;a class="link" href="https://blog.robsewell.com/?p=513" target="_blank" rel="noopener"
>Just need that lottery win now !!)&lt;/a>&lt;/p>
&lt;p>I have also transferred my Cricket Averages database to WASD and am talking with a friend of mine about developing an app that will use the mobile service as well.&lt;/p>
&lt;p>The rate of change is much quicker in the cloud, things change and change quickly. As quickly as I had written my post about &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>Spinning up and Shutting Down VMS in Azure&lt;/a> Microsoft changed the rules and didn’t charge for machines that were turned off. New services appear all the time. New services move quickly through from Preview to release and as &lt;a class="link" href="http://www.scarydba.com/2013/11/05/more-azure-goodies/" target="_blank" rel="noopener"
>Grant Fritchey noticed this week&lt;/a> new views have been added to to Windows Azure SQL Database under the covers. I think this is something we are just going to have to live with. The scale of the cloud means it is much easier to test improvements at large scale and that means they can be released quicker.  It makes it more challenging to keep up I admit but it’s a constant drip of new things rather than a big bang all at once.&lt;/p>
&lt;p>Azure has brought me to where I am today and I think it will continue to be part of my future. If I remember to submit my PowerShell session for SQL Saturday Exeter (&lt;a class="link" href="http://www.sqlsaturday.com/269/callforspeakers.aspx" target="_blank" rel="noopener"
>Submit yours here&lt;/a>) and it gets chosen then you will be able to see me there &lt;a class="link" href="http://www.sqlsaturday.com/269/" target="_blank" rel="noopener"
>(if you register here&lt;/a>) using Azure to give back to the SQL Community&lt;/p></description></item><item><title>Launching Azure VM After Starting With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/launching-azure-vm-after-starting-with-powershell/</link><pubDate>Sat, 26 Oct 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/launching-azure-vm-after-starting-with-powershell/</guid><description>&lt;p>So this morning I decided I was going to run through this blog post on understanding query plans &lt;a class="link" href="http://sqlmag.com/t-sql/understanding-query-plans" target="_blank" rel="noopener"
>http://sqlmag.com/t-sql/understanding-query-plans&lt;/a>. I logged into my Azure Portal to check my balance and clicked start on the machine and then immediately clicked connect.&lt;/p>
&lt;p>D’oh&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image3.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course the RDP session wouldn’t open as the machine was not up so I went and made a coffee. Whilst doing that I thought of a way of doing it with PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>A little Do Until loop on the PowerState Property 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course if I was doing it all though PowerShell I would have done this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item></channel></rss>