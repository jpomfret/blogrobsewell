<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>github on Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/tags/github/</link><description>Recent content in github on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 22 Feb 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/tags/github/index.xml" rel="self" type="application/rss+xml"/><item><title>.NET PowerShell Notebooks â€“ Using Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/.net-powershell-notebooks-using-pester/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/.net-powershell-notebooks-using-pester/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-16.png" alt="Featured image of post .NET PowerShell Notebooks â€“ Using Pester" />&lt;p>&lt;a class="link" href="http://localhost:4001/blog/jupyter%20notebooks/azure%20data%20studio/powershell/pwsh/dbatools/dbachecks/new-net-notebooks-are-here-powershell-7-notebooks-are-here/" target="_blank" rel="noopener"
>My last post&lt;/a> had a lot of information about the new .NET PowerShell notebooks including installation instructions.&lt;/p>
&lt;p>.NET Notebooks are Jupyter Notebooks that use .NET core to enable C#, F# and PowerShell kernels.&lt;/p>
&lt;h2 id="use-cases">Use Cases&lt;/h2>
&lt;p>One of the main benefits that I see for Jupyter Notebooks for Ops folk is that the results of the query are saved with the notebook. This makes them fantastic for Incident resolution.&lt;/p>
&lt;p>If you have an incident at 3am and you know that you will need that information in the wash up meeting the next day instead of copying and pasting results into a OneNote document or a text file, you can simply run the queries in a notebook and save it.&lt;/p>
&lt;p>In the meeting, you can simply open the notebook and the results will be available for everyone to see.&lt;/p>
&lt;p>Even better, if you have a template notebook for those scenarios and you can then compare them to previous occurrences.&lt;/p>
&lt;h2 id="using-pester">Using Pester&lt;/h2>
&lt;p>Using Pester to validate that an environment is as you expect it is a good resource for incident resolution, potentially enabling you to quickly establish an area to concentrate on for the issue. However, if you try to run Pester in a .NET Notebook you will receive an error&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> | ^ The term 'Get-CimInstance' is not recognized as the name of a
| cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included,
| verify that the path is correct and try again.
&lt;/code>&lt;/pre>
&lt;p>Import-Module: The module to process &amp;lsquo;Pester.psm1&amp;rsquo;, listed in field &amp;lsquo;ModuleToProcess/RootModule&amp;rsquo; of module manifest &amp;lsquo;C:\Users\mrrob\Documents\PowerShell\Modules\Pester\4.9.0\Pester.psd1&amp;rsquo; was not processed because no valid module was found in any module directory. &lt;!-- raw HTML omitted -->
Thats odd, why is it failing there? Dongbo Wang from the PowerShell team explains &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>in the issue that I raised&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Yes, it was the CimCmdlets module from the system32 module path that got imported (via theÂ &lt;code>WinCompat&lt;/code>Â feature added in PS7). This is because currently the PS kernel donâ€™t ship all the built-in modules along with it â€¦&lt;br>
The built-in modules are not published anywhere and are platform specific, itâ€™s hard for an application that host powershell to ship them along. We have the issueÂ &lt;a class="link" href="https://github.com/PowerShell/PowerShell/issues/11783" target="_blank" rel="noopener"
>PowerShell/PowerShell#11783&lt;/a>Â to track this work.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/DotNet%20Notebook/01-PesterWontRun.ipynb" target="_blank" rel="noopener"
>You can see all of this including all the results in this notebook that I have created and shared on GitHub and also below as a gist to embed in this blog post&lt;/a>&lt;/p>
&lt;h2 id="sharing-code-and-results-">Sharing Code AND Results ðŸ™‚&lt;/h2>
&lt;p>Notebooks â€“ A brilliant way of sharing what you did and the results that you got enabling others to follow along. You can do this with this Notebook. Download it and open it in your Jupyter Lab and you will be able to run it and see all of the errors and the fix on your machine.&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>How to fork a GitHub repository and contribute to an open source project</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/CreatePR.png" alt="Featured image of post How to fork a GitHub repository and contribute to an open source project" />&lt;p>I enjoy maintaining open source GitHub repositories such as &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>. I absolutely love it when people add more functionality to them.&lt;/p>
&lt;p>To collaborate with a repository in GitHub you need to follow these steps&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/GitHub.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>Fork the repository into your own GitHub&lt;/li>
&lt;li>Clone the repository to your local machine&lt;/li>
&lt;li>Create a new branch for your changes&lt;/li>
&lt;li>Make some changes and commit them with useful messages&lt;/li>
&lt;li>Push the changes to your repository&lt;/li>
&lt;li>Create a Pull Request from your repository back to the original one&lt;/li>
&lt;/ul>
&lt;p>You will need to have &lt;code>git.exe&lt;/code> available which you can download and install from &lt;a class="link" href="https://git-scm.com/downloads" target="_blank" rel="noopener"
>https://git-scm.com/downloads&lt;/a> if required&lt;/p>
&lt;h2 id="fork-the-repository-into-your-own-github">Fork the repository into your own GitHub&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/ForkRepo.png"
loading="lazy"
>&lt;/p>
&lt;p>A fork is a copy of the original repository. This allows you to make changes without affecting the original project. It does not get updated when the original project gets updated (We will talk about that in the next post) This enables you to code a new feature or a bug fix, test it locally and make sure it is working.&lt;/p>
&lt;p>Letâ€™s take dbachecks as our example. Start by going to the project in GiHub. In this case the URL is &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks&lt;/a> You will see a Fork button at the top right of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-41.png?fit=630%2C74&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When you click the button the repository is copied into your own GitHub account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-42.png?resize=630%2C304&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The page will open at &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> in this case &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/dbachecks&lt;/a> You will be able to see that it is a fork of the original repository at the top of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-43.png?resize=474%2C119&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="clone-the-repository-to-your-local-machine">Clone the repository to your local machine&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CloneRepo-2.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Forking the repository has created a &lt;em>remote&lt;/em> repository stored on the GitHub servers. Now that the repository has been forked you need to clone it to your local machine to create a &lt;em>local&lt;/em> repository so that you can start coding your amazing fix. When you have finished you can then sync it back to your &lt;em>remote&lt;/em> repository ready for a Pull Request back to the original repository.&lt;/p>
&lt;p>In your browser, at your &lt;em>remote&lt;/em> repository that you just created (&lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> if you have closed the page) click on &lt;code>Clone or Download&lt;/code> and then the icon to the right to copy the url&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-46.png?fit=630%2C316&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone your repository in &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>VS Code&lt;/a> or &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> by clicking F1 or CTRL + SHIFT + P in Windows or Linux and â‡§âŒ˜P or F1 on a Mac&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-44.png?fit=630%2C206&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>then start typing clone until you see &lt;code>Git:Clone&lt;/code> and press enter or click&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-45.png?fit=630%2C100&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Paste in the URL that you just copied and click enter. A dialog will open asking you to select a folder. This is the parent directory where your &lt;em>local&lt;/em> repository will be created. The clone will create a directory for your repository so you do not need to. I suggest that you use a folder called GitHub or something similar to place all of the repositories that you are going to clone and create.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-47.png?fit=630%2C345&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When it has finished it will ask you if you wish to open the repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-49.png?fit=630%2C215&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>if you click &lt;code>Open&lt;/code> it will close anything that you have already got opened and open the folder. If you click &lt;code>Add to Workspace&lt;/code> it will add the folder to the workspace and leave everything you already had open as it was and surprisingly clicking &lt;code>Open in New Window&lt;/code> will open the folder in a new instance of Visual Studio Code or Azure Data Studio!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-51.png?fit=630%2C997&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and you will also be able to see the local repository files on your computer&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-50.png?resize=442%2C244&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone the repository at the command line if you wish by navigating to your local GitHub directory and running &lt;code>git clone TheURLYouCopied&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-48.png?fit=630%2C165&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now your &lt;em>local&lt;/em> repository has been created, itâ€™s time to do your magic coding.&lt;/p>
&lt;h2 id="create-a-new-branch-for-your-changes">Create a new branch for your changes&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/NewBranch.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>It is a good idea to create a branch for your &lt;code>amazing new feature&lt;/code> This enables you to work on coding for that feature in isolation. It has the added advantage that if you mess it right royally up, you can just delete that branch and start again with a new one!&lt;/p>
&lt;p>To create a branch in VS Code or Azure Data Studio you can click on the branch name at the bottom left.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-52.png?resize=630%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Or open the Command Palette and type Branch until you see &lt;code>Git: Create Branch&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-53.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will be prompted for a branch name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-54.png?fit=630%2C96&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I like to choose a name that relates to the code that I am writing like &lt;code>configurable_engine&lt;/code> or &lt;code>removeerroringexample&lt;/code> You can see the name of the branch in the bottom left so that you always know which branch you are working on.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?fit=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The icon shows that the branch is only &lt;em>local&lt;/em> and hasnâ€™t been pushed (published) to the &lt;em>remote&lt;/em> repository yet&lt;/p>
&lt;h2 id="make-some-changes-and-commit-them-with-useful-messages">Make some changes and commit them with useful messages&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/awesomenewfeature.png?resize=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now you can start writing your code for your awesome new feature, bug fix or maybe just documentation improvement. Keep your commits small and give them useful commit messages that explain &lt;em>why&lt;/em> you have made the change as the diff tooling will be able to show &lt;em>what&lt;/em> change you have made&lt;/p>
&lt;p>Write your code or change the documentation, save the file and in Visual Studio Code or Azure Data Studio you will see that the source control icon has a number on it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-56.png?fit=630%2C143&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Clicking on the icon will show the files that have changes ready&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-57.png?fit=630%2C290&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can write your commit message in the box and click CTRL + ENTER to commit your changes with a message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-58.png?fit=630%2C296&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you want to do this at the command line, you can use &lt;code>git status&lt;/code> to see which files have changes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-59.png?fit=630%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will need to &lt;code>git add .&lt;/code>or &lt;code>git add .\pathtofile&lt;/code> to stage your changes ready for committing and then &lt;code>git commit -m 'Commit Message'&lt;/code> to commit them&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-60.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Notice that I did exactly what I just said not to do! A better commit message would have been &lt;em>So that people can find the guide to forking and creating a PR&lt;/em>&lt;/p>
&lt;h2 id="push-the-changes-to-your-repository">Push the changes to your repository&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/publishbranch.png?resize=630%2C219&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You only have the changes that you have made in your &lt;em>local&lt;/em> repository on your computer. Now you need to push those changes to GitHub your &lt;em>remote&lt;/em> repository. You can click on the publish icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?resize=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will get a pop-up asking you if you wish to stage your changes. I click &lt;code>Yes&lt;/code> and never &lt;code>Always&lt;/code> so that I can use this prompt as a sanity check that I am doing the right thing&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-75.png?fit=630%2C150&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>At the command line you can push the branch, if you do that, you will have to tell git where the branch needs to go. If you just type &lt;code>git push&lt;/code> it will helpfully tell you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-61.png?fit=630%2C121&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>fatal: The current branch AwesomeNewFeature has no upstream branch.
To push the current branch and set the remote as upstream, use
git push --set-upstream origin AwesomeNewFeature
&lt;/code>&lt;/pre>
&lt;p>So you will need to use that command&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-62.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can see in the bottom left that the icon has changed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-63.png?fit=630%2C186&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and if you read the output of the &lt;code>git push&lt;/code> command you will see what the next step is also.&lt;/p>
&lt;h2 id="create-a-pull-request-from-your-repository-back-to-the-original-one">Create a Pull Request from your repository back to the original one&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CreatePR.png?resize=630%2C238&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can CTRL click the link in the &lt;code>git push&lt;/code> output if you have pushed from the command line or if you visit either you repository or the original repository in your browser you will see that there is a &lt;code>Compare and Pull Request&lt;/code> button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-64.png?fit=630%2C334&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You click that and let GitHub do its magic&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-65.png?fit=630%2C459&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will create a Pull Request for you ready for you to fill in the required information, ask for reviewers and other options. Once you have done that you can click &lt;code>Create pull request&lt;/code> and wait for the project maintainer to review it and (hopefully) accept it into their project&lt;/p>
&lt;p>You can find the Pull Request that I created here &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/720" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks/pull/720&lt;/a> and see how the rest of this blog post was created.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-66.png?fit=630%2C489&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you make more changes to the code in the same branch in your &lt;em>local&lt;/em> repository and push them, they will automatically be added to this Pull Request whilst it is open. You can do this if the maintainer or reviewer asks for changes.&lt;/p>
&lt;p>Shane has asked for a change&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-67.png?resize=630%2C110&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can go to my &lt;em>local&lt;/em> repository in Azure Data Studio and make the requested change and save the file. If I look in the source control in Azure Data Studio I can again see there is a change waiting to be committed and if I click on the name of the file I can open the diff tool to see what the change was&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-68.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Once I am happy with my change I can commit it again in the same way as before either in the editor or at the command line. The icon at the bottom will change to show that I have one commit in my &lt;em>local&lt;/em> repository waiting to be pushed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-69.png?fit=630%2C160&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>To do the same thing at the command line I can type &lt;code>git status&lt;/code> and see the same thing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-70.png?fit=630%2C138&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can then push my change to my remote repository either in the GUI or by using &lt;code>git push&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-72.png?fit=630%2C213&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will automatically be added to the Pull Request as you can see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-73.png?fit=630%2C480&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now that the required changes for the review have been made, the review has been approved by Shane and the pull request is now ready to be merged. (You can also see that dbachecks runs some checks against the code when a Pull Request is made)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-74.png?resize=630%2C359&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Many, many thanks to Shane &lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>t&lt;/a> who helped with the writing of this post even whilst on a â€œno techâ€ holiday.&lt;/p>
&lt;h2 id="go-ahead--contribute-to-an-open-source-project">Go Ahead â€“ Contribute to an Open Source Project&lt;/h2>
&lt;p>Hopefully you can now see how easy it is to create a fork of a GitHub repository, clone it to your own machine and contribute. There are many open source projects that you can contribute to.&lt;/p>
&lt;p>You can use this process to contribute to the Microsoft Docs for example by clicking on the edit button on any page.&lt;/p>
&lt;p>You can contribute other open source projects like&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/PowerShell/PowerShell" target="_blank" rel="noopener"
>PowerShell&lt;/a>&lt;/strong> by Microsoft&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/tigertoolbox" target="_blank" rel="noopener"
>tigertoolbox&lt;/a>&lt;/strong> by Microsoft Tiger Team&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/PSDatabaseClone" target="_blank" rel="noopener"
>PSDatabaseClone&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/OpenQueryStore/OpenQueryStore" target="_blank" rel="noopener"
>OpenQueryStore&lt;/a>&lt;/strong> by William Durkin and Enrico van de Laar&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/marcingminski/sqlwatch" target="_blank" rel="noopener"
>sqlwatch&lt;/a>&lt;/strong> by Marcin Gminski&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/red-gate/SQLCop" target="_blank" rel="noopener"
>SQLCop&lt;/a> by Redgate&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/amachanic/sp_whoisactive" target="_blank" rel="noopener"
>sp_whoisactive&lt;/a>&lt;/strong> by Adam Machanic&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/olahallengren/sql-server-maintenance-solution" target="_blank" rel="noopener"
>sql-server-maintenance-solution&lt;/a>&lt;/strong> by Ola Hallengren&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit" target="_blank" rel="noopener"
>SQL-Server-First-Responder-Kit&lt;/a>&lt;/strong> by Brent Ozar Unlimited&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>ReportingServicesTools&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>or go and find the the ones that you use and can help with.&lt;/p></description></item><item><title>Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-40.png" alt="Featured image of post Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps" />&lt;h1 id="fixing-the-failed-to-generate-the-compressed-file-for-module-cprogram-filesdotnetdotnetexe-error-when-deploying-to-the-powershell-gallery-using-azure-devops">Fixing the Failed to generate the compressed file for module C:\Program Files\dotnet\dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps&lt;/h1>
&lt;p>The PowerShell module for validating your SQL Server estate &lt;a class="link" href="http://beard.media/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> is deployed via &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_release?_a=releases&amp;amp;view=mine&amp;amp;definitionId=2" target="_blank" rel="noopener"
>Azure DevOps, you can see how it is working (or not) via this link&lt;/a>&lt;/p>
&lt;h2 id="grrr-automation-for-the-lose">Grrr Automation for the Lose!&lt;/h2>
&lt;p>Until recently, this had worked successfully. In the last few weeks I have been receiving errors&lt;/p>
&lt;pre>&lt;code>Exception : Microsoft.PowerShell.Commands.WriteErrorException: Failed to generate the compressed file for module 'C:\Program Files\dotnet\dotnet.exe failed to pack: error
C:\Program Files\dotnet\sdk\3.0.100\Sdks\NuGet.Build.Tasks.Pack\build\NuGet.Build.Tasks.Pack.targets(198,5): error :
2 Index was outside the bounds of the array.
[C:\Users\VssAdministrator\AppData\Local\Temp\cbc14ba6-5832-46fd-be89-04bb552a83ac\Temp.csproj]
'.
At C:\Program Files\WindowsPowerShell\Modules\PowerShellGet\2.2.1\PSModule.psm1:10944 char:17
20 Publish-PSArtifactUtility @PublishPSArtifactUtility_Param ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ CategoryInfo : InvalidOperation: (:) [Write-Error], WriteErrorException
2019-11-25T22:44:46.8459493Z + FullyQualifiedErrorId : FailedToCreateCompressedModule,Publish-PSArtifactUtility
&lt;/code>&lt;/pre>
&lt;p>You can see these errors in the &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_apps/hub/ms.vss-releaseManagement-web.cd-release-progress?_a=release-environment-logs&amp;amp;releaseId=127&amp;amp;environmentId=127" target="_blank" rel="noopener"
>release pipeline logs here&lt;/a>&lt;/p>
&lt;h2 id="confusion">Confusion&lt;/h2>
&lt;p>This was very frustrating as it was stopping the continuous delivery to the PowerShell Gallery. It was even more confusing as I was successfully deploying the &lt;a class="link" href="http://beard.media/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook module&lt;/a> to the gallery using the same method as &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/ADSSQLNotebook/_build/results?buildId=541" target="_blank" rel="noopener"
>you can see here&lt;/a>.&lt;/p>
&lt;h2 id="raise-an-issue-on-github">Raise an Issue on GitHub&lt;/h2>
&lt;p>I went and looked at the &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/" target="_blank" rel="noopener"
>PowerShellGet GitHub repository&lt;/a> and opened an &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/554" target="_blank" rel="noopener"
>issue&lt;/a> I also found &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/551" target="_blank" rel="noopener"
>another issue regarding Required Modules&lt;/a>&lt;/p>
&lt;p>But this doesn&amp;rsquo;t help to get dbachecks released.&lt;/p>
&lt;h2 id="just-try-to-make-it-work">Just Try to Make it Work&lt;/h2>
&lt;p>I asked the wonderful folk in the &lt;a class="link" href="http://powershell.slack.com" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a> â€“ Through the magic of automation, you can also interact with them via the powershellhelp channel in the &lt;a class="link" href="http://beard.media/sqlslack" target="_blank" rel="noopener"
>SQL Server Slack&lt;/a> as well but there were no answers that could assist.&lt;/p>
&lt;p>So I had to go searching for an answer. PowerShellGet uses &lt;a class="link" href="https://www.nuget.org/" target="_blank" rel="noopener"
>nuget&lt;/a> for package management. I found that if I downloaded an earlier version and placed it in my user profile (in the right location) I could publish the module.&lt;/p>
&lt;p>I found this out by removing the nuget.exe from anywhere useful on the machine and trying to publish the module. The error message says&lt;/p>
&lt;pre>&lt;code>NuGet.exe upgrade is required to continue
This version of PowerShellGet requires minimum version '4.1.0' of NuGet.exe to publish an item to the NuGet-based repositories. NuGet.exe must be available in
'C:\ProgramData\Microsoft\Windows\PowerShell\PowerShellGet\' or 'C:\Users\BeardyMcBeardFace\AppData\Local\Microsoft\Windows\PowerShell\PowerShellGet\', or under
one of the paths specified in PATH environment variable value. NuGet.exe can be downloaded from https://aka.ms/psget-nugetexe. For more information, see
https://aka.ms/installing-powershellget . Do you want PowerShellGet to upgrade to the latest version of NuGet.exe now?
&lt;/code>&lt;/pre>
&lt;p>If I said yes then I got the latest version and the error continued.&lt;/p>
&lt;p>However, on my laptop I can go to the &lt;a class="link" href="https://www.nuget.org/downloads" target="_blank" rel="noopener"
>nuget downloads page&lt;/a> and download an earlier version and place it in one of those paths then I could publish the module.&lt;/p>
&lt;h2 id="can-i-automate-it">Can I Automate it?&lt;/h2>
&lt;p>I would rather not have to deploy manually though, and as I use hosted agents my access to the operating system is limited so I wondered if I could place the nuget.exe in the user profile and it would get used or if it would look for the the latest one. Turns out it uses the one in the user profile ðŸ™‚&lt;/p>
&lt;p>So now I have this code as a step in my Azure DevOps Release pipeline before calling &lt;code>Publish-Module&lt;/code> and we have automated the releases again.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>and now deployments to the PowerShell Gallery are just triggered by the build and the pipeline is green again ðŸ™‚&lt;/p>
&lt;p>&lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=129&amp;amp;environmentId=129" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-40.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>test&lt;/p></description></item><item><title>Adding a Folder of Scripts to GitHub with Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github-with-azure-data-studio/</link><pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github-with-azure-data-studio/</guid><description>&lt;p>In my last post I showed how to &lt;a class="link" href="https://blog.robsewell.com/10501/" target="_blank" rel="noopener"
>add a folder of scripts to GitHub&lt;/a> using Visual Studio Code.&lt;/p>
&lt;p>You can do it with Azure Data Studio as well. Itâ€™s exactly the same steps!&lt;/p>
&lt;p>The blog post could end here but read on for some screen shots ðŸ˜‰&lt;/p>
&lt;p>Follow the previous post for details of setting up a new GitHub account&lt;/p>
&lt;p>Create a repository in GitHub&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-27.png"
loading="lazy"
>&lt;/p>
&lt;p>Open the folder in Azure Data Studio with CTRL K CTRL O (Or File â€“&amp;gt; Open Folder)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-28.png"
loading="lazy"
>&lt;/p>
&lt;p>Click on the Source Control icon or CTRL + SHIFT + G and then Initialize Repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-29.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose the folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-30.png"
loading="lazy"
>&lt;/p>
&lt;p>Write a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-31.png"
loading="lazy"
>&lt;/p>
&lt;p>Say yes to the prompt. Press CTRL + â€˜ to open the terminal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-32.png"
loading="lazy"
>&lt;/p>
&lt;p>Navigate to the scripts folder. (I have a PSDrive set up to my Git folder)&lt;/p>
&lt;pre>&lt;code>Set-Location GIT:\\ADS-Scripts\
&lt;/code>&lt;/pre>
&lt;p>and copy the code from the GitHub page after â€œâ€¦or push an existing repository from the command lineâ€&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-33.png"
loading="lazy"
>&lt;/p>
&lt;p>and run it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-34.png"
loading="lazy"
>&lt;/p>
&lt;p>and there are your scripts in GitHub&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-35.png"
loading="lazy"
>&lt;/p>
&lt;p>Make some changes to a script and it will go muddy brown&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-36.png"
loading="lazy"
>&lt;/p>
&lt;p>and then write a commit message. If you click on the file name in the source control tab then you can see the changes that have been made, that are not currently tracked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-37.png"
loading="lazy"
>&lt;/p>
&lt;p>Commit the change with CTRL + ENTER and then click the roundy-roundy icon (seriously anyone know its name ?) click yes on the prompt and your changes are in GitHub as well ðŸ™‚&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-38.png"
loading="lazy"
>&lt;/p>
&lt;p>Realistically, you can use the previous post to do this with Azure Data Studio as it is built on top of Visual Studio Code but I thought it was worth showing the steps in Azure Data Studio.&lt;/p>
&lt;p>Happy Source Controlling&lt;/p></description></item><item><title>Adding a Folder of Scripts to GitHub</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</link><pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</guid><description>&lt;p>Yesterday there was a tweet from Allen White.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/SQLRunr/status/1113862196201758720" target="_blank" rel="noopener"
>https://twitter.com/SQLRunr/status/1113862196201758720&lt;/a>&lt;/p>
&lt;p>Allen wanted to add his scripts folder to source control but didn&amp;rsquo;t have a how to do it handy. So I thought I would write one. Hopefully this will enable someone new to GitHub and to source control get a folder of scripts under source control&lt;/p>
&lt;h2 id="github-account">GitHub account&lt;/h2>
&lt;p>If you do not have a GitHub account go to &lt;a class="link" href="https://github.com" target="_blank" rel="noopener"
>https://github.com&lt;/a> and create a new account&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>There is a funky are you a human challenge&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-1.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then you can choose your subscription&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-2.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then answer some questions (Note - you probably want to choose different answers to the what are you interested in question! I&amp;rsquo;d suggest something technical)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-3.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You need to do the email verification&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-4.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Next is a very important step - Please do not skip this. You should set up 2 factor authentication. Yes even if &amp;ldquo;It&amp;rsquo;s just for me there is nothing special here&amp;rdquo;&lt;/p>
&lt;p>Click your user icon top right and then settings&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-5.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then click set up two factor authentication&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png?fit=630%2C365&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and either set up with an app or via SMS (I suggest the app is better)&lt;/p>
&lt;p>OK - Now you have your GitHub account set up. It should have taken you less time than reading this far.&lt;/p>
&lt;h2 id="add-a-scripts-folder-to-github">Add a Scripts Folder to GitHub&lt;/h2>
&lt;p>OK, Now to add a folder of scripts to a repository. Here is my folder of scripts. They can be any type of files. I would recommend copy the folder to a specific Git folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-7.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Open VS Code - If you don&amp;rsquo;t have VS Code, download it from
&lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>https://code.visualstudio.com/&lt;/a> From the welcome window choose open folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-8.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and open your scripts folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-9.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>In VS Code click the Source Control button&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-10.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and up at the top you will see a little icon - initialise repository&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-11.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click that and choose your folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-12.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Which will then show all of the changes to the repository (adding all the new files)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-13.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now we need to add a commit message for our changes. I generally try to write commit messages that are the reason why the change has been made as the what has been changed is made easy to see in VS Code (as well as other source control GUI tools)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-14.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click the tick or press CTRL + ENTER and this box will pop up&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-15.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I never click Always, I click yes, so that I can check if I am committing the correct files. Now we have created a local repository for our scripts folder. Our next step is to publish it to GitHub&lt;/p>
&lt;h2 id="create-a-new-repository-in-github">Create a New Repository in GitHub&lt;/h2>
&lt;p>In GitHub we need to create a remote repository. Click on the New Button. Give your repository a name and decide if you want it to be Public (available for anyone to search and find) or Private (only available to people you explicitly provide access to).&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-18.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This will give you a page that looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png?fit=630%2C499&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Copy the code after â€¦or push an existing repository from the command line&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># make sure prompt is at right place
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-Location C:\Git\MyScriptsFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Then paste the code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git remote add origin https://github.com/SQLDBAWithABeard-Test/TheBeardsFunkyScriptFolder.git
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git push -u origin master
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and paste it into PowerShell in VS Code. Make sure that your prompt is at the root of your scripts folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png?fit=630%2C340&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Fill in your username and password and your 2FA&lt;/p>
&lt;p>Then you will see a page like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png?fit=630%2C180&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and if you refresh your GitHub page you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png?fit=630%2C504&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Congratulations, your code is source controlled :-)&lt;/p>
&lt;h2 id="making-changes">Making Changes&lt;/h2>
&lt;p>Now you can make a change to a file&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-23.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-23.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Commit your change&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-24.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-24.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Hit the roundy-roundy icon (anyone know its proper name ?)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-25.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-25.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Press OK and your commit will be pushed to GitHub :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-26.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-26.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Yay - Source Control all the things&lt;/p></description></item><item><title>Whats a SQL Notebook in Azure Data Studio?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-7.png" alt="Featured image of post Whats a SQL Notebook in Azure Data Studio?" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-2017?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a cross-platform database tool for data professionals using the Microsoft family of on-premises and cloud data platforms on Windows, MacOS, and Linux.&lt;/p>
&lt;p>Recently Vicky Harp tweeted&lt;/p>
&lt;blockquote>
&lt;p>We&amp;rsquo;re getting very close to release of SQL Notebooks in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>! You can give the feature an early spin today with the insider build. &lt;a class="link" href="https://t.co/SEZp7ZdxCp" target="_blank" rel="noopener"
>pic.twitter.com/SEZp7ZdxCp&lt;/a>&lt;/p>
&lt;p>â€” Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1104127412944551936?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 8, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>By the way, you can watch a recording from SQLBits of Vickyâ€™s session&lt;/p>
&lt;blockquote>
&lt;p>If you missed &lt;a class="link" href="https://twitter.com/hashtag/sqlbits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#sqlbits&lt;/a>, you will definitely want to watch this demo by &lt;a class="link" href="https://twitter.com/vickyharp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@vickyharp&lt;/a> and &lt;a class="link" href="https://twitter.com/MGoCODE?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@MGoCODE&lt;/a> about &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>. Learn the latest about our cross-platform tool, including a new feature, SQL Notebooks &lt;a class="link" href="https://twitter.com/hashtag/SQLServer?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLServer&lt;/a> &lt;a class="link" href="https://t.co/diubYwQckn" target="_blank" rel="noopener"
>https://t.co/diubYwQckn&lt;/a>&lt;/p>
&lt;p>â€” Azure Data Studio (@AzureDataStudio) &lt;a class="link" href="https://twitter.com/AzureDataStudio/status/1103806327065722880?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 7, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>So in the interest of learning about something new I decided to give it a try.&lt;/p>
&lt;h2 id="install-the-insiders-edition">Install The Insiders Edition&lt;/h2>
&lt;p>Unlike &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> which has a link to the insiders download on the front page, you will have to &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio#azure-data-studio" target="_blank" rel="noopener"
>visit the GitHub repository for the links to download the insiders release of Azure Data Studio&lt;/a>. Scroll down and you will see&lt;/p>
&lt;p>Try out the latest insiders build fromÂ &lt;code>master&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider" target="_blank" rel="noopener"
>Windows User Installer â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider" target="_blank" rel="noopener"
>Windows System Installer â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider" target="_blank" rel="noopener"
>Windows ZIP â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider" target="_blank" rel="noopener"
>macOS ZIP â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider" target="_blank" rel="noopener"
>Linux TAR.GZ â€“Â &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See theÂ &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>change log&lt;/a>Â for additional details of whatâ€™s in this release.
Once you have installed you can connect to an instance, right click and choose New Notebook or you can use File â€“ New Notebook
&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image.png"
loading="lazy"
>&lt;/p>
&lt;p>Incidentally, I use the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> to create the containers and I map &lt;code>C:\MSSQL\BACKUP\KEEP&lt;/code> on my local machine (where my backups are) to &lt;code>/var/opt/mssql/backups&lt;/code> on the containers on lines 10 and 17 of the docker-compose so change as required . If you want to follow along then put the ValidationResults.bak in the folder on your local machine.
The &lt;code>Create-Ag.ps1&lt;/code> shows the code and creates an AG with &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.&lt;/a> But I digress!&lt;/p>
&lt;h2 id="install-notebook-dependencies">Install Notebook Dependencies&lt;/h2>
&lt;p>Once you click New Notebook you will get a prompt to install the dependencies.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>It will show its output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and take a few minutes to run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>It took all but 11 minutes on my machine&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-notebook">Create a Notebook&lt;/h2>
&lt;p>OK, so now that we have the dependencies installed we can create a notebook. I decided to use the ValidationResults database that &lt;a class="link" href="https://blog.robsewell.com/dbachecks-save-the-results-to-a-database-for-historical-reporting/" target="_blank" rel="noopener"
>I use for my dbachecks demos and describe here&lt;/a>. I need to restore it from my local folder that I have mapped as a volume to my container. Of course, I use dbatools for this ðŸ™‚&lt;/p>
&lt;pre>&lt;code># U: sqladmin P: dbatools.IO
$cred = Get-Credential
$restoreDbaDatabaseSplat = @{
SqlInstance = $sqlinstance1
SqlCredential = $cred
UseDestinationDefaultDirectories = $true
Path = '/var/opt/mssql/backups/ValidationResults.bak'
}
Restore-DbaDatabase @restoreDbaDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>I had already got a connection saved to the instance in Azure Data Studio, you may need to create a new one using the new connection icon at the top left and filling in the details. The password is in the code above.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can start with my notebook. I am faced with this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I click on text and provide an intro&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I had written that and clicked out, I couldnâ€™t see what to do straight away!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I saw the code and text buttons at the top ðŸ™‚ Right, lets get on with it ðŸ™‚ I hit the code button and paste in the T-SQL to reset the dates in the database to simulate dbachecks having been run this morning.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-9.png"
loading="lazy"
>
Thereâ€™s a run cell button on the right and when I press it&amp;gt;&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->
Cool ðŸ™‚&lt;/p>
&lt;p>If the SQL query has results then they are shown as well&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>This is fun and I can see plenty of uses for it. Go and have a play with SQL notebooks ðŸ™‚&lt;/p>
&lt;h2 id="source-control">Source Control&lt;/h2>
&lt;p>I used CTRL K, CTRL O to open a folder and saved my notebook in my local Presentations folder which is source controlled. When I opened the explorer CTRL + SHIFT + E I can see that the folder and the file are colour coded green and have a U next to them marking them as Untracked. I can also see that the source control icon has a 1 for the number of files with changes and in the bottom left that I am in the master branch.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>If I click on the source control icon (or CTRL + SHIFT + G) I can see the files with the changes and can enter a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>I then press CTRL + ENTER to commit my change and get this pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>As I only have one file and it has all the changes for this commit I click yes. If I had changed more than one file and only wanted to commit a single one at a time I would hover my mouse over the file and click the + to stage my change.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>If I make a further change to the notebook and save it, I can see that the source control provider recognises the change but this time the folder the file is in and the file are colour coded brown with an M to show that they have been modified.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Unlike Visual Studio Code, when you then click on the source control icon and click on the change it does not show the differences in the notebook although this works with SQL files.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>When I have made all my changes and committed them with good commit messages&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/imgs.xkcd.com/comics/git_commit.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can see that there are 3 local changes ready to be pushed to by remote repository (GitHub in this case) and 0 remote commits in this branch by looking at the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I can click on the â€œroundy roundyâ€ icon (I don&amp;rsquo;t know its proper name ðŸ˜Š) and synchronise my changes. This comes with a pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Personally I never press OK, Donâ€™t Show Again because I like the double check and to think â€œIs this really what I want to do right nowâ€. Once I press OK my changes will be synched with the remote repository. Explaining this means that you can find the notebook I have used in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/Notebooks" target="_blank" rel="noopener"
>Presentations GitHub Repository&lt;/a> which means that you can run the Notebook too using the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> and the instructions further up in the post.&lt;/p></description></item><item><title>Using Docker to run Integration Tests for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</link><pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</guid><description>&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>AndrÃ© Kamman&lt;/a> wrote a fantastic blog post this week &lt;a class="link" href="https://andrekamman.com/sql-server-container-instances-via-cloudshell/" target="_blank" rel="noopener"
>SQL Server Container Instances via Cloudshell&lt;/a> about how he uses containers in Azure to test code against different versions of SQL Server.&lt;/p>
&lt;p>It reminded me that I do something very similar to test &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> code changes. I thought this might make a good blog post. I will talk through how I do this locally as I merge a PR from another great friend &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>ClÃ¡udio Silva&lt;/a> who has added &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/582" target="_blank" rel="noopener"
>agent job history checks.&lt;/a>&lt;/p>
&lt;h2 id="github-pr-vs-code-extension">GitHub PR VS Code Extension&lt;/h2>
&lt;p>I use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github" target="_blank" rel="noopener"
>GitHub Pull Requests extension for VS Code&lt;/a> to work with pull requests for &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pulls" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This enables me to see all of the information about the Pull Request, merge it, review it, comment on it all from VS Code&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/GitHub-Pull-Request-VsCode-Extension.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see which files have been changed and which changes have been made&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/viewing-a-change.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I am ready to test the pull request I perform a checkout using the extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/checkout-pull-request-checkout.png"
loading="lazy"
>&lt;/p>
&lt;p>This will update all of the files in my local repository with all of the changes in this pull request&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>You can see at the bottom left that the branch changes from development to the name of the PR.&lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-unit-tests">Running The Unit Tests&lt;/h2>
&lt;p>The first thing that I do is to run the Unit Tests for the module. These will test that the code is following all of the guidelines that we require and that the tests are formatted in the correct way for the Power Bi to parse. I have blogged about this &lt;a class="link" href="https://blog.robsewell.com/using-the-ast-in-pester-for-dbachecks/" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-the-powershell-ast-to-find-a-foreach-method/" target="_blank" rel="noopener"
>here&lt;/a> and we use this Pester in our CI process in Azure DevOps which I described &lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>here.&lt;/a>&lt;/p>
&lt;p>I navigate to the root of the dbachecks repository on my local machine and run&lt;/p>
&lt;pre>&lt;code> $testresults = Invoke-Pester .\tests -ExcludeTag Integration -Show Fails -PassThru
&lt;/code>&lt;/pre>
&lt;p>and after about a minute&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/pester-tests.png"
loading="lazy"
>&lt;/p>
&lt;p>Thank you ClÃ¡udio, the code has passed the tests ðŸ˜‰&lt;/p>
&lt;h2 id="running-some-integration-tests">Running Some Integration Tests&lt;/h2>
&lt;p>The difference between Unit tests and Integration tests in a nutshell is that the Unit tests are testing that the code is doing what is expected without any other external influences whilst the Integration tests are checking that the code is doing what is expected when running on an actual environment. In this scenario we know that the code is doing what is expected but we want to check what it does when it runs against a SQL Server and even when it runs against multiple SQL Servers of different versions.&lt;/p>
&lt;h2 id="multiple-versions-of-sql-server">Multiple Versions of SQL Server&lt;/h2>
&lt;p>As I have described &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>before&lt;/a> my friend and former colleague Andrew Pruski &lt;a class="link" href="http://dbafromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="http://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has many resources for running SQL in containers. This means that I can quickly and easily create fresh uncontaminated instances of SQL 2012, 2014, 2016 and 2017 really quickly.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/creating-contatiners.png"
loading="lazy"
>&lt;/p>
&lt;p>I can create 4 instances of different versions of SQL in (a tad over) 1 minute. How about you?&lt;/p>
&lt;p>Imagine how long it would take to run the installers for 4 versions of SQL and the pain you would have trying to uninstall them and make sure everything is â€˜cleanâ€™. Even images that have been sysprepâ€™d wonâ€™t be done in 1 minute.&lt;/p>
&lt;h2 id="docker-compose-up-">Docker Compose Up ?&lt;/h2>
&lt;p>So what is this magic command that has enabled me to do this? docker compose uses a YAML file to define multi-container applications. This means that with a file called docker-compose.yml like &lt;a class="link" href="https://gist.github.com/SQLDBAWithABeard/b589d499484af4ebfb7d637cb6b4efa3" target="_blank" rel="noopener"
>this&lt;/a>&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/ mssql-server-windows-developer:2017-latest
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and in that directory just run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>and 4 SQL containers are available to you. You can interact with them via SSMS if you wish with localhost comma PORTNUMBER. The port numbers in the above file are 15586, 15587,15588 and 15589&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?resize=630%2C188&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>Now it must be noted, as I &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>describe here&lt;/a> that first I pulled the images to my laptop. The first time you run docker compose will take significantly longer if you havenâ€™t pulled the images already (pulling the images will take quite a while depending on your broadband speed)&lt;/p>
&lt;h2 id="credential">Credential&lt;/h2>
&lt;p>The next thing is to save a credential to make it easier to automate.&lt;del>I use the method described by my PowerShell friend Jaap Brasser &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/del>&lt;/p>
&lt;p>EDIT (September or is it March? 2020) - Nowadays I use the Secret Management Module&lt;/p>
&lt;p>I run this code&lt;/p>
&lt;pre>&lt;code> $CredentialPath = 'C:\MSSQL\BACKUP\KEEP\sacred.xml'
Get-Credential | Export-Clixml -Path $CredentialPath
&lt;/code>&lt;/pre>
&lt;p>and then I can create a credential object using&lt;/p>
&lt;pre>&lt;code>$cred = Import-Clixml $CredentialPath
&lt;/code>&lt;/pre>
&lt;h2 id="check-the-connections">Check The Connections&lt;/h2>
&lt;p>I ensure a clean session by removing the dbatools and dbachecks modules and then import the local version of dbachecks and set some variables&lt;/p>
&lt;pre>&lt;code>$dbacheckslocalpath = 'GIT:\dbachecks\'
Remove-Module dbatools, dbachecks -ErrorAction SilentlyContinue
Import-Module $dbacheckslocalpath\dbachecks.psd1
$cred = Import-Clixml $CredentialPath
$containers = 'localhost,15589', 'localhost,15588', 'localhost, 15587', 'localhost,15586'
&lt;/code>&lt;/pre>
&lt;p>Now I can start to run my Integration tests. First reset the dbachecks configuration and set some configuration values&lt;/p>
&lt;pre>&lt;code># run the checks against these instances
$null = Set-DbcConfig -Name app.sqlinstance $containers
# We are using SQL authentication
$null = Set-DbcConfig -Name policy.connection.authscheme -Value SQL
# sometimes its a bit slower than the default value
$null = Set-DbcConfig -Name policy.network.latencymaxms -Value 100 # because the containers run a bit slow!
&lt;/code>&lt;/pre>
&lt;p>Then I will run the dbachecks connectivity checks and save the results to a variable without showing any output&lt;/p>
&lt;pre>&lt;code>$ConnectivityTests = Invoke-DbcCheck -SqlCredential $cred -Check Connectivity -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>I can then use Pester to check that dbachecks has worked as expected by testing if the failedcount property returned is 0.&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;Testing the checks are running as expected&amp;quot; -Tag Integration {
Context &amp;quot;Connectivity Checks&amp;quot; {
It &amp;quot;All Tests should pass&amp;quot; {
$ConnectivityTests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default settings&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/check-connectivity.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="what-is-the-unit-test-for-this-pr">What is the Unit Test for this PR?&lt;/h2>
&lt;p>Next I think about what we need to be testing for the this PR. The Unit tests will help us.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/what-are-the-unit-tests.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="choose-some-integration-tests">Choose some Integration Tests&lt;/h2>
&lt;p>This check is checking the Agent job history settings and the unit tests are&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows disabled (-1)â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows disabled (-1) but configured value is 1000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows being 10000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows being less than 10000â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œPasses Check Correctly with Maximum History Rows per job being 100â€&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It â€œFails Check Correctly with Maximum History Rows per job being less than 100â€&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So we will check the same things on real actual SQL Servers. First though we need to start the SQL Server Agent as it is not started by default. We can do this as follows&lt;/p>
&lt;pre>&lt;code>docker exec -ti integration_sql2012_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2014_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2016_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2017_1 powershell start-service SQLSERVERAGENT
&lt;/code>&lt;/pre>
&lt;p>Unfortunately, the agent service wont start in the SQL 2014 container so I cant run agent integration tests for that container but itâ€™s better than no integration tests.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/agent-wont-start.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="this-is-what-we-will-test">This is What We Will Test&lt;/h2>
&lt;p>So we want to test if the check will pass with default settings. In general, dbachecks will pass for default instance, agent or database settings values by default.&lt;/p>
&lt;p>We also want the check to fail if the configured value for dbachecks is set to default but the value has been set on the instance.&lt;/p>
&lt;p>We want the check to pass if the configured value for the dbachecks configuration is set and the instance (agent, database) setting matches it.&lt;/p>
&lt;h2 id="if-you-are-doing-something-more-than-once-">If You Are Doing Something More Than Once â€¦â€¦&lt;/h2>
&lt;p>Letâ€™s automate that. We are going to be repeatedly running those three tests for each setting that we are running integration tests for. I have created 3 functions for this again checking that FailedCount or Passed Count is 0 depending on the test.&lt;/p>
&lt;pre>&lt;code>function Invoke-DefaultCheck {
It &amp;quot;All Checks should pass with default for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)default&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default setting (Yes we may set some values before but you get my drift)&amp;quot;
}
}
function Invoke-ConfigCheck {
It &amp;quot;All Checks should fail when config changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)configchanged&amp;quot; -ValueOnly
$Tests.PassedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and fail when we have changed the config values&amp;quot;
}
}
function Invoke-ValueCheck {
It &amp;quot;All Checks should pass when setting changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check) value changed&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass when we have changed the settings to match the config values&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Now I can use those functions inside a loop in my Integration Pester Test&lt;/p>
&lt;pre>&lt;code>$TestingTheChecks = @('errorlogscount','jobhistory')
Foreach ($Check in $TestingTheChecks) {
Context &amp;quot;$Check Checks&amp;quot; {
Invoke-DefaultCheck
Invoke-ConfigCheck
Invoke-ValueCheck
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="write-some-integration-tests">Write Some Integration Tests&lt;/h2>
&lt;p>So for this new test I have added a value to the TestingTheChecks array then I can test my checks. The default check I can check like this&lt;/p>
&lt;pre>&lt;code># run the checks against these instances (SQL2014 agent wont start :-( ))
$null = Set-DbcConfig -Name app.sqlinstance $containers.Where {$_ -ne 'localhost,15588'}
# by default all tests should pass on default instance settings
$jobhistorydefault = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Now I need to change the configurations so that they do not match the defaults and run the checks again&lt;/p>
&lt;pre>&lt;code>#Change the configuration to test that the checks fail
$null = Set-DbcConfig -Name agent.history. maximumjobhistoryrows -value 1000
$null = Set-DbcConfig -Name agent.history.maximumhistoryrows -value 10000
$jobhistoryconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Next we have to change the instance settings so that they match the dbachecks configuration and run the checks and test that they all pass.&lt;/p>
&lt;p>We will (of course) use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> for this. First we need to find the command that we need&lt;/p>
&lt;pre>&lt;code>Find-DbaCommand jobserver
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/find-dbacommand.png"
loading="lazy"
>&lt;/p>
&lt;p>and then work out how to use it&lt;/p>
&lt;pre>&lt;code>Get-Help Set-DbaAgentServer -Detailed
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/set-the-values.png"
loading="lazy"
>&lt;/p>
&lt;p>There is an example that does exactly what we want ðŸ™‚ So we can run this.&lt;/p>
&lt;pre>&lt;code>$setDbaAgentServerSplat = @{
MaximumJobHistoryRows = 1000
MaximumHistoryRows = 10000
SqlInstance = $containers.Where{$_ -ne 'localhost,15588'}
SqlCredential = $cred
}
Set-DbaAgentServer @setDbaAgentServerSplat
$jobhistoryvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;h2 id="run-the-integration-tests">Run the Integration Tests&lt;/h2>
&lt;p>And then we will check that all of the checks are passing and failing as expected&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\DockerTests.ps1
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/testing-the-checks.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="integration-test-for-error-log-counts">Integration Test For Error Log Counts&lt;/h2>
&lt;p>There is another integration test there for the error logs count. This works in the same way. Here is the code&lt;/p>
&lt;pre>&lt;code>#region error Log Count - PR 583
# default test
$errorlogscountdefault = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set a value and then it will fail
$null = Set-DbcConfig -Name policy.errorlog.logcount -Value 10
$errorlogscountconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set the value and then it will pass
$null = Set-DbaErrorLogConfig -SqlInstance $containers -SqlCredential $cred -LogCount 10
$errorlogscountvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
#endregion
&lt;/code>&lt;/pre>
&lt;h2 id="merge-the-changes">Merge the Changes&lt;/h2>
&lt;p>So with all the tests passing I can merge the PR into the development branch and Azure DevOps will start a build. Ultimately, I would like to add the integration to the build as well following &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>AndrÃ©&lt;/a>â€˜s blog post but for now I used the GitHub Pull Request extension to merge the pull request into development which started a &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_build/results?buildId=365&amp;amp;view=results" target="_blank" rel="noopener"
>build&lt;/a> and then merged that into master which signed the code and deployed it to the PowerShell gallery as you can see &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=81&amp;amp;environmentId=81" target="_blank" rel="noopener"
>here&lt;/a> and the result is&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.164" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/dbachecks/1.1.164&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/powershell-gallery.png"
loading="lazy"
>&lt;/p></description></item><item><title>SQL Server Availability Group FailoverDetection Utility PowerShell Function Improvements â€“ Named Instances, Archiving Data, Speed</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</link><pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</guid><description>&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>my last post I wrote about a new function&lt;/a> for gathering the data and running the &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy/" target="_blank" rel="noopener"
>FailoverDetection utility&lt;/a> by the &lt;a class="link" href="https://twitter.com/mssqltiger" target="_blank" rel="noopener"
>Tiger Team&lt;/a> to analyse availability group failovers. I have updated it following some comments and using it for a day.&lt;/p>
&lt;h3 id="dont-forget-the-named-instances-rob">Donâ€™t forget the named instances Rob!&lt;/h3>
&lt;p>Michael Karpenko wrote a comment pointing out that I had not supported named instances, which was correct as it had not been written for that. Thank you Michael ðŸ™‚ I have updated the code to deal withÂ named instances.&lt;/p>
&lt;h3 id="confusing-results">Confusing results&lt;/h3>
&lt;p>I also realised as we started testing the code that if you had run the code once and then ran it again against a different availability group the tool does not clear out the data folder that it uses so you can get confusing results.&lt;/p>
&lt;p>In the image below I had looked at the default instance and then a MIRROR named instance. As you can see the results json on the left shows the default instance SQLClusterAG while the one on the right shows both the SQLClusterAG and the MirrrAG instance results.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png"
loading="lazy"
alt="duplicate results.png"
>&lt;/a>&lt;/p>
&lt;p>This is not so useful if you donâ€™t notice this at first with the expanded json!! Now you may in this situation want to see the combined results from all of the availability groups on one cluster. You could gather all of the data from each instance and then add it to the data folder easily enough.&lt;/p>
&lt;p>By cleaning out the data folder before running the utility the results are as expected.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results-fixed.png"
loading="lazy"
alt="duplicate results fixed.png"
>&lt;/p>
&lt;h3 id="archive-the-data-for-historical-analysis">Archive the data for historical analysis&lt;/h3>
&lt;p>One of the production DBAs pointed out that having gathered the information, it would be useful to hold it for better analysis of repeated issues. I have added an archiving step so that when the tools runs, if there is already data in the data gathering folder, it will copy that to an archive folder and name it with the date and time that the cluster log was created as this is a good estimation of when the analysis was performed. If an archive folder location is not provided it will create an archive folder in the data folder. This is not an ideal solution though, as the utility will copy all of the files and folders from there to its own location so it is better to define an archive folder in the parameters.&lt;/p>
&lt;h3 id="get-eventlog-is-sloooooooooooow">Get-Eventlog is sloooooooooooow&lt;/h3>
&lt;p>I was running the tools and noticed it sat running the system event log task for a long long time. I ran some tests using a variation of the &lt;a class="link" href="http://dbatools.io/prompt" target="_blank" rel="noopener"
>dbatools prompt.&lt;/a>&lt;/p>
&lt;p>This will show in the prompt how long it took to run the previous statement .&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/speed.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/speed.png"
loading="lazy"
alt="speed.png"
>&lt;/a>&lt;/p>
&lt;p>In the image above (which you can click to get a larger version as with all images on this blog) you can see that it took 18ms to set the date variable, FOUR MINUTES and FORTY THREE seconds to get the system log in the last 2 days using Get-EventLog and 29.1 seconds using Get-WinEvent and a FilterHashtable.&lt;/p>
&lt;h3 id="getting-the-function">Getting the function&lt;/h3>
&lt;p>This function requires PowerShell version 5 and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment â€“ will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>. .\Invoke-SqlFailOverDetection.ps1&lt;/p>
&lt;p>There are two .â€™s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters and more info &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>on my previous post.&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Gathering all the Logs and Running the Availability Group Failover Detection Utility with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</link><pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</guid><description>&lt;p>30/11/2018 â€“ Function has been updated to deal with named instances.&lt;/p>
&lt;p>Last week the Tiger Team released their Availability Group Failover Detection Utility which will provide root cause analysis on Cluster Logs, SQL Error Logs, and the Availability groups extended events logs. There is a &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy" target="_blank" rel="noopener"
>blog post here&lt;/a> and the tool can be downloaded from the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/tree/master/Always-On/FailoverDetection" target="_blank" rel="noopener"
>Tiger Team GitHub Repository&lt;/a>&lt;/p>
&lt;h3 id="a-bit-of-faffing">A Bit of Faffing*&lt;/h3>
&lt;p>It states on the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/blob/master/README.md" target="_blank" rel="noopener"
>readme&lt;/a> for the Tiger Team GitHub Repository.&lt;/p>
&lt;blockquote>
&lt;p>Repository for Tiger team for â€œas-isâ€ solutions and tools/scripts that the team publishes.&lt;/p>
&lt;/blockquote>
&lt;p>The important words are â€œas-isâ€ sometimes these tools need a bit of faffing some looking after!&lt;/p>
&lt;p>There is a pre-requisite and sometimes a little â€œfixingâ€ that you need to do to get it to run correctly.&lt;/p>
&lt;p>First, install the â€œMicrosoft Visual C++ Redistributable for Visual Studio 2017â€ &lt;a class="link" href="https://visualstudio.microsoft.com/downloads/" target="_blank" rel="noopener"
>from here.&lt;/a> On the download page, scroll down to the â€œOther Tools and Frameworksâ€ section to download the redistributable (x64 version).&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/cdistributable.png"
loading="lazy"
alt="cdistributable.PNG"
>&lt;/p>
&lt;p>Then when you run &lt;code>FailoverDetection.exe&lt;/code> you may get strong name validation errors like.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png"
loading="lazy"
alt="strong name.png"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Unhandled Exception: System.IO.FileLoadException: Could not load file or assembly â€˜Microsoft.Sq1Server.XEvent.Linq, Version=15.0.0.0, Culture=neutral, PublicKeyToken=89845dcd808cc91â€™ or one of it s dependencies. Strong name validation failed. (Exception from HRESULT; 0x8013141A) â€“ â€“ â€“ &amp;gt;.Security.SecurityException: Strong name validation failed. (Exception from HRESULT: 0x8e13141A)&lt;br>
â€”End of inner exception stack traceÂ  â€”&lt;br>
at FailoverDetector. XeventParser.LoadXevent(String xelFi1eName, String serverName)&lt;/p>
&lt;/blockquote>
&lt;p>Then you will need to run the sn.exe tool which is in the zip file. Use this syntax.&lt;/p>
&lt;p>&lt;code>.\sn.exe -Vr PATHTODLLFile&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png"
loading="lazy"
alt="stroingname fix.png"
>&lt;/a>&lt;/p>
&lt;p>I had to do it for two DLLs.&lt;/p>
&lt;p>NOTE â€“ If you get an error like this when running sn.exe (or any executable) from PowerShell it means that you have missed the &lt;code>.\&lt;/code> (dot whack) in front of the executable name.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.pnghttps://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png"
loading="lazy"
alt="striong name fail.png"
>&lt;/a>&lt;/p>
&lt;p>* &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>Faffing&lt;/a> â€“ Doing something that is a bit awkwardÂ &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>See Link&lt;/a>Â .&lt;/p>
&lt;h3 id="logs-required-for-the-tool">Logs required for the Tool&lt;/h3>
&lt;p>To run the Failover Detection Utility you need to gather the following information from each replica and place it in the specified data folder.&lt;/p>
&lt;ul>
&lt;li>SQL error logs&lt;/li>
&lt;li>Always On Availability Groups Extended Event Logs&lt;/li>
&lt;li>System Health Extended Event Logs&lt;/li>
&lt;li>System log&lt;/li>
&lt;li>Windows cluster log&lt;/li>
&lt;/ul>
&lt;p>Once you have gathered all of that data then you need to alter the configuration file for the executable.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Data Source Path&amp;#34;: &amp;#34;Path to Data File&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Health Level&amp;#34;: 3,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Instances&amp;#34;: \[
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica1&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica3&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="running-the-tool">Running The Tool&lt;/h3>
&lt;p>Once you have done that you can then run the Failover Detection Utility. You can double click the exe,&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png"
loading="lazy"
alt="run the exe.PNG"
>&lt;/a>&lt;/p>
&lt;p>or you can run it from the command line.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.pnghttps://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png"
loading="lazy"
alt="run the exe with powershell.PNG"
>&lt;/a>&lt;/p>
&lt;p>In both cases it wonâ€™t exit so when you see the Saving Results to JSON file, you can press enter (sometimes twice!).&lt;/p>
&lt;p>The results can be seen in the JSON file which will be stored in a Results directory in the directory that the the FailoverDetection.exe exists.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results.png"
loading="lazy"
alt="results.PNG"
>&lt;/a>&lt;/p>
&lt;p>You can also use some switches with the FailoverDetection utility.&lt;/p>
&lt;p>**â€“Analyze â€“Â **When â€œâ€“Analyzeâ€ is specified as a parameter, the utility will load configuration file without copying log data. It assumes the log files have already been copied over. It does everything as default mode except copying log data. This option is useful if you already have the data in the local tool execution subdirectories and want to rerun the analysis.&lt;/p>
&lt;p>â€“&lt;strong>-Show&lt;/strong>Â -The utility after analyzing log data will display the results in the command console. Additionally, the results will be persisted to a JSON file in the results folder.&lt;/p>
&lt;p>They look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results-show.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results-show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results-show.png"
loading="lazy"
alt="results - show.PNG"
>&lt;/a>&lt;/p>
&lt;p>Again, you need to press enter for the details to come through. The results are still saved to the Results folder as json as well so you wonâ€™t lose them.&lt;/p>
&lt;h3 id="when-you-are-doing-something-more-than-once-">When You Are Doing Something More Than Once â€¦.&lt;/h3>
&lt;p>Automate it ðŸ™‚&lt;/p>
&lt;p>When I saw the data that needed to be gathered for this tool, I quickly turned to PowerShell to enable me to easily gather the information. That has turned into a function which will&lt;/p>
&lt;ul>
&lt;li>Download and extract the zip file from the Tiger Team GitHub repository&lt;/li>
&lt;li>Identify all of the replicas for an Availability Group and dynamically create the configuration JSON file&lt;/li>
&lt;li>Gather all of the required log files and place them in a specified data folder&lt;/li>
&lt;li>Run the FailoverDetection.exe with any of the switches&lt;/li>
&lt;li>Includes -Verbose, -Confirm, -Whatif switches so that you can easily see what is happening, be prompted to confirm before actions or see what would happen if you ran the function&lt;/li>
&lt;li>You still need to press enter at the end though ðŸ™&lt;/li>
&lt;li>and you will still need to install the â€œMicrosoft Visual C++ Redistributable for Visual Studio 2017â€ and runt he strong names tool if needed&lt;/li>
&lt;/ul>
&lt;p>This function requires PowerShell version 5, the failovercluster module and and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment â€“ will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>&lt;code>. .\Invoke-SqlFailOverDetection.ps1&lt;/code>&lt;/p>
&lt;p>There are two .â€™s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>&lt;code>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/code>&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters.&lt;/p>
&lt;p>Letâ€™s see it in action.&lt;/p>
&lt;p>First lets run with a -WhatIf switch which will show us what will happen without performing any state changing actions.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat -WhatIf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png"
loading="lazy"
alt="whatif.PNG"
>&lt;/a>&lt;/p>
&lt;p>So you can see that if we run it without the -WhatIf switch it will&lt;/p>
&lt;ul>
&lt;li>Create some directories&lt;/li>
&lt;li>Download the zip file from the repo&lt;/li>
&lt;li>Extract the zip file&lt;/li>
&lt;li>Copy the required logs from each of the replicas to the data folder&lt;/li>
&lt;li>Create the JSON configuration file&lt;/li>
&lt;li>Run the executable&lt;/li>
&lt;/ul>
&lt;p>NOTE : â€“ I have limited the gathering of the system event log to the last 2 days to limit the amount of time spent dealing with a large system log. I gather all of the SQL Error logs in the Error log path as that works for the first scenario I wrote this for, your mileage may vary.&lt;/p>
&lt;p>So if we want to run the command we can remove the -WhatIf switch.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It can take a little while to run depending on the number of replicas, size of logs etc but once it has started running you can do other things.&lt;/p>
&lt;p>It will require being run as an account with permissions to all of the folders specified and Windows and SQL permissions on all of the replicas in the Availability Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run1.png"
loading="lazy"
alt="run1.PNG"
>&lt;/a>&lt;/p>
&lt;p>As you can see below it has gathered all of the results and placed them in the data folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png"
loading="lazy"
alt="datagathered.PNG"
>&lt;/a>&lt;/p>
&lt;p>The results can be found in the results folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png"
loading="lazy"
alt="resultsjson.PNG"
>&lt;/a>&lt;/p>
&lt;p>If I have already run the tool, I can use the Analyze switch to save gathering the data again. I also use the AlreadyDownloaded switch as I do not need to download the zip file again.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png"
loading="lazy"
alt="analyze.PNG"
>&lt;/a>&lt;/p>
&lt;p>and the results are again saved in the results folder.&lt;/p>
&lt;p>I can show the results on the screen as well as saving them as JSON with the Show parameter.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Show = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/show.png"
loading="lazy"
alt="show.PNG"
>&lt;/a>&lt;/p>
&lt;p>You will then need to press enter to get the next lot of results.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/more-show-results.png"
loading="lazy"
alt="more show results.PNG"
>&lt;/p>
&lt;h3 id="why-not-add-this-to-dbatools">Why Not Add This To dbatools?&lt;/h3>
&lt;p>I havenâ€™t added this to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> (yet) because I wrote it in this way for a particular need and &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> requires support for PowerShell V3 . I have, however created an issueÂ a&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools/issues/4601" target="_blank" rel="noopener"
>dded to this issue in the dbatools GitHub Repository&lt;/a> (as this is how you to start the process of adding things to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>) so hopefully we can get it in there soon as well â€“ in which case I will come back and update this post.&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>dbachecks â€“ Which Configuration Item For Which Check ?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-which-configuration-item-for-which-check/</link><pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-which-configuration-item-for-which-check/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/03-New-dbccheck.png" alt="Featured image of post dbachecks â€“ Which Configuration Item For Which Check ?" />&lt;p>I love showing &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> to people. Itâ€™s really cool seeing how people will use it and listening to their experiences. I was showing it to a production DBA a month or so ago and he said&lt;/p>
&lt;h2 id="how-do-i-know-which-checks-there-are">How Do I Know Which Checks There Are?&lt;/h2>
&lt;p>OK you just need to run&lt;/p>
&lt;p>&lt;code>Get-DbcCheck&lt;/code>&lt;/p>
&lt;p>and it will show you&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-get-dbcchecks.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-get-dbcchecks.png"
loading="lazy"
alt="01 - get-dbcchecks.png"
>&lt;/a>&lt;/p>
&lt;p>It will show you the group, the type (does it need a computer name or an instance name), The description, the unique tag for running just that check and all the tags that will run that check&lt;/p>
&lt;p>OK he said, you talked about configurations&lt;/p>
&lt;h2 id="how-do-i-know-which-configurations-there-are">How Do I Know Which Configurations There Are?&lt;/h2>
&lt;p>So to do that you just need to run&lt;/p>
&lt;p>&lt;code>Get-DbcConfig&lt;/code>&lt;/p>
&lt;p>and it will show you&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-dbcconfig.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-dbcconfig.png"
loading="lazy"
alt="02 - dbcconfig.png"
>&lt;/a>&lt;/p>
&lt;p>You can see the name, the current value and the description&lt;/p>
&lt;p>Ah thats cool he said so&lt;/p>
&lt;h2 id="how-do-i-know-which-configuration-is-for-which-check">How Do I Know Which Configuration Is For Which Check?&lt;/h2>
&lt;p>Well, you justâ€¦. , you knowâ€¦â€¦ AHHHHHHH&lt;/p>
&lt;p>Ping â€“ light bulb moment!&lt;/p>
&lt;p>Itâ€™s always really useful to give something you have built to people who have never seen it before and then listen to what they say. Their new eyes and different experiences or expectations will give you lots of insight&lt;/p>
&lt;p>None of the amazing contributors to dbachecks had thought of this scenario so I decided to fix this. First I asked for an &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/issues" target="_blank" rel="noopener"
>issue to be raised in GitHub&lt;/a>Â because an issue can be an improvement or a suggestion not just a bug.&lt;/p>
&lt;p>Then I fixed it so that it would do what was required. Thank you Nick for this feedback and for helping to improve dbachecks&lt;/p>
&lt;p>I improved &lt;code>Get-DbcCheck&lt;/code> so that now it shows the configuration item related to each check&lt;/p>
&lt;p>It is easier to see (and sort or search) if you use Out-GridView&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-New-dbccheck.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-New-dbccheck.png"
loading="lazy"
alt="03 - New dbccheck.png"
>&lt;/a>&lt;/p>
&lt;p>So now you can see which configuration can be set for each check!&lt;/p>
&lt;p>Happy Validating!&lt;/p></description></item><item><title>Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png" alt="Featured image of post Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS" />&lt;p>At the fabulous &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference EU&lt;/a> I presented about Continuous Delivery to the PowerShell Gallery with VSTS and explained how we use VSTS to enable CD for &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>. We even released a new version during the session ðŸ™‚&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So how do we achieve this?&lt;/p>
&lt;p>We have a few steps&lt;/p>
&lt;ul>
&lt;li>Create a project and link to our GitHub&lt;/li>
&lt;li>Run unit uests with Pester to make sure that our code is doing what we expect.&lt;/li>
&lt;li>Update our module version and commit the change to GitHub&lt;/li>
&lt;li>Sign our code with a code signing certificate&lt;/li>
&lt;li>Publish to the PowerShell Gallery&lt;/li>
&lt;/ul>
&lt;h2 id="create-project-and-link-to-github">Create Project and link to GitHub&lt;/h2>
&lt;p>First you need to create a VSTS project by going toÂ &lt;a class="link" href="https://www.visualstudio.com/" target="_blank" rel="noopener"
>https://www.visualstudio.com/&lt;/a> This is free for up to 5 users with 1 concurrent CI/CD queue limited to a maximum of 60 minutes run time which should be more than enough for your PowerShell module.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-sign-up-1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-sign-up-1.png"
loading="lazy"
alt="01 - sign up.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Get Started for free under Visual Studio Team Services and fill in the required information. Then on the front page click new project&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-New-Project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-New-Project.png"
loading="lazy"
alt="02 - New Project.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in the details and click create&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-create-project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-create-project.png"
loading="lazy"
alt="03 - create project.png"
>&lt;/a>&lt;/p>
&lt;p>Click on builds and then new definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-builds.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-builds.png"
loading="lazy"
alt="04- builds.png"
>&lt;/a>&lt;/p>
&lt;p>next you need to link your project to your GitHub (or other source control providers) repository&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-github-auth.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-github-auth.png"
loading="lazy"
alt="05 - github auth.png"
>&lt;/a>&lt;/p>
&lt;p>You can either authorise with OAuth or you can &lt;a class="link" href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/" target="_blank" rel="noopener"
>provide a PAT token following the instructions here&lt;/a>. Once that is complete choose your repo. Save the PAT as you will need it later in the process!&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/06-choose-repo.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/06-choose-repo.png"
loading="lazy"
alt="06 - choose repo.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the branch that you want this build definition to run against.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-branch.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-branch.png"
loading="lazy"
alt="07 branch.png"
>&lt;/a>&lt;/p>
&lt;p>I chose to run the Unit Tests when a PR was merged into the development branch. I will then create another build definition for the master branch to sign the code and update module version. This enables us to push several PRs into the development branch and create a single release for the gallery.&lt;/p>
&lt;p>Then I start with an empty process&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-empty-process.png"
loading="lazy"
alt="08 - empty process.png"
>&lt;/a>&lt;/p>
&lt;p>and give it a suitable name&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-name-it.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-name-it.png"
loading="lazy"
alt="09 - name it.png"
>&lt;/a>&lt;/p>
&lt;p>i chose the hosted queue but you can download an agent to your build server if you need to do more or your integration tests require access to other resources not available on the hosted agent.&lt;/p>
&lt;h2 id="run-unit-tests-with-pester">Run Unit Tests with Pester&lt;/h2>
&lt;p>We have a number of Unit tests in our &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/tree/development/tests" target="_blank" rel="noopener"
>tests folder in dbachecks&lt;/a>Â so we want to run them to ensure that everything is as it should be and the new code will not break existing functionality (and for dbachecks the &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/using-the-ast-in-pester-for-dbachecks/" >format of the PowerBi&lt;/a>)&lt;/p>
&lt;p>You can use theÂ &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=richardfennellBM.BM-VSTS-PesterRunner-Task" target="_blank" rel="noopener"
>Pester Test Runner Build Task&lt;/a>Â from the folk at &lt;a class="link" href="http://blackmarble.com/" target="_blank" rel="noopener"
>Black Marble&lt;/a>Â by clicking on the + sign next to Phase 1 and searching for Pester&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/10-Pester-task-runner.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/10-Pester-task-runner.png"
loading="lazy"
alt="10 - Pester task runner.png"
>&lt;/a>&lt;/p>
&lt;p>You will need to click Get It Free to install it and then click add to add the task to your build definition. You can pretty much leave it as default if you wish and Pester will run all of the *.Tests.ps1 files that it finds in the directory where it downloads the GitHub repo which is referred to using the variableÂ $(Build.SourcesDirectory). It will then output the results to a json file called Test-Pester.XML ready for publishing.&lt;/p>
&lt;p>However, as dbachecks has a number of dependent modules, this task was not suitable. I spoke with Chris GardnerÂ  &lt;a class="link" href="https://chrislgardner.github.io/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/HalbaradKenafin" target="_blank" rel="noopener"
>t&lt;/a>Â  from Black Marble at the PowerShell Conference and he says that this can be resolved so look out for the update. Chris is a great guy and always willing to help, you can often find him in the &lt;a class="link" href="http://slack.poshcode.org/" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a> answering questions and helping people&lt;/p>
&lt;p>But as you can use PowerShell in VSTS tasks, this is not a problem although you need to write your PowerShell using try catch to make sure that your task fails when your PowerShell errors. This is the code I use to install the modules&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;&lt;/p>
&lt;p># Set location to module home path in artifacts directory
try {
Set-Location $(Build.SourcesDirectory)
Get-ChildItem
}
catch {
Write-Error &amp;ldquo;Failed to set location&amp;rdquo;&lt;/p>
&lt;p>}&lt;/p>
&lt;p># Get the Module versions
Install-Module Configuration -Scope CurrentUser -Force
$Modules = Get-ManifestValue -Path .\dbachecks.psd1 -PropertyName RequiredModules&lt;/p>
&lt;p>$PesterVersion = $Modules.Where{$&lt;em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;Pester&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$PSFrameworkVersion = $Modules.Where{$&lt;/em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;PSFramework&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$dbatoolsVersion = $Modules.Where{$_.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;dbatools&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)&lt;/p>
&lt;p># Install Pester
try {
Write-Output &amp;ldquo;Installing Pester&amp;rdquo;
Install-Module Pester -RequiredVersion $PesterVersion -Scope CurrentUser -Force -SkipPublisherCheck
Write-Output &amp;ldquo;Installed Pester&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install Pester $($_)&amp;rdquo;
}
# Install dbatools
try {
Write-Output &amp;ldquo;Installing PSFramework&amp;rdquo;
Install-Module PSFramework -RequiredVersion $PsFrameworkVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed PSFramework&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install PSFramework $($_)&amp;rdquo;
}
# Install dbachecks
try {
Write-Output &amp;ldquo;Installing dbatools&amp;rdquo;
Install-Module dbatools -RequiredVersion $dbatoolsVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed dbatools&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbatools $($_)&amp;rdquo;
}&lt;/p>
&lt;p># Add current folder to PSModulePath
try {
Write-Output &amp;ldquo;Adding local folder to PSModulePath&amp;rdquo;
$ENV:PSModulePath = $ENV:PSModulePath + &amp;ldquo;;$pwd&amp;rdquo;
Write-Output &amp;ldquo;Added local folder to PSModulePath&amp;rdquo; &lt;br>
$ENV:PSModulePath.Split(&amp;rsquo;;&amp;rsquo;)
}
catch {
Write-Error &amp;ldquo;Failed to add $pwd to PSModulePAth - $_&amp;rdquo;
}&lt;/p>
&lt;p>I use the &lt;a class="link" href="https://github.com/PoshCode/Configuration" target="_blank" rel="noopener"
>Configuration module&lt;/a> from &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>Joel Bennett&lt;/a>Â to get the required module versions for the required modules and then add the path toÂ $ENV:PSModulePath so that the modules will be imported. I think this is because the modules did not import correctly without it.&lt;/p>
&lt;p>Once I have the modules I can then run Pester as follows&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Installing dbachecks&amp;rdquo;
Import-Module .\dbachecks.psd1
Write-Output &amp;ldquo;Installed dbachecks&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbachecks $($_)&amp;rdquo;
}
$TestResults = Invoke-Pester .\tests -ExcludeTag Integration,IntegrationTests -Show None -OutputFile $(Build.SourcesDirectory)\Test-Pester.XML -OutputFormat NUnitXml -PassThru&lt;/p>
&lt;p>if ($TestResults.failedCount -ne 0) {
Write-Error &amp;ldquo;Pester returned errors&amp;rdquo;
}&lt;/p>
&lt;p>As you can see I import the dbachecks module from the local folder, run Invoke-Pester and output the results to an XML file and check that there are no failing tests.&lt;/p>
&lt;p>Whether you use the task or PowerShell the next step is to Publish the test results so that they are displayed in the build results in VSTS.&lt;/p>
&lt;p>Click on the + sign next to Phase 1 and search for Publish&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/12-publish-test-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/12-publish-test-results.png"
loading="lazy"
alt="12 - publish test results.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the Publish Test Results task and leave everything as default unless you have renamed the xml file. This means that on the summary page you will see some test results&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/13-Test-on-sumary-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/13-Test-on-sumary-page.png"
loading="lazy"
alt="13 - Test on sumary page.png"
>&lt;/a>&lt;/p>
&lt;p>and on the tests tab you can see more detailed information and drill down into the tests&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/14-detailed-test-report.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/14-detailed-test-report.png"
loading="lazy"
alt="14 - detailed test report.png"
>&lt;/a>&lt;/p>
&lt;h2 id="trigger">Trigger&lt;/h2>
&lt;p>The next step is to trigger a build when a commit is pushed to the development branch. Click on Triggers and tick enable continuous integration&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/15-Trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/15-Trigger.png"
loading="lazy"
alt="15 Trigger.png"
>&lt;/a>&lt;/p>
&lt;h2 id="saving-the-build-definition">Saving the Build Definition&lt;/h2>
&lt;p>I would normally save the build definition regularly and ensure that there is a good message in the comment. I always tell clients that this is like a commit message for your build process so that you can see the history of the changes for the build definition.&lt;/p>
&lt;p>You can see the history on the edit tab of the build definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/16-build-history.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/16-build-history.png"
loading="lazy"
alt="16 - build history.png"
>&lt;/a>&lt;/p>
&lt;p>If you want to compare or revert the build definition this can be done using the hamburger menu as shown below.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/17-build-history-compare-revert.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/17-build-history-compare-revert.png"
loading="lazy"
alt="17 - build history compare revert.png"
>&lt;/a>&lt;/p>
&lt;h2 id="update-the-module-version">Update the Module Version&lt;/h2>
&lt;p>Now we need to create a build definition for the master branch to update the module version and sign the code ready for publishing to the PowerShell Gallery when we commit or merge to master&lt;/p>
&lt;p>Create a new build definition as above but this time choose the master branch&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/18-master-build.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/18-master-build.png"
loading="lazy"
alt="18 - master build.png"
>&lt;/a>&lt;/p>
&lt;p>Again choose an empty process and name it sensibly, click the + sign next to Phase 1 and search for PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/19-PowerShell-task.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/19-PowerShell-task.png"
loading="lazy"
alt="19 - PowerShell task.png"
>&lt;/a>&lt;/p>
&lt;p>I change the version to 2 and use this code. Note that the commit message hasÂ ***NO_CI*** in it. Putting this in a commit message tells VSTS not to trigger a build for this commit.&lt;/p>
&lt;p>$manifest = Import-PowerShellDataFile .\dbachecks.psd1
[version]$version = $Manifest.ModuleVersion
Write-Output &amp;ldquo;Old Version - $Version&amp;rdquo;
# Add one to the build of the version number
[version]$NewVersion = &amp;ldquo;{0}.{1}.{2}&amp;rdquo; -f $Version.Major, $Version.Minor, ($Version.Build + 1)
Write-Output &amp;ldquo;New Version - $NewVersion&amp;rdquo;
# Update the manifest file
try {
Write-Output &amp;ldquo;Updating the Module Version to $NewVersion&amp;rdquo;
$path = &amp;ldquo;$pwd\dbachecks.psd1&amp;rdquo;
(Get-Content .\dbachecks.psd1) -replace $version, $NewVersion | Set-Content .\dbachecks.psd1 -Encoding string
Write-Output &amp;ldquo;Updated the Module Version to $NewVersion&amp;rdquo;
}
catch {
Write-Error &amp;ldquo;Failed to update the Module Version - $_&amp;rdquo;
}&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Updating GitHub&amp;rdquo;
git config user.email &amp;ldquo;&lt;a class="link" href="mailto:mrrobsewell@outlook.com" >mrrobsewell@outlook.com&lt;/a>&amp;rdquo;
git config user.name &amp;ldquo;SQLDBAWithABeard&amp;rdquo;
git add .\dbachecks.psd1
git commit -m &amp;ldquo;Updated Version Number to $NewVersion ***NO_CI***&amp;rdquo;&lt;/p>
&lt;p>git push https://$(RobsGitHubPAT)@github.com/sqlcollaborative/dbachecks.git HEAD:master
Write-Output &amp;ldquo;Updated GitHub &amp;quot;&lt;/p>
&lt;p>}
catch {
$_ | Fl -Force
Write-Output &amp;ldquo;Failed to update GitHub&amp;rdquo;
}&lt;/p>
&lt;p>I use Get-Content Set-Content as I had errors with the Update-ModuleManifest but Adam Murray &lt;a class="link" href="https://github.com/muzzar78" target="_blank" rel="noopener"
>g&lt;/a> | &lt;a class="link" href="https://twitter.com/muzzar78" target="_blank" rel="noopener"
>t&lt;/a> uses this code to update the version using the BuildID from VSTS&lt;/p>
&lt;p>$newVersion = New-Object version -ArgumentList 1, 0, 0, $env:BUILD_BUILDID
$Public = @(Get-ChildItem -Path $ModulePath\Public\*.ps1)
$Functions = $public.basename
Update-ModuleManifest -Path $ModulePath\$ModuleName.psd1 -ModuleVersion $newVersion -FunctionsToExport $Functions&lt;/p>
&lt;p>You can commit your change by adding your PAT token as a variable under the variables tab. Donâ€™t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/20-variables.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/20-variables.png"
loading="lazy"
alt="20 - variables.png"
>&lt;/a>&lt;/p>
&lt;h2 id="sign-the-code-with-a-certificate">Sign the code with a certificate&lt;/h2>
&lt;p>The SQL Collaborative uses a code signing certificate from &lt;a class="link" href="https://digicert.com/" target="_blank" rel="noopener"
>DigiCert&lt;/a>Â who allow MVPs to use one for free to sign their code for open source projects, Thank You. We had to upload the certificate to the secure files store in the VSTS library. Click on library, secure files and the blue +Secure File button&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/21-secure-file-store.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/21-secure-file-store.png"
loading="lazy"
alt="21 - secure file store.png"
>&lt;/a>&lt;/p>
&lt;p>You also need to add the password as a variable under the variables tab as above. Again donâ€™t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>Then you need to add a task to download the secure file. Click on the + sign next to Phase 1 and search for secure&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/22-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/22-download-secure-file.png"
loading="lazy"
alt="22 download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>choose the file from the drop down&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/23-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/23-download-secure-file.png"
loading="lazy"
alt="23 - download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>Next we need to import the certificate and sign the code. I use a PowerShell task for this with the following code&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;
# read in the certificate from a pre-existing PFX file
# I have checked this with @IISResetMe and this does not go in the store only memory
$cert = [System.Security.Cryptography.X509Certificates.X509Certificate2]::new(&amp;quot;$(Agent.WorkFolder)\_temp\dbatools-code-signing-cert.pfx&amp;rdquo;,&amp;quot;$(CertPassword)&amp;quot;)&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Signing Files&amp;rdquo;
# find all scripts in your module&amp;hellip;
Get-ChildItem -Filter *.ps1 -Include *.ps1 -Recurse -ErrorAction SilentlyContinue |
# &amp;hellip;that do not have a signature yet&amp;hellip;
Where-Object {
($_ | Get-AuthenticodeSignature).Status -eq &amp;lsquo;NotSigned&amp;rsquo;
} |
# and apply one
# (note that we added -WhatIf so no signing occurs. Remove this only if you
# really want to add digital signatures!)
Set-AuthenticodeSignature -Certificate $cert
Write-Output &amp;ldquo;Signed Files&amp;rdquo;
}
catch {
$_ | Format-List -Force
Write-Error &amp;ldquo;Failed to sign scripts&amp;rdquo;
}&lt;/p>
&lt;p>which will import the certificate into memory and sign all of the scripts in the module folder.&lt;/p>
&lt;h2 id="publish-your-artifact">Publish your artifact&lt;/h2>
&lt;p>The last step of the master branch build publishes the artifact (your signed module) to VSTS ready for the release task. Again, click the + sign next to Phase one and choose the Publish Artifact task not the deprecated copy and publish artifact task and give the artifact a useful name&lt;/p>
&lt;h2 id="24---publish-artifactpngassetsuploads20180524-publish-artifactpngassetsuploads20180524-publish-artifactpng">&lt;a class="link" href="assets/uploads/2018/05/24-publish-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/24-publish-artifact.png"
loading="lazy"
alt="24 - publish artifact.png"
>&lt;/a>&lt;/h2>
&lt;p>Donâ€™t forget to set the trigger for the master build as well following the same steps as the development build above&lt;/p>
&lt;h2 id="publish-to-the-powershell-gallery">Publish to the PowerShell Gallery&lt;/h2>
&lt;p>Next we create a release to trigger when there is an artifact ready and publish to the PowerShell Gallery.&lt;/p>
&lt;p>Click the Releases tab and New Definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/25-Reelase-creation.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/25-Reelase-creation.png"
loading="lazy"
alt="25 - Reelase creation"
>&lt;/a>&lt;/p>
&lt;p>Choose an empty process and name the release definition appropriately&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/26-Release-name-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/26-Release-name-empty-process.png"
loading="lazy"
alt="26 Release name empty process.png"
>&lt;/a>&lt;/p>
&lt;p>Now click on the artifact and choose the master build definition. If you have not run a build you will get an error like below but dont worry click add.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/27-add-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/27-add-artifact.png"
loading="lazy"
alt="27 - add artifact.png"
>&lt;/a>&lt;/p>
&lt;p>Click on the lightning bolt next to the artifact to open the continuous deployment trigger&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Choose-lightning-bolt.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Choose-lightning-bolt.png"
loading="lazy"
alt="28 - Choose lightning bolt"
>&lt;/a>&lt;/p>
&lt;p>and turn on Continuous Deployment so that when an artifact has been created with an updated module version and signed code it is published to the gallery&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Continuous-deployment-trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Continuous-deployment-trigger.png"
loading="lazy"
alt="28 - Continuous deployment trigger"
>&lt;/a>&lt;/p>
&lt;p>Next, click on the environment and name it appropriately and then click on the + sign next to Agent Phase and choose a PowerShell step&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/29-PowerShell-Publish-step.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/29-PowerShell-Publish-step.png"
loading="lazy"
alt="29 - PowerShell Publish step"
>&lt;/a>&lt;/p>
&lt;p>You may wonder why I dont choose the PowerShell Gallery Packager task. There are two reasons. First I need to install the required modules for dbachecks (dbatools, PSFramework, Pester) prior to publishing and second it appears that the API Key is stored in plain text&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png"
loading="lazy"
alt="30 - PowerShell Gallery Publisher"
>&lt;/a>&lt;/p>
&lt;p>I save my API key for the PowerShell Gallery as a variable again making sure to tick the padlock to make it a secret&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/31-API-Key-variable.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/31-API-Key-variable.png"
loading="lazy"
alt="31 - API Key variable.png"
>&lt;/a>&lt;/p>
&lt;p>and then use the following code to install the required modules and publish the module to the gallery&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser -Force
Install-Module Pester -Scope CurrentUser -SkipPublisherCheck -Force
Install-Module PSFramework -Scope CurrentUser -Force&lt;/p>
&lt;p>Publish-Module -Path &amp;ldquo;$(System.DefaultWorkingDirectory)/Master - Version Update, Signing and Publish Artifact/dbachecks&amp;rdquo; -NuGetApiKey &amp;ldquo;$(GalleryApiKey)&amp;rdquo;&lt;/p>
&lt;p>Thats it ðŸ™‚&lt;/p>
&lt;p>Now we have a process that will automatically run our Pester tests when we commit or merge to the development branch and then update our module version number and sign our code and publish to the PowerShell Gallery when we commit or merge to the master branch&lt;/p>
&lt;h2 id="added-extra--dashboard">Added Extra â€“ Dashboard&lt;/h2>
&lt;p>I like to create dashboards in VSTS to show the progress of the various definitions. You can do this under the dashboard tab. Click edit and choose or search for widgets and add them to the dashboard&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/32-Dashboard.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png"
loading="lazy"
alt="32 - Dashboard.png"
>&lt;/a>&lt;/p>
&lt;h2 id="added-extra--badges">Added Extra â€“ Badges&lt;/h2>
&lt;p>You can also enable badges for displaying on your readme in GitHub (or VSTS). For the build defintions this is under the options tab.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/33-Build-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/33-Build-badges.png"
loading="lazy"
alt="33 - Build badges"
>&lt;/a>&lt;/p>
&lt;p>for the release definitions, click the environment and then options and integrations&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/34-Release-Badge.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/34-Release-Badge.png"
loading="lazy"
alt="34 - Release Badge"
>&lt;/a>&lt;/p>
&lt;p>You can then copy the URL and use it in your readme &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>like this on dbachecks&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/35-dbachecks-readme-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/35-dbachecks-readme-badges.png"
loading="lazy"
alt="35 - dbachecks readme badges.png"
>&lt;/a>&lt;/p>
&lt;p>The SQL Collaborative has joined the preview of enabling public access to VSTS projects as &lt;a class="link" href="https://blogs.msdn.microsoft.com/devops/2018/04/27/vsts-public-projects-limited-preview/" target="_blank" rel="noopener"
>detailed in this blog post&lt;/a>Â So you can &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/dbachecks%20Team/_build" target="_blank" rel="noopener"
>see the dbachecks build and release without the need to log in&lt;/a> and soon &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbatools/_build" target="_blank" rel="noopener"
>the dbatools process as well&lt;/a>&lt;/p>
&lt;p>I hope you found this useful and if you have any questions or comments please feel free to contact me&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>VS Code â€“ Terminal crashes when formatting script</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-terminal-crashes-when-formatting-script/</link><pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-terminal-crashes-when-formatting-script/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/formatting.gif" alt="Featured image of post VS Code â€“ Terminal crashes when formatting script" />&lt;p>I love VS Code. I love being able to press ALT + SHIFT + F and format my code.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/formatting.gif" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/formatting.gif"
loading="lazy"
alt="formatting.gif"
>&lt;/a>&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/format-error.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/format-error.png"
loading="lazy"
alt="format error.png"
>&lt;/a>&lt;/p>
&lt;p>I could reproduce it will. This was very frustrating.&lt;/p>
&lt;h2 id="turning-on-verbose-logging">Turning on Verbose Logging&lt;/h2>
&lt;p>To turn on verbose logging for the PowerShell Editor Services go the Cog in the bottom left, click it and then click User Settings.&lt;/p>
&lt;p>Search for powershell.developer.editorServicesLogLevel&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/powershell.developer.editorServicesLogLevel.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/powershell.developer.editorServicesLogLevel.png"
loading="lazy"
alt="powershell.developer.editorServicesLogLevel.png"
>&lt;/a>&lt;/p>
&lt;p>If you hover over the left hand channel a pencil will appear, click it and then click replace in settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/edit-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/edit-settings.png"
loading="lazy"
alt="edit settings.png"
>&lt;/a>&lt;/p>
&lt;p>This will put the entry in the right hand side where you can change the value. Set it to Verbose and save&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/user-settigns.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/user-settigns.png"
loading="lazy"
alt="user settigns.png"
>&lt;/a>&lt;/p>
&lt;p>a prompt will come up asking if you want to restart PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/start-a-new-session.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/start-a-new-session.png"
loading="lazy"
alt="start a new session.png"
>&lt;/a>&lt;/p>
&lt;p>When you restart PowerShell, if you click onÂ  Output and choose PowerShell Extension Logs you will see the path to the log file&lt;/p>
&lt;h2 id="logfilepathpnghttpsblogrobsewellcomassetsuploads201802logfilepathpnghttpsblogrobsewellcomassetsuploads201802logfilepathpng">&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/logfilepath.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/logfilepath.png"
loading="lazy"
alt="logfilepath.png"
>&lt;/a>&lt;/h2>
&lt;h2 id="reproduce-the-error">Reproduce the error&lt;/h2>
&lt;p>I then reproduced the error and opened the log file this is what I got&lt;/p>
&lt;blockquote>
&lt;p>10/02/2018 09:11:19 [ERROR] â€“ Method â€œOnListenTaskCompletedâ€ at line 391 of C:\projects\powershelleditorservices\src\PowerShellEditorServices.Protocol\MessageProtocol\ProtocolEndpoint.cs&lt;/p>
&lt;p>ProtocolEndpoint message loop terminated due to unhandled exception:&lt;/p>
&lt;p>System.AggregateException: One or more errors occurred. â€”&amp;gt; System.Management.Automation.CommandNotFoundException: The term â€˜Invoke-Formatterâ€™ is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.&lt;br>
at System.Management.Automation.Runspaces.PipelineBase.Invoke(IEnumerable input)&lt;br>
at System.Management.Automation.PowerShell.Worker.ConstructPipelineAndDoWork(Runspace rs, Boolean performSyncInvoke)&lt;br>
at System.Management.Automation.PowerShell.Worker.CreateRunspaceIfNeededAndDoWork(Runspace rsToUse, Boolean isSync)&lt;br>
at System.Management.Automation.PowerShell.CoreInvokeHelper[TInput,TOutput](PSDataCollection`1 input, PSDataCollection`1 output, PSInvocationSettings settings)&lt;br>
at System.Management.Automation.PowerShell.CoreInvoke[TInput,TOutput](PSDataCollection`1 input, PSDataCollection`1 output, PSInvocationSettings settings)&lt;br>
at System.Management.Automation.PowerShell.Invoke(IEnumerable input, PSInvocationSettings settings)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.InvokePowerShell(String command, IDictionary&lt;code>2 paramArgMap)
at System.Threading.Tasks.Task&lt;/code>1.InnerInvoke()&lt;br>
at System.Threading.Tasks.Task.Execute()&lt;br>
â€” End of stack trace from previous location where exception was thrown â€”&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;br>
at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.&lt;!-- raw HTML omitted -->d__31.MoveNext()&lt;br>
â€” End of stack trace from previous location where exception was thrown â€”&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;br>
at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.&lt;!-- raw HTML omitted -->d__22.MoveNext()&lt;br>
â€” End of stack trace from previous location where exception was thrown â€”&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;/p>
&lt;/blockquote>
&lt;h2 id="open-an-issue-on-github">Open an issue on GitHub&lt;/h2>
&lt;p>I couldnt quickly see what was happening so &lt;a class="link" href="https://github.com/PowerShell/vscode-powershell/issues/1193" target="_blank" rel="noopener"
>I opened an issue&lt;/a> on the &lt;a class="link" href="https://github.com/PowerShell/vscode-powershell" target="_blank" rel="noopener"
>vscode-powershell repo&lt;/a>Â by going to issues and clicking new issue and following the instructions&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/new-issue.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/new-issue.png"
loading="lazy"
alt="new issue.png"
>&lt;/a>&lt;/p>
&lt;h2 id="the-resolution">The Resolution&lt;/h2>
&lt;p>Keith Hill &lt;a class="link" href="https://rkeithhill.wordpress.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/r_keith_hill" target="_blank" rel="noopener"
>t&lt;/a>Â pointed me to the resolution. Thank you Keith.&lt;/p>
&lt;p>Further up in the log file there is a line where the editor services is loading the PSScriptAnalyzer module and it should have the Invoke-Formatter command exported, but mine was not. It loaded the PsScriptAnalyzer moduleÂ  from my users module directory&lt;/p>
&lt;blockquote>
&lt;p>10/02/2018 09:11:01 [NORMAL] â€“ Method â€œFindPSScriptAnalyzerModuleâ€ at line 354 of C:\projects\powershelleditorservices\src\PowerShellEditorServices\Analysis\AnalysisService.cs&lt;/p>
&lt;p>PSScriptAnalyzer found at C:\Users\XXXX\Documents\WindowsPowerShell\Modules\PSScriptAnalyzer\1.10.0\PSScriptAnalyzer.psd1&lt;/p>
&lt;p>10/02/2018 09:11:01 [VERBOSE] â€“ Method â€œEnumeratePSScriptAnalyzerCmdletsâ€ at line 389 of C:\projects\powershelleditorservices\src\PowerShellEditorServices\Analysis\AnalysisService.cs&lt;/p>
&lt;p>The following cmdlets are available in the imported PSScriptAnalyzer module:&lt;br>
Get-ScriptAnalyzerRule&lt;br>
Invoke-ScriptAnalyzer&lt;/p>
&lt;/blockquote>
&lt;p>I ran&lt;/p>
&lt;p>$Env:PSModulePath.Split(&amp;rsquo;;')&lt;/p>
&lt;p>to see the module paths&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/module-path.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/module-path.png"
loading="lazy"
alt="module path.png"
>&lt;/a>&lt;/p>
&lt;p>and looked in the .vscode-insiders\extensions\ms-vscode.powershell-1.5.1\modules directory. There was no PsScriptAnalyzer folder&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/no-module.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/no-module.png"
loading="lazy"
alt="no module.png"
>&lt;/a>&lt;/p>
&lt;p>So I copied the PSScriptAnalyzer folder from the normal VS Code PowerShell Extension module folder into that folder and restarted PowerShell and I had my formatting back again ðŸ™‚&lt;/p>
&lt;p>I then reset the logging mode in my user settings back to Normal&lt;/p>
&lt;p>Thank you Keith&lt;/p></description></item><item><title>How I created PowerShell.cool using Flow, Azure SQL DB, Cognitive Services &amp; PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</link><pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</guid><description>&lt;p>Last weekend I was thinking about how to save the tweets for PowerShell Conference Europe. This annual event occurs in Hanover and this year it is onÂ April 17-20, 2018. The agenda has just been released and you can find it on the websiteÂ &lt;a class="link" href="http://www.psconf.eu/" target="_blank" rel="noopener"
>http://www.psconf.eu/&lt;/a>&lt;/p>
&lt;p>I ended up creating an interactive PowerBi report to which my good friend and Data Platform MVP Paul Andrew &lt;a class="link" href="https://mrpaulandrew.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/mrpaulandrew" target="_blank" rel="noopener"
>t&lt;/a>Â added a bit of magic andÂ I published it. The magnificent Tobias Weltner &lt;a class="link" href="http://www.powertheshell.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/TobiasPSP" target="_blank" rel="noopener"
>t&lt;/a> who organises PSConfEU pointed the domain name &lt;a class="link" href="http://powershell.cool" target="_blank" rel="noopener"
>http://powershell.cool&lt;/a> at the link. It looks like this.&lt;/p>
&lt;p>During the monthly &lt;a class="link" href="https://twitter.com/hashtag/PSTweetChat?src=hash" target="_blank" rel="noopener"
>#PSTweetChat&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Reminder that we do this chat the first Friday of every month from 1-2PM Eastern which I think is 6:00PM UTC &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p>â€” Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959495635182477324?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I mentioned that I need to blog about how I created it and Jeff replied&lt;/p>
&lt;blockquote>
&lt;p>Yes, please. I&amp;rsquo;d love to setup something similiar for the PowerShell+DevOps Summit. &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p>â€” Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959494450547511298?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>so here it is! Looking forward to seeing the comparison between the &lt;a class="link" href="https://powershell.org/summit/" target="_blank" rel="noopener"
>PowerShell and Devops Summi&lt;/a>t and the &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference Europe&lt;/a> ðŸ™‚&lt;/p>
&lt;p>This is an overview of how it works&lt;/p>
&lt;ul>
&lt;li>A &lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>Microsoft Flow&lt;/a> looks for tweets with the &lt;a class="link" href="https://twitter.com/search?q=%23PSConfEU&amp;amp;src=typd" target="_blank" rel="noopener"
>#PSConfEU&lt;/a> hashtag and then gets the information about the tweet&lt;/li>
&lt;li>&lt;a class="link" href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/" target="_blank" rel="noopener"
>Microsoft Cognitive Services Text Analysis API&lt;/a> analyses the sentiment of the tweet and provides a score between 0 (negative) and 1 (positive)&lt;/li>
&lt;li>Details about the tweet and the sentiment are saved in &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/sql-database/" target="_blank" rel="noopener"
>Azure SQL database&lt;/a>&lt;/li>
&lt;li>A &lt;a class="link" href="http://PowerBi.com" target="_blank" rel="noopener"
>PowerBi&lt;/a> report uses that data and provides the report&lt;/li>
&lt;/ul>
&lt;p>You will find all of the resources and the scripts to do all of the below in &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>the GitHub repo.&lt;/a> So clone it and navigate to the filepath&lt;/p>
&lt;h2 id="create-database">Create Database&lt;/h2>
&lt;p>First lets create a database. Connect to your Azure subscription&lt;/p>
&lt;pre>&lt;code>## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YourSubscriptionIDHere
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png"
loading="lazy"
alt="01 - subscription.png"
>&lt;/a>&lt;/p>
&lt;p>Then set some variables&lt;/p>
&lt;pre>&lt;code># The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
# The logical server name: Use a random value or replace with your own value (do not capitalize)
$servername = &amp;quot;server-$(Get-Random)&amp;quot;
# Set an admin login and password for your database
# The login information for the server You need to set these and uncomment them - Dont use these values
# $adminlogin = &amp;quot;ServerAdmin&amp;quot;
# $password = &amp;quot;ChangeYourAdminPassword1&amp;quot;
# The ip address range that you want to allow to access your server - change as appropriate
# $startip = &amp;quot;0.0.0.0&amp;quot;
# $endip = &amp;quot;0.0.0.0&amp;quot;
# To just add your own IP Address
$startip = $endip = (Invoke-WebRequest 'http:// myexternalip.com/raw').Content -replace &amp;quot;`n&amp;quot;
# The database name
$databasename = &amp;quot;tweets&amp;quot;
$AzureSQLServer = &amp;quot;$servername.database. windows.net,1433&amp;quot;
$Table = &amp;quot;table.sql&amp;quot;
$Proc = &amp;quot;InsertTweets.sql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>They should all make sense, take note that you need to set and uncomment the login and password and choose which IPs to allow through the firewall&lt;/p>
&lt;p>Create a Resource Group&lt;/p>
&lt;pre>&lt;code>## Create a resource group
New-AzureRmResourceGroup -Name $resourcegroupname -Location $location
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png"
loading="lazy"
alt="02 - resource group.png"
>&lt;/a>&lt;/p>
&lt;p>Create a SQL Server&lt;/p>
&lt;pre>&lt;code>## Create a Server
$newAzureRmSqlServerSplat = @{
SqlAdministratorCredentials = $SqlAdministratorCredentials
ResourceGroupName = $resourcegroupname
ServerName = $servername
Location = $location
}
New-AzureRmSqlServer @newAzureRmSqlServerSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png"
loading="lazy"
alt="03 - create server.png"
>&lt;/a>&lt;/p>
&lt;p>Create a firewall rule, I just use my own IP and add the allow azure IPs&lt;/p>
&lt;pre>&lt;code>$newAzureRmSqlServerFirewallRuleSplat = @{
EndIpAddress = $endip
StartIpAddress = $startip
ServerName = $servername
ResourceGroupName = $resourcegroupname
FirewallRuleName = &amp;quot;AllowSome&amp;quot;
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
# Allow Azure IPS
$newAzureRmSqlServerFirewallRuleSplat = @{
AllowAllAzureIPs = $true
ServerName = $servername
ResourceGroupName = $resourcegroupname
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png"
loading="lazy"
alt="03a - firewall rule.png"
>&lt;/a>&lt;/p>
&lt;p>Create a database&lt;/p>
&lt;pre>&lt;code># Create a database
$newAzureRmSqlDatabaseSplat = @{
ServerName = $servername
ResourceGroupName = $resourcegroupname
Edition = 'Basic'
DatabaseName = $databasename
}
New-AzureRmSqlDatabase @newAzureRmSqlDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png"
loading="lazy"
alt="04 - create database.png"
>&lt;/a>&lt;/p>
&lt;p>I have used the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>Â to run the scripts to create the database. You can get it using&lt;/p>
&lt;pre>&lt;code>Install-Module dbatools # -Scope CurrentUser # if not admin process
Run the scripts
# Create a credential
$newObjectSplat = @{
ArgumentList = $adminlogin, $ (ConvertTo-SecureString -String $password -AsPlainText -Force)
TypeName = 'System.Management.Automation. PSCredential'
}
$SqlAdministratorCredentials = New-Object @newObjectSplat
## Using dbatools module
$invokeDbaSqlCmdSplat = @{
SqlCredential = $SqlAdministratorCredentials
Database = $databasename
File = $Table,$Proc
SqlInstance = $AzureSQLServer
}
Invoke-DbaSqlCmd @invokeDbaSqlCmdSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png"
loading="lazy"
alt="05 - Create Table Sproc.png"
>&lt;/a>&lt;/p>
&lt;p>This will have created the following in Azure, you can see it in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/07-portal.png"
loading="lazy"
alt="07 - portal.png"
>&lt;/p>
&lt;p>You can connect to the database in SSMS and you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png"
loading="lazy"
alt="06 - show table.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-cognitive-services">Create Cognitive Services&lt;/h2>
&lt;p>Now you can create the Text Analysis Cognitive Services API&lt;/p>
&lt;p>First login (if you need to) and set some variables&lt;/p>
&lt;pre>&lt;code>## This creates cognitive services for analysing the tweets
## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YOUR SUBSCRIPTION ID HERE
#region variables
# The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
$APIName = 'TweetAnalysis'
#endregion
Then create the API and get the key
#Create the cognitive services
$newAzureRmCognitiveServicesAccountSplat = @{
ResourceGroupName = $resourcegroupname
Location = $location
SkuName = 'F0'
Name = $APIName
Type = 'TextAnalytics'
}
New-AzureRmCognitiveServicesAccount @newAzureRmCognitiveServicesAccountSplat
# Get the Key
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat
&lt;/code>&lt;/pre>
&lt;p>You will need to accept the prompt&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png"
loading="lazy"
alt="08 -cognitive service"
>&lt;/a>&lt;/p>
&lt;p>Copy the Endpoint URL as you will need it.Then save one ofÂ  the keys for the next step!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png"
loading="lazy"
alt="09 cognitiveservice key"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow">Create the Flow&lt;/h2>
&lt;p>I have exported the Flow to a zip file and also the json for a PowerApp (no details about that in this post). Both are available in the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a>. I have submitted a template but it is not available yet.&lt;/p>
&lt;p>Navigate toÂ &lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>https://flow.microsoft.com/&lt;/a>Â and sign in&lt;/p>
&lt;h2 id="creating-connections">Creating Connections&lt;/h2>
&lt;p>You will need to set up your connections. Click New Connection and search for Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png"
loading="lazy"
alt="16 - import step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add and fill in the Account Key and the Site URL from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png"
loading="lazy"
alt="17 import step 5.png"
>&lt;/a>&lt;/p>
&lt;p>click new connection and search for SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png"
loading="lazy"
alt="18 - import step 6.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the SQL Server Name (value of &lt;code>$AzureSQLServer&lt;/code>) , Database Name , User Name and Password from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png"
loading="lazy"
alt="19 - import step 7.png"
>&lt;/a>&lt;/p>
&lt;p>Click new Connection and search for Twitter and create a connection (the authorisation pop-up may be hidden behind other windows!)&lt;/p>
&lt;h2 id="import-the-flow">Import the Flow&lt;/h2>
&lt;p>If you have a premium account you can import the flow, click Import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png"
loading="lazy"
alt="11 - import flow.png"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png"
loading="lazy"
alt="12 - choose import.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the import.zip from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub Repo&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png"
loading="lazy"
alt="13 import step 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Create as new and choose a name&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png"
loading="lazy"
alt="14 - import step 2.png"
>&lt;/a>&lt;/p>
&lt;p>Click select during import next to Sentiment and choose the Sentiment connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png"
loading="lazy"
alt="15 impot step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Select during import for the SQL Server Connection and choose the SQL Server Connection and do the same for the Twitter Connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png"
loading="lazy"
alt="20 - import stpe 8.png"
>&lt;/a>&lt;/p>
&lt;p>Then click import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png"
loading="lazy"
alt="21 - imported.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow-without-import">Create the flow without import&lt;/h2>
&lt;p>If you do not have a premium account you can still create the flow using these steps. I have created a template but it is not available at the moment. Create the connections as above and then click Create from blank.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png"
loading="lazy"
alt="22 - importblank.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the trigger When a New Tweet is posted and add a search term. You may need to choose the connection to twitter by clicking the three dots&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png"
loading="lazy"
alt="23 - importblank 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add an action&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png"
loading="lazy"
alt="24 - add action.png"
>&lt;/a>&lt;/p>
&lt;p>search for detect and choose the Text Analytics Detect Sentiment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png"
loading="lazy"
alt="25 - choose sentuiment.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the name for the connection, the account key and the URL from the creation of the API above. If you forgot to copy them&lt;/p>
&lt;pre>&lt;code>#region Forgot the details
# Copy the URL if you forget to save it
$getAzureRmCognitiveServicesAccountSplat = @{
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccount @getAzureRmCognitiveServicesAccountSplat). Endpoint | Clip
# Copy the Key if you forgot
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat). Key1 | Clip
#endregion
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png"
loading="lazy"
alt="26 - enter details.png"
>&lt;/a>&lt;/p>
&lt;p>Click in the text box and choose Tweet Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png"
loading="lazy"
alt="27 - choose tweet text.png"
>&lt;/a>&lt;/p>
&lt;p>Click New Step and add an action. Search for SQL Server and choose SQL Server â€“ Execute Stored Procedure&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png"
loading="lazy"
alt="28 - choose sql server execute stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the stored procedureÂ [dbo].[InsertTweet]&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png"
loading="lazy"
alt="29 - choose stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in as follows&lt;/p>
&lt;ul>
&lt;li>__PowerAppsID__Â  Â  Â  Â  Â 0&lt;/li>
&lt;li>DateÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Created At&lt;/li>
&lt;li>Sentiment Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Score&lt;/li>
&lt;li>Tweet Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Tweet Text&lt;/li>
&lt;li>UserLocationÂ  Â  Â  Â  Â  Â  Â  Â  Â Location&lt;/li>
&lt;li>UserNameÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Tweeted By&lt;/li>
&lt;/ul>
&lt;p>as shown below&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?resize=630%2C368&amp;amp;ssl=1"
loading="lazy"
alt="30 stored procedure info.png"
>&lt;/a>&lt;/p>
&lt;p>Give the flow a name at the top and click save flow&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png"
loading="lazy"
alt="31 flow created.png"
>&lt;/a>&lt;/p>
&lt;h2 id="connect-powerbi">Connect PowerBi&lt;/h2>
&lt;p>Open theÂ PSConfEU Twitter Analysis Direct.pbix from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a> in PowerBi Desktop. Click the arrow next to Edit Queries and then change data source settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png"
loading="lazy"
alt="32 change data source.png"
>&lt;/a>&lt;/p>
&lt;p>Click Change source and enter the serverÂ (value of &lt;code>$AzureSQLServer&lt;/code>) and the database name. It will alert you to apply changes&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png"
loading="lazy"
alt="33 apply changes.png"
>&lt;/a>&lt;/p>
&lt;p>It will then pop-up with a prompt for the credentials. Choose Database and enter your credentials and click connect&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?resize=630%2C370&amp;amp;ssl=1"
loading="lazy"
alt="34 - creds.png"
>&lt;/a>&lt;/p>
&lt;p>and your PowerBi will be populated from the Azure SQL Database ðŸ™‚ This will fail if there are no records in the table because your flow hasnâ€™t run yet. If it does just wait until you see some tweets and then click apply changes again.&lt;/p>
&lt;p>You will probably want to alter the pictures and links etc and then yo can publish the report&lt;/p>
&lt;p>Happy Twitter Analysis&lt;/p>
&lt;p>Dont forget to keep an eye on your flow runs to make sure they have succeeded.&lt;/p></description></item><item><title>TSQL2sDay â€“ Get-PostRoundup</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</link><pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Writing Dynamic and Random Tests Cases for Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/writing-dynamic-and-random-tests-cases-for-pester/</link><pubDate>Thu, 06 Jul 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/writing-dynamic-and-random-tests-cases-for-pester/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Creating a PowerShell Module and TDD for Get-SQLDiagRecommendations</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</link><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>PowerShell Module for the SQL Server Diagnostics API â€“ 1st Command Get-SQLDiagRecommendations</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-module-for-the-sql-server-diagnostics-api-1st-command-get-sqldiagrecommendations/</link><pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-module-for-the-sql-server-diagnostics-api-1st-command-get-sqldiagrecommendations/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>The SQL Server Community Collaborative GitHub Organisation is born</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</link><pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" alt="Featured image of post The SQL Server Community Collaborative GitHub Organisation is born" />&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and I are the creators of two GitHub repositories for SQL Server and PowerShell called &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a>&lt;/p>
&lt;p>If you are working with SQL Server I highly recommend that you take a look at the vast number of commands available to you at &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> which will help you complete tasks within SQL Server especially for Instance migrations and also a growing number of best practice implementations&lt;/p>
&lt;p>Both of these modules are not just the work of one person any more. We have over 20 people who have collaborated on the modules THANK YOU ALL and more that have provided guidance and comments via the Slack Channels in the SQL Server Community Slack &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>Â and via the Trello boards &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>https://dbatools.io/trello&lt;/a> and &lt;a class="link" href="https://dbareports/trello" target="_blank" rel="noopener"
>https://dbareports/trello&lt;/a>&lt;/p>
&lt;p>At SQL Saturday Cambridge this weekend I was proud to join Chrissy in her presentation as we talked about both modules. Heres a fabulous picture of us with Buck Woody&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg"
loading="lazy"
alt="wp_20160910_10_14_58_pro"
>&lt;/a>&lt;/p>
&lt;p>We had discussed previously that it didnâ€™t feel quite right that these community tools were under our own personal accounts and it also caused some administration issues with allowing access. So with that in mind after a naming discussion in the slack channel we created an organisation to hold them both&lt;/p>
&lt;h2 id="sql-server-community-collaborative">Â SQL Server Community Collaborative&lt;/h2>
&lt;p>is born at &lt;a class="link" href="https://github.com/sqlcollaborative" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative&lt;/a>&lt;/p>
&lt;p>Nothing much changes except the name. we have even found that all the old links work and GitHub desktop updated. We will continue to make great commands with all of our fantastic collaborators. Discussions will happen in Slack and organisation in Trello and we will continue to grow and learn and teach andÂ share and create together.&lt;/p>
&lt;p>We would love you to come and join us&lt;/p></description></item><item><title>Remove-SQLDatabaseSafely My First Contribution to DBATools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</link><pubDate>Wed, 20 Jul 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</guid><description>&lt;p>What is DBA Tools?&lt;/p>
&lt;blockquote>
&lt;p>A collection of modules for SQL Server DBAs. It initially started out as â€˜sqlmigrationâ€™, but has now grown into a collection of various commands that help automate DBA tasks and encourage best practices.&lt;/p>
&lt;/blockquote>
&lt;p>You can read more about &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>here&lt;/a>Â and it is &lt;a class="link" href="https://github.com/ctrlbold/dbatools" target="_blank" rel="noopener"
>freely available for download on GitHub&lt;/a>Â I thoroughly recommend that &lt;a class="link" href="https://www.youtube.com/watch?v=PciYdDEBiDM" target="_blank" rel="noopener"
>you watch this quick video&lt;/a> to see just how easy it is to migrate an entire SQL instance in one command (&lt;a class="link" href="https://www.youtube.com/watch?v=kQYUrSlb0wg" target="_blank" rel="noopener"
>Longer session here&lt;/a>Â )&lt;/p>
&lt;p>Installing it is as easy as&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>which will get you over 80 commands . Visit &lt;a class="link" href="https://dbatools.io/functions/" target="_blank" rel="noopener"
>https://dbatools.io/functions/&lt;/a>Â to find out more information about them&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png"
loading="lazy"
alt="cmdlets"
>&lt;/a>&lt;/p>
&lt;p>The journey to &lt;code>Remove-SQLDatabaseSafely&lt;/code> started with William Durkin &lt;a class="link" href="http://williamdurkin.com/" target="_blank" rel="noopener"
>b&lt;/a>Â | &lt;a class="link" href="https://twitter.com/sql_williamd" target="_blank" rel="noopener"
>t&lt;/a>Â who presented to the &lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>SQL South West User Group&lt;/a> Â (&lt;a class="link" href="http://www.sqlsaturday.com/269/Sessions/Details.aspx?sid=28201" target="_blank" rel="noopener"
>You can get his slides here)&lt;/a>&lt;/p>
&lt;p>Following that session Â I wrote a Powershell Script to gather information about the last used date for databases &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-one/" >which I blogged about here&lt;/a> and then a T-SQL script to take a final backup and create a SQL Agent Job to restore from that back up &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-two-2/" >which I blogged about here&lt;/a>Â The team have used this solution (updated to load the DBA Database and aÂ report instead of using Excel) ever since and it proved invaluable when a read-only database was dropped and could quickly and easily be restored with no fuss.&lt;/p>
&lt;p>I was chatting with Chrissy LeMaire who foundedÂ DBAToolsÂ &lt;a class="link" href="https://blog.netnerds.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>t&lt;/a>Â about this process and when she asked for contributions in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a>Â I offered my help and she suggested I write this command. I have learnt so much. I thoroughly enjoyed and highly recommend working on projects collaboratively to improve your skills. It is amazing to work with such incredible professional PowerShell people.&lt;/p>
&lt;p>I went back to the basics and thought about what was required and watched one of my favourite videos again. &lt;a class="link" href="https://sqlps.io/backuprant" target="_blank" rel="noopener"
>Grant Fritcheys Backup Rant&lt;/a>&lt;/p>
&lt;p>I decided that the process should be as follows&lt;/p>
&lt;ol>
&lt;li>Performs a DBCC CHECKDB&lt;/li>
&lt;li>Database is backed up WITH CHECKSUM&lt;/li>
&lt;li>Database is restored with VERIFY ONLY on the source&lt;/li>
&lt;li>An Agent Job is created to easily restore from that backup&lt;/li>
&lt;li>The database is dropped&lt;/li>
&lt;li>The Agent Job restores the database&lt;/li>
&lt;li>performs a DBCC CHECKDB and drops the database for a final time&lt;/li>
&lt;/ol>
&lt;p>This (hopefully) passes all of Grants checks. This is how I created the command&lt;/p>
&lt;p>I check that the SQL Agent is running otherwise we wont be able to run the job. I use a while loop with a timeout like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$agentservice = Get-Service -ComputerName $ipaddr -Name $serviceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($agentservice.Status -ne &amp;#39;Running&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentservice.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $timeout = new-timespan -seconds 60
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $sw = [diagnostics.stopwatch]::StartNew()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentstatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($dbStatus -ne &amp;#39;Running&amp;#39; -and $sw.elapsed -lt $timeout) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dbStatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There are a lot more checks and logic than I will describe here to make sure that the process is as robust as possible. For example, the script can exit after errors are found using DBCC CHECKDB or continue and label the database backup file and restore job appropriately. Unless the force option is used it will exit if the job name already exists. We have tried to think of everything but ifÂ something has beenÂ missed or you have suggestions let us know (details at end of post)&lt;/p>
&lt;p>The only thing I didnâ€™t add was a LARGE RED POP UP SAYING ARE YOU SURE YOU WANT TO DROP THIS DATABASE but I considered it!!&lt;/p>
&lt;h2 id="performs-a-dbcc-checkdb">Performs a DBCC CHECKDB&lt;/h2>
&lt;p>Running DBCC CHECKDB with Powershell is as easy as this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$sourceserver = New-Object Microsoft.SQLServer.Management.Smo.Server &amp;#34;ServerName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $sourceserver.databases[$dbname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $db.CheckTables(&amp;#39;None&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.database.checktables.aspx" target="_blank" rel="noopener"
>you can read more on MSDN&lt;/a>&lt;/p>
&lt;h2 id="database-is-backed-up-with-checksum">Database is backed up WITH CHECKSUM&lt;/h2>
&lt;p>Stuart Moore is my go to for doing &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>backups and restores with SMO&lt;/a>&lt;/p>
&lt;p>I ensured that the backup was performed with checksum like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$backup = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Backup
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Action = [Microsoft.SqlServer.Management.SMO.BackupActionType]::Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.BackupSetDescription = &amp;#34;Final Full Backup of $dbname Prior to Dropping&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Checksum = $True
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="database-is-restored-with-verify-only-on-the-source">Database is restored with VERIFY ONLY on the source&lt;/h2>
&lt;p>I used SMO all the way through this command and performed the restore verify only like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$restoreverify = New-Object &amp;#39;Microsoft.SqlServer.Management.Smo.Restore&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Devices.AddDevice($filename, $devicetype)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$result = $restoreverify.SqlVerify($sourceserver)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="an-agent-job-is-created-to-easily-restore-from-that-backup">An Agent Job is created to easily restore from that backup&lt;/h2>
&lt;p>First I created a category for the Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Function New-SqlAgentJobCategory {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ([string]$categoryname,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [object]$jobServer)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!$jobServer.JobCategories[$categoryname]) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Pscmdlet.ShouldProcess($sourceserver, &amp;#34;Creating Agent Job Category $categoryname&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Creating Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category = New-Object Microsoft.SqlServer.Management.Smo.Agent.JobCategory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Parent = $jobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Name = $categoryname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Created Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Exception $_
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> throw &amp;#34;FAILED : To Create Agent Job Category $categoryname - Aborting&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then generated the TSQL for the restore step by using the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.restore.script.aspx" target="_blank" rel="noopener"
>script method on the Restore SMO object&lt;/a>&lt;/p>
&lt;p>This is how to create an Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$job = New-Object Microsoft.SqlServer.Management.Smo.Agent.Job $jobServer, $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Name = $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.OwnerLoginName = $jobowner
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Description = &amp;#34;This job will restore the $dbname database using the final backup located at $filename&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then to add a job step to run the restore command&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$jobStep = new-object Microsoft.SqlServer.Management.Smo.Agent.JobStep $job, $jobStepName $jobStep.SubSystem = &amp;#39;TransactSql&amp;#39; # &amp;#39;PowerShell&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.DatabaseName = &amp;#39;master&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.Command = $jobStepCommmand
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnSuccessAction = &amp;#39;QuitWithSuccess&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnFailAction = &amp;#39;QuitWithFailure&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Pscmdlet.ShouldProcess($destination, &amp;#34;Creating Agent JobStep on $destination&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $null = $jobStep.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.ApplyToTargetServer($destination)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.StartStepID = $jobStartStepid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Alter()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-database-is-dropped">The database is dropped&lt;/h2>
&lt;p>We try 3 different methods to drop the database&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$server.KillDatabase($dbname)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$server.databases[$dbname].Drop()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $server.ConnectionContext.ExecuteNonQuery(&amp;#34;DROP DATABASE &amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-agent-job-restores-the-database">The Agent Job restores the database&lt;/h2>
&lt;p>To run the Agent Job I call the start method of the Job SMO Object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $job = $destserver.JobServer.Jobs[$jobname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($status -ne &amp;#39;Idle&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;amp;quot; Restore Job for $dbname on $destination is $status&amp;amp;quot;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Refresh()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Start-Sleep -Seconds 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we drop the database for the final time with the confidence that we have a safe backup and an easy one clickÂ method to restore it from that backup (as long as the backup is in the same location)&lt;/p>
&lt;p>There are further details on the &lt;a class="link" href="https://dbatools.io/functions/remove-sqldatabasesafely/" target="_blank" rel="noopener"
>functions page on dbatools&lt;/a>&lt;/p>
&lt;p>Some videos of it in action are on YouTube &lt;a class="link" href="http://dbatools.io/video" target="_blank" rel="noopener"
>http://dbatools.io/video&lt;/a>&lt;/p>
&lt;p>You can take a look at &lt;a class="link" href="https://github.com/ctrlbold/dbatools/blob/fbd2f19b4442a8065f3cb133d385fde9b2cddea0/functions/Remove-SqlDatabaseSafely.ps1" target="_blank" rel="noopener"
>the code on GitHub here&lt;/a>&lt;/p>
&lt;p>You can install it with&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>You can provide feedback via the &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>Trello Board&lt;/a> or discuss it in the #dbatools channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>Sqlserver Community Slack&lt;/a>&lt;/p>
&lt;p>You too can also become a contributor &lt;a class="link" href="https://dbatools.io/join-us/" target="_blank" rel="noopener"
>https://dbatools.io/join-us/&lt;/a>Â Come and write a command to make it easy for DBAs to (this bit is up to your imagination).&lt;/p></description></item><item><title>Some Pester Tests for SQL Defaults</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/some-pester-tests-for-sql-defaults/</link><pubDate>Tue, 24 May 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/some-pester-tests-for-sql-defaults/</guid><description>&lt;p>When I was at &lt;a class="link" href="http://www.psconf.eu/" target="_blank" rel="noopener"
>PowerShell Conference EU&lt;/a> in Hannover last month (The videos are available now â€“ &lt;a class="link" href="https://www.youtube.com/c/powershellconferenceeu" target="_blank" rel="noopener"
>click here&lt;/a> and the &lt;a class="link" href="https://github.com/psconfeu/2016" target="_blank" rel="noopener"
>slides and code here&lt;/a>) I found out about &lt;a class="link" href="https://pshirwin.wordpress.com/2016/04/08/active-directory-operations-test/" target="_blank" rel="noopener"
>Irwin Strachans Active Directory Operations Test&lt;/a> which got me thinking.&lt;/p>
&lt;p>I decided to do the same for my usual SQL Set-up. Treating all of your servers to the same defaults makes it even easier to manage at scale remotely.&lt;/p>
&lt;p>I am comfortable with using SMO to gather and change properties on SQL Instances so I started by doing this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> It &amp;#39;Should have a default Backup Directory of F:\SQLBACKUP\BACKUPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SqlServer.Management.Smo.Server .
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">return $srv.BackupDirectory}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$State = Invoke-Command -ComputerName ROB-SURFACEBOOK -ScriptBlock $Scriptblock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$State |Should Be &amp;#39;F:\SQLBACKUP\BACKUPS&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is the how to find the properties that you want&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> ## Load the Assemblies
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Create a Server SMO object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SqlServer.Management.Smo.Server SERVERNAME
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Explore it
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv|gm
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## If you find an array pick the first one and expand and then explore that
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.Databases[0] | select *
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.Databases[0] | gm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I quickly found as I added more tests that it was taking a long time to perform the tests (about 5 seconds each test) and that it took an age to fail each of the tests if the server name was incorrect or the server unavailable.&lt;/p>
&lt;p>I fixed the first one by testing with a ping before running the tests&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> ## Check for connectivity
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if((Test-Connection $Server -count 1 -Quiet) -eq $false){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Error &amp;#39;Could not connect to $Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$_
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The continue is there because I wanted to loop through an array of servers&lt;/p>
&lt;p>I improved the performance using a remote session and a custom object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;$Server&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BeforeAll {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[pscustomobject]$Return = @{}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = &amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLAdmins = $Using:SQLAdmins
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SQLServer.Management.SMO.Server $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.DBAAdminDb = $Srv.Databases.Name.Contains(&amp;#39;DBA-Admin&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Logins = $srv.Logins.Where{$_.IsSystemObject -eq $false}.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SQLAdmins = @(Compare-Object $Logins $SQLAdmins -SyncWindow 0).Length - $Logins.count -eq $SQLAdmins.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SysAdmins = $Srv.Roles[&amp;#39;sysadmin&amp;#39;].EnumMemberNames()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SQLAdmin = @(Compare-Object $SysAdmins $SQLAdmins -SyncWindow 0).Length - $SysAdmins.count -eq $SQLAdmins.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.BackupDirectory = $srv.BackupDirectory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.DataDirectory = $srv.DefaultFile
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The BeforeAll script block is run, as it sounds like it should, once before all of the tests, BeforeEach would run once before each of the tests. I define an empty custom object and then create an SMO object and add the properties I am interested in testing to it. I then return the custom object at the end&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Return.Alerts82345Exist = ($srv.JobServer.Alerts |Where {$_.Messageid -eq 823 -or $_.Messageid -eq 824 -or $_.Messageid -eq 825}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Enabled = ($srv.JobServer.Alerts |Where {$_.Messageid -eq 823 -or $_.Messageid -eq 824 -or $_.Messageid -eq 825 -and $_.IsEnabled -eq $true}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SysDatabasesFullBackupToday = $srv.Databases.Where{$_.IsSystemObject -eq $true -and $_.Name -ne &amp;#39;tempdb&amp;#39; -and $_.LastBackupDate -lt (Get-Date).AddDays(-1)}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return $Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return = Invoke-Command -ScriptBlock $Scriptblock -ComputerName $Server -ErrorAction Stop
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Error &amp;#34;Unable to Connect to $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">I was then able to test against the property of the custom object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#39;Should have Alerts for Severity 20 and above&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts20SeverityPlusExist | Should Be 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Severity 20 and above Alerts should be enabled&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts20SeverityPlusEnabled | Should Be 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Should have alerts for 823,824 and 825&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Exist |Should Be 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Alerts for 823,824 and 825 should be enebled&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Enabled |Should Be 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Occasionally, for reasons I havenâ€™t explored I had to test against the value property of the returned object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;The Full User Database Backup should be scheduled Weekly $OlaUserFullSchedule&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.OlaUserFullSchedule.value | Should Be $OlaUserFullSchedule
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I wanted to be able to run the tests against environments or groups of servers with different default values so I parameterised the Test Results as well and then the logical step was to turn it into a function and then I could do some parameter splatting. This also gives me the opportunity to show all of the things that I am currently giving parameters to the test for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Parms = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Servers = &amp;#39;SQLServer1&amp;#39;,&amp;#39;SQLServer2&amp;#39;,&amp;#39;SQLServer3&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLAdmins = &amp;#39;THEBEARD\Rob&amp;#39;,&amp;#39;THEBEARD\SQLDBAsAlsoWithBeards&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BackupDirectory = &amp;#39;C:\MSSQL\Backup&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataDirectory = &amp;#39;C:\MSSQL\Data\&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogDirectory = &amp;#39;C:\MSSQL\Logs\&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MaxMemMb = &amp;#39;4096&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Collation = &amp;#39;Latin1_General_CI_AS&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TempFiles = 4 ;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaSysFullFrequency = &amp;#39;Daily&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaSysFullStartTime = &amp;#39;21:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullFrequency = 1 ;## 1 for Sunday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullStartTime = &amp;#39;22:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffFrequency = 126; ## 126 for every day except Sunday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffStartTime = &amp;#39;22:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserLogSubDayInterval = 15;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserLoginterval = &amp;#39;Minute&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitz = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitzCache = $True;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitzIndex = $True;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPAskBrent = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HASSPBlitzTrace = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPWhoisActive = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogWhoIsActiveToTable = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTable = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableEnabled = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableScheduled = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableFrequency = 2 ; # 2 means Monday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableStartTime = &amp;#39;03:00:00&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-SQLDefault @Parms
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have some other tests which always return what I want, particularly the firewall rules which you will have to modify to suit your own environment&lt;/p>
&lt;p>To be able to run this you will need to have the Pester Module. If you are using Windows 10 then it is installed by default, if not&lt;/p>
&lt;p>&lt;code>Find-Module â€“Name 'Pester' | Install-Module&lt;/code>&lt;/p>
&lt;p>You can find more about Pester &lt;a class="link" href="https://mcpmag.com/articles/2016/05/11/testing-powershell-scripts-with-pester.aspx?utm_content=buffer5606b&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="http://mikefrobbins.com/category/pester/" target="_blank" rel="noopener"
>here&lt;/a> and also these &lt;a class="link" href="https://www.youtube.com/channel/UCxgrI58XiKnDDByjhRJs5fg/search?query=pester" target="_blank" rel="noopener"
>videos from the conference&lt;/a>&lt;br>
You can find the tests on &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Test-SQLDefaults.ps1" target="_blank" rel="noopener"
>GitHub here&lt;/a> and I will continue to add to the defaults that I check.&lt;br>
This is not a replacement for other SQL configuration tools such as PBM but it is a nice simple way of giving a report on the current status of a SQL installation either at a particular point in time when something is wrong or after an installation prior to passing the server over to another team or into service&lt;/p></description></item></channel></rss>