<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>dbatools on Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/tags/dbatools/</link><description>Recent content in dbatools on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 28 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/tags/dbatools/index.xml" rel="self" type="application/rss+xml"/><item><title>How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</guid><description>&lt;img src="https://images.unsplash.com/photo-1614791962365-7590111b1b1c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80" alt="Featured image of post How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error" />&lt;p>There are a number of methods to import PowerShell modules into Azure automation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>as described in the documentation here&lt;/a>&lt;/p>
&lt;p>You may however miss an important piece of information hidden in that documentation if you are uploading a module from a GitHub release instead of via the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. The name that you refer to the module must match the module name and module folder name in the zip file.&lt;/p>
&lt;h1 id="method-one---from-gallery">Method one - from Gallery&lt;/h1>
&lt;p>This is my preferred method for importing modules into Azure Automation accounts, the only bothersome part is remembering to do it twice, once for 5.1 and once for 7.1 as I am sure that if I forget that will be the one module that I will need!&lt;/p>
&lt;h2 id="find-the-module">Find the module&lt;/h2>
&lt;p>Go to the Module page for the automation account and then Add module and browse the gallery and search for &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> (other modules are available!) and install it&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550108-e6096986-3392-4585-a57a-5c515c2890bf.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>It will take a few moments to install but you will see it in the list with a green tick once it has imported.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181548887-0ec695e4-41b9-45b3-8ab3-a004968c2323.png"
loading="lazy"
alt="image"
>#&lt;/p>
&lt;p>Then it is available in all of my PowerShell 7.1 runbooks in my automation account - Here I have just run &lt;code>Get-DbaToolsConfig&lt;/code> in a test runbook to prove that the module has imported&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550937-7e89c7b3-31e8-4af1-b965-c82f2f63562f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="method-two---using-the-zip-file-from-a-github-release">Method two - using the zip file from a GitHub Release&lt;/h1>
&lt;p>Sometimes you may wish to not use the PowerShell Gallery to import the modules, maybe you have a custom module that you are not ready to upload to the gallery or maybe the module is just internally developed and not available on the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. In this scenario, you can still import hte module so that it can be used by your runbooks.&lt;/p>
&lt;p>To demonstrate, I will remove the dbatools module from the Automation Account&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181553061-9be2da4d-344d-4027-aa7f-902445cee12b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and download the latest release from GitHub directly&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/dataplat/dbatools/releases/tag/v1.1.118" target="_blank" rel="noopener"
>https://github.com/dataplat/dbatools/releases/tag/v1.1.118&lt;/a>&lt;/p>
&lt;p>If you are unable to use the PowerShell Gallery to get the latest dbatools release, I would always use the official signed release.&lt;/p>
&lt;p>You can then upload the zip from the same Modules page using the Browse for file but here is the &lt;em>important bit&lt;/em> You must update the name of the module. By default Azure will set the name to match the name of the zip file as that is what is expected and indeed mentioned in the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules#author-modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft documentation here &lt;/a>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181561112-6aecd5e3-efaa-4b2a-84d7-f7e521035d04.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and once it is imported successfully and I have a green tick&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181564377-df8c707e-24ec-43eb-8d57-702fcb39400b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>I can run the test - Again I just ran &lt;code>Get-DbaToolsConfig&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181569077-2b2e59e2-4bf1-46b6-851f-2e624cf9c43c.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>This method will work with both PowerShell 5.1 and PowerShell 7.1, you will just have to upload the zip (and remember to rename the module entry) twice.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571123-8acb8ff5-7b36-4b62-91f7-34b3df36a1d8.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571518-909ecc6f-9270-45d2-a7b5-0de4406c88c4.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="when-it-goes-wrong">When it goes wrong&lt;/h1>
&lt;p>If you do not rename the module correctly but leave it as the name of file &lt;code>dbatools-signed&lt;/code> in this example&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571939-b881b4bc-4449-4569-b71a-66142436158a.png"
loading="lazy"
alt="image"
>
.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181572041-2fe18929-cc14-40ae-b654-62653206903f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;blockquote>
&lt;p>Error importing the module dbatools-signed. Import failed with the following error:&lt;br>
Orchestrator.Shared.AsyncModuleImport.ModuleImportException: Cannot import the module of name dbatools-signed, as the module structure was invalid. at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.ExecuteInternal(CodeActivityContext context, Byte[] moduleContent, String moduleName, ModuleLanguage moduleLanguage) at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.Execute(CodeActivityContext context) at&lt;br>
System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)&lt;/p>
&lt;/blockquote>
&lt;p>If you get that, just re-upload the zip file and use the correct name in the form.&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Quickly Creating Test Users in SQL Server using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/02/remove-them-all.png" alt="Featured image of post Quickly Creating Test Users in SQL Server using dbatools" /></description></item><item><title>TSQL2sDay - Do I use Notebooks?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-do-i-use-notebooks/</link><pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-do-i-use-notebooks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/images/TSQL2sDay150x150.jpg" alt="Featured image of post TSQL2sDay - Do I use Notebooks?" />&lt;h1 id="do-i-use-notebooks">Do I use Notebooks?&lt;/h1>
&lt;p>T-SQL Tuesday is the brainchild of Adam Machanic (&lt;a class="link" href="http://dataeducation.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/adammachanic?lang=en" target="_blank" rel="noopener"
>Twitter&lt;/a>). The first T-SQL Tuesday invitation was in December 2009 and it is still going strong. It is a monthly blog party on the second Tuesday of each month. Currently, Steve Jones (&lt;a class="link" href="https://voiceofthedba.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/way0utwest" target="_blank" rel="noopener"
>Twitter&lt;/a>) organises the event and maintains &lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>a website with all previous posts&lt;/a>. Everyone is welcome to participate in this monthly blog post.&lt;/p>
&lt;p>This month’s T-SQL Tuesday is hosted by Steve. Steve says:&lt;/p>
&lt;blockquote>
&lt;p>I want you to write about how you have used, or would like to use, a Jupyter notebook. This seemed to be exciting for many people at first, but I haven’t seen a lot of uptake from users in general. So I’m curious if you are using them.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://www.sqlservercentral.com/blogs/tsql2sday-137-invite-using-notebooks-every-day" target="_blank" rel="noopener"
>The original post is here.&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlservercentral.com/blogs/tsql2sday-137-invite-using-notebooks-every-day" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/a>&lt;/p>
&lt;h1 id="am-i-using-notebooks-">Am I using Notebooks ?&lt;/h1>
&lt;p>Hehe. I LOVE notebooks. I use them all of the time and every day.&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://blog.robsewell.com/categories/#jupyter-notebooks" target="_blank" rel="noopener"
>I have written a few posts about them as well&lt;/a>.&lt;/li>
&lt;li>I have a repository on GitHub with many notebooks &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>https://beard.media/Notebooks&lt;/a>.&lt;/li>
&lt;li>I have given presentations about notebooks &lt;a class="link" href="https://beard.media/presentations" target="_blank" rel="noopener"
>https://beard.media/presentations&lt;/a>&lt;/li>
&lt;li>I have videos on my youtube channel about notebooks &lt;a class="link" href="https://beard.media/notebooksyoutube" target="_blank" rel="noopener"
>https://beard.media/notebooksyoutube&lt;/a>&lt;/li>
&lt;li>I have written a &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook/0.0.20201008.1" target="_blank" rel="noopener"
>PowerShell Module&lt;/a> to create Notebooks []&lt;/li>
&lt;/ul>
&lt;p>I have assisted clients with using notebooks to&lt;/p>
&lt;ul>
&lt;li>Integrate new team members&lt;/li>
&lt;li>Create a repository of incident response notebooks &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/" target="_blank" rel="noopener"
>dynamically created with Azure DevOps&lt;/a>&lt;/li>
&lt;li>Create a repository of daily tasks notebooks&lt;/li>
&lt;li>Create a repository of common large scale changes&lt;/li>
&lt;li>Off-load DBA requests to Service Desk with notebooks&lt;/li>
&lt;li>Use notebooks to demonstrate changes to Product Owners and other teams&lt;/li>
&lt;li>Use notebooks for diagnosis by customers&lt;/li>
&lt;li>Use notebooks to investigate Azure environments and Azure Data Services&lt;/li>
&lt;li>and more&lt;/li>
&lt;/ul>
&lt;p>I use notebooks to validate dbachecks PRs, to demonstrate &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/tree/master/notebooks/NotDotNet/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/tree/master/notebooks/NotDotNet/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a> with docker that anyone can use.&lt;/p>
&lt;p>I am thoroughly looking forward to seeing what other people do with notebooks. I love how the community helps us all to develop and move forward by sharing.&lt;/p>
&lt;h1 id="all-this-and">All this and&lt;/h1>
&lt;p>&lt;a class="link" href="https://www.advancinganalytics.co.uk/" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2021/nodatascientist.png"
loading="lazy"
alt="nodatascientist"
>&lt;/a>&lt;br>
Thank you - &lt;a class="link" href="https://www.advancinganalytics.co.uk/" target="_blank" rel="noopener"
>https://www.advancinganalytics.co.uk/&lt;/a>&lt;/p></description></item><item><title>Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/08/image-16.png" alt="Featured image of post Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools" />&lt;p>Following on from my posts about using Secret Management &lt;a class="link" href="https://blog.robsewell.com/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>Good bye Import-CliXml&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/" target="_blank" rel="noopener"
>running programmes as a different user&lt;/a>, I have another use case.&lt;/p>
&lt;p>After creating Azure SQL Databases in an Elastic Pool using a process pretty similar to this one &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>I blogged about last year&lt;/a>, I needed to be able to programmatically create users and assign permissions.&lt;/p>
&lt;h2 id="i-need-a-user-to-login-with">I need a user to login with&lt;/h2>
&lt;p>When I created my Azure SQL Server with Terraform, I set the Azure Admin to be a SPN as you can see in the image from the portal and set it to have an identity using the documentation for &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_server.html" target="_blank" rel="noopener"
>azurerm_mssql_server&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-18.png"
loading="lazy"
>
This allows this user to manage the access for the SQL Server as long as the SQL Server Azure AD identity has Directory Reader privileges. The SQL Server is called temp-beard-sqls and as you can see the identity is assigned to the role.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-11.png"
loading="lazy"
>
The privileges required to do this for a single identity are quite high&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>so now, you can assign an Azure Active Directory Group to that Role and allow less-privileged users to add the identity to this group . The documentation is &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> and there is a tutorial &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal-tutorial?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> explaining the steps you need to take.&lt;/p>
&lt;h2 id="what-is-an-azure-spn">What is an Azure SPN?&lt;/h2>
&lt;blockquote>
&lt;p>An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest&lt;/a>&lt;/p>
&lt;p>I created the SPN using Azure CLI straight from the Azure Portal by clicking this button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and running&lt;/p>
&lt;pre>&lt;code>az ad sp create-for-rbac --name ServicePrincipalName
&lt;/code>&lt;/pre>
&lt;p>This will quickly create a SPN for you and return the password&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes I have deleted this one&lt;/p>
&lt;h2 id="add-azure-key-vault-to-secret-management">Add Azure Key Vault to Secret Management&lt;/h2>
&lt;p>In my previous posts, I have been using the Default Key Vault which is limited to your local machine and the user that is running the code. It would be better to use Azure Key Vault to store the details for the SPN so that it safely stored in the cloud and not on my machine and also so that anyone (or app) that has permissions to the vault can use it.&lt;/p>
&lt;p>First you need to login to Azure in PowerShell (You will need to have the AZ* modules installed)&lt;/p>
&lt;pre>&lt;code>Connect-AzAccount
&lt;/code>&lt;/pre>
&lt;p>Be aware, the login box can appear behind the VS Code or Azure Data Studio window!&lt;/p>
&lt;p>Once connected, if you have several Azure subscriptions, you can list them with&lt;/p>
&lt;pre>&lt;code>Get-AzSubscription
&lt;/code>&lt;/pre>
&lt;p>You can choose your subscription with&lt;/p>
&lt;pre>&lt;code>$AzureSubscription = Set-AzContext -SubscriptionName &amp;quot;NAME OF SUBSCRIPTION&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>For the Secret Management Module to manage the Azure Key Vault, you first need to register it.&lt;/p>
&lt;p>Ensure that you have permissions to connect by following the details in the network security documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/network-security?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/network-security&lt;/a> and the secure access documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault&lt;/a>&lt;/p>
&lt;p>Then you can run &lt;code>Register-SecretVault&lt;/code> . You need to provide the local name for the key vault, the module name &lt;code>Az.KeyVault&lt;/code>, and a &lt;code>VaultParameters&lt;/code> hashtable with the KeyVault name and the Azure Subscription ID. You can register other types of Key Vaults to the Secret Management module in this way and they will require different values for the &lt;code>VaultParameters&lt;/code> parameter.&lt;/p>
&lt;pre>&lt;code>$KeyVaultName = 'beard-key-vault'
Register-SecretVault -Name BeardKeyVault -ModuleName Az.KeyVault -VaultParameters @{ AZKVaultName = $KeyVaultName; SubscriptionId = $AzureSubscription.Subscription.Id }
&lt;/code>&lt;/pre>
&lt;h2 id="adding-the-spn-details-to-the-azure-key-vault">Adding the SPN details to the Azure Key Vault&lt;/h2>
&lt;p>Using the values for AppID – (Note NOT the display name) and the values for the password from the Azure CLI output or by creating a new secret for the SPN with PowerShell or via the portal. You can use the following code to add the SPN details and the tenantid to the Azure Key Vault using the Secret Management module&lt;/p>
&lt;pre>&lt;code>$ClientId = Read-Host &amp;quot;Enter ClientID&amp;quot; -AsSecureString
$SecretFromPortal = Read-Host &amp;quot;Enter Client Secret&amp;quot; -AsSecureString
$tenantid = Read-Host &amp;quot;Enter TenantId&amp;quot; -AsSecureString
Set-Secret -Vault BeardKeyVault -Name service-principal-guid -Secret $ClientId
Set-Secret -Vault BeardKeyVault -Name service-principal-secret -SecureStringSecret $SecretFromPortal
Set-Secret -Vault BeardKeyVault -Name Tenant-Id -Secret $tenantid
&lt;/code>&lt;/pre>
&lt;p>You can also do this with the Az.KeyVault module by following the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can see the secrets in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>and also at the command line with the Secret Management module using&lt;/p>
&lt;pre>&lt;code>Get-SecretInfo -Vault RegisteredNameOfVault
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="can-my-user-connect">Can my user connect?&lt;/h2>
&lt;p>If I try to connect in Azure Data Studio to my Azure SQL Database with my AAD account to the temp-sql-db-beard database. It fails.&lt;/p>
&lt;p>By the way a great resource for troubleshooting the SQL error 18456 failure states can be found here &lt;a class="link" href="https://sqlblog.org/2020/07/28/troubleshooting-error-18456" target="_blank" rel="noopener"
>https://sqlblog.org/2020/07/28/troubleshooting-error-18456&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-13.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="dbatools-to-the-rescue-">dbatools to the rescue 🙂&lt;/h2>
&lt;p>dbatools is an open source community collaboration PowerShell module for administrating SQL Server. You can find more about it at &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.io&lt;/a> and get the book that Chrissy and I are writing about dbatools at &lt;a class="link" href="http://dbatools.io%5Cbook" target="_blank" rel="noopener"
>dbatools.io\book&lt;/a>&lt;/p>
&lt;p>You can connect to Azure SQL Database with an Azure SPN using the following code. It will get the secrets from the Azure Key Vault that have been set above and create a connection. Lets see if I can run a query as the SPN.&lt;/p>
&lt;pre>&lt;code>$SqlInstance = 'temp-beard-sqls.database.windows.net'
$databasename = 'master'
$appid = Get-Secret -Vault BeardKeyVault -Name service-principal-guid -AsPlainText
$Clientsecret = Get-Secret -Vault BeardKeyVault -Name service-principal-secret
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = Get-Secret -Vault BeardKeyVault -Name Sewells-Tenant-Id -AsPlainText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
Invoke-DbaQuery -SqlInstance $AzureSql -Database master -SqlCredential $credential -Query &amp;quot;Select SUSER_NAME() as 'username'&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Excellent 🙂&lt;/p>
&lt;h2 id="add-a-user-to-the-user-database">Add a user to the user database&lt;/h2>
&lt;p>I can then add my user to the temp-sql-db-beard Database. I need to create a new connection to the user database as you cannot use the &lt;code>USE [DatabaseName]&lt;/code> statement&lt;/p>
&lt;pre>&lt;code>$Userdatabasename = 'temp-sql-db-beard'
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $Userdatabasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre>
&lt;p>Whilst you can use dbatools to create new users in Azure SQL Database at present you cant create AAD users. You can run a T-SQL Script to do this though. This script will create a contained database user in the database. I have added the role membership also but this can also be done with &lt;a class="link" href="https://docs.dbatools.io/#Add-DbaDbRoleMember" target="_blank" rel="noopener"
>Add-DbaDbRoleMember&lt;/a> from dbatools&lt;/p>
&lt;pre>&lt;code>$Query = @&amp;quot;
CREATE USER [rob@sewells-consulting.co.uk] FROM EXTERNAL PROVIDER
ALTER ROLE db_datareader ADD MEMBER [rob@sewells-consulting.co.uk]
&amp;quot;@
Invoke-DbaQuery -SqlInstance $AzureSql -Database $Userdatabasename -SqlCredential $credential -Query $Query
&lt;/code>&lt;/pre>
&lt;p>Lets check the users on the database with dbatools&lt;/p>
&lt;pre>&lt;code>Get-DbaDbUser -SqlInstance $AzureSql -Database $Userdatabasename |Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>I have my user and it is of type External user. Lets see if I can connect&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Bingo 🙂&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>Because I dont like to see awesome people struggling with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Here is the same code using just the Az.KeyVault module&lt;/p>
&lt;pre>&lt;code>$appid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-guid&amp;quot;).SecretValueText
$Clientsecret = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-secret&amp;quot;).SecretValue
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;Sewells-Tenant-Id&amp;quot;).SecretValueText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre></description></item><item><title>Notifying a Teams Channel of a SQL Agent Job result</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</link><pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-18.png" alt="Featured image of post Notifying a Teams Channel of a SQL Agent Job result" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>yesterdays post about creating an overview of SQL Agent Job Results and sending it to a Teams channel&lt;/a>, I was given another challenge&lt;/p>
&lt;blockquote>
&lt;p>Can you write a job step that I can add to SQL Agent jobs that can send the result of that job to a Teams Channel&lt;/p>
&lt;p>A person with a need&lt;/p>
&lt;/blockquote>
&lt;p>The use case was for some migration projects that had steps that were scheduled via SQL Agent Jobs and instead of the DBA having to estimate when they would finish and keep checking so that they could let the next team know that it was time for their part to start, they wanted it to notify a Teams channel. This turned out especially useful as the job finished earlier than expected at 3am and the off-shore team could begin their work immediately.&lt;/p>
&lt;h2 id="using-sql-agent-job-tokens-with-powershell">Using SQL Agent Job tokens with PowerShell&lt;/h2>
&lt;p>You can use &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/ssms/agent/use-tokens-in-job-steps?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>SQL Agent job tokens in Job step commands to reference the existing instance or job&lt;/a> but I did not know if you could use that with PowerShell until I read &lt;a class="link" href="https://littlekendra.com/2009/12/02/sql-2008-agent-jobs-tokens-work-in-powershell/" target="_blank" rel="noopener"
>Kendra Little’s blog post from 2009&lt;/a>.&lt;/p>
&lt;p>Thank you Kendra&lt;/p>
&lt;h2 id="nothing-is-ever-as-easy-as-you-think">Nothing is ever as easy as you think&lt;/h2>
&lt;p>So I thought, this is awesome, I can create a function and pass in the Instance and the JobId and all will be golden.&lt;/p>
&lt;p>Nope&lt;/p>
&lt;h2 id="job_id--jobid">job_id &amp;lt;&amp;gt; $(JobID)&lt;/h2>
&lt;p>If we look in the sysjobs table at the Agent Job that we want to notify Teams about the result.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>We can see that the job_id is&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>If we look at the JobId property with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-15.png?resize=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>We get&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>Awesome, they are the same&lt;/p>
&lt;p>But&lt;/p>
&lt;p>If we look at the value of the $(JobID) SQL Agent Job Token,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>we get&lt;/p>
&lt;pre>&lt;code>C33759DC6F76B747A5A548365708659A
&lt;/code>&lt;/pre>
&lt;p>which makes matching it to the JobId tricky&lt;/p>
&lt;p>I tried all sorts of ways of casting and converting this value in SQL and PowerShell and in the end I just decided to manually convert the value&lt;/p>
&lt;pre>&lt;code> $CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
&lt;/code>&lt;/pre>
&lt;h2 id="send-the-information-to-teams">Send the information to Teams&lt;/h2>
&lt;p>Following the &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>same pattern as yesterdays post&lt;/a>, I created a function to send a message, depending on the outcome of the job and post it to the Teams function.&lt;/p>
&lt;p>Again, I used Enter-PsSession to run the Teams notification from a machine that can send the message. (I have also included the code to do this without requiring that below so that you can send the message from the same machine that runs the job if required)&lt;/p>
&lt;p>This code below is saved on a UNC share or the SQL Server as SingleNotifyTeams.ps1&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$NotifyCommand = {
$parameters = @{
&amp;quot;URI&amp;quot; = $Using:webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $Using:TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre>
&lt;p>Then it can be called in a SQL Agent job step, again following the guidelines at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a>&lt;/p>
&lt;p>It is called slightly differently as you ned to pass in the SQL Agent tokens as parameters to the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-16.png"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>powershell.exe -File path to Notify-TeamsSQLAgentJob.ps1 -SQLInstance $(ESCAPE_SQUOTE(SRVR)) -JobID $(ESCAPE_NONE(JOBID))
&lt;/code>&lt;/pre>
&lt;h2 id="sql-agent-job-step-success-and-failure">SQL Agent Job Step Success and Failure&lt;/h2>
&lt;p>We need to take another step to ensure that this works as expected. We have to change the On Failure action for each job step to the “Go To Notify Teams” step&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-17.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="making-people-smile">Making people smile&lt;/h2>
&lt;p>You can also add images (make sure the usage rights allow) so that the success notification can look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>and the failure looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Happy Automating !&lt;/p>
&lt;p>Here is the code that does not require remoting to another server to send the message&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;https://outlook.office.com/webhook/5a8057cd-5e1a-4c84-9227-74a309f1c738@b122247e-1ebf-4b52-b309-c2aa7436fc6b/IncomingWebhook/affb85f05804438eb7ffb57665879248/f32fc7e6-a998-4670-8b33-635876559b80&amp;quot;
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre></description></item><item><title>Sending a SQL Agent Job results overview to a Microsoft Teams Channel</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</link><pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-11.png" alt="Featured image of post Sending a SQL Agent Job results overview to a Microsoft Teams Channel" />&lt;p>Microsoft Teams is fantastic for collaboration. It enables groups of people, teams if you like to be able to communicate, collaborate on documents, hold meetings and much much more.&lt;/p>
&lt;h2 id="sql-agent-job-overview">SQL Agent Job Overview&lt;/h2>
&lt;p>Using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> we can create a simple script to gather the results of Agent Jobs form a list of instances. Maybe it would be good to be able to get the job runs results every 12 hours so that at 6am in the morning the early-bird DBA can quickly identify if there are any failures that need immediate action and at 6pm , the team can check that everything was ok before they clock off.&lt;/p>
&lt;p>Here is an example of such a script&lt;/p>
&lt;pre>&lt;code>$SqlInstances = (Get-Vm -ComputerName BEARDNUC,BEARDNUC2).Where{$_.State -eq 'Running' -and $_.Name -like '*SQL*'}.Name
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and an example of running it.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-2.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-teams-channel">Create a Teams Channel&lt;/h2>
&lt;p>If you have permissions, you can create a new Teams channel by clicking on the 3 ellipses and add channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Then fill in the blanks&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-webhook-connector-for-the-channel">Create a Webhook Connector for the channel&lt;/h2>
&lt;p>Next, you need to have a connector for the channel, click on the 3 ellipses for the channel and click on connectors&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Then you can choose the Incoming Webhook connector and click configure&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>Give the connector a name and upload an image if you wish and click create&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The resulting screen will give you a URL that you can copy. If you need to find it again, then use the 3 ellipses again, click connectors and look at configured. You can then choose the webhook that you have created and click manage and you will find the URL.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-8.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="send-to-teams-using-powershell">Send to Teams using PowerShell&lt;/h2>
&lt;p>Now you can send a message to that Teams channel using PowerShell. You will need to add the webhook URL from your Teams connector&lt;/p>
&lt;pre>&lt;code>[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = &amp;quot;&amp;quot;
$Text = @&amp;quot;
# Here is a Title
and a message
Image is from
https://www.flickr.com/photos/157270154@N05/38494483572
Photo by CreditDebitPro
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;This is my summary&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Something Important &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;I have something to say&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>The code above will send a message that looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-9.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="running-as-a-sql-agent-job">Running as a SQL Agent Job&lt;/h2>
&lt;p>Now we can run this code as a SQL Agent Job and schedule it. Now, you may not be able to run that code on your SQL Server. It cannot connect to the internet, so how can we contact the Teams webhook?&lt;/p>
&lt;p>There are probably a number of ways to do this but the solution that I took, was to allow a proxy account the ability to use PSRemoting and run the part of the script that connects to Teams on a different machine, that does have connectivity.&lt;/p>
&lt;p>The script I used was as follows. You will need to add in the SQL Instances or better still dynamically gather them from your source of truth. You will need the webhook URL and the name of the server that can connect to Teams&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
$NotifyCommand = {
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = $Using:TeamsWebhook
$allJobsMessage = $Using:AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($Using:startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($Using:startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
&lt;/code>&lt;/pre>
&lt;p>Then, follow the steps at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a> to create an agent job to run the script above on an instance with the dbatools module available to the SQL Service account. Use or create a proxy with permissions on the notify server and create an Agent Job.&lt;/p>
&lt;pre>&lt;code>USE [msdb]
GO
/****** Object: Job [I am a Job that notifies Teams] Script Date: 27/07/2020 20:27:27 ******/
BEGIN TRANSACTION
DECLARE @ReturnCode INT
SELECT @ReturnCode = 0
/****** Object: JobCategory [[Uncategorized (Local)]] Script Date: 27/07/2020 20:27:28 ******/
IF NOT EXISTS (SELECT name FROM msdb.dbo.syscategories WHERE name=N'[Uncategorized (Local)]' AND category_class=1)
BEGIN
EXEC @ReturnCode = msdb.dbo.sp_add_category @class=N'JOB', @type=N'LOCAL', @name=N'[Uncategorized (Local)]'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
END
DECLARE @jobId BINARY(16)
EXEC @ReturnCode = msdb.dbo.sp_add_job @job_name=N'12 Hour Teams Notify',
@enabled=1,
@notify_level_eventlog=0,
@notify_level_email=0,
@notify_level_netsend=0,
@notify_level_page=0,
@delete_level=0,
@description=N'This job will notify Teams every 12 hours',
@category_name=N'[Uncategorized (Local)]',
@owner_login_name=N'THEBEARD\SQL_SVC', @job_id = @jobId OUTPUT
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
/****** Object: Step [Notify Teams] Script Date: 27/07/2020 20:27:28 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N'Notify Teams',
@step_id=1,
@cmdexec_success_code=0,
@on_success_action=1,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N'CmdExec',
@command=N'powershell.exe -File C:\temp\AgentJobs\NotifyTeams.ps1',
@flags=0,
@proxy_name=N'TheBeardIsMighty'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_update_job @job_id = @jobId, @start_step_id = 1
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_add_jobserver @job_id = @jobId, @server_name = N'(local)'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
COMMIT TRANSACTION
GOTO EndSave
QuitWithRollback:
IF (@@TRANCOUNT &amp;gt; 0) ROLLBACK TRANSACTION
EndSave:
GO
&lt;/code>&lt;/pre>
&lt;p>When the job runs&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>The results are posted to the Teams Channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>If you can run the Agent Job on a machine that can connect to Teams and your SQL Instances then you can remove the need to use a remote session by using this code&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$allJobsMessage = $AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Results &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>Happy automating!&lt;/p></description></item><item><title>Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/runas.png" alt="Featured image of post Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>my last post about the Secret Management module&lt;/a>. I was asked another question.&lt;/p>
&lt;blockquote>
&lt;p>Can I use this to run applications as my admin account?&lt;/p>
&lt;p>A user with a beard&lt;/p>
&lt;/blockquote>
&lt;p>It is good practice to not log into your work station with an account with admin privileges. In many shops, you will need to open applications that can do administration tasks with another set of account credentials.&lt;/p>
&lt;p>Unfortunately, people being people, they will often store their admin account credentials in a less than ideal manner (OneNote, Notepad ++ etc) to make it easier for them, so that when they right click and run as a different user, they can copy and paste the password.&lt;/p>
&lt;h2 id="use-the-secret-management-module">Use the Secret Management module&lt;/h2>
&lt;p>Again, I decided to use a notebook to show this as it is a fantastic way to share code and results and because it means that anyone can try it out.&lt;/p>
&lt;p>The notebook may not render on a mobile device.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Using the notebook, I can quickly store my admin password safely and open and run the applications using the credential&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/runas.png"
loading="lazy"
>&lt;/p></description></item><item><title>Good Bye Import-CliXML – Use the Secrets Management module for your labs and demos</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</link><pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-1.png" alt="Featured image of post Good Bye Import-CliXML – Use the Secrets Management module for your labs and demos" />&lt;p>Don’t want to read all this? There are two dotnet interactive notebooks here with the relevant information for you to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;h2 id="jaap-is-awesome">Jaap is awesome&lt;/h2>
&lt;p>&lt;img src="https://pbs.twimg.com/media/DBbP9lHXYAAopb3?format=jpg&amp;amp;name=4096x4096"
loading="lazy"
>&lt;/p>
&lt;p>I have to start here. For the longest time, whenever anyone has asked me how I store my credentials for use in my demos and labs I have always referred them to Jaap Brassers &lt;a class="link" href="https://twitter.com/Jaap_Brasser" target="_blank" rel="noopener"
>t&lt;/a> blog post&lt;/p>
&lt;p>&lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/&lt;/a>&lt;/p>
&lt;h2 id="joel-is-also-awesome">Joel is also awesome!&lt;/h2>
&lt;p>When people wanted a method of storing credentials that didn&amp;rsquo;t involve files on disk I would suggest Joel Bennett’s &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>t&lt;/a> module BetterCredentials which uses the Windows Credential Manager&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/BetterCredentials/4.5" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/BetterCredentials/4.5&lt;/a>&lt;/p>
&lt;h2 id="microsoft-also-awesome">Microsoft? Also awesome!&lt;/h2>
&lt;p>In February, Microsoft released the SecretManagement module for preview.&lt;/p>
&lt;p>&lt;a class="link" href="https://devblogs.microsoft.com/powershell/secrets-management-development-release?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://devblogs.microsoft.com/powershell/secrets-management-development-release/&lt;/a>&lt;/p>
&lt;p>Sydney &lt;a class="link" href="https://twitter.com/sydneysmithreal" target="_blank" rel="noopener"
>t&lt;/a> gave a presentation at the European PowerShell Conference which you can watch on Youtube.&lt;/p>
&lt;h2 id="good-bye-import-clixml">Good Bye Import-CliXML&lt;/h2>
&lt;p>So now I say, it is time to stop using Import-Clixml for storing secrets and use the Microsoft.PowerShell.SecretsManagement module instead for storing your secrets.&lt;/p>
&lt;h2 id="notebooks-are-as-good-as-blog-posts">Notebooks are as good as blog posts&lt;/h2>
&lt;p>I love notebooks and to show some people who had asked about storing secrets, I have created some. So, because I am efficient lazy I have embedded them here for you to see. You can find them in my Jupyter Notebook repository&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;p>in the Secrets folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-1.png?resize=630%2C349&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-and-using-the-secrets-management-module">Installing and using the Secrets Management Module&lt;/h2>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="using-the-secret-management-module-in-your-scripts">Using the Secret Management Module in your scripts&lt;/h2>
&lt;p>Here is a simple example of using the module to provide the credential for a docker container and then to dbatools to query the container&lt;/p>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>New .NET Notebooks are here – PowerShell 7 notebooks are here.</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</link><pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-13.png" alt="Featured image of post New .NET Notebooks are here – PowerShell 7 notebooks are here." />&lt;p>Data Science folk used Notebooks for documentation and to show re-runnable research. Azure Data Studio included this notebook functionality and &lt;a class="link" href="https://blog.robsewell.com/dbatools/dbachecks/blog/jupyter%20notebooks/azure%20data%20studio/powershell/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>added SQL&lt;/a> kernel where &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbachecks/dbatools/powershell-in-sql-notebooks-in-azure-data-studio//" target="_blank" rel="noopener"
>with a little bit of faffing you could run PowerShell&lt;/a> and then a &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/powershell-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>Python kernel that enabled PowerShell&lt;/a>. It seems that notebooks are so cool that everyone is creating them these days! I was browsing twitter when I saw this tweet.&lt;/p>
&lt;blockquote>
&lt;p>.NET Notebooks Preview 2 is here! Preview 2 includes 🎉&lt;a class="link" href="https://twitter.com/PowerShell_Team?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@PowerShell_Team&lt;/a>, &lt;a class="link" href="https://twitter.com/nteractio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@nteractio&lt;/a>, and a new tool. Check out our blog to learn more. Congratulations to &lt;a class="link" href="https://twitter.com/jonsequitur?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@jonsequitur&lt;/a> &lt;a class="link" href="https://twitter.com/colombod?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@colombod&lt;/a> and our entire team&lt;a class="link" href="https://t.co/WqNWQWR3Bo" target="_blank" rel="noopener"
>https://t.co/WqNWQWR3Bo&lt;/a>&lt;a class="link" href="https://twitter.com/dotnet?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@dotnet&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/jupyter?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#jupyter&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/PowerShell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#PowerShell&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/interactiveprogramming?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#interactiveprogramming&lt;/a>.&lt;/p>
&lt;p>— Maria Naggaga (@LadyNaggaga) &lt;a class="link" href="https://twitter.com/LadyNaggaga/status/1225464258823163906?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="powershell-7-notebooks-">PowerShell 7 Notebooks 🙂&lt;/h2>
&lt;p>A notebook experience for PowerShell 7 that sounds amazing. This will enable a true cross-platform PowerShell Notebook experience which is lacking from the Python version as it uses Windows PowerShell on Windows and PowerShell Core on other OS’s&lt;/p>
&lt;p>The first thing I asked was – Will this come to Azure Data Studio. I got an immediate response from Sydney Smith PowerShell Program Manager saying it is on the roadmap&lt;/p>
&lt;blockquote>
&lt;p>Moving this kernel into ADS is on our roadmap! Right now our kernel uses hosted pwsh 7 but we would love to know if you have scenarios that don&amp;rsquo;t work with 7&lt;/p>
&lt;p>— Sydney Smith (@sydneysmithreal) &lt;a class="link" href="https://twitter.com/sydneysmithreal/status/1225488719567818752?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="install-dependencies">Install dependencies&lt;/h2>
&lt;p>To be able to run the notebook, you need to install some dependencies. First install the .NET CORE SDK which you can download from &lt;a class="link" href="https://dotnet.microsoft.com/download?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://dotnet.microsoft.com/download&lt;/a> This needs admin permissions to install.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image.png?resize=620%2C418&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You also need a Python installation – You can use Anaconda, which you can download from here &lt;a class="link" href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener"
>https://www.anaconda.com/distribution/&lt;/a> This does not need admin to install&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-1.png?resize=531%2C232&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-2.png?fit=630%2C490&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-anaconda-to-windows-terminal">Add Anaconda to Windows Terminal&lt;/h2>
&lt;p>I have added the Anaconda prompt to Windows Terminal so that I have one entry point for all my CLIs. Open the settings file and add the code below. (It will also give you an icon and background.&lt;/p>
&lt;pre>&lt;code> {
// Make changes here to the Anaconda.exe profile
&amp;quot;guid&amp;quot;: &amp;quot;{0caa0dad-35be-5f56-a7ff-afceeeaa6101}&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;Anaconda&amp;quot;,
&amp;quot;commandline&amp;quot;: &amp;quot;cmd.exe /K C:\\Users\\mrrob\\Anaconda3\\Scripts\\activate.bat&amp;quot;,
&amp;quot;hidden&amp;quot;: false,
&amp;quot;backgroundImage&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;icon&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;backgroundImageAlignment&amp;quot;: &amp;quot;topRight&amp;quot;,
&amp;quot;backgroundImageStretchMode&amp;quot;: &amp;quot;uniform&amp;quot;,
&amp;quot;backgroundImageOpacity&amp;quot;: 0.1
}
&lt;/code>&lt;/pre>
&lt;p>and it appears in the drop down&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-3.png?resize=509%2C409&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>With Anaconda installed, check that that the kernel is available on your path. If like me you have Azure Data Studio installed, you will have additional kernels but the important one line here is&lt;/p>
&lt;p>&lt;code>python3 C:\Users\USERNAME\Anaconda3\share\jupyter\kernels\python3&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-4.png?resize=630%2C210&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>In Windows Terminal move to a PowerShell 7 prompt and install the dotnet interactive tool&lt;/p>
&lt;pre>&lt;code>dotnet tool install --global Microsoft.dotnet-interactive
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-5.png?resize=630%2C259&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can install the .NET kernel in your Anaconda prompt using this command&lt;/p>
&lt;pre>&lt;code>dotnet interactive jupyter install
&lt;/code>&lt;/pre>
&lt;h2 id="sometimes-new-things-have-errors">Sometimes new things have errors&lt;/h2>
&lt;p>I had an error when I tried this first time&lt;/p>
&lt;blockquote>
&lt;p>Could not execute because the specified command or file was not found.&lt;br>
Possible reasons for this include:&lt;br>
* You misspelled a built-in dotnet command.&lt;br>
* You intended to execute a .NET Core program, but dotnet-interactive does not exist.&lt;br>
* You intended to run a global tool, but a dotnet-prefixed executable with this name could not be found on the PATH.&lt;/p>
&lt;/blockquote>
&lt;p>This is easily fixed by adding &lt;code>%USERPROFILE%\.dotnet\tools&lt;/code> to my path with &lt;code>set PATH=%PATH%;%USERPROFILE%\.dotnet\tools&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-6.png?fit=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Running &lt;code>jupyter kernelspec list&lt;/code> shows that the .NET kernel is installed for C Sharp, F Sharp and .NET PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-7.png?resize=630%2C197&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="lets-open-a-notebook">Lets open a Notebook&lt;/h2>
&lt;p>Now you want to play with it!&lt;br>
You can run the lab environment using `jupyter lab`&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-8.png?fit=630%2C194&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>This opens a browser&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-9.png?fit=630%2C272&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can open existing Azure Data Studio PowerShell notebooks (but not SQL ones)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-10.png?fit=630%2C492&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="sometimes-new-things-have-errors-part-2">Sometimes new things have errors Part 2&lt;/h2>
&lt;p>Unfortunately, I get errors when trying to import Pester which means I can not use my dbachecks notebooks in this blog post. &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>I have raised an issue on the repo here&lt;/a>.&lt;/p>
&lt;h2 id="create-a-new-notebook">Create a New Notebook&lt;/h2>
&lt;p>But it is easy to create a new Notebook&lt;/p>
&lt;p>In the launcher page click the .NET PowerShell button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-12.png?resize=567%2C171&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Which will open a new Notebook in the directory that you launched the lab from. You can then add Code or Markdown as I have &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>described before here&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-11.png?resize=316%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can add code, markdown and images to create your notebook.&lt;/p>
&lt;p>Once you have finished using the notebook lab, you can shut it down in the Anaconda prompt with &lt;code>CTRL + C&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-15.png?fit=630%2C103&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Here is a video of running a notebook which anyone can use to create a couple of Docker containers running SQL 2019 and query them with dbatools. You can find the notebook further down this post.&lt;/p>
&lt;h2 id="sharing-notebooks">Sharing Notebooks&lt;/h2>
&lt;p>You can create notebooks to run common tasks. Even better, from the lab you can convert the notebook including the results to a variety of formats to share with other none-technical people. I used this functionality this week to export Azure Data Studio Notebooks to HTML and PDF for a Project manager 🙂&lt;/p>
&lt;p>You can find the Export Notebook command in the File menu&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-13.png?resize=610%2C542&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Exporting to HTML did not export the images but it does include the results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-14.png?fit=630%2C476&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can share notebooks via GitHub – Either in a gist like this&lt;/p>
&lt;p>or by providing a straight link to the notebook in GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb&lt;/a>&lt;/p>
&lt;p>You can also use Binder &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a>&lt;/p>
&lt;p>This uses Docker to create an interactive Notebook. Create a GitHub repo like &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks&lt;/a> (or just clone it) Copy your notebooks into the notebooks folder and push the changes to GitHub and then go to &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a> and add your URL to the repository.&lt;/p>
&lt;p>You can see what it looks like by clicking the button below which Binder creates for you&lt;/p>
&lt;p>&lt;a class="link" href="https://mybinder.org/v2/gh/SQLDBAWithABeard/Notebooks/master" target="_blank" rel="noopener"
>&lt;img src="https://mybinder.org/badge_logo.svg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Unfortunately the kernel only supports Python for the moment but you can see the possibilities 🙂&lt;/p></description></item><item><title>How to fork a GitHub repository and contribute to an open source project</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/CreatePR.png" alt="Featured image of post How to fork a GitHub repository and contribute to an open source project" />&lt;p>I enjoy maintaining open source GitHub repositories such as &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>. I absolutely love it when people add more functionality to them.&lt;/p>
&lt;p>To collaborate with a repository in GitHub you need to follow these steps&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/GitHub.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>Fork the repository into your own GitHub&lt;/li>
&lt;li>Clone the repository to your local machine&lt;/li>
&lt;li>Create a new branch for your changes&lt;/li>
&lt;li>Make some changes and commit them with useful messages&lt;/li>
&lt;li>Push the changes to your repository&lt;/li>
&lt;li>Create a Pull Request from your repository back to the original one&lt;/li>
&lt;/ul>
&lt;p>You will need to have &lt;code>git.exe&lt;/code> available which you can download and install from &lt;a class="link" href="https://git-scm.com/downloads" target="_blank" rel="noopener"
>https://git-scm.com/downloads&lt;/a> if required&lt;/p>
&lt;h2 id="fork-the-repository-into-your-own-github">Fork the repository into your own GitHub&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/ForkRepo.png"
loading="lazy"
>&lt;/p>
&lt;p>A fork is a copy of the original repository. This allows you to make changes without affecting the original project. It does not get updated when the original project gets updated (We will talk about that in the next post) This enables you to code a new feature or a bug fix, test it locally and make sure it is working.&lt;/p>
&lt;p>Let’s take dbachecks as our example. Start by going to the project in GiHub. In this case the URL is &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks&lt;/a> You will see a Fork button at the top right of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-41.png?fit=630%2C74&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When you click the button the repository is copied into your own GitHub account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-42.png?resize=630%2C304&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The page will open at &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> in this case &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/dbachecks&lt;/a> You will be able to see that it is a fork of the original repository at the top of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-43.png?resize=474%2C119&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="clone-the-repository-to-your-local-machine">Clone the repository to your local machine&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CloneRepo-2.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Forking the repository has created a &lt;em>remote&lt;/em> repository stored on the GitHub servers. Now that the repository has been forked you need to clone it to your local machine to create a &lt;em>local&lt;/em> repository so that you can start coding your amazing fix. When you have finished you can then sync it back to your &lt;em>remote&lt;/em> repository ready for a Pull Request back to the original repository.&lt;/p>
&lt;p>In your browser, at your &lt;em>remote&lt;/em> repository that you just created (&lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> if you have closed the page) click on &lt;code>Clone or Download&lt;/code> and then the icon to the right to copy the url&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-46.png?fit=630%2C316&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone your repository in &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>VS Code&lt;/a> or &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> by clicking F1 or CTRL + SHIFT + P in Windows or Linux and ⇧⌘P or F1 on a Mac&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-44.png?fit=630%2C206&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>then start typing clone until you see &lt;code>Git:Clone&lt;/code> and press enter or click&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-45.png?fit=630%2C100&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Paste in the URL that you just copied and click enter. A dialog will open asking you to select a folder. This is the parent directory where your &lt;em>local&lt;/em> repository will be created. The clone will create a directory for your repository so you do not need to. I suggest that you use a folder called GitHub or something similar to place all of the repositories that you are going to clone and create.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-47.png?fit=630%2C345&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When it has finished it will ask you if you wish to open the repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-49.png?fit=630%2C215&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>if you click &lt;code>Open&lt;/code> it will close anything that you have already got opened and open the folder. If you click &lt;code>Add to Workspace&lt;/code> it will add the folder to the workspace and leave everything you already had open as it was and surprisingly clicking &lt;code>Open in New Window&lt;/code> will open the folder in a new instance of Visual Studio Code or Azure Data Studio!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-51.png?fit=630%2C997&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and you will also be able to see the local repository files on your computer&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-50.png?resize=442%2C244&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone the repository at the command line if you wish by navigating to your local GitHub directory and running &lt;code>git clone TheURLYouCopied&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-48.png?fit=630%2C165&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now your &lt;em>local&lt;/em> repository has been created, it’s time to do your magic coding.&lt;/p>
&lt;h2 id="create-a-new-branch-for-your-changes">Create a new branch for your changes&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/NewBranch.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>It is a good idea to create a branch for your &lt;code>amazing new feature&lt;/code> This enables you to work on coding for that feature in isolation. It has the added advantage that if you mess it right royally up, you can just delete that branch and start again with a new one!&lt;/p>
&lt;p>To create a branch in VS Code or Azure Data Studio you can click on the branch name at the bottom left.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-52.png?resize=630%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Or open the Command Palette and type Branch until you see &lt;code>Git: Create Branch&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-53.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will be prompted for a branch name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-54.png?fit=630%2C96&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I like to choose a name that relates to the code that I am writing like &lt;code>configurable_engine&lt;/code> or &lt;code>removeerroringexample&lt;/code> You can see the name of the branch in the bottom left so that you always know which branch you are working on.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?fit=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The icon shows that the branch is only &lt;em>local&lt;/em> and hasn’t been pushed (published) to the &lt;em>remote&lt;/em> repository yet&lt;/p>
&lt;h2 id="make-some-changes-and-commit-them-with-useful-messages">Make some changes and commit them with useful messages&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/awesomenewfeature.png?resize=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now you can start writing your code for your awesome new feature, bug fix or maybe just documentation improvement. Keep your commits small and give them useful commit messages that explain &lt;em>why&lt;/em> you have made the change as the diff tooling will be able to show &lt;em>what&lt;/em> change you have made&lt;/p>
&lt;p>Write your code or change the documentation, save the file and in Visual Studio Code or Azure Data Studio you will see that the source control icon has a number on it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-56.png?fit=630%2C143&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Clicking on the icon will show the files that have changes ready&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-57.png?fit=630%2C290&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can write your commit message in the box and click CTRL + ENTER to commit your changes with a message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-58.png?fit=630%2C296&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you want to do this at the command line, you can use &lt;code>git status&lt;/code> to see which files have changes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-59.png?fit=630%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will need to &lt;code>git add .&lt;/code>or &lt;code>git add .\pathtofile&lt;/code> to stage your changes ready for committing and then &lt;code>git commit -m 'Commit Message'&lt;/code> to commit them&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-60.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Notice that I did exactly what I just said not to do! A better commit message would have been &lt;em>So that people can find the guide to forking and creating a PR&lt;/em>&lt;/p>
&lt;h2 id="push-the-changes-to-your-repository">Push the changes to your repository&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/publishbranch.png?resize=630%2C219&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You only have the changes that you have made in your &lt;em>local&lt;/em> repository on your computer. Now you need to push those changes to GitHub your &lt;em>remote&lt;/em> repository. You can click on the publish icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?resize=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will get a pop-up asking you if you wish to stage your changes. I click &lt;code>Yes&lt;/code> and never &lt;code>Always&lt;/code> so that I can use this prompt as a sanity check that I am doing the right thing&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-75.png?fit=630%2C150&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>At the command line you can push the branch, if you do that, you will have to tell git where the branch needs to go. If you just type &lt;code>git push&lt;/code> it will helpfully tell you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-61.png?fit=630%2C121&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>fatal: The current branch AwesomeNewFeature has no upstream branch.
To push the current branch and set the remote as upstream, use
git push --set-upstream origin AwesomeNewFeature
&lt;/code>&lt;/pre>
&lt;p>So you will need to use that command&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-62.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can see in the bottom left that the icon has changed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-63.png?fit=630%2C186&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and if you read the output of the &lt;code>git push&lt;/code> command you will see what the next step is also.&lt;/p>
&lt;h2 id="create-a-pull-request-from-your-repository-back-to-the-original-one">Create a Pull Request from your repository back to the original one&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CreatePR.png?resize=630%2C238&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can CTRL click the link in the &lt;code>git push&lt;/code> output if you have pushed from the command line or if you visit either you repository or the original repository in your browser you will see that there is a &lt;code>Compare and Pull Request&lt;/code> button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-64.png?fit=630%2C334&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You click that and let GitHub do its magic&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-65.png?fit=630%2C459&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will create a Pull Request for you ready for you to fill in the required information, ask for reviewers and other options. Once you have done that you can click &lt;code>Create pull request&lt;/code> and wait for the project maintainer to review it and (hopefully) accept it into their project&lt;/p>
&lt;p>You can find the Pull Request that I created here &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/720" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks/pull/720&lt;/a> and see how the rest of this blog post was created.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-66.png?fit=630%2C489&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you make more changes to the code in the same branch in your &lt;em>local&lt;/em> repository and push them, they will automatically be added to this Pull Request whilst it is open. You can do this if the maintainer or reviewer asks for changes.&lt;/p>
&lt;p>Shane has asked for a change&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-67.png?resize=630%2C110&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can go to my &lt;em>local&lt;/em> repository in Azure Data Studio and make the requested change and save the file. If I look in the source control in Azure Data Studio I can again see there is a change waiting to be committed and if I click on the name of the file I can open the diff tool to see what the change was&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-68.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Once I am happy with my change I can commit it again in the same way as before either in the editor or at the command line. The icon at the bottom will change to show that I have one commit in my &lt;em>local&lt;/em> repository waiting to be pushed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-69.png?fit=630%2C160&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>To do the same thing at the command line I can type &lt;code>git status&lt;/code> and see the same thing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-70.png?fit=630%2C138&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can then push my change to my remote repository either in the GUI or by using &lt;code>git push&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-72.png?fit=630%2C213&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will automatically be added to the Pull Request as you can see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-73.png?fit=630%2C480&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now that the required changes for the review have been made, the review has been approved by Shane and the pull request is now ready to be merged. (You can also see that dbachecks runs some checks against the code when a Pull Request is made)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-74.png?resize=630%2C359&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Many, many thanks to Shane &lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>t&lt;/a> who helped with the writing of this post even whilst on a “no tech” holiday.&lt;/p>
&lt;h2 id="go-ahead--contribute-to-an-open-source-project">Go Ahead – Contribute to an Open Source Project&lt;/h2>
&lt;p>Hopefully you can now see how easy it is to create a fork of a GitHub repository, clone it to your own machine and contribute. There are many open source projects that you can contribute to.&lt;/p>
&lt;p>You can use this process to contribute to the Microsoft Docs for example by clicking on the edit button on any page.&lt;/p>
&lt;p>You can contribute other open source projects like&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/PowerShell/PowerShell" target="_blank" rel="noopener"
>PowerShell&lt;/a>&lt;/strong> by Microsoft&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/tigertoolbox" target="_blank" rel="noopener"
>tigertoolbox&lt;/a>&lt;/strong> by Microsoft Tiger Team&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/PSDatabaseClone" target="_blank" rel="noopener"
>PSDatabaseClone&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/OpenQueryStore/OpenQueryStore" target="_blank" rel="noopener"
>OpenQueryStore&lt;/a>&lt;/strong> by William Durkin and Enrico van de Laar&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/marcingminski/sqlwatch" target="_blank" rel="noopener"
>sqlwatch&lt;/a>&lt;/strong> by Marcin Gminski&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/red-gate/SQLCop" target="_blank" rel="noopener"
>SQLCop&lt;/a> by Redgate&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/amachanic/sp_whoisactive" target="_blank" rel="noopener"
>sp_whoisactive&lt;/a>&lt;/strong> by Adam Machanic&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/olahallengren/sql-server-maintenance-solution" target="_blank" rel="noopener"
>sql-server-maintenance-solution&lt;/a>&lt;/strong> by Ola Hallengren&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit" target="_blank" rel="noopener"
>SQL-Server-First-Responder-Kit&lt;/a>&lt;/strong> by Brent Ozar Unlimited&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>ReportingServicesTools&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>or go and find the the ones that you use and can help with.&lt;/p></description></item><item><title>Create a PowerShell Notebook for Azure Data Studio with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</link><pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</guid><description>&lt;p>The latest update to the ADSNotebook PowerShell module &lt;a class="link" href="https://blog.robsewell.com/create-azure-data-studio-sql-notebooks-with-powershell/" target="_blank" rel="noopener"
>I blogged about here&lt;/a> now enables the creation of PowerShell notebooks with PowerShell.&lt;/p>
&lt;p>You can install the module with&lt;/p>
&lt;pre>&lt;code>Install-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>or if you have already installed it you can use&lt;/p>
&lt;pre>&lt;code>Update-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>In the latest release, there is an extra parameter for &lt;code>New-AdsWorkBook&lt;/code> of &lt;code>-Type&lt;/code> which will accept either SQL or PowerShell&lt;/p>
&lt;h2 id="create-a-powershell-notebook-with-powershell-rob">Create a PowerShell Notebook with PowerShell Rob&lt;/h2>
&lt;p>OK!&lt;/p>
&lt;p>Here is some code to create a PowerShell Notebook. First we will create some cells using &lt;code>New-AdsWorkBookCell&lt;/code> including all the markdown to add images and links. You can find my notebooks which explain how to write the markdown for your notebooks in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/2019/PASS%20Summit/SQL%20Notebooks%20in%20Azure%20Data%20Studio%20for%20the%20DBA" target="_blank" rel="noopener"
>GitHub Presentations Repository&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then we will create a new workbook using those cells&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then, when that code is run we can open the Notebook and ta-da&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?fit=630%2C505&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>And it is super quick to run as well&lt;/p>
&lt;p>UPDATE – Tyler Leonhardt &lt;a class="link" href="https://twitter.com/TylerLeonhardt" target="_blank" rel="noopener"
>t&lt;/a> from the PowerShell team asked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-36.png?resize=597%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Challenge accepted, with extra meta, here is the PowerShell to create a PowerShell Notebook which will create a PowerShell Notebook!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item><item><title>PowerShell Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-8.png" alt="Featured image of post PowerShell Notebooks in Azure Data Studio" />&lt;p>The latest release of the &lt;a class="link" href="https://github.com/microsoft/azuredatastudio#try-out-the-latest-insiders-build-from-master" target="_blank" rel="noopener"
>insiders edition of Azure Data Studio&lt;/a> brings the first edition of PowerShell Notebooks!&lt;/p>
&lt;p>You can download the latest insiders edition from the link above, it can be installed alongside the stable release.&lt;/p>
&lt;p>To access many of the commands available use F1 to open the command palette (like many of my tips this also works in Visual Studio Code). You can then start typing to get the command that you want.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>You can then hit enter with the command that you want highlighted, use the mouse or use the shortcut which is displayed to the right.&lt;/p>
&lt;p>In a new notebook, you can click the drop down next to kernel and now you can see that PowerShell is available&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>When you choose the PowerShell kernel, you will get a prompt asking you to configure the Python installation&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>If you have Python already installed you can browse to the location that it is installed or you can install Python. In the bottom pane you will be able to see the progress of the installation.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>When it has completed, you will see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>You may also get a prompt asking if you would like to upgrade some packages&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>Again this will be displayed in the tasks pane&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-14.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="addingpowershell">&lt;strong>Adding PowerShell&lt;/strong>&lt;/h2>
&lt;p>To add PowerShell Code to the notebook click the Code button at the top of the file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>or the one you can find by highlighting above or below a block&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I did not have intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block.&lt;/p>
&lt;p>Interestingly Shawn Melton ( &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>t&lt;/a> ) did&lt;/p>
&lt;blockquote>
&lt;p>Curious, you state &amp;ldquo;There is not any intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block&amp;rdquo;…&lt;/p>
&lt;p>It works flawlessly for me on Windows. &lt;a class="link" href="https://t.co/Lx6fGH9F5L" target="_blank" rel="noopener"
>pic.twitter.com/Lx6fGH9F5L&lt;/a>&lt;/p>
&lt;p>— Shawn Melton (@wsmelton) &lt;a class="link" href="https://twitter.com/wsmelton/status/1184819132598013952?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>October 17, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This was because he had the PowerShell extension installed and I did not (I know !!)&lt;br>
If you find you dont have intellisense then install the PowerShell extension!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the play button (which is only visible when you hover the mouse over it) will run the code&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can clear the results from every code block using the clear results button at the top&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>Otherwise, you can save the results with the Notebook by saving it. This is the part that is missing from running PowerShell in the Markdown blocks in a &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>SQL Notebook as I described here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>I am looking forward to how this develops. You can find my sample PowerShell notebook (with the code results) &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/powershell.ipynb" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p></description></item><item><title>Getting SQL Server installation date with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-7.png" alt="Featured image of post Getting SQL Server installation date with PowerShell using dbatools" />&lt;p>Most of my writing time at the moment is devoted to  &lt;em>&lt;a class="link" href="https://dbatools.io/book" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> which is now available but here is a short post following a question someone asked me.&lt;/p>
&lt;h2 id="how-can-i-get-the-installation-date-for-sql-server-on-my-estate-into-a-database-with-dbatools-">How can I get the Installation Date for SQL Server on my estate into a database with dbatools ?&lt;/h2>
&lt;p>You can get the date that SQL Server was installed using the creation date of the NT Authority\System login using T-SQL&lt;/p>
&lt;pre>&lt;code>SELECT create_date
FROM sys.server_principals
WHERE sid = 0x010100000000000512000000
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="with-dbatools">With dbatools&lt;/h2>
&lt;p>To do this with dbatools you can use the command &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaInstanceInstallDate" target="_blank" rel="noopener"
>Get-DbaInstanceInstallDate&lt;/a> command&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-1.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="more-than-one-instance">More than one instance&lt;/h2>
&lt;p>If we want to get the installation date for more than one instance we can simply create an array of instances for the SqlInstance parameter&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE
&lt;/code>&lt;/pre>
&lt;h2 id="get-the-windows-installation-date-too">Get the Windows installation date too&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also get the windows installation date with the IncludeWindows switch&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE -IncludeWindows
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-3.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="gather-your-instances">Gather your instances&lt;/h2>
&lt;p>How you get the instances in your estate is going to be different per reader but here is an example using Registered Servers from my local registered servers list, you can also use a Central Management Server&lt;/p>
&lt;pre>&lt;code>Get-DbaRegisteredServer -Group local
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>So we can gather those instances into a variable and pass that to Get-DbaInstanceInstallDate&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-to-database">Add to database&lt;/h2>
&lt;p>To add the results of any PowerShell command to a database, you can pipe the results to &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDbTableData" target="_blank" rel="noopener"
>Write-DbaDbTableData&lt;/a>&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
$writeDbaDataTableSplat = @{
SqlInstance = 'localhost'
Table = 'InstallDate'
Database = 'tempdb'
Schema = 'dbo'
AutoCreateTable = $true
}
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances | Write-DbaDataTable @writeDbaDataTableSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>This will create a table called InstallDate and put the results of the Get-DbaInstanceInstallDate command. Note – If you want to try this code, I would advise using a different database than tempdb!!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>It is important to note that the table created may not have the most optimal data types and that you may want to pre-create the table.&lt;/p>
&lt;p>So there you go, all the installation dates for your estate in a database table. Hope that helps you Jonny.&lt;/p></description></item><item><title>MEAP MEAP – #dbatoolsMoL – Live Book edition</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</link><pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</guid><description>&lt;p>It’s been a busy time!&lt;/p>
&lt;p>As well as many other things, the fantastical &lt;a class="link" href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life" target="_blank" rel="noopener"
>BDFL&lt;/a> of &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a> and myself have written enough of a chunk of &lt;em>&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> that our publisher &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Manning Publications&lt;/a> have agreed to release it as a MEAP. Not a text book, this book is written in a fun conversational style and split up into chapters that you can read in a lunch-time.&lt;/p>
&lt;p>It is impossible for me to hear MEAP and not think of this 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://tenor.com/view/hungry-coyote-looney-tunes-gif-5063446" target="_blank" rel="noopener"
>Roadrunner Speeding GIF&lt;/a> from &lt;a class="link" href="https://tenor.com/search/hungry-gifs" target="_blank" rel="noopener"
>Hungry GIFs&lt;/a>&lt;/p>
&lt;p>but I expect you are wondering what a MEAP is?&lt;/p>
&lt;blockquote>
&lt;p>What is MEAP?&lt;br>
A book can take a year or more to write, so how do you learn that hot new technology today? The answer is MEAP, the Manning Early Access Program. In MEAP, you read a book chapter-by-chapter while it’s being written and get the final eBook as soon as it’s finished. If you pre-order the pBook, you’ll get it long before it’s available in stores.&lt;/p>
&lt;p>&lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>https://www.manning.com/meap-program&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Basically, to make it easy to get and for those that like to get in early, you can order the book and get the first 4 chapters (three in reality) RIGHT NOW!! (It also means that Chrissy and I have to write the rest of book – dang still going to be busy!)&lt;/p>
&lt;p>Simply head over to &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a> and use the code mlsewell and you can get access to the book too.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/08/meap.png"
loading="lazy"
>](&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a>)&lt;/p>
&lt;p>This will also give you access to the live book.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/livebook.png"
loading="lazy"
>&lt;/p>
&lt;p>live book&lt;/p>
&lt;p>The live book is fantastic, you can read the whole book from within your browser. See the three icons that appear to the right of the book?&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/stuffage.png"
loading="lazy"
>&lt;/p>
&lt;p>3 little icons (no porridge)&lt;/p>
&lt;p>The left hand one enables you to bookmark an important part so that you can come back to it easily using the bookmarks link in the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/bookmark.png"
loading="lazy"
>&lt;/p>
&lt;p>bookmarks&lt;/p>
&lt;p>The middle icon enables you to write notes for yourself, maybe ways that you can use the information or maybe comments about an awesome Italian.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/satori.png"
loading="lazy"
>&lt;/p>
&lt;p>Shoes&lt;/p>
&lt;p>The last one is the way that you can make comments and engage us , the authors in conversation, ask questions, request clarification or wonder about Dutch data manglers&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/sander.png"
loading="lazy"
>&lt;/p>
&lt;p>I think its down to PII&lt;/p>
&lt;p>If you select a piece of text, another menu opens up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlight.png"
loading="lazy"
>&lt;/p>
&lt;p>The first icon lets you highlight the text, to make it easier to find later&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlightyellow.png"
loading="lazy"
>&lt;/p>
&lt;p>Hover over the highlight and you can choose different colours for different things.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/image.png"
loading="lazy"
>&lt;/p>
&lt;p>or even create pretty pictures for Mathias&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/pretty.png"
loading="lazy"
>&lt;/p>
&lt;p>Mathias – Why isn’t he an MVP?&lt;/p>
&lt;p>You can choose to annotate, which is sort of like highlighting and writing a note with the next icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/other-users.png"
loading="lazy"
>&lt;/p>
&lt;p>When you want to share a link to a particular part of the book with someone else, you can highlight part of it and click the link icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/linkylinky.png"
loading="lazy"
>&lt;/p>
&lt;p>It’s easy to start PowerShell as another user as long as you remember when to press SHIFT&lt;/p>
&lt;p>Which will highlight the paragraph and open a dialogue at the bottom where you can create and copy the link.&lt;/p>
&lt;p>By far the most important part for Chrissy and I is the last link. When you find something wrong you can mark it for our attention. Yes, even with Chrissy and I proof reading each others words, the fabulous proof reader Cláudio Silva (&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>t&lt;/a>) and awesome tech editor Mike Shepard (&lt;a class="link" href="https://powershellstation.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/MikeShepard70" target="_blank" rel="noopener"
>t&lt;/a>)  as well as many community reviewers there are still, and will continue to be, issues. So when you find them, highlight them and click the right hand most link&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/withwith.png"
loading="lazy"
>&lt;/p>
&lt;p>with with more more than than one one&lt;/p>
&lt;p>This will open up as shown so that you can fill in what was wrong (Please don’t report this error again Shane &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>t&lt;/a> has beaten you to it!)&lt;/p>
&lt;p>You will have noticed on social media and elsewhere that we have left some easter eggs in the book&lt;/p>
&lt;blockquote>
&lt;p>Yup, we have some easter eggs in &lt;a class="link" href="https://twitter.com/hashtag/dbatoolsMol?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatoolsMol&lt;/a>&lt;/p>
&lt;p>We hope you enjoy them &lt;a class="link" href="https://t.co/iZa3u8iLPC" target="_blank" rel="noopener"
>https://t.co/iZa3u8iLPC&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1167116661503266819?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>August 29, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you find them or whenever you want to talk about the book on social media, please use the hashtag #dbatoolsMoL – you never know what goodies may end up in your inbox.&lt;/p>
&lt;p>Oh and if you have got this far and don’t know what dbatools in a Month of Lunches is, listen to the hair and read more &lt;a class="link" href="https://dbatools.io/meap/" target="_blank" rel="noopener"
>https://dbatools.io/meap/&lt;/a>&lt;/p></description></item><item><title>PowerShell in SQL Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</link><pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/07/image-4.png" alt="Featured image of post PowerShell in SQL Notebooks in Azure Data Studio" />&lt;p>I have done a lot of writing in the last few months but you see no blog posts! My wonderful friend Chrissy and I are writing “dbatools in a Month of Lunches” to be published by Manning. That has taken up a lot of my writing mojo. We have hit a little break whilst we have some reviews done ready for the &lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>MEAP&lt;/a> (For everyone who asks, the answer is the unfulfilling ‘soon’) so it’s time for a blog post!&lt;/p>
&lt;h2 id="sql-notebooks-are-cool">SQL Notebooks are cool&lt;/h2>
&lt;p>I have had a lot of fun with SQL Notebooks recently. I have presented a session about them at a couple of events this month &lt;a class="link" href="http://datagrillen.com" target="_blank" rel="noopener"
>DataGrillen&lt;/a> and SQL Saturday Cork. Here is a little snippet&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/hashtag/dbatools?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatools&lt;/a> in PowerShell in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> SQL Notebooks for creating the containers and restoring the &lt;a class="link" href="https://twitter.com/hashtag/dbachecks?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbachecks&lt;/a> historical database for running queries in 🙂&lt;br>
Getting ready for presentation for &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/wiQ41bblQV" target="_blank" rel="noopener"
>pic.twitter.com/wiQ41bblQV&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1130871277449875456?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 21, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Yes, you can run PowerShell in a SQL Notebook in Azure Data Studio just by clicking a link in the markdown cell. This opens up a lot of excellent possibilities.&lt;/p>
&lt;p>I have had several discussions about how SQL Notebooks can be used by SQL DBAs within their normal everyday roles. (Mainly because I don’t really understand what the sorcerers of data science do with notebooks!). I have helped clients to look at some of their processes and use SQL Notebooks to help with them. Creating Disaster Recovery or Change Run-books or Incident Response Templates or using them for product demonstrations. Of course, I needed to use PowerShell in that 🙂&lt;/p>
&lt;p>I have really enjoyed working out how to run PowerShell in the markdown in a SQL Notebook in Azure Data Studio and I think &lt;a class="link" href="http://www.centinosystems.com/blog/author/aencentinosystems-com/" target="_blank" rel="noopener"
>Anthony the kubernetes magician&lt;/a> did too!&lt;/p>
&lt;blockquote>
&lt;p>I think &lt;a class="link" href="https://twitter.com/sqldbawithbeard?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@sqldbawithbeard&lt;/a> is an actual wizard! You should see the things he can do with &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/KMeZR3CrPK" target="_blank" rel="noopener"
>pic.twitter.com/KMeZR3CrPK&lt;/a>&lt;/p>
&lt;p>— Anthony E. Nocentino (@nocentino) &lt;a class="link" href="https://twitter.com/nocentino/status/1141709511700467712?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>June 20, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>OK enough magic puns lets talk about PowerShell in SQL Notebooks. You can read about &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>how to create a SQL Notebook and run T-SQL queries here&lt;/a>, (you no longer need the Insider Edition by the way)&lt;/p>
&lt;h2 id="powershell-in-markdown">PowerShell in Markdown!&lt;/h2>
&lt;p>First, before I go any further, I must say this. I was at the European PowerShell Conference when I was working this out and creating my sessions and I said the words&lt;/p>
&lt;blockquote>
&lt;p>“Cool, I can click a link and run PowerShell, this is neat”&lt;/p>
&lt;p>A Beardy fellow in Hannover&lt;/p>
&lt;/blockquote>
&lt;p>This stopped some red team friends of mine in their tracks and they said “Show me”. One of them was rubbing their hands with glee! You can imagine the sort of wicked, devious things that they were immediately considering doing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes, it’s funny but also it carries a serious warning. Without understanding what it is doing, please don’t enable PowerShell to be run in a SQL Notebook that someone sent you in an email or you find on a GitHub. In the same way as you don’t open the word document attachment which will get a thousand million trillion europounddollars into your bank account or run code you copy from the internet on production without understanding what it does, this could be a very dangerous thing to do.&lt;/p>
&lt;p>With that warning out of the way, there are loads of really useful and fantastic use cases for this. SQL Notebooks make great run-books or incident response recorders and PowerShell is an obvious tool for this. (If only we could save the PowerShell output in a SQL Notebook, this would be even better)&lt;/p>
&lt;h2 id="how-on-earth-did-you-work-this-out">How on earth did you work this out?&lt;/h2>
&lt;p>Someone asked me how I worked it out. I didn’t! It began with Vicky Harp PM lead for the SQL Tools team at Microsoft&lt;/p>
&lt;blockquote>
&lt;p>Did you know you can add markdown links to open a terminal and paste in a command in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> notebooks? &lt;a class="link" href="https://t.co/YHX9pIVQco" target="_blank" rel="noopener"
>pic.twitter.com/YHX9pIVQco&lt;/a>&lt;/p>
&lt;p>— Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1128359827128950784?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 14, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I then went and looked at &lt;a class="link" href="https://twitter.com/kevcunnane" target="_blank" rel="noopener"
>Kevin Cunnane&lt;/a>‘s notebook. Kevin is a member of the tools team working on Azure Data Studio. With SQL Notebooks, you can double click the markdown cell and see the code that is behind it. To understand how it is working, lets deviate a little.&lt;/p>
&lt;h2 id="keyboard-shortcuts">Keyboard Shortcuts&lt;/h2>
&lt;p>IF you click the cog at the bottom left of Azure Data Studio and choose Keyboard Shortcuts&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image.png"
loading="lazy"
>&lt;/p>
&lt;p>you can make Azure Data Studio (and Visual Studio Code) work exactly how you want it to. Typing in the top box will find a command and you can then set the shortcuts that you want to use to save yourself time.&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1" target="_blank" rel="noopener"
>https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This also enables you to see the command that is called when you use a keyboard shortcut. For example, you can see that for the focus terminal command it says &lt;code>workbench.action.terminal.focus&lt;/code>.&lt;/p>
&lt;p>It turns out that you can call this as a link in a Markdown document using HTML with &lt;code>&amp;lt;a href=&amp;quot;&amp;quot;&amp;gt;&lt;/code> and adding &lt;code>command:&lt;/code> prior to the command text. When the link is clicked the command will run. Cool 🙂&lt;/p>
&lt;p>For this to be able to work (you read the warning above?) you need to set the Notebook to be trusted by clicking this button.&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1" target="_blank" rel="noopener"
>https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This will allow any command to be run. Of course, people with beards will helpfully advise when this is required for a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/05%20-Working%20with%20dbachecks%20Validation%20Results.ipynb" target="_blank" rel="noopener"
>SQL Notebook&lt;/a>. (Safe to say people attempting nefarious actions will try the same with your users)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Now that we know how to run an Azure Data Studio command using a link in a markdown cell the next step is to run a PowerShell command. I headed to the &lt;a class="link" href="https://code.visualstudio.com/docs/editor/integrated-terminal" target="_blank" rel="noopener"
>Visual Studio Code documentation&lt;/a> and found&lt;/p>
&lt;blockquote>
&lt;p>Send text from a keybinding&lt;br>
The &lt;code>workbench.action.terminal.sendSequence&lt;/code> command can be used to send a specific sequence of text to the terminal, including escape sequence&lt;/p>
&lt;/blockquote>
&lt;p>That’s the command we need, however, we still need to craft the command so that it will work as a link. It needs to be converted into a URL.&lt;/p>
&lt;p>I started by using this website &lt;a class="link" href="https://www.url-encode-decode.com/" target="_blank" rel="noopener"
>https://www.url-encode-decode.com/&lt;/a> to do this. This is &lt;strong>how you can check the code in other peoples notebook, use the decode capability.&lt;/strong>&lt;/p>
&lt;p>Encoding &lt;code>Set-Location C:\dbachecks&lt;/code> gives `Set-Location+C%3A%5Cdbacheck``&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59567164-e5044300-9061-11e9-802b-7b28c3aee345.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can just put that code into the href link and bingo!&lt;/p>
&lt;p>If only it was that easy!!&lt;/p>
&lt;h2 id="some-replacing-is-required">Some Replacing is required&lt;/h2>
&lt;p>The + needs to be replaced with a space or &lt;code>%20&lt;/code>&lt;/p>
&lt;p>You also need to double the &lt;code>\&lt;/code> and replace the &lt;code>%3A&lt;/code> with a &lt;code>:&lt;/code>&lt;br>
The &lt;code>&amp;quot;&lt;/code> needs to be replaced with &lt;code>\u022&lt;/code>, the &lt;code>'&lt;/code> with &lt;code>\u027&lt;/code>, the curly braces won’t work unless you remove the &lt;code>%0D%0A&lt;/code>. Got all that? Good!&lt;/p>
&lt;p>Once you have written your PowerShell, encoded it, performed the replacements, you add &lt;code>\u000D&lt;/code> at the end of the code to pass an enter to run the code and then place all of that into a link like this&lt;/p>
&lt;p>&lt;code>&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 PLACE THE ENCODED CODE HERE %22%7D&amp;quot;&amp;gt;Link Text&amp;lt;/a&amp;gt;&lt;/code>&lt;/p>
&lt;p>This means that if you want to add the PowerShell code to set a location and then list the files and folders in that location to a Markdown cell using PowerShell like this&lt;/p>
&lt;pre>&lt;code>Set-Location C:\dbachecks
Get-ChildItem
&lt;/code>&lt;/pre>
&lt;p>You would end up with a link like this&lt;/p>
&lt;p>&lt;code>`&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 Set-Location C:%5C%5Cdbachecks \u000D Get-ChildItem \u000D %22%7D&amp;quot;&amp;gt;Set Location and list files&amp;lt;/a`&lt;/code>&amp;gt;&lt;/p>
&lt;h2 id="doing-something-more-than-once">Doing something more than once?&lt;/h2>
&lt;p>I don’t want to remember that all of the time so I wrote a PowerShell function. You can find it on GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1&lt;/a>&lt;/p>
&lt;p>This will take a PowerShell command and turn it into a link that will work in an Azure Data Studio markdown. It’s not magic, it’s PowerShell. There is a –&lt;code>ToClipboard&lt;/code> parameter which will copy the code to the clipboard ready for you to paste into the cell (On Windows machines only)&lt;/p>
&lt;h2 id="giants">Giants&lt;/h2>
&lt;p>There are many uses for this but here’s one I think is cool.&lt;/p>
&lt;p>The link below will go to a notebook, which will show how you the giants upon whose shoulders I stand&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/GlennAlanBerry" target="_blank" rel="noopener"
>Glenn Berry&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André&lt;/a> &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Kamman&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/spaghettidba" target="_blank" rel="noopener"
>Gianluca Sartori&lt;/a>&lt;/p>
&lt;p>have enabled me to create a SQL Notebook with a link which will run some PowerShell to create a SQL Notebook which will have all of the Diagnostic Queries in it.&lt;/p>
&lt;p>You could possibly use something like it for your incident response SQL Notebook.&lt;/p>
&lt;p>It’s also cool that GitHub renders the notebook in a browser (You can’t run PowerShell or T-SQL from there though, you need Azure Data Studio!)&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-4.png"
loading="lazy"
>&lt;/p></description></item><item><title>Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</link><pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-125.png" alt="Featured image of post Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools" />&lt;p>In my posts about using Azure Devops to build Azure resources with Terraform, &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>I built a Linux SQL VM.&lt;/a> I used the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>Terraform in this GitHub&lt;/a> repository and created this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-mobaxterm">Connecting with MobaXterm&lt;/h2>
&lt;p>I had set the Network security rules to accept connections only from my static IP using variables in the Build Pipeline. I use &lt;a class="link" href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener"
>MobaXterm&lt;/a> as my SSH client. Its a free download. I click on sessions&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-120.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose a SSH session and fill in the remote host address from the portal&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-121.png"
loading="lazy"
>&lt;/p>
&lt;p>fill in the password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-122.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="configuring-sql">Configuring SQL&lt;/h2>
&lt;p>The next task is to configure the SQL installation. Following the instructions on the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sql/provision-sql-server-linux-virtual-machine?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft docs site&lt;/a> I run&lt;/p>
&lt;pre>&lt;code>sudo systemctl stop mssql-server
sudo /opt/mssql/bin/mssql-conf set-sa-password
&lt;/code>&lt;/pre>
&lt;p>enter the sa password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-123.png"
loading="lazy"
>&lt;/p>
&lt;p>Now to start SQL&lt;/p>
&lt;pre>&lt;code>sudo systemctl start mssql-server
&lt;/code>&lt;/pre>
&lt;h2 id="installing-pwsh">Installing pwsh&lt;/h2>
&lt;p>Installing PowerShell Core (pwsh) is easy with snap&lt;/p>
&lt;p>sudo snap install powershell &amp;ndash;classic&lt;/p>
&lt;p>A couple of minutes of downloads and install&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-124.png"
loading="lazy"
>&lt;/p>
&lt;p>and pwsh is ready for use&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-125.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-dbatools">Installing dbatools&lt;/h2>
&lt;p>To install &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbatools" target="_blank" rel="noopener"
>Powershell Gallery&lt;/a> simply run&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser&lt;/p>
&lt;p>This will prompt you to allow installing from an untrusted repository&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-126.png"
loading="lazy"
>&lt;/p>
&lt;p>and dbatools is ready to go&lt;/p>
&lt;pre>&lt;code>#Set a credential
$cred = Get-Credential
# Show the databases on the local instance
Get-DbaDatabase -SqlInstance localhost -SqlCredential $cred
&lt;/code>&lt;/pre>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-127.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-azure-data-studio">Connecting with Azure Data Studio&lt;/h2>
&lt;p>I can also connect with Azure Data Studio&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-128.png"
loading="lazy"
>&lt;/p>
&lt;p>and connect&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/p>
&lt;p>Just a quick little post explaining what I did 🙂&lt;/p>
&lt;p>Happy Linuxing!&lt;/p></description></item><item><title>Generating a Workload against AdventureWorks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</link><pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-51.png" alt="Featured image of post Generating a Workload against AdventureWorks with PowerShell" />&lt;p>For a later blog post I have been trying to generate some workload against an AdventureWorks database.&lt;/p>
&lt;p>I found this excellent blog post by Pieter Vanhove &lt;a class="link" href="https://twitter.com/Pieter_Vanhove" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/&lt;/a> which references this 2011 post by Jonathan Kehayias &lt;a class="link" href="https://twitter.com/SQLPoolBoy" target="_blank" rel="noopener"
>t&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/" target="_blank" rel="noopener"
>https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/&lt;/a>&lt;/p>
&lt;p>Both of these run a random query in a single thread so I thought I would use &lt;a class="link" href="https://www.powershellgallery.com/packages/PoshRSJob/1.7.4.4" target="_blank" rel="noopener"
>PoshRSJob&lt;/a> by Boe Prox &lt;a class="link" href="https://learn-powershell.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>t&lt;/a> to run multiple queries at the same time 🙂&lt;/p>
&lt;p>To install PoshRSJob, like with any PowerShell module, you run&lt;/p>
&lt;pre>&lt;code>Install-Module -Name PoshRSJob
&lt;/code>&lt;/pre>
&lt;p>I downloaded AdventureWorksBOLWorkload zip from Pieters blog post and extracted to my &lt;code>C:\temp folder&lt;/code>. I created a &lt;code>Invoke-RandomWorkload&lt;/code> function which you can get from my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions" target="_blank" rel="noopener"
>functions repository in GitHub&lt;/a>. The guts of the function are&lt;/p>
&lt;pre>&lt;code> 1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
&lt;/code>&lt;/pre>
&lt;p>which will created $NumberOfJobs jobs and then run $Throttle number of jobs in the background until they have all completed. Each job will run a random query from the query file using Invoke-SqlCmd. Why did I use Invoke-SqlCmd and not Invoke-DbaQuery from dbatools? dbatools creates runspaces in the background to help with logging and creating runspaces inside background jobs causes errors&lt;/p>
&lt;p>Then I can run the function with&lt;/p>
&lt;pre>&lt;code>Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?resize=630%2C256&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and create a random workload. Creating lots of background jobs takes resources so when I wanted to run a longer workload I created a loop.&lt;/p>
&lt;pre>&lt;code>$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
&lt;/code>&lt;/pre>
&lt;p>You can get the function here. The full code is below&lt;/p>
&lt;pre>&lt;code># With thanks to Jonathan Kehayias and Pieter Vanhove
&amp;lt;#
.SYNOPSIS
Runs a random workload against a database using a sql file
.DESCRIPTION
Runs a random workload against a database using PoshRSJobs to create parallel jobs to run random
queries from a T-SQL file by default it uses the AdventureWorksBOLWorkload.sql from Pieter Vanhove
.PARAMETER SqlInstance
The SQL instance to run the queries against
.PARAMETER SqlCredential
The SQL Credential for the Instance if required
.PARAMETER Database
The name of the database to run the queries against
.PARAMETER NumberOfJobs
The number of jobs to create - default 10
.PARAMETER Delay
The delay in seconds for the output for the running jobs - default 10
.PARAMETER Throttle
The number of parallel jobs to run at a time - default 5
.PARAMETER PathToScript
The path to the T-SQL script holding the queries - default 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql'
.PARAMETER Delimiter
The delimiter in the T-SQL Script between the queries - default ------
.PARAMETER ShowOutput
Shows the output from the jobs
.EXAMPLE
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 100 -Delay 10 -Throttle 10
Runs 100 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23
.EXAMPLE
$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
Runs 1000 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23 10 times in a loop
.NOTES
With thanks to Pieter Vanhove
https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/
and
Jonathan Kehayias
https://www.sqlskills.com/blogs/jonathan/ the-adventureworks2008r2-books-online-random-workload-generator /
&amp;gt;
function Invoke-RandomWorkload {
#Requires -Module PoshRsJob
#Requires -Module SQLServer
Param(
[string]$SqlInstance,
[pscredential]$SqlCredential,
[string]$Database,
[int]$NumberOfJobs = 10,
[int]$Delay = 10,
[int]$Throttle = 5,
[string]$PathToScript = 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql',
[string]$Delimiter = &amp;quot;------&amp;quot;,
[switch]$ShowOutput
)
#Check if there are old Workload Jobs
$WorkloadJobs = Get-RSJob -Name Workload
if ($WorkloadJobs) {
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
$WorkloadJobs |Stop-RSJob
$WorkloadJobs | Remove-RSJob
}
Write-Output &amp;quot;Creating Background Jobs&amp;quot;
1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
$runningJobs = (Get-RSJob -Name WorkLoad -State Running). Count
While ($runningJobs -ne 0) {
$jobs = Get-RSJob -Name WorkLoad
$runningJobs = $Jobs.Where{$PSItem.State -eq 'Running'} .Count
$WaitingJobs = $Jobs.Where{$PSItem.State -eq 'NotStarted'}.Count
$CompletedJobs = $Jobs.Where{$PSItem.State -eq 'Completed'}.Count
Write-Output &amp;quot;$runningJobs jobs running - $WaitingJobs jobs waiting - $CompletedJobs -jobs finished&amp;quot;
Start-Sleep -Seconds $Delay
}
Write-Output &amp;quot;Jobs have finished&amp;quot;
if ($ShowOutput) {
Write-Output &amp;quot;WorkLoad Jobs Output below -&amp;quot;
Get-RSJob -Name WorkLoad | Receive-RSJob
}
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
Get-RSJob -Name WorkLoad | Remove-RSJob
Write-Output &amp;quot;Finished&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Whats a SQL Notebook in Azure Data Studio?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-7.png" alt="Featured image of post Whats a SQL Notebook in Azure Data Studio?" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-2017?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a cross-platform database tool for data professionals using the Microsoft family of on-premises and cloud data platforms on Windows, MacOS, and Linux.&lt;/p>
&lt;p>Recently Vicky Harp tweeted&lt;/p>
&lt;blockquote>
&lt;p>We&amp;rsquo;re getting very close to release of SQL Notebooks in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>! You can give the feature an early spin today with the insider build. &lt;a class="link" href="https://t.co/SEZp7ZdxCp" target="_blank" rel="noopener"
>pic.twitter.com/SEZp7ZdxCp&lt;/a>&lt;/p>
&lt;p>— Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1104127412944551936?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 8, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>By the way, you can watch a recording from SQLBits of Vicky’s session&lt;/p>
&lt;blockquote>
&lt;p>If you missed &lt;a class="link" href="https://twitter.com/hashtag/sqlbits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#sqlbits&lt;/a>, you will definitely want to watch this demo by &lt;a class="link" href="https://twitter.com/vickyharp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@vickyharp&lt;/a> and &lt;a class="link" href="https://twitter.com/MGoCODE?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@MGoCODE&lt;/a> about &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>. Learn the latest about our cross-platform tool, including a new feature, SQL Notebooks &lt;a class="link" href="https://twitter.com/hashtag/SQLServer?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLServer&lt;/a> &lt;a class="link" href="https://t.co/diubYwQckn" target="_blank" rel="noopener"
>https://t.co/diubYwQckn&lt;/a>&lt;/p>
&lt;p>— Azure Data Studio (@AzureDataStudio) &lt;a class="link" href="https://twitter.com/AzureDataStudio/status/1103806327065722880?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 7, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>So in the interest of learning about something new I decided to give it a try.&lt;/p>
&lt;h2 id="install-the-insiders-edition">Install The Insiders Edition&lt;/h2>
&lt;p>Unlike &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> which has a link to the insiders download on the front page, you will have to &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio#azure-data-studio" target="_blank" rel="noopener"
>visit the GitHub repository for the links to download the insiders release of Azure Data Studio&lt;/a>. Scroll down and you will see&lt;/p>
&lt;p>Try out the latest insiders build from &lt;code>master&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider" target="_blank" rel="noopener"
>Windows User Installer – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider" target="_blank" rel="noopener"
>Windows System Installer – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider" target="_blank" rel="noopener"
>Windows ZIP – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider" target="_blank" rel="noopener"
>macOS ZIP – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider" target="_blank" rel="noopener"
>Linux TAR.GZ – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See the &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>change log&lt;/a> for additional details of what’s in this release.
Once you have installed you can connect to an instance, right click and choose New Notebook or you can use File – New Notebook
&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image.png"
loading="lazy"
>&lt;/p>
&lt;p>Incidentally, I use the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> to create the containers and I map &lt;code>C:\MSSQL\BACKUP\KEEP&lt;/code> on my local machine (where my backups are) to &lt;code>/var/opt/mssql/backups&lt;/code> on the containers on lines 10 and 17 of the docker-compose so change as required . If you want to follow along then put the ValidationResults.bak in the folder on your local machine.
The &lt;code>Create-Ag.ps1&lt;/code> shows the code and creates an AG with &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.&lt;/a> But I digress!&lt;/p>
&lt;h2 id="install-notebook-dependencies">Install Notebook Dependencies&lt;/h2>
&lt;p>Once you click New Notebook you will get a prompt to install the dependencies.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>It will show its output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and take a few minutes to run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>It took all but 11 minutes on my machine&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-notebook">Create a Notebook&lt;/h2>
&lt;p>OK, so now that we have the dependencies installed we can create a notebook. I decided to use the ValidationResults database that &lt;a class="link" href="https://blog.robsewell.com/dbachecks-save-the-results-to-a-database-for-historical-reporting/" target="_blank" rel="noopener"
>I use for my dbachecks demos and describe here&lt;/a>. I need to restore it from my local folder that I have mapped as a volume to my container. Of course, I use dbatools for this 🙂&lt;/p>
&lt;pre>&lt;code># U: sqladmin P: dbatools.IO
$cred = Get-Credential
$restoreDbaDatabaseSplat = @{
SqlInstance = $sqlinstance1
SqlCredential = $cred
UseDestinationDefaultDirectories = $true
Path = '/var/opt/mssql/backups/ValidationResults.bak'
}
Restore-DbaDatabase @restoreDbaDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>I had already got a connection saved to the instance in Azure Data Studio, you may need to create a new one using the new connection icon at the top left and filling in the details. The password is in the code above.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can start with my notebook. I am faced with this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I click on text and provide an intro&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I had written that and clicked out, I couldn’t see what to do straight away!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I saw the code and text buttons at the top 🙂 Right, lets get on with it 🙂 I hit the code button and paste in the T-SQL to reset the dates in the database to simulate dbachecks having been run this morning.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-9.png"
loading="lazy"
>
There’s a run cell button on the right and when I press it&amp;gt;&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->
Cool 🙂&lt;/p>
&lt;p>If the SQL query has results then they are shown as well&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>This is fun and I can see plenty of uses for it. Go and have a play with SQL notebooks 🙂&lt;/p>
&lt;h2 id="source-control">Source Control&lt;/h2>
&lt;p>I used CTRL K, CTRL O to open a folder and saved my notebook in my local Presentations folder which is source controlled. When I opened the explorer CTRL + SHIFT + E I can see that the folder and the file are colour coded green and have a U next to them marking them as Untracked. I can also see that the source control icon has a 1 for the number of files with changes and in the bottom left that I am in the master branch.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>If I click on the source control icon (or CTRL + SHIFT + G) I can see the files with the changes and can enter a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>I then press CTRL + ENTER to commit my change and get this pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>As I only have one file and it has all the changes for this commit I click yes. If I had changed more than one file and only wanted to commit a single one at a time I would hover my mouse over the file and click the + to stage my change.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>If I make a further change to the notebook and save it, I can see that the source control provider recognises the change but this time the folder the file is in and the file are colour coded brown with an M to show that they have been modified.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Unlike Visual Studio Code, when you then click on the source control icon and click on the change it does not show the differences in the notebook although this works with SQL files.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>When I have made all my changes and committed them with good commit messages&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/imgs.xkcd.com/comics/git_commit.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can see that there are 3 local changes ready to be pushed to by remote repository (GitHub in this case) and 0 remote commits in this branch by looking at the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I can click on the “roundy roundy” icon (I don&amp;rsquo;t know its proper name 😊) and synchronise my changes. This comes with a pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Personally I never press OK, Don’t Show Again because I like the double check and to think “Is this really what I want to do right now”. Once I press OK my changes will be synched with the remote repository. Explaining this means that you can find the notebook I have used in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/Notebooks" target="_blank" rel="noopener"
>Presentations GitHub Repository&lt;/a> which means that you can run the Notebook too using the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> and the instructions further up in the post.&lt;/p></description></item><item><title>Using Docker to run Integration Tests for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</link><pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</guid><description>&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> wrote a fantastic blog post this week &lt;a class="link" href="https://andrekamman.com/sql-server-container-instances-via-cloudshell/" target="_blank" rel="noopener"
>SQL Server Container Instances via Cloudshell&lt;/a> about how he uses containers in Azure to test code against different versions of SQL Server.&lt;/p>
&lt;p>It reminded me that I do something very similar to test &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> code changes. I thought this might make a good blog post. I will talk through how I do this locally as I merge a PR from another great friend &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>Cláudio Silva&lt;/a> who has added &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/582" target="_blank" rel="noopener"
>agent job history checks.&lt;/a>&lt;/p>
&lt;h2 id="github-pr-vs-code-extension">GitHub PR VS Code Extension&lt;/h2>
&lt;p>I use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github" target="_blank" rel="noopener"
>GitHub Pull Requests extension for VS Code&lt;/a> to work with pull requests for &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pulls" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This enables me to see all of the information about the Pull Request, merge it, review it, comment on it all from VS Code&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/GitHub-Pull-Request-VsCode-Extension.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see which files have been changed and which changes have been made&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/viewing-a-change.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I am ready to test the pull request I perform a checkout using the extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/checkout-pull-request-checkout.png"
loading="lazy"
>&lt;/p>
&lt;p>This will update all of the files in my local repository with all of the changes in this pull request&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>You can see at the bottom left that the branch changes from development to the name of the PR.&lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-unit-tests">Running The Unit Tests&lt;/h2>
&lt;p>The first thing that I do is to run the Unit Tests for the module. These will test that the code is following all of the guidelines that we require and that the tests are formatted in the correct way for the Power Bi to parse. I have blogged about this &lt;a class="link" href="https://blog.robsewell.com/using-the-ast-in-pester-for-dbachecks/" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-the-powershell-ast-to-find-a-foreach-method/" target="_blank" rel="noopener"
>here&lt;/a> and we use this Pester in our CI process in Azure DevOps which I described &lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>here.&lt;/a>&lt;/p>
&lt;p>I navigate to the root of the dbachecks repository on my local machine and run&lt;/p>
&lt;pre>&lt;code> $testresults = Invoke-Pester .\tests -ExcludeTag Integration -Show Fails -PassThru
&lt;/code>&lt;/pre>
&lt;p>and after about a minute&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/pester-tests.png"
loading="lazy"
>&lt;/p>
&lt;p>Thank you Cláudio, the code has passed the tests 😉&lt;/p>
&lt;h2 id="running-some-integration-tests">Running Some Integration Tests&lt;/h2>
&lt;p>The difference between Unit tests and Integration tests in a nutshell is that the Unit tests are testing that the code is doing what is expected without any other external influences whilst the Integration tests are checking that the code is doing what is expected when running on an actual environment. In this scenario we know that the code is doing what is expected but we want to check what it does when it runs against a SQL Server and even when it runs against multiple SQL Servers of different versions.&lt;/p>
&lt;h2 id="multiple-versions-of-sql-server">Multiple Versions of SQL Server&lt;/h2>
&lt;p>As I have described &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>before&lt;/a> my friend and former colleague Andrew Pruski &lt;a class="link" href="http://dbafromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="http://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has many resources for running SQL in containers. This means that I can quickly and easily create fresh uncontaminated instances of SQL 2012, 2014, 2016 and 2017 really quickly.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/creating-contatiners.png"
loading="lazy"
>&lt;/p>
&lt;p>I can create 4 instances of different versions of SQL in (a tad over) 1 minute. How about you?&lt;/p>
&lt;p>Imagine how long it would take to run the installers for 4 versions of SQL and the pain you would have trying to uninstall them and make sure everything is ‘clean’. Even images that have been sysprep’d won’t be done in 1 minute.&lt;/p>
&lt;h2 id="docker-compose-up-">Docker Compose Up ?&lt;/h2>
&lt;p>So what is this magic command that has enabled me to do this? docker compose uses a YAML file to define multi-container applications. This means that with a file called docker-compose.yml like &lt;a class="link" href="https://gist.github.com/SQLDBAWithABeard/b589d499484af4ebfb7d637cb6b4efa3" target="_blank" rel="noopener"
>this&lt;/a>&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/ mssql-server-windows-developer:2017-latest
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and in that directory just run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>and 4 SQL containers are available to you. You can interact with them via SSMS if you wish with localhost comma PORTNUMBER. The port numbers in the above file are 15586, 15587,15588 and 15589&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?resize=630%2C188&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>Now it must be noted, as I &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>describe here&lt;/a> that first I pulled the images to my laptop. The first time you run docker compose will take significantly longer if you haven’t pulled the images already (pulling the images will take quite a while depending on your broadband speed)&lt;/p>
&lt;h2 id="credential">Credential&lt;/h2>
&lt;p>The next thing is to save a credential to make it easier to automate.&lt;del>I use the method described by my PowerShell friend Jaap Brasser &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/del>&lt;/p>
&lt;p>EDIT (September or is it March? 2020) - Nowadays I use the Secret Management Module&lt;/p>
&lt;p>I run this code&lt;/p>
&lt;pre>&lt;code> $CredentialPath = 'C:\MSSQL\BACKUP\KEEP\sacred.xml'
Get-Credential | Export-Clixml -Path $CredentialPath
&lt;/code>&lt;/pre>
&lt;p>and then I can create a credential object using&lt;/p>
&lt;pre>&lt;code>$cred = Import-Clixml $CredentialPath
&lt;/code>&lt;/pre>
&lt;h2 id="check-the-connections">Check The Connections&lt;/h2>
&lt;p>I ensure a clean session by removing the dbatools and dbachecks modules and then import the local version of dbachecks and set some variables&lt;/p>
&lt;pre>&lt;code>$dbacheckslocalpath = 'GIT:\dbachecks\'
Remove-Module dbatools, dbachecks -ErrorAction SilentlyContinue
Import-Module $dbacheckslocalpath\dbachecks.psd1
$cred = Import-Clixml $CredentialPath
$containers = 'localhost,15589', 'localhost,15588', 'localhost, 15587', 'localhost,15586'
&lt;/code>&lt;/pre>
&lt;p>Now I can start to run my Integration tests. First reset the dbachecks configuration and set some configuration values&lt;/p>
&lt;pre>&lt;code># run the checks against these instances
$null = Set-DbcConfig -Name app.sqlinstance $containers
# We are using SQL authentication
$null = Set-DbcConfig -Name policy.connection.authscheme -Value SQL
# sometimes its a bit slower than the default value
$null = Set-DbcConfig -Name policy.network.latencymaxms -Value 100 # because the containers run a bit slow!
&lt;/code>&lt;/pre>
&lt;p>Then I will run the dbachecks connectivity checks and save the results to a variable without showing any output&lt;/p>
&lt;pre>&lt;code>$ConnectivityTests = Invoke-DbcCheck -SqlCredential $cred -Check Connectivity -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>I can then use Pester to check that dbachecks has worked as expected by testing if the failedcount property returned is 0.&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;Testing the checks are running as expected&amp;quot; -Tag Integration {
Context &amp;quot;Connectivity Checks&amp;quot; {
It &amp;quot;All Tests should pass&amp;quot; {
$ConnectivityTests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default settings&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/check-connectivity.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="what-is-the-unit-test-for-this-pr">What is the Unit Test for this PR?&lt;/h2>
&lt;p>Next I think about what we need to be testing for the this PR. The Unit tests will help us.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/what-are-the-unit-tests.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="choose-some-integration-tests">Choose some Integration Tests&lt;/h2>
&lt;p>This check is checking the Agent job history settings and the unit tests are&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows disabled (-1)”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows disabled (-1) but configured value is 1000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows being 10000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows being less than 10000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows per job being 100”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows per job being less than 100”&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So we will check the same things on real actual SQL Servers. First though we need to start the SQL Server Agent as it is not started by default. We can do this as follows&lt;/p>
&lt;pre>&lt;code>docker exec -ti integration_sql2012_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2014_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2016_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2017_1 powershell start-service SQLSERVERAGENT
&lt;/code>&lt;/pre>
&lt;p>Unfortunately, the agent service wont start in the SQL 2014 container so I cant run agent integration tests for that container but it’s better than no integration tests.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/agent-wont-start.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="this-is-what-we-will-test">This is What We Will Test&lt;/h2>
&lt;p>So we want to test if the check will pass with default settings. In general, dbachecks will pass for default instance, agent or database settings values by default.&lt;/p>
&lt;p>We also want the check to fail if the configured value for dbachecks is set to default but the value has been set on the instance.&lt;/p>
&lt;p>We want the check to pass if the configured value for the dbachecks configuration is set and the instance (agent, database) setting matches it.&lt;/p>
&lt;h2 id="if-you-are-doing-something-more-than-once-">If You Are Doing Something More Than Once ……&lt;/h2>
&lt;p>Let’s automate that. We are going to be repeatedly running those three tests for each setting that we are running integration tests for. I have created 3 functions for this again checking that FailedCount or Passed Count is 0 depending on the test.&lt;/p>
&lt;pre>&lt;code>function Invoke-DefaultCheck {
It &amp;quot;All Checks should pass with default for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)default&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default setting (Yes we may set some values before but you get my drift)&amp;quot;
}
}
function Invoke-ConfigCheck {
It &amp;quot;All Checks should fail when config changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)configchanged&amp;quot; -ValueOnly
$Tests.PassedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and fail when we have changed the config values&amp;quot;
}
}
function Invoke-ValueCheck {
It &amp;quot;All Checks should pass when setting changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check) value changed&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass when we have changed the settings to match the config values&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Now I can use those functions inside a loop in my Integration Pester Test&lt;/p>
&lt;pre>&lt;code>$TestingTheChecks = @('errorlogscount','jobhistory')
Foreach ($Check in $TestingTheChecks) {
Context &amp;quot;$Check Checks&amp;quot; {
Invoke-DefaultCheck
Invoke-ConfigCheck
Invoke-ValueCheck
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="write-some-integration-tests">Write Some Integration Tests&lt;/h2>
&lt;p>So for this new test I have added a value to the TestingTheChecks array then I can test my checks. The default check I can check like this&lt;/p>
&lt;pre>&lt;code># run the checks against these instances (SQL2014 agent wont start :-( ))
$null = Set-DbcConfig -Name app.sqlinstance $containers.Where {$_ -ne 'localhost,15588'}
# by default all tests should pass on default instance settings
$jobhistorydefault = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Now I need to change the configurations so that they do not match the defaults and run the checks again&lt;/p>
&lt;pre>&lt;code>#Change the configuration to test that the checks fail
$null = Set-DbcConfig -Name agent.history. maximumjobhistoryrows -value 1000
$null = Set-DbcConfig -Name agent.history.maximumhistoryrows -value 10000
$jobhistoryconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Next we have to change the instance settings so that they match the dbachecks configuration and run the checks and test that they all pass.&lt;/p>
&lt;p>We will (of course) use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> for this. First we need to find the command that we need&lt;/p>
&lt;pre>&lt;code>Find-DbaCommand jobserver
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/find-dbacommand.png"
loading="lazy"
>&lt;/p>
&lt;p>and then work out how to use it&lt;/p>
&lt;pre>&lt;code>Get-Help Set-DbaAgentServer -Detailed
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/set-the-values.png"
loading="lazy"
>&lt;/p>
&lt;p>There is an example that does exactly what we want 🙂 So we can run this.&lt;/p>
&lt;pre>&lt;code>$setDbaAgentServerSplat = @{
MaximumJobHistoryRows = 1000
MaximumHistoryRows = 10000
SqlInstance = $containers.Where{$_ -ne 'localhost,15588'}
SqlCredential = $cred
}
Set-DbaAgentServer @setDbaAgentServerSplat
$jobhistoryvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;h2 id="run-the-integration-tests">Run the Integration Tests&lt;/h2>
&lt;p>And then we will check that all of the checks are passing and failing as expected&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\DockerTests.ps1
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/testing-the-checks.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="integration-test-for-error-log-counts">Integration Test For Error Log Counts&lt;/h2>
&lt;p>There is another integration test there for the error logs count. This works in the same way. Here is the code&lt;/p>
&lt;pre>&lt;code>#region error Log Count - PR 583
# default test
$errorlogscountdefault = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set a value and then it will fail
$null = Set-DbcConfig -Name policy.errorlog.logcount -Value 10
$errorlogscountconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set the value and then it will pass
$null = Set-DbaErrorLogConfig -SqlInstance $containers -SqlCredential $cred -LogCount 10
$errorlogscountvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
#endregion
&lt;/code>&lt;/pre>
&lt;h2 id="merge-the-changes">Merge the Changes&lt;/h2>
&lt;p>So with all the tests passing I can merge the PR into the development branch and Azure DevOps will start a build. Ultimately, I would like to add the integration to the build as well following &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André&lt;/a>‘s blog post but for now I used the GitHub Pull Request extension to merge the pull request into development which started a &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_build/results?buildId=365&amp;amp;view=results" target="_blank" rel="noopener"
>build&lt;/a> and then merged that into master which signed the code and deployed it to the PowerShell gallery as you can see &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=81&amp;amp;environmentId=81" target="_blank" rel="noopener"
>here&lt;/a> and the result is&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.164" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/dbachecks/1.1.164&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/powershell-gallery.png"
loading="lazy"
>&lt;/p></description></item><item><title>Running Windows and Linux SQL Containers together</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-windows-and-linux-sql-containers-together/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-windows-and-linux-sql-containers-together/</guid><description>&lt;p>Just for fun I decided to spend Christmas Eve getting Windows and Linux SQL containers running together.&lt;/p>
&lt;h2 id="warning">WARNING&lt;/h2>
&lt;p>This is NOT a production ready solution, in fact I would not even recommend that you try it.&lt;br>
I definitely wouldn’t recommend it on any machine with anything useful on it that you want to use again.&lt;br>
We will be using a re-compiled dockerd.exe created by someone else and you know the rules about downloading things from the internet don’t you? and trusting unknown unverified people?&lt;/p>
&lt;p>Maybe you can try this in an Azure VM or somewhere else safe.&lt;/p>
&lt;p>Anyway, with that in mind, lets go.&lt;/p>
&lt;h2 id="linux-containers-on-windows">Linux Containers On Windows&lt;/h2>
&lt;p>You can run Linux containers on Windows in Docker as follows. You need to be running the latest Docker for Windows.&lt;/p>
&lt;p>Right click on the whale in the task bar and select Settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-settings.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Notice that I am running Windows Containers as there is a switch to Linux containers option. If you see Switch to Windows containers then click that first.&lt;/p>
&lt;p>Click on Daemon and then tick the experimental features tick box and press apply.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-daemon-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-daemon-settings.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Docker will restart and you can now run Linux containers alongside windows containers.&lt;/p>
&lt;p>So you you can pull the Ubuntu container with&lt;/p>
&lt;pre>&lt;code>docker pull ubuntu:18.04
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-image-pull.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-image-pull.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and then you can run it with&lt;/p>
&lt;pre>&lt;code>docker run -it --name ubuntu ubuntu:18.04
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-coontainer-interactively.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-coontainer-interactively.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>There you go one Linux container running 🙂&lt;br>
A good resource for learning bash for SQL Server DBAs is Kellyn Pot’Vin-Gorman &lt;a class="link" href="https://dbakevlar.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/DBAKevlar" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://www.red-gate.com/simple-talk/sql/sql-linux/how-to-linux-for-sql-server-dbas-part-1/" target="_blank" rel="noopener"
>series on Simple Talk&lt;/a>&lt;/p>
&lt;p>Type Exit to get out of the container and to remove it&lt;/p>
&lt;pre>&lt;code>docker rm ubuntu
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/exit-remove-ubuntu.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/exit-remove-ubuntu.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;p>Running SQL Linux Containers On Windows&lt;/p>
&lt;p>So can we run SQL Containers ?&lt;/p>
&lt;p>Well, we can pull the image successfully.&lt;/p>
&lt;pre>&lt;code>docker pull mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
&lt;/code>&lt;/pre>
&lt;p>If you try that without the experimental features enabled you will get this error.&lt;/p>
&lt;blockquote>
&lt;p>image operating system “linux” cannot be used on this platform&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/wrong-platform.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/wrong-platform.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>So you would think that what you can do is to use the code from Andrew ‘dbafromthecold’ Pruski’s &lt;a class="link" href="http://DBAfromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/DBAfromthecold" target="_blank" rel="noopener"
>t&lt;/a> excellent &lt;a class="link" href="https://dbafromthecold.com/2017/03/15/summary-of-my-container-series/" target="_blank" rel="noopener"
>container series&lt;/a>&lt;/p>
&lt;pre>&lt;code>docker run -d -p 15789:1433 --env ACCEPT_EULA=Y --env SA_PASSWORD=Testing1122 --name testcontainer mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
&lt;/code>&lt;/pre>
&lt;p>When you do, the command will finish successfully but the container won’t be started (as can been seen by the red dot in the docker explorer).&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/container-wont-run.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/container-wont-run.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If you look at the logs for the container. (I am lazy, I right click on the container and choose show logs in VS Code 🙂 ) you will see&lt;/p>
&lt;blockquote>
&lt;p>sqlservr: This program requires a machine with at least 2000 megabytes of memory.&lt;br>
/opt/mssql/bin/sqlservr: This program requires a machine with at least 2000 megabytes of memory.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/needs-more-memory.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/needs-more-memory.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now, if you are running Linux containers, this is an easy fix. All you have to do is to right click on the whale in the taskbar, choose Settings, Advanced and move the slider for the Memory and click apply.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/linux-containers-memory-increase.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/linux-containers-memory-increase.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>But in Windows containers that option is not available.&lt;/p>
&lt;p>If you go a-googling you will find that &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>Shawn Melton&lt;/a> created an &lt;a class="link" href="https://github.com/Microsoft/mssql-docker/issues/293" target="_blank" rel="noopener"
>issue for thi&lt;/a>s many months ago, which gets referenced by &lt;a class="link" href="https://github.com/Microsoft/opengcs/issues/145" target="_blank" rel="noopener"
>this issue&lt;/a> for the guest compute service, which references t&lt;a class="link" href="https://github.com/moby/moby/pull/37296" target="_blank" rel="noopener"
>his PR&lt;/a> in moby. But as this hasn’t been merged into master yet it is not available. I got bored of waiting for this and decided to look a bit deeper today.&lt;/p>
&lt;h3 id="get-it-working-just-for-fun">Get It Working Just For Fun&lt;/h3>
&lt;p>So, you read the warning at the top?&lt;/p>
&lt;p>Now let’s get it working. I take zero credit here. All of the work was done by Brian Weeteling &lt;a class="link" href="https://www.brianweet.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://github.com/brianweet" target="_blank" rel="noopener"
>G&lt;/a> in &lt;a class="link" href="https://www.brianweet.com/2018/04/26/running-mssql-server-linux-using-lcow.html" target="_blank" rel="noopener"
>this post&lt;/a>&lt;/p>
&lt;p>So you can follow Brians examples and check out the source code and compile it as he says or you can &lt;a class="link" href="https://www.brianweet.com/assets/mssql-linux/dockerd.rar" target="_blank" rel="noopener"
>download the exe&lt;/a> that he has made available (remember the warning?)&lt;/p>
&lt;p>Stop Docker for Windows, and with the file downloaded and unzipped, open an admin PowerShell and navigate to the directory the dockerd.exe file is and run&lt;/p>
&lt;pre>&lt;code>.\dockerd.exe
&lt;/code>&lt;/pre>
&lt;p>You will get an output like this and it will keep going for a while.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/running-dockerd.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/running-dockerd.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Leave this window open whilst you are using Docker like this. Once you see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/logs.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/logs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then open a new PowerShell window or VS Code. You will need to run it as admin. I ran&lt;/p>
&lt;pre>&lt;code>docker ps-a
&lt;/code>&lt;/pre>
&lt;p>to see if it was up and available.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-ps.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-ps.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I also had to create a bootx64.efi file at C:\Program Files\Linux Containers which I did by copying and renaming the kernel file in that folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/bootx64-file.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/bootx64-file.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now I can use a docker-compose file to create 5 containers. Four will be Windows containers from &lt;a class="link" href="https://hub.docker.com/u/dbafromthecold" target="_blank" rel="noopener"
>Andrews Docker hub repositories&lt;/a> or &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server/" target="_blank" rel="noopener"
>Microsoft’s Docker Hub&lt;/a> for SQL 2012, SQL 2014, SQL 2016, and SQL 2017 and one will be the latest &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server" target="_blank" rel="noopener"
>Ubuntu SQL 2019 CTP 2.2 image&lt;/a>. Note that you have to use version 2.4 of docker compose as the platform tag is not available yet in any later version, although it is coming to 3.7 soon.&lt;/p>
&lt;pre>&lt;code>version: '2.4'
services:
sql2019:
image: mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
platform: linux
ports:
- &amp;quot;15585:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
platform: windows
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
platform: windows
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
platform: windows
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/mssql-server-windows-developer:2017-latest
platform: windows
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Save this code as docker-compose.yml and navigate to the directory in an admin PowerShell or VS Code and run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and now I have Windows and Linux SQL containers running together. This means that I can test some code against all versions of SQL from 2012 to 2019 easily in containers 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/containers-in-SSMS.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/containers-in-SSMS.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers-dbatools.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers-dbatools.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>So that is just a bit of fun.&lt;/p>
&lt;p>To return to the normal Docker, simply CTRL and C the admin PowerShell you ran .\dockerd.exe in and you will see the logs showing it shutting down.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/shutdown-docker.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/shutdown-docker.png?fit=630%2C142"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You will then be able to start Docker For Windows as usual.&lt;/p>
&lt;p>I look forward to the time, hopefully early next year when all of the relevant PR’s have been merged and this is available in Docker for Windows.&lt;/p>
&lt;p>Happy Automating 🙂&lt;/p></description></item><item><title>Getting SQL Services, Starting, Stopping and Restarting them with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-services-starting-stopping-and-restarting-them-with-dbatools/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-services-starting-stopping-and-restarting-them-with-dbatools/</guid><description>&lt;p>There was a question in the &lt;a class="link" href="https://sqlcommunity.slack.com/#dbatools" target="_blank" rel="noopener"
>#dbatools slack channel &lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/dbatools-question.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/dbatools-question.png"
loading="lazy"
alt="dbatools question"
>&lt;/a>&lt;/p>
&lt;h3 id="getting-dbatools">Getting dbatools&lt;/h3>
&lt;p>dbatools enables you to administer SQL Server with PowerShell. To get it simply open PowerShell run&lt;/p>
&lt;p>Install-Module dbatools&lt;/p>
&lt;p>You can find more details on &lt;a class="link" href="http://dbatools.io/install" target="_blank" rel="noopener"
>the web-site&lt;/a>&lt;/p>
&lt;h3 id="finding-the-command">Finding the Command&lt;/h3>
&lt;p>To find a command you can use the dbatools command &lt;a class="link" href="https://docs.dbatools.io/#Find-DbaCommand" target="_blank" rel="noopener"
>Find-DbaCommand&lt;/a>&lt;br>
For commands for service run&lt;/p>
&lt;p>Find-DbaCommand Service&lt;/p>
&lt;p>There are a whole bundle returned&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/find-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/find-services.png"
loading="lazy"
alt="find services.png"
>&lt;/a>&lt;/p>
&lt;p>This is how you can find any dbatools command. There is also a -Tag parameter on Find-DbaCommand.&lt;/p>
&lt;p>Find-DbaCommand -Tag Service&lt;/p>
&lt;p>This returns&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/find-services-tag.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/find-services-tag.png"
loading="lazy"
alt="find services tag.png"
>&lt;/a>&lt;/p>
&lt;h3 id="how-to-use-any-powershell-command">How to use any PowerShell command&lt;/h3>
&lt;p>Always always start with Get-Help&lt;/p>
&lt;p>Get-Help Get-DbaService -Detailed&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/get-help.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/get-help.png"
loading="lazy"
alt="get help.png"
>&lt;/a>&lt;/p>
&lt;p>This will show you all the information about the command including examples 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/help-examples.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/help-examples.png"
loading="lazy"
alt="help examples.png"
>&lt;/a>&lt;/p>
&lt;p>All of these commands below require that the account running the PowerShell is a Local Admin on the host.&lt;/p>
&lt;h3 id="one-host-many-hosts">One Host Many Hosts&lt;/h3>
&lt;p>Now I have used just one host for all of the examples on this page. Do not be fooled, you can always use an array of hosts wherever I have $ComputerName you can set it to as many hosts as you like&lt;/p>
&lt;p>$ComputerName = &amp;lsquo;SQL0&amp;rsquo;,&amp;lsquo;SQL1&amp;rsquo;&lt;/p>
&lt;p>You can even get those names form a database, Excel sheet, CMS.&lt;/p>
&lt;h3 id="getting-the-services">Getting the Services&lt;/h3>
&lt;p>So to get the services on a machine run&lt;/p>
&lt;p>$ComputerName = &amp;lsquo;Name of Computer&amp;rsquo;
Get-DbaService -ComputerName $ComputerName&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/getting-servies-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/getting-servies-1.png"
loading="lazy"
alt="getting servies 1.png"
>&lt;/a>&lt;/p>
&lt;p>You can output into a table format.&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>I will use the alias ft for this in some of the examples, that is fine for the command line but use the full command name in any code that you write that other people use&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/services-table.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/services-table.png"
loading="lazy"
alt="services table.png"
>&lt;/a>&lt;/p>
&lt;p>You have an object returned so you can output to anything if you want – CSV, JSON, text file, email, azure storage, database, the world is your oyster.&lt;/p>
&lt;h3 id="getting-the-services-for-one-instance">Getting the Services for one instance&lt;/h3>
&lt;p>The &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaService" target="_blank" rel="noopener"
>Get-DbaService&lt;/a> command has a number of parameters. There is an InstanceName parameter enabling you to get only the services for one instance. If we just want the default instance services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MSSQLSERVER| Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/default-instances.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/default-instances.png"
loading="lazy"
alt="default instances.png"
>&lt;/a>&lt;/p>
&lt;p>Just the MIRROR instance services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MIRROR| Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/mirror-instances.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/mirror-instances.png"
loading="lazy"
alt="mirror instances.png"
>&lt;/a>&lt;/p>
&lt;h3 id="getting-just-the-engine-or-agent-services">Getting just the Engine or Agent services&lt;/h3>
&lt;p>You can also use the -Type parameter to get only services of a particular type. You can get one of the following: “Agent”,”Browser”,”Engine”,”FullText”,”SSAS”,”SSIS”,”SSRS”, “PolyBase”&lt;/p>
&lt;p>So to get only the Agent Services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/agent-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/agent-services.png"
loading="lazy"
alt="agent services.png"
>&lt;/a>&lt;/p>
&lt;p>You can combine the InstanceName and the Type parameters to get say only the default instance engine service&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MSSQLSERVER -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/default-engine-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/default-engine-service.png"
loading="lazy"
alt="default engine service.png"
>&lt;/a>&lt;/p>
&lt;h3 id="starting-and-stopping-and-restarting-services">Starting and stopping and restarting services&lt;/h3>
&lt;p>You can use &lt;a class="link" href="https://docs.dbatools.io/#Start-DbaService" target="_blank" rel="noopener"
>Start-DbaService&lt;/a> and &lt;a class="link" href="https://docs.dbatools.io/#Stop-DbaService" target="_blank" rel="noopener"
>Stop-DbaService&lt;/a> to start and stop the services. They each have ComputerName, InstanceName and Type parameters like Get-DbaService.&lt;/p>
&lt;p>So if after running&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>you find that all services are stopped&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped.png"
loading="lazy"
alt="all stopped.png"
>&lt;/a>&lt;/p>
&lt;h3 id="start-all-the-services">Start All the Services&lt;/h3>
&lt;p>You can run&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>and start them all&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-them-all.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-them-all.png"
loading="lazy"
alt="start them all.png"
>&lt;/a>&lt;/p>
&lt;p>The full text service was started with the engine service which is why it gave a warning. You can see this if you have all of the services stopped and just want to start the engine services with the type parameter.&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table
Start-DbaService -ComputerName $ComputerName -Type Engine
Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped-start-engine.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped-start-engine.png"
loading="lazy"
alt="all stopped - start engine.png"
>&lt;/a>&lt;/p>
&lt;p>If you just want to start the Agent services, you can use&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-agent.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-agent.png"
loading="lazy"
alt="start agent.png"
>&lt;/a>&lt;/p>
&lt;p>You can start just the services for one instance&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -InstanceName MIRROR&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-instance-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-instance-services.png"
loading="lazy"
alt="start instance services.png"
>&lt;/a>&lt;/p>
&lt;h3 id="stopping-the-services">Stopping the services&lt;/h3>
&lt;p>Stopping the services works in the same way. Lets stop the MIRROR instance services we have just started. This will stop the services for an instance&lt;/p>
&lt;p>Stop-DbaService -ComputerName $ComputerName -InstanceName MIRROR&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stopping-instance-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stopping-instance-services.png"
loading="lazy"
alt="stopping instance services.png"
>&lt;/a>&lt;/p>
&lt;p>We can stop them by type as well, although this will show an extra requirement. If we start our MIRROR instance services again and then try to stop just the engine type.&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -InstanceName MIRROR | ft
Stop-DbaService -ComputerName $ComputerName -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/cant-stop.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/cant-stop.png"
loading="lazy"
alt="cant stop.png"
>&lt;/a>&lt;/p>
&lt;p>You will get a warning due to the dependant services&lt;/p>
&lt;blockquote>
&lt;p>WARNING: [10:31:02][Update-ServiceStatus] (MSSQL$MIRROR on SQL0) The attempt to stop the service returned the following error: The service cannot be stopped because other services that are running are dependent on it.&lt;br>
WARNING: [10:31:02][Update-ServiceStatus] (MSSQL$MIRROR on SQL0) Run the command with ‘-Force’ switch to force the restart of a dependent SQL Agent&lt;/p>
&lt;/blockquote>
&lt;p>So all you have to do is use the force Luke (or whatever your name is!)&lt;/p>
&lt;p>Stop-DbaService -ComputerName $ComputerName -Type Engine -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/Use-the-force.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/Use-the-force.png"
loading="lazy"
alt="Use the force.png"
>&lt;/a>&lt;/p>
&lt;p>You can also stop the services for an entire host, again you will need the Force parameter.&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName |ft
Stop-DbaService -ComputerName $ComputerName -Force | ft&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stop-all-of-them.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stop-all-of-them.png"
loading="lazy"
alt="stop all of them.png"
>&lt;/a>&lt;/p>
&lt;h3 id="restarting-services">Restarting Services&lt;/h3>
&lt;p>It will come as no surprise by now to learn that &lt;a class="link" href="https://docs.dbatools.io/#Restart-DbaService" target="_blank" rel="noopener"
>Restart-DbaService&lt;/a> follows the same pattern. It also has ComputerName, InstanceName and Type parameters like Get-DbaService, Start-DbaService and Stop-DbaService (Consistency is great, It’s one of the things that is being worked on towards 1.0 as you can see in the &lt;a class="link" href="https://sqlcollaborative.github.io/boh.html" target="_blank" rel="noopener"
>Bill of Health&lt;/a>)&lt;/p>
&lt;p>Again you will need the -Force for dependant services, you can restart all of the services on a host with&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-tehm-all.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-tehm-all.png"
loading="lazy"
alt="restart tehm all.png"
>&lt;/a>&lt;/p>
&lt;p>or just the services for an instance&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -InstanceName MIRROR -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-instance.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-instance.png"
loading="lazy"
alt="restart instance.png"
>&lt;/a>&lt;/p>
&lt;p>or just the Agent Services&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-agent.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-agent.png"
loading="lazy"
alt="restart agent.png"
>&lt;/a>&lt;/p>
&lt;h3 id="doing-a-bit-of-coding">Doing a bit of coding&lt;/h3>
&lt;p>Now none of that answers @g-kannan’s question. Restarting only services with a certain service account.&lt;/p>
&lt;p>With PowerShell you can pipe commands together so that the results of the first command are piped into the second. So we can get all of the engine services on a host for an instance with Get-DbaService and start them with Start-DbaService like this&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Start-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start.png"
loading="lazy"
alt="start.png"
>&lt;/a>&lt;/p>
&lt;p>or get all of the engine services for an instance on a host and stop them&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine  -InstanceName Mirror| Stop-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stop-one-isntance.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stop-one-isntance.png"
loading="lazy"
alt="stop one isntance.png"
>&lt;/a>&lt;/p>
&lt;p>or maybe you want to get all of the service that have stopped&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine).Where{$_.State -eq &amp;lsquo;Stopped&amp;rsquo;}&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stopped-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stopped-services.png"
loading="lazy"
alt="stopped services.png"
>&lt;/a>&lt;/p>
&lt;p>You can do the same thing with syntax that may make more sense to you if you are used to T-SQL as follows&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine) | Where State -eq &amp;lsquo;Stopped&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/T-SQL-syntax-powershell.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/T-SQL-syntax-powershell.png"
loading="lazy"
alt="T SQL syntax powershell.png"
>&lt;/a>&lt;/p>
&lt;p>and then start only those services you could do&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine) | Where State -eq &amp;lsquo;Stopped&amp;rsquo; | Start-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-the-stopped-ones.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-the-stopped-ones.png"
loading="lazy"
alt="start the stopped ones.png"
>&lt;/a>&lt;/p>
&lt;p>(note – you would just use Start-DbaService in this case as it wont start services that are already started!)&lt;/p>
&lt;p># Stop just one of the engine services
Stop-DbaService -ComputerName $ComputerName -InstanceName MIRROR -Type Engine
# Get the engine services
Get-DbaService -ComputerName $ComputerName -Type Engine
# This will only start the one engine service that is stopped
Start-DbaService -ComputerName $ComputerName -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/only-one-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/only-one-service.png"
loading="lazy"
alt="only one service.png"
>&lt;/a>&lt;/p>
&lt;h3 id="come-on-rob-answer-the-question">Come On Rob! Answer the question!&lt;/h3>
&lt;p>So now that you know a lot more about these commands, you can restart only the services using a particular service account by using Get-DbaService to get the services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Where StartName -eq &amp;rsquo;thebeard\sqlsvc&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/services-by-start-name.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/services-by-start-name.png"
loading="lazy"
alt="services by start name.png"
>&lt;/a>&lt;/p>
&lt;p>and then once you know that you have the right ‘query’ you can pipe that to Restart-DbaService (Like making sure your SELECT query returns the correct rows for your WHERE clause before running the DELETE or UPDATE)&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Where StartName -eq &amp;rsquo;thebeard\sqlsvc&amp;rsquo; | Restart-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restarting-only-one.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restarting-only-one.png"
loading="lazy"
alt="restarting only one.png"
>&lt;/a>&lt;/p>
&lt;p>Happy Automating !&lt;/p></description></item><item><title>SQL Server Availability Group FailoverDetection Utility PowerShell Function Improvements – Named Instances, Archiving Data, Speed</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</link><pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</guid><description>&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>my last post I wrote about a new function&lt;/a> for gathering the data and running the &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy/" target="_blank" rel="noopener"
>FailoverDetection utility&lt;/a> by the &lt;a class="link" href="https://twitter.com/mssqltiger" target="_blank" rel="noopener"
>Tiger Team&lt;/a> to analyse availability group failovers. I have updated it following some comments and using it for a day.&lt;/p>
&lt;h3 id="dont-forget-the-named-instances-rob">Don’t forget the named instances Rob!&lt;/h3>
&lt;p>Michael Karpenko wrote a comment pointing out that I had not supported named instances, which was correct as it had not been written for that. Thank you Michael 🙂 I have updated the code to deal with named instances.&lt;/p>
&lt;h3 id="confusing-results">Confusing results&lt;/h3>
&lt;p>I also realised as we started testing the code that if you had run the code once and then ran it again against a different availability group the tool does not clear out the data folder that it uses so you can get confusing results.&lt;/p>
&lt;p>In the image below I had looked at the default instance and then a MIRROR named instance. As you can see the results json on the left shows the default instance SQLClusterAG while the one on the right shows both the SQLClusterAG and the MirrrAG instance results.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png"
loading="lazy"
alt="duplicate results.png"
>&lt;/a>&lt;/p>
&lt;p>This is not so useful if you don’t notice this at first with the expanded json!! Now you may in this situation want to see the combined results from all of the availability groups on one cluster. You could gather all of the data from each instance and then add it to the data folder easily enough.&lt;/p>
&lt;p>By cleaning out the data folder before running the utility the results are as expected.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results-fixed.png"
loading="lazy"
alt="duplicate results fixed.png"
>&lt;/p>
&lt;h3 id="archive-the-data-for-historical-analysis">Archive the data for historical analysis&lt;/h3>
&lt;p>One of the production DBAs pointed out that having gathered the information, it would be useful to hold it for better analysis of repeated issues. I have added an archiving step so that when the tools runs, if there is already data in the data gathering folder, it will copy that to an archive folder and name it with the date and time that the cluster log was created as this is a good estimation of when the analysis was performed. If an archive folder location is not provided it will create an archive folder in the data folder. This is not an ideal solution though, as the utility will copy all of the files and folders from there to its own location so it is better to define an archive folder in the parameters.&lt;/p>
&lt;h3 id="get-eventlog-is-sloooooooooooow">Get-Eventlog is sloooooooooooow&lt;/h3>
&lt;p>I was running the tools and noticed it sat running the system event log task for a long long time. I ran some tests using a variation of the &lt;a class="link" href="http://dbatools.io/prompt" target="_blank" rel="noopener"
>dbatools prompt.&lt;/a>&lt;/p>
&lt;p>This will show in the prompt how long it took to run the previous statement .&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/speed.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/speed.png"
loading="lazy"
alt="speed.png"
>&lt;/a>&lt;/p>
&lt;p>In the image above (which you can click to get a larger version as with all images on this blog) you can see that it took 18ms to set the date variable, FOUR MINUTES and FORTY THREE seconds to get the system log in the last 2 days using Get-EventLog and 29.1 seconds using Get-WinEvent and a FilterHashtable.&lt;/p>
&lt;h3 id="getting-the-function">Getting the function&lt;/h3>
&lt;p>This function requires PowerShell version 5 and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment – will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>. .\Invoke-SqlFailOverDetection.ps1&lt;/p>
&lt;p>There are two .’s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters and more info &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>on my previous post.&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Gathering all the Logs and Running the Availability Group Failover Detection Utility with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</link><pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</guid><description>&lt;p>30/11/2018 – Function has been updated to deal with named instances.&lt;/p>
&lt;p>Last week the Tiger Team released their Availability Group Failover Detection Utility which will provide root cause analysis on Cluster Logs, SQL Error Logs, and the Availability groups extended events logs. There is a &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy" target="_blank" rel="noopener"
>blog post here&lt;/a> and the tool can be downloaded from the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/tree/master/Always-On/FailoverDetection" target="_blank" rel="noopener"
>Tiger Team GitHub Repository&lt;/a>&lt;/p>
&lt;h3 id="a-bit-of-faffing">A Bit of Faffing*&lt;/h3>
&lt;p>It states on the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/blob/master/README.md" target="_blank" rel="noopener"
>readme&lt;/a> for the Tiger Team GitHub Repository.&lt;/p>
&lt;blockquote>
&lt;p>Repository for Tiger team for “as-is” solutions and tools/scripts that the team publishes.&lt;/p>
&lt;/blockquote>
&lt;p>The important words are “as-is” sometimes these tools need a bit of faffing some looking after!&lt;/p>
&lt;p>There is a pre-requisite and sometimes a little “fixing” that you need to do to get it to run correctly.&lt;/p>
&lt;p>First, install the “Microsoft Visual C++ Redistributable for Visual Studio 2017” &lt;a class="link" href="https://visualstudio.microsoft.com/downloads/" target="_blank" rel="noopener"
>from here.&lt;/a> On the download page, scroll down to the “Other Tools and Frameworks” section to download the redistributable (x64 version).&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/cdistributable.png"
loading="lazy"
alt="cdistributable.PNG"
>&lt;/p>
&lt;p>Then when you run &lt;code>FailoverDetection.exe&lt;/code> you may get strong name validation errors like.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png"
loading="lazy"
alt="strong name.png"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Unhandled Exception: System.IO.FileLoadException: Could not load file or assembly ‘Microsoft.Sq1Server.XEvent.Linq, Version=15.0.0.0, Culture=neutral, PublicKeyToken=89845dcd808cc91’ or one of it s dependencies. Strong name validation failed. (Exception from HRESULT; 0x8013141A) – – – &amp;gt;.Security.SecurityException: Strong name validation failed. (Exception from HRESULT: 0x8e13141A)&lt;br>
—End of inner exception stack trace  —&lt;br>
at FailoverDetector. XeventParser.LoadXevent(String xelFi1eName, String serverName)&lt;/p>
&lt;/blockquote>
&lt;p>Then you will need to run the sn.exe tool which is in the zip file. Use this syntax.&lt;/p>
&lt;p>&lt;code>.\sn.exe -Vr PATHTODLLFile&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png"
loading="lazy"
alt="stroingname fix.png"
>&lt;/a>&lt;/p>
&lt;p>I had to do it for two DLLs.&lt;/p>
&lt;p>NOTE – If you get an error like this when running sn.exe (or any executable) from PowerShell it means that you have missed the &lt;code>.\&lt;/code> (dot whack) in front of the executable name.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.pnghttps://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png"
loading="lazy"
alt="striong name fail.png"
>&lt;/a>&lt;/p>
&lt;p>* &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>Faffing&lt;/a> – Doing something that is a bit awkward &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>See Link&lt;/a> .&lt;/p>
&lt;h3 id="logs-required-for-the-tool">Logs required for the Tool&lt;/h3>
&lt;p>To run the Failover Detection Utility you need to gather the following information from each replica and place it in the specified data folder.&lt;/p>
&lt;ul>
&lt;li>SQL error logs&lt;/li>
&lt;li>Always On Availability Groups Extended Event Logs&lt;/li>
&lt;li>System Health Extended Event Logs&lt;/li>
&lt;li>System log&lt;/li>
&lt;li>Windows cluster log&lt;/li>
&lt;/ul>
&lt;p>Once you have gathered all of that data then you need to alter the configuration file for the executable.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Data Source Path&amp;#34;: &amp;#34;Path to Data File&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Health Level&amp;#34;: 3,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Instances&amp;#34;: \[
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica1&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica3&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="running-the-tool">Running The Tool&lt;/h3>
&lt;p>Once you have done that you can then run the Failover Detection Utility. You can double click the exe,&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png"
loading="lazy"
alt="run the exe.PNG"
>&lt;/a>&lt;/p>
&lt;p>or you can run it from the command line.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.pnghttps://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png"
loading="lazy"
alt="run the exe with powershell.PNG"
>&lt;/a>&lt;/p>
&lt;p>In both cases it won’t exit so when you see the Saving Results to JSON file, you can press enter (sometimes twice!).&lt;/p>
&lt;p>The results can be seen in the JSON file which will be stored in a Results directory in the directory that the the FailoverDetection.exe exists.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results.png"
loading="lazy"
alt="results.PNG"
>&lt;/a>&lt;/p>
&lt;p>You can also use some switches with the FailoverDetection utility.&lt;/p>
&lt;p>**–Analyze – **When “–Analyze” is specified as a parameter, the utility will load configuration file without copying log data. It assumes the log files have already been copied over. It does everything as default mode except copying log data. This option is useful if you already have the data in the local tool execution subdirectories and want to rerun the analysis.&lt;/p>
&lt;p>–&lt;strong>-Show&lt;/strong> -The utility after analyzing log data will display the results in the command console. Additionally, the results will be persisted to a JSON file in the results folder.&lt;/p>
&lt;p>They look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results-show.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results-show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results-show.png"
loading="lazy"
alt="results - show.PNG"
>&lt;/a>&lt;/p>
&lt;p>Again, you need to press enter for the details to come through. The results are still saved to the Results folder as json as well so you won’t lose them.&lt;/p>
&lt;h3 id="when-you-are-doing-something-more-than-once-">When You Are Doing Something More Than Once ….&lt;/h3>
&lt;p>Automate it 🙂&lt;/p>
&lt;p>When I saw the data that needed to be gathered for this tool, I quickly turned to PowerShell to enable me to easily gather the information. That has turned into a function which will&lt;/p>
&lt;ul>
&lt;li>Download and extract the zip file from the Tiger Team GitHub repository&lt;/li>
&lt;li>Identify all of the replicas for an Availability Group and dynamically create the configuration JSON file&lt;/li>
&lt;li>Gather all of the required log files and place them in a specified data folder&lt;/li>
&lt;li>Run the FailoverDetection.exe with any of the switches&lt;/li>
&lt;li>Includes -Verbose, -Confirm, -Whatif switches so that you can easily see what is happening, be prompted to confirm before actions or see what would happen if you ran the function&lt;/li>
&lt;li>You still need to press enter at the end though 🙁&lt;/li>
&lt;li>and you will still need to install the “Microsoft Visual C++ Redistributable for Visual Studio 2017” and runt he strong names tool if needed&lt;/li>
&lt;/ul>
&lt;p>This function requires PowerShell version 5, the failovercluster module and and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment – will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>&lt;code>. .\Invoke-SqlFailOverDetection.ps1&lt;/code>&lt;/p>
&lt;p>There are two .’s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>&lt;code>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/code>&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters.&lt;/p>
&lt;p>Let’s see it in action.&lt;/p>
&lt;p>First lets run with a -WhatIf switch which will show us what will happen without performing any state changing actions.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat -WhatIf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png"
loading="lazy"
alt="whatif.PNG"
>&lt;/a>&lt;/p>
&lt;p>So you can see that if we run it without the -WhatIf switch it will&lt;/p>
&lt;ul>
&lt;li>Create some directories&lt;/li>
&lt;li>Download the zip file from the repo&lt;/li>
&lt;li>Extract the zip file&lt;/li>
&lt;li>Copy the required logs from each of the replicas to the data folder&lt;/li>
&lt;li>Create the JSON configuration file&lt;/li>
&lt;li>Run the executable&lt;/li>
&lt;/ul>
&lt;p>NOTE : – I have limited the gathering of the system event log to the last 2 days to limit the amount of time spent dealing with a large system log. I gather all of the SQL Error logs in the Error log path as that works for the first scenario I wrote this for, your mileage may vary.&lt;/p>
&lt;p>So if we want to run the command we can remove the -WhatIf switch.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It can take a little while to run depending on the number of replicas, size of logs etc but once it has started running you can do other things.&lt;/p>
&lt;p>It will require being run as an account with permissions to all of the folders specified and Windows and SQL permissions on all of the replicas in the Availability Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run1.png"
loading="lazy"
alt="run1.PNG"
>&lt;/a>&lt;/p>
&lt;p>As you can see below it has gathered all of the results and placed them in the data folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png"
loading="lazy"
alt="datagathered.PNG"
>&lt;/a>&lt;/p>
&lt;p>The results can be found in the results folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png"
loading="lazy"
alt="resultsjson.PNG"
>&lt;/a>&lt;/p>
&lt;p>If I have already run the tool, I can use the Analyze switch to save gathering the data again. I also use the AlreadyDownloaded switch as I do not need to download the zip file again.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png"
loading="lazy"
alt="analyze.PNG"
>&lt;/a>&lt;/p>
&lt;p>and the results are again saved in the results folder.&lt;/p>
&lt;p>I can show the results on the screen as well as saving them as JSON with the Show parameter.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Show = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/show.png"
loading="lazy"
alt="show.PNG"
>&lt;/a>&lt;/p>
&lt;p>You will then need to press enter to get the next lot of results.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/more-show-results.png"
loading="lazy"
alt="more show results.PNG"
>&lt;/p>
&lt;h3 id="why-not-add-this-to-dbatools">Why Not Add This To dbatools?&lt;/h3>
&lt;p>I haven’t added this to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> (yet) because I wrote it in this way for a particular need and &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> requires support for PowerShell V3 . I have, however created an issue a&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools/issues/4601" target="_blank" rel="noopener"
>dded to this issue in the dbatools GitHub Repository&lt;/a> (as this is how you to start the process of adding things to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>) so hopefully we can get it in there soon as well – in which case I will come back and update this post.&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Getting the SQL Version from a backup using dbatools ………. on PowerShell Core</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-the-sql-version-from-a-backup-using-dbatools-.-on-powershell-core/</link><pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-the-sql-version-from-a-backup-using-dbatools-.-on-powershell-core/</guid><description>&lt;p>Following an upgrade to SQL Server the backup share had a number of backups, some from the old version and some from the newer version. I was asked if I had a script to be able to get the SQL Version from the backup file from all of the files in the backup share.&lt;/p>
&lt;p>With &lt;a class="link" href="http://dbatools,io" target="_blank" rel="noopener"
>dbatools&lt;/a> this was easy to accomplish with &lt;a class="link" href="https://docs.dbatools.io/#Read-DbaBackupHeader" target="_blank" rel="noopener"
>Read-DbaBackuoHeader&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$backupshare = &amp;#34;$share\\keep&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instance = &amp;#34;SQL0\\Mirror&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$information = foreach ($BackupFile in (Get-ChildItem $backupshare)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $FileName = @{Name = &amp;#39;FileName&amp;#39;; Expression = {$BackupFile.Name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Read-DbaBackupHeader -SqlInstance $Instance -Path $BackupFile.FullName | Select-Object $FileName, DatabaseName , CompatibilityLevel, SqlVersion
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$information | Format-Table
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/read-dbabackupheader.png"
loading="lazy"
alt="read-dbabackupheader.PNG"
>&lt;/p>
&lt;p>You can get more information about the backup using &lt;code>Read-DbaBackupHeader&lt;/code> and as it is PowerShell it is easy to put this information into any format that you wish, maybe into a database with &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDataTable" target="_blank" rel="noopener"
>&lt;code>Write-DbaDataTable&lt;/code>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>So I looked at &lt;a class="link" href="https://t.co/MUw7Dw7CRv" target="_blank" rel="noopener"
>https://t.co/MUw7Dw7CRv&lt;/a>&lt;/p>
&lt;p>I saw the words &amp;quot; Support for PS Core on Windows 🎉&amp;quot;&lt;/p>
&lt;p>I updated the module to 0.9.522 and ran a command and&lt;/p>
&lt;p>BOOOOOOOOOOOOOOOOOOM&lt;/p>
&lt;p>Good work fine &lt;a class="link" href="https://twitter.com/psdbatools?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@psdbatools&lt;/a> contirbutors and &lt;a class="link" href="https://twitter.com/cl?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@cl&lt;/a> &lt;a class="link" href="https://t.co/fzpSIju1Gx" target="_blank" rel="noopener"
>pic.twitter.com/fzpSIju1Gx&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1065955800823332864?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>November 23, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Support for PowerShell Core in dbatools is coming along very nicely. Following some hard work by the dbatools team and some PowerShell Community members like &lt;a class="link" href="https://twitter.com/IISResetMe" target="_blank" rel="noopener"
>Mathias Jessen&lt;/a> it is now possible to run a large number of dbatools commands in PowerShell Core running on Windows. There is still a little bit of work to do to get it working on Linux and Mac but I hear the team are working hard on that.&lt;/p>
&lt;p>So the code example you see above was running on Windows 10 using PowerShell 6.1.1 the current latest stable release. This is excellent news and congratulations to all those working hard to make this work&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/dbatoolscore.png"
loading="lazy"
alt="dbatoolscore.PNG"
>&lt;/p>
&lt;p>If you want to try PowerShell Core, you can follow the instructions&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-windows?view=powershell-6" target="_blank" rel="noopener"
>Here for Windows&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-linux?view=powershell-6" target="_blank" rel="noopener"
>Here for Linux&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-macos?view=powershell-6" target="_blank" rel="noopener"
>Or here for MacOs&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>PASS Summit, SQLTrain and My First US SQL Saturday</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</link><pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</guid><description>&lt;p>Next week is the week when I used to dread looking at Twitter and especially the &lt;a class="link" href="https://twitter.com/search?q=%23passsummit&amp;amp;src=typd" target="_blank" rel="noopener"
>#PASSsummit&lt;/a> hashtag, watching all of those folk having a great time in great sessions and doing all of the networking. Last year I was lucky enough to attend for the first time and take part in &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and CKs pre-con, this year I decided to add a US SQL Saturday to the list.&lt;/p>
&lt;p>I shall be attending &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Oregon in Portland&lt;/a> and presenting about &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>dbatools&lt;/a>. I am really lucky, my amazing Dad, now that he is retired, happily plays Dad’s taxi (still!) and frequently drives me to the airport when I go away on trips. This is the first time he has really gone Wow! When I asked why, it is because Portland is where &lt;a class="link" href="https://www.imdb.com/title/tt1830617/" target="_blank" rel="noopener"
>Grimm is filmed&lt;/a> and he has watched the whole series and loved it!&lt;/p>
&lt;p>I am looking forward to ticking off another thing on my list of things to do and presenting at a US SQL Saturday to add to 12 SQL Saturday cities in Europe and multiple other events around the world. If you are there come up and say hi.&lt;/p>
&lt;p>I shall also be room monitoring for the &lt;a class="link" href="https://www.sqlsaturday.com/808/Speakers/Details.aspx?name=amy-herold&amp;amp;spid=1767" target="_blank" rel="noopener"
>PowerShell for the DBA session&lt;/a> by Amy Herold &lt;a class="link" href="https://twitter.com/texasamy" target="_blank" rel="noopener"
>t&lt;/a> | &lt;a class="link" href="http://www.sqlkitten.com/" target="_blank" rel="noopener"
>b&lt;/a> There are still volunteer slots available to help, &lt;a class="link" href="https://www.sqlsaturday.com/808/Volunteers.aspx" target="_blank" rel="noopener"
>sign up here&lt;/a> if you are going. It is a lot of fun and an excellent way to give something back. SQL Saturdays take a lot of work to organise and organisers are always willing for some help. You will meet new people and have a lot of fun as well.&lt;/p>
&lt;p>To get to Seattle I am going on the SQL Train. A whole bunch of data platform folk travelling on a train together up to Seattle for PASS Summit. It looks like it will be a lot of fun 🙂&lt;/p>
&lt;p>Once in Seattle it is time for the week where others will not want to look at my twitter feed 🙂 A whole week at PASS Summit watching the sessions and networking (there may be beer involved) with our peers.&lt;/p>
&lt;p>My one piece of advice is please don’t hide away in your hotel room for all of the time that sessions are not on. I know that dealing with a large amount of people can be tough and you might need some me time ( I will ) but there are a lot of activities both loud and quieter where you will have the opportunity to meet up and make new friends and contacts which may really pay back further down the line and you will have fun too.&lt;/p>
&lt;p>On the Tuesday I am doing a pre-conference session Professional and Proficient PowerShell: From Writing Scripts to Developing Solutions. A whole day where I will be showing how to write PowerShell modules and all of the tips and tricks that I have learnt over the years.&lt;/p>
&lt;p>Wednesday sees me embracing my inner &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> – unfortunately he is unable to make PASS Summit this year, so I will be delivering the session dbatools Powershell Library – The Complete Introduction in his place in room 2AB. I shall try to do it in as cool and relaxed a way as he does (It probably wont work I will get too excited 🙂 )&lt;/p>
&lt;p>On Thursday I will be talking about &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> in room 6C which will also be streamed on PASSTv.&lt;/p>
&lt;p>In between all of that, I shall be attending some networking events, visiting sessions, hanging out with people new and old and walking down the corridors, so if you see me, stop me and say hi, I’d love to meet you 🙂&lt;br>
(note – just before my sessions I may be too nervous to properly have a conversation)&lt;/p>
&lt;p>Hopefully, I will meet you there and for the twitter folk stuck back in Europe I empathise 🙂&lt;/p></description></item><item><title>PASS Summit, SQLTrain and My First US SQL Saturday</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</link><pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</guid><description>&lt;p>Next week is the week when I used to dread looking at Twitter and especially the &lt;a class="link" href="https://twitter.com/search?q=%23passsummit&amp;amp;src=typd" target="_blank" rel="noopener"
>#PASSsummit&lt;/a> hashtag, watching all of those folk having a great time in great sessions and doing all of the networking. Last year I was lucky enough to attend for the first time and take part in &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and CKs pre-con, this year I decided to add a US SQL Saturday to the list.&lt;/p>
&lt;p>I shall be attending &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Oregon in Portland&lt;/a> and presenting about &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>dbatools&lt;/a>. I am really lucky, my amazing Dad, now that he is retired, happily plays Dad’s taxi (still!) and frequently drives me to the airport when I go away on trips. This is the first time he has really gone Wow! When I asked why, it is because Portland is where &lt;a class="link" href="https://www.imdb.com/title/tt1830617/" target="_blank" rel="noopener"
>Grimm is filmed&lt;/a> and he has watched the whole series and loved it!&lt;/p>
&lt;p>I am looking forward to ticking off another thing on my list of things to do and presenting at a US SQL Saturday to add to 12 SQL Saturday cities in Europe and multiple other events around the world. If you are there come up and say hi.&lt;/p>
&lt;p>I shall also be room monitoring for the &lt;a class="link" href="https://www.sqlsaturday.com/808/Speakers/Details.aspx?name=amy-herold&amp;amp;spid=1767" target="_blank" rel="noopener"
>PowerShell for the DBA session&lt;/a> by Amy Herold &lt;a class="link" href="https://twitter.com/texasamy" target="_blank" rel="noopener"
>t&lt;/a> | &lt;a class="link" href="http://www.sqlkitten.com/" target="_blank" rel="noopener"
>b&lt;/a> There are still volunteer slots available to help, &lt;a class="link" href="https://www.sqlsaturday.com/808/Volunteers.aspx" target="_blank" rel="noopener"
>sign up here&lt;/a> if you are going. It is a lot of fun and an excellent way to give something back. SQL Saturdays take a lot of work to organise and organisers are always willing for some help. You will meet new people and have a lot of fun as well.&lt;/p>
&lt;p>To get to Seattle I am going on the SQL Train. A whole bunch of data platform folk travelling on a train together up to Seattle for PASS Summit. It looks like it will be a lot of fun 🙂&lt;/p>
&lt;p>Once in Seattle it is time for the week where others will not want to look at my twitter feed 🙂 A whole week at PASS Summit watching the sessions and networking (there may be beer involved) with our peers.&lt;/p>
&lt;p>My one piece of advice is please don’t hide away in your hotel room for all of the time that sessions are not on. I know that dealing with a large amount of people can be tough and you might need some me time ( I will ) but there are a lot of activities both loud and quieter where you will have the opportunity to meet up and make new friends and contacts which may really pay back further down the line and you will have fun too.&lt;/p>
&lt;p>On the Tuesday I am doing a pre-conference session Professional and Proficient PowerShell: From Writing Scripts to Developing Solutions. A whole day where I will be showing how to write PowerShell modules and all of the tips and tricks that I have learnt over the years.&lt;/p>
&lt;p>Wednesday sees me embracing my inner &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> – unfortunately he is unable to make PASS Summit this year, so I will be delivering the session dbatools Powershell Library – The Complete Introduction in his place in room 2AB. I shall try to do it in as cool and relaxed a way as he does (It probably wont work I will get too excited 🙂 )&lt;/p>
&lt;p>On Thursday I will be talking about &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> in room 6C which will also be streamed on PASSTv.&lt;/p>
&lt;p>In between all of that, I shall be attending some networking events, visiting sessions, hanging out with people new and old and walking down the corridors, so if you see me, stop me and say hi, I’d love to meet you 🙂&lt;br>
(note – just before my sessions I may be too nervous to properly have a conversation)&lt;/p>
&lt;p>Hopefully, I will meet you there and for the twitter folk stuck back in Europe I empathise 🙂&lt;/p></description></item><item><title>Checking Trace Flags with dbachecks, online docs and PSPowerHour</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-trace-flags-with-dbachecks-online-docs-and-pspowerhour/</link><pubDate>Sat, 29 Sep 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-trace-flags-with-dbachecks-online-docs-and-pspowerhour/</guid><description>&lt;p>It’s been a few weeks since i have blogged as I have been busy with a lot of other things. One of which is preparing for &lt;a class="link" href="https://www.pass.org/summit/2018/Sessions/Details.aspxsid=80306" target="_blank" rel="noopener"
>my SQL Pass Summit pre-con&lt;/a> which has lead to me improving the CI/CD for &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> by adding auto-creation of online documentation, which you can find at &lt;a class="link" href="https://dbachecks.readthedocs.io" target="_blank" rel="noopener"
>https://dbachecks.readthedocs.io&lt;/a> or by running Get-Help with the -Online switch for any dbachecks command.&lt;/p>
&lt;p>Get-Help Invoke-DbcCheck -Online&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/01-online-help.png"
loading="lazy"
alt="01 - online help.png"
>&lt;/p>
&lt;p>I will blog about how dbachecks uses &lt;a class="link" href="https://azure.microsoft.com/en-us/services/devops/" target="_blank" rel="noopener"
>Azure DevOps&lt;/a> to do this another time&lt;/p>
&lt;h2 id="pspowerhour">PSPowerHour&lt;/h2>
&lt;p>The PowerShell community members &lt;a class="link" href="https://twitter.com/barbariankb" target="_blank" rel="noopener"
>Michael T Lombardi&lt;/a> and &lt;a class="link" href="http://twitter.com/psCookieMonster" target="_blank" rel="noopener"
>Warren Frame&lt;/a> have created &lt;a class="link" href="https://github.com/PSPowerHour/PSPowerHour" target="_blank" rel="noopener"
>PSPowerHour&lt;/a>. PSPowerHour is “like a virtual User Group, with a lightning-demo format, and room for non-PowerShell-specific content. Eight community members will give a demo each PowerHour.”&lt;/p>
&lt;p>&lt;a class="link" href="http://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy&lt;/a> blogged about the first one &lt;a class="link" href="https://dbatools.io/pspowerhour/" target="_blank" rel="noopener"
>on the dbatools blog&lt;/a>&lt;/p>
&lt;p>You can watch the videos on the &lt;a class="link" href="https://www.youtube.com/channel/UCtHKcGei3EjxBNYQCFZ3WNQ" target="_blank" rel="noopener"
>Youtube channel&lt;/a> and keep an eye out for more online &lt;a class="link" href="https://twitter.com/hashtag/PSPowerHoursrc=hash" target="_blank" rel="noopener"
>PSPowerHours via twitter&lt;/a> or &lt;a class="link" href="https://github.com/PSPowerHour/PSPowerHour" target="_blank" rel="noopener"
>the GitHub page&lt;/a>.&lt;/p>
&lt;p>While watching the first group of sessions &lt;a class="link" href="https://twitter.com/awickham" target="_blank" rel="noopener"
>Andrew Wickham&lt;/a> demonstrated using dbatools with trace flags and I thought that needs to be added to dbachecks so I created &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/issues/529" target="_blank" rel="noopener"
>an issue.&lt;/a> Anyone can do this to file improvements as well as bugs for members of the team to code.&lt;/p>
&lt;h2 id="trace-flags">Trace Flags&lt;/h2>
&lt;p>The previous release of dbachecks brought 2 new checks for traceflags. One for traceflags expected to be running and one for traceflags not expected to be running.&lt;/p>
&lt;p>You will need to have installed &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks" target="_blank" rel="noopener"
>dbachecks from the PowerShell Gallery&lt;/a> to do this. This can be done using&lt;/p>
&lt;p>Install-Module -Name dbachecks&lt;/p>
&lt;p>Once dbachecks is installed you can find the checks using&lt;/p>
&lt;p>Get-DBcCheck&lt;/p>
&lt;p>you can filter using the pattern parameter&lt;/p>
&lt;p>Get-DBcCheck -Pattern traceflag&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/02-get0dbcconfig.png"
loading="lazy"
alt="02 - get0dbcconfig.png"
>&lt;/p>
&lt;p>This will show you&lt;/p>
&lt;ul>
&lt;li>the UniqueTag which will enable you to run only that check if you wish&lt;/li>
&lt;li>AllTags which shows which tags will include that check&lt;/li>
&lt;li>Config will show you which configuration items can be set for this check&lt;/li>
&lt;/ul>
&lt;p>The trace flag checks require the app.sqlinstance configuration which is the list of SQL instances that the checks will run against. You can also specify the instances as a parameter for &lt;a class="link" href="https://dbachecks.readthedocs.io/en/latest/functions/Invoke-DbcCheck/" target="_blank" rel="noopener"
>Invoke-DbCheck&lt;/a> as well.&lt;/p>
&lt;p>The configuration for the expected traceflags is policy.traceflags.expected By default it is set to null. You can see what configuration it has using&lt;/p>
&lt;p>Get-DBcConfig policy.traceflags.expected&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/get-dbcconfig.png"
loading="lazy"
alt="get-dbcconfig.png"
>&lt;/p>
&lt;p>So if you want to check that there are no trace flags running, then you can run&lt;/p>
&lt;p>$instance = &amp;lsquo;sql0&amp;rsquo;
Set-DbcConfig -Name app.sqlinstance -Value $instance
Invoke-DbcCheck -Check TraceFlagsExpected&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/check-1.png"
loading="lazy"
alt="check 1.png"
>&lt;/p>
&lt;p>Maybe this instance is required to have &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_pfe_blog/2017/07/18/trace-flag-1117-growth-and-contention/" target="_blank" rel="noopener"
>trace flag 1117 enabled&lt;/a> so that &lt;a class="link" href="https://www.brentozar.com/archive/2014/06/trace-flags-1117-1118-tempdb-configuration/" target="_blank" rel="noopener"
>all files in a file group grow equally&lt;/a>, you can set the trace flag you expect to be running using&lt;/p>
&lt;p>Set-DbcConfig -Name policy.traceflags.expected -Value 1117&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-config.png"
loading="lazy"
alt="set config.png"
>&lt;/p>
&lt;p>Now you when you run the check it fails&lt;/p>
&lt;p>Invoke-DbcCheck -Check TraceFlagsExpecte&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/not-found.png"
loading="lazy"
alt="not found.png"
>&lt;/p>
&lt;p>and gives you the error message&lt;/p>
&lt;blockquote>
&lt;p> [-] Expected Trace Flags 1117 exist on sql0 593ms&lt;br>
Expected 1117 to be found in collection @(), because We expect that Trace Flag 1117 will be set on sql0, but it was not found.&lt;/p>
&lt;/blockquote>
&lt;p>So we have a failing test. We need to fix that. We can use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/p>
&lt;p>Enable-DbaTraceFlag -SqlInstance $instance -TraceFlag 1117&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-traceflag.png"
loading="lazy"
alt="set traceflag.png"
>&lt;/p>
&lt;p>This time when we run the check&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsExpected&lt;/code>&lt;/p>
&lt;p>it passes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/passed-test.png"
loading="lazy"
alt="passed test"
>&lt;/p>
&lt;p>If you just need to see what trace flags are enabled you can use&lt;/p>
&lt;p>&lt;code>Get-DbaTraceFlag -SqlInstance $instance&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/get-trace-flag.png"
loading="lazy"
alt="get trace flag.png"
>&lt;/p>
&lt;p>Reset the configuration for the expected trace flag to an empty array and then set the configuration for traceflags we do not expect to be running to 1117&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.traceflags.expected -Value @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.traceflags.notexpected -Value 1117
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-config-2.png"
loading="lazy"
alt="set config 2.png"
>&lt;/p>
&lt;p>and then run the trace flags not expected to be running check with&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsNotExpected&lt;/code>&lt;/p>
&lt;p>It will fail as 1117 is still running&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/not-expected-fail.png"
loading="lazy"
alt="not expected fail.png"
>&lt;/p>
&lt;p>and give the message&lt;/p>
&lt;blockquote>
&lt;p>[-] Expected Trace Flags 1117 to not exist on sql0 321ms&lt;br>
Expected 1117 to not be found in collection 1117, because We expect that Trace Flag 1117 will not be set on sql0, but it was found.&lt;/p>
&lt;/blockquote>
&lt;p>So to resolve this failing check we need to disable the trace flag and we can do that with dbatools using&lt;/p>
&lt;p>&lt;code>Disable-DbaTraceFlag -SqlInstance $instance -TraceFlag 1117&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/disable-trace-flag-1.png"
loading="lazy"
alt="disable trace flag"
>&lt;/p>
&lt;p>and now when we run the check&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsNotExpected&lt;/code>&lt;/p>
&lt;p>it passes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/passed-bnot-expected.png"
loading="lazy"
alt="passed bnot expected.png"
>&lt;/p>
&lt;p>The checks also work with multiple traceflags so you can set multiple values for trace flags that are not expexted to be running&lt;/p>
&lt;p>&lt;code>Set-DbcConfig -Name policy.traceflags.notexpected -Value 1117, 1118&lt;/code>&lt;/p>
&lt;p>and as we saw earlier, you can run both trace flag checks using&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlag&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/multi-checks.png"
loading="lazy"
alt="multi checks.png"
>&lt;/p>
&lt;p>You can use this or any of the 95 available checks to validate that your SQL instances, singular or your whole estate are as you expect them to be.&lt;/p></description></item><item><title>A PowerShell Pester Check for parsing SQL scripts</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-pester-check-for-parsing-sql-scripts/</link><pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-pester-check-for-parsing-sql-scripts/</guid><description>&lt;p>I like &lt;a class="link" href="https://blog.robsewell.com/?s=pester" target="_blank" rel="noopener"
>to write Pester checks&lt;/a> to make sure that all is as expected! This is just a quick post as much to help me remember this script 🙂&lt;/p>
&lt;p>This is a quick Pester test I wrote to ensure that some SQL Scripts in a directory would parse so there was some guarantee that they were valid T-SQL. It uses the SQLParser.dll and because it was using a build server without SQL Server I have to load the required DLLs from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module (Thank you dbatools 🙂 )&lt;/p>
&lt;p>It simply runs through all of the .sql files and runs the parser against them and checks the errors. In the case of failures it will output where it failed in the error message in the failed Pester result as well.&lt;/p>
&lt;p>You will need &lt;a class="link" href="http://dbatools.io/install" target="_blank" rel="noopener"
>dbatools module installed&lt;/a> on the instance and at least &lt;a class="link" href="https://github.com/pester/Pester/wiki/Installation-and-Updatehttps://github.com/pester/Pester/wiki/Installation-and-Update" target="_blank" rel="noopener"
>version 4 of the Pester module&lt;/a> as well&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Testing SQL&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Running Parser&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Load assembly
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Parserdll = (Get-ChildItem &amp;#39;C:\\Program Files\\WindowsPowerShell\\Modules\\dbatools&amp;#39; -Include Microsoft.SqlServer.Management.SqlParser.dll -Recurse)\[0\].FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \[System.Reflection.Assembly\]::LoadFile($Parserdll) | Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TraceDll = (Get-ChildItem &amp;#39;C:\\Program Files\\WindowsPowerShell\\Modules\\dbatools&amp;#39; -Include Microsoft.SqlServer.Diagnostics.Strace.dll -Recurse)\[0\].FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \[System.Reflection.Assembly\]::LoadFile($TraceDll) | Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ParseOptions = New-Object Microsoft.SqlServer.Management.SqlParser.Parser.ParseOptions
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ParseOptions.BatchSeparator = &amp;#39;GO&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $files = Get-ChildItem -Path $Env:Directory -Include *.sql -Recurse ## This variable is set as a Build Process Variable or put your path here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $files.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;$($Psitem.FullName) Should Parse SQL correctly&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $filename = $Psitem.FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $sql = Get-Content -LiteralPath &amp;#34;$fileName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Script = \[Microsoft.SqlServer.Management.SqlParser.Parser.Parser\]::Parse($SQL, $ParseOptions)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Script.Errors | Should -BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>dbachecks – Improved Descriptions</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-improved-descriptions/</link><pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-improved-descriptions/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/04-get-dbacheck-ogv.png" alt="Featured image of post dbachecks – Improved Descriptions" />&lt;p>With the latest release of &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.128" target="_blank" rel="noopener"
>dbachecks&lt;/a> we have added a new check for testing that foreign keys and constraints are trusted thanks to Cláudio Silva &lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/ClaudioESSilva" target="_blank" rel="noopener"
>t&lt;/a>&lt;/p>
&lt;p>To get the latest release you will need to run&lt;/p>
&lt;pre>&lt;code>Update-Module dbachecks
&lt;/code>&lt;/pre>
&lt;p>You should do this regularly as we release &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" >new improvements frequently&lt;/a>.&lt;/p>
&lt;p>We have also added better descriptions for the checks which was suggested by the same person who inspired the previous improvement &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/dbachecks-which-configuration-item-for-which-check/" >I blogged about here&lt;/a>&lt;/p>
&lt;p>Instead of the description just being the name of the check it is now more of a, well, a description really 🙂&lt;/p>
&lt;p>This has the added effect that it means that just running Get-DbcCheck in the command line will not fit all of the information on a normal screen&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-get-dbccheck.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-get-dbccheck.png"
loading="lazy"
alt="01 - get-dbccheck.png"
>&lt;/a>&lt;/p>
&lt;p>You can use the &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/format-table?view=powershell-5.1" target="_blank" rel="noopener"
>Format-Table&lt;/a> command (or its alias ft at the command line) and select the properties to display using&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | ft -Property UniqueTag, Description -Wrap
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-get-dbccheck-format-table.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-get-dbccheck-format-table.png"
loading="lazy"
alt="02 - get-dbccheck format table"
>&lt;/a>&lt;/p>
&lt;p>or you can use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/format-list?view=powershell-5.1" target="_blank" rel="noopener"
>Format-List &lt;/a>(or its alias fl at the command line)&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | fl
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-get-dbccheck-format-list.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-get-dbccheck-format-list.png"
loading="lazy"
alt="03 get-dbccheck format list.png"
>&lt;/a>&lt;/p>
&lt;p>Or you can use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/out-gridview?view=powershell-5.1" target="_blank" rel="noopener"
>Out-GridView&lt;/a> (or its alias ogv at the command line) (Incidentally, could you also thumbs up &lt;a class="link" href="https://github.com/PowerShell/PowerShell/issues/3957" target="_blank" rel="noopener"
>this issue on Github&lt;/a> to get Out-GridView functionality in PowerShell 6)&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | ogv
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-get-dbacheck-ogv.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-get-dbacheck-ogv.png"
loading="lazy"
alt="04 - get-dbacheck ogv"
>&lt;/a>&lt;/p>
&lt;p>Happy Validating !&lt;/p></description></item><item><title>Creating SQL Server Containers for versions 2012-2017</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-containers-for-versions-2012-2017/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-containers-for-versions-2012-2017/</guid><description>&lt;p>I am working on my &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> presentations for &lt;a class="link" href="http://www.sqlsaturday.com/735/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Finland&lt;/a>, &lt;a class="link" href="https://sqlday.pl/" target="_blank" rel="noopener"
>SQLDays&lt;/a>, &lt;a class="link" href="http://www.sqlsaturday.com/742/EventHome.aspx" target="_blank" rel="noopener"
>SQL Saturday Cork&lt;/a> and &lt;a class="link" href="https://sqlgrillen.de/" target="_blank" rel="noopener"
>SQLGrillen&lt;/a> I want to show the two modules running against a number of SQL Versions so I have installed&lt;/p>
&lt;ul>
&lt;li>2 Domain Controllers&lt;/li>
&lt;li>2 SQL 2017 instances on Windows 2016 with an Availability Group and WideWorldImporters database&lt;/li>
&lt;li>1 Windows 2016 jump box with all the programmes I need&lt;/li>
&lt;li>1 Windows 2016 with containers&lt;/li>
&lt;/ul>
&lt;p>using a VSTS build and this set of &lt;a class="link" href="https://github.com/SQLDBAWithABeard/ARMTemplates/tree/master/DeployAlwaysOn" target="_blank" rel="noopener"
>ARM templates and scripts&lt;/a>&lt;/p>
&lt;p>I wanted to create containers running SQL2017, SQL2016, SQL2014 and SQL2012 and restore versions of the AdventureWorks database onto each one.&lt;/p>
&lt;h2 id="move-docker-location">Move Docker Location&lt;/h2>
&lt;p>I redirected my docker location from my &lt;code>C:\&lt;/code> drive to my &lt;code>E:\&lt;/code> drive so I didnt run out of space. I did this by creating a &lt;code>daemon.json&lt;/code> file in &lt;code>C:\ProgramData\docker\config&lt;/code> and adding&lt;/p>
&lt;p>&lt;code>{&amp;quot;data-root&amp;quot;: &amp;quot;E:\containers&amp;quot;}&lt;/code>&lt;/p>
&lt;p>and restarting the docker service which created folders like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/01-folders.png"
loading="lazy"
alt="01 - folders.png"
>&lt;/p>
&lt;p>Then I ran&lt;/p>
&lt;p>&lt;code>docker volume create SQLBackups&lt;/code>&lt;/p>
&lt;p>to create a volume to hold the backups that I could mount on the containers&lt;/p>
&lt;h2 id="adventureworks-backups">AdventureWorks Backups&lt;/h2>
&lt;p>I downloaded &lt;a class="link" href="https://github.com/Microsoft/sql-server-samples/releases/tag/adventureworks" target="_blank" rel="noopener"
>all the AdventureWorks backups from GitHub&lt;/a> and copied them to &lt;code>E:\containers\volumes\sqlbackups\_data&lt;/code>&lt;/p>
&lt;p>&lt;code>Get-ChildItem $Home\Downloads\AdventureWorks* | Copy-Item -Destination E:\containers\volumes\sqlbackups\_data&lt;/code>&lt;/p>
&lt;h2 id="getting-the-images">Getting the Images&lt;/h2>
&lt;p>To download the &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server-windows-developer/" target="_blank" rel="noopener"
>SQL 2017 image from the DockerHub&lt;/a> I ran&lt;/p>
&lt;p>&lt;code>docker pull microsoft/mssql-server-windows-developer:latest&lt;/code>&lt;/p>
&lt;p>and waited for it to download and extract&lt;/p>
&lt;p>I also needed the images for other versions. My good friend Andrew Pruski &lt;a class="link" href="https://dbafromthecold.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has versions available for us to use on &lt;a class="link" href="https://hub.docker.com/u/dbafromthecold/" target="_blank" rel="noopener"
>his Docker Hub &lt;/a> so it is just a case of running&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2016dev:sp1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2014dev:sp2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2012dev:sp4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and waiting for those to download and extract (This can take a while!)&lt;/p>
&lt;h2 id="create-the-containers">Create the containers&lt;/h2>
&lt;p>Creating the containers is as easy as&lt;/p>
&lt;p>&lt;code>docker run -d -p ExposedPort:InternalPort --name NAME -v VolumeName:LocalFolder -e sa\_password=THEPASSWORD -e ACCEPT\_EULA=Y IMAGENAME&lt;/code>&lt;/p>
&lt;p>so all I needed to run to create 4 SQL containers one of each version was&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker run -d -p 15789:1433 --name 2017 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y microsoft/mssql-server-windows-developer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15788:1433 --name 2016 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2016dev:sp1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15787:1433 --name 2014 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2014dev:sp2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15786:1433 --name 2012 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2012dev:sp4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and just a shade over 12 seconds later I have 4 SQL instances ready for me 🙂&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/02-creating-containers.png"
loading="lazy"
alt="02 - creating containers.png"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/03-Containers-at-the-ready.png"
loading="lazy"
alt="03 - Containers at the ready.png"
>&lt;/p>
&lt;h2 id="storing-credentials">Storing Credentials&lt;/h2>
&lt;p>This is not something I would do in a Production environment but I save my credentials using this method that Jaap Brasser &lt;a class="link" href="http://www.jaapbrasser.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/jaap_brasser" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>shared here&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-Credential | Export-Clixml -Path $HOME\Documents\sa.cred&lt;/code>&lt;/p>
&lt;p>which means that I can get the credentials in my PowerShell session (as long as it is the same user that created the file) using&lt;/p>
&lt;p>&lt;code>$cred = Import-Clixml $HOME\Documents\sa.cred&lt;/code>&lt;/p>
&lt;h2 id="restoring-the-databases">Restoring the databases&lt;/h2>
&lt;p>I restored all of the AdventureWorks databases that each instance will support onto each instance, so 2017 has all of them whilst 2012 only has the 2012 versions.&lt;/p>
&lt;p>First I needed to get the filenames of the backup files into a variable&lt;/p>
&lt;p>&lt;code>$filenames = (Get-ChildItem '\bearddockerhost\e$\containers\volumes\sqlbackups\_data').Name&lt;/code>&lt;/p>
&lt;p>and the container connection strings, which are the hostname and the port number&lt;/p>
&lt;p>&lt;code>$containers = 'bearddockerhost,15789', 'bearddockerhost,15788', 'bearddockerhost,15787', 'bearddockerhost,15786'&lt;/code>&lt;/p>
&lt;p>then I can restore the databases using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> using a switch statement on the version which I get with the NameLevel property of &lt;code>Get-DbaSqlBuildReference&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$cred = Import-Clixml $HOME\Documents\sa.cred
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$containers = &amp;#39;bearddockerhost,15789&amp;#39;, &amp;#39;bearddockerhost,15788&amp;#39;, &amp;#39;bearddockerhost,15787&amp;#39;, &amp;#39;bearddockerhost,15786&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$filenames = (Get-ChildItem &amp;#39;\bearddockerhost\e$\containers\volumes\sqlbackups\_data&amp;#39;).Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$containers.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Container = $Psitem
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $NameLevel = (Get-DbaSqlBuildReference-SqlInstance $Container-SqlCredential $cred).NameLevel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> switch ($NameLevel) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2017 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path C:\sqlbackups\ -useDestinationDefaultDirectories -WithReplace |Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2017&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2016 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -notlike &amp;#39;\*2017\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2016&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2014 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -notlike &amp;#39;\*2017\*&amp;#39; -and $Psitem -notlike &amp;#39;\*2016\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2014&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2012 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -like &amp;#39;\*2012\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2012&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Default {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I need to create the file paths for each backup file by getting the correct backups and appending the names to &lt;code>C:\SQLBackups&lt;/code> which is where the volume is mounted inside the container&lt;/p>
&lt;p>As Get-DbaDatabase gives the container ID as the Computer Name I have highlighted each container below&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/04-databases.png"
loading="lazy"
alt="04 - databases.png"
>&lt;/p>
&lt;p>That is how easy it is to create a number of SQL containers of differing versions for your presentations or exploring needs&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Visual Studio Code Live Sharing Set-Up</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/visual-studio-code-live-sharing-set-up/</link><pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/visual-studio-code-live-sharing-set-up/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/07-sign-in.png" alt="Featured image of post Visual Studio Code Live Sharing Set-Up" />&lt;p>There was an &lt;a class="link" href="https://code.visualstudio.com/blogs/2018/05/07/live-share-public-preview" target="_blank" rel="noopener"
>announcement on the Visual Studio Code blog&lt;/a> about the public preview of Live Share. This enables you to easily collaborate on code by securely sharing your coding session.&lt;/p>
&lt;p>It is remarkably easy to set up 🙂&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Open Visual Studio Code, open the Extensions side bar (CTRL + SHIFT + X)&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-open-extensions.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-open-extensions.png"
loading="lazy"
alt="01 - open extensions"
>&lt;/a>&lt;/p>
&lt;p>Search for Live Share&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-search.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-search.png"
loading="lazy"
alt="02 - search.png"
>&lt;/a>&lt;/p>
&lt;p>Click Install and then reload when it has done&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-reload.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-reload.png"
loading="lazy"
alt="03 - reload.png"
>&lt;/a>&lt;/p>
&lt;p>You will notice in the bottom bar it will say finishing the installation and if you open the terminal (CTRL + ‘) and click on Output and change the drop down on the right to Visual Studio Live Share you can see what it is doing&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-finishing-installation.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-finishing-installation.png"
loading="lazy"
alt="04 - finishing installation.png"
>&lt;/a>&lt;/p>
&lt;p>It is installing the dependancies as shown below&lt;/p>
&lt;blockquote>
&lt;p>[Client I] Installing dependencies for Live Share…&lt;/p>
&lt;p>[Client I] Downloading package ‘.NET Core Runtime 2.0.5 for win7-x86’&lt;/p>
&lt;p>[Client I] Download complete.&lt;/p>
&lt;p>[Client I] Downloading package ‘OmniSharp for Windows (.NET 4.6)’&lt;/p>
&lt;p>[Client I] Download complete.&lt;/p>
&lt;p>[Client I] Installing package ‘.NET Core Runtime 2.0.5 for win7-x86’&lt;/p>
&lt;p>[Client V] Extracted packed files&lt;/p>
&lt;p>[Client I] Validated extracted files.&lt;/p>
&lt;p>[Client I] Moved and validated extracted files.&lt;/p>
&lt;p>[Client I] Finished installing.&lt;/p>
&lt;p>[Client I] Installing package ‘OmniSharp for Windows (.NET 4.6)’&lt;/p>
&lt;p>[Client V] Extracted packed files&lt;/p>
&lt;p>[Client I] Validated extracted files.&lt;/p>
&lt;p>[Client I] Finished installing.&lt;/p>
&lt;p>[Client I] No workspace id found.&lt;/p>
&lt;/blockquote>
&lt;p>Incidentally, this will also show the location of the log file&lt;/p>
&lt;p>You will see in the bottom bar it will now say sign in&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/06-sign-in.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/06-sign-in.png"
loading="lazy"
alt="06 - sign in.png"
>&lt;/a>&lt;/p>
&lt;p>Clicking that will open a browser and give you a choice of accounts to sign in with, your GitHub or your Microsoft ID&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-sign-in.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-sign-in.png"
loading="lazy"
alt="07 - sign in.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the one that you want to use and do your 2FA.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-2FA.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-2FA.png"
loading="lazy"
alt="08 - 2FA.png"
>&lt;/a>&lt;/p>
&lt;p>You do have 2FA on your Microsoft and GitHub (and all the other services)? If not go and set it up now – &lt;a class="link" href="https://account.live.com/proofs/manage/additional?mkt=en-US&amp;amp;refd=account.microsoft.com&amp;amp;refp=security" target="_blank" rel="noopener"
>here for Microsoft&lt;/a> and &lt;a class="link" href="https://github.com/settings/security" target="_blank" rel="noopener"
>here for GitHub &lt;/a>&lt;/p>
&lt;p>Once you have signed in you will get this notification which you can close&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-close-this-notification.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-close-this-notification.png"
loading="lazy"
alt="09 - close this notification.png"
>&lt;/a>&lt;/p>
&lt;p>The icon in the bottom will change and show your account name and if you click it it will open the menu&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-sharing-menu.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-sharing-menu.png"
loading="lazy"
alt="09 - sharing menu.png"
>&lt;/a>&lt;/p>
&lt;h2 id="sharing">Sharing&lt;/h2>
&lt;p>To share your session you click on the Share icon in the bottom bar or the Start collaboration session in the menu above. The first time you do this there will be a pop-up as shown&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-firewall-popup.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-firewall-popup.png"
loading="lazy"
alt="05 - firewall popup.png"
>&lt;/a>&lt;/p>
&lt;p>You can decide which way you (or your organisation) want to share. I chose to accept the firewall exception.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/10-invite-link.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/10-invite-link.png"
loading="lazy"
alt="10 - invite link.png"
>&lt;/a>&lt;/p>
&lt;p>The invite link is in your clipboard ready to share with your friends and colleagues (other open source contributors ??)&lt;/p>
&lt;p>They can either open the link in a browser&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/11-join-via-browser.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/11-join-via-browser.png"
loading="lazy"
alt="11 - join via browser.png"
>&lt;/a>&lt;/p>
&lt;p>or by using the Join Collaboration Session in the menu in VS Code&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/12-Join-via-VS-COde.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/12-Join-via-VS-COde.png"
loading="lazy"
alt="12 - Join via VS COde.png"
>&lt;/a>&lt;/p>
&lt;p>Once they do the sharer will get a notification&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/13-notification-of-sharing.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/13-notification-of-sharing.png"
loading="lazy"
alt="13 - notification of sharing.png"
>&lt;/a>&lt;/p>
&lt;p>and the person who has joined will have the same workspace opened in their Visual Studio Code&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/14-shared-workspace.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/14-shared-workspace.png"
loading="lazy"
alt="14 -shared workspace.png"
>&lt;/a>&lt;/p>
&lt;p>You can then collaborate on your code and share the session. In the video below the left hand side is running in my jump box in Azure and the right hand side on my laptop and you can see that if you highlight code in one side it is shown in the other and if you alter it in one side it is changed in the other. I also saved that file in the joined session rather than from the session that initialised the sharing and it then saved in both sessions 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So that shows how easy it is to install and to use. You can dive deeper &lt;a class="link" href="https://docs.microsoft.com/en-us/visualstudio/liveshare/" target="_blank" rel="noopener"
>using the documentation&lt;/a>.&lt;/p>
&lt;p>Happy Collaborating 🙂&lt;/p></description></item><item><title>Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png" alt="Featured image of post Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS" />&lt;p>At the fabulous &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference EU&lt;/a> I presented about Continuous Delivery to the PowerShell Gallery with VSTS and explained how we use VSTS to enable CD for &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>. We even released a new version during the session 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So how do we achieve this?&lt;/p>
&lt;p>We have a few steps&lt;/p>
&lt;ul>
&lt;li>Create a project and link to our GitHub&lt;/li>
&lt;li>Run unit uests with Pester to make sure that our code is doing what we expect.&lt;/li>
&lt;li>Update our module version and commit the change to GitHub&lt;/li>
&lt;li>Sign our code with a code signing certificate&lt;/li>
&lt;li>Publish to the PowerShell Gallery&lt;/li>
&lt;/ul>
&lt;h2 id="create-project-and-link-to-github">Create Project and link to GitHub&lt;/h2>
&lt;p>First you need to create a VSTS project by going to &lt;a class="link" href="https://www.visualstudio.com/" target="_blank" rel="noopener"
>https://www.visualstudio.com/&lt;/a> This is free for up to 5 users with 1 concurrent CI/CD queue limited to a maximum of 60 minutes run time which should be more than enough for your PowerShell module.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-sign-up-1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-sign-up-1.png"
loading="lazy"
alt="01 - sign up.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Get Started for free under Visual Studio Team Services and fill in the required information. Then on the front page click new project&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-New-Project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-New-Project.png"
loading="lazy"
alt="02 - New Project.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in the details and click create&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-create-project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-create-project.png"
loading="lazy"
alt="03 - create project.png"
>&lt;/a>&lt;/p>
&lt;p>Click on builds and then new definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-builds.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-builds.png"
loading="lazy"
alt="04- builds.png"
>&lt;/a>&lt;/p>
&lt;p>next you need to link your project to your GitHub (or other source control providers) repository&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-github-auth.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-github-auth.png"
loading="lazy"
alt="05 - github auth.png"
>&lt;/a>&lt;/p>
&lt;p>You can either authorise with OAuth or you can &lt;a class="link" href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/" target="_blank" rel="noopener"
>provide a PAT token following the instructions here&lt;/a>. Once that is complete choose your repo. Save the PAT as you will need it later in the process!&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/06-choose-repo.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/06-choose-repo.png"
loading="lazy"
alt="06 - choose repo.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the branch that you want this build definition to run against.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-branch.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-branch.png"
loading="lazy"
alt="07 branch.png"
>&lt;/a>&lt;/p>
&lt;p>I chose to run the Unit Tests when a PR was merged into the development branch. I will then create another build definition for the master branch to sign the code and update module version. This enables us to push several PRs into the development branch and create a single release for the gallery.&lt;/p>
&lt;p>Then I start with an empty process&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-empty-process.png"
loading="lazy"
alt="08 - empty process.png"
>&lt;/a>&lt;/p>
&lt;p>and give it a suitable name&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-name-it.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-name-it.png"
loading="lazy"
alt="09 - name it.png"
>&lt;/a>&lt;/p>
&lt;p>i chose the hosted queue but you can download an agent to your build server if you need to do more or your integration tests require access to other resources not available on the hosted agent.&lt;/p>
&lt;h2 id="run-unit-tests-with-pester">Run Unit Tests with Pester&lt;/h2>
&lt;p>We have a number of Unit tests in our &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/tree/development/tests" target="_blank" rel="noopener"
>tests folder in dbachecks&lt;/a> so we want to run them to ensure that everything is as it should be and the new code will not break existing functionality (and for dbachecks the &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/using-the-ast-in-pester-for-dbachecks/" >format of the PowerBi&lt;/a>)&lt;/p>
&lt;p>You can use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=richardfennellBM.BM-VSTS-PesterRunner-Task" target="_blank" rel="noopener"
>Pester Test Runner Build Task&lt;/a> from the folk at &lt;a class="link" href="http://blackmarble.com/" target="_blank" rel="noopener"
>Black Marble&lt;/a> by clicking on the + sign next to Phase 1 and searching for Pester&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/10-Pester-task-runner.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/10-Pester-task-runner.png"
loading="lazy"
alt="10 - Pester task runner.png"
>&lt;/a>&lt;/p>
&lt;p>You will need to click Get It Free to install it and then click add to add the task to your build definition. You can pretty much leave it as default if you wish and Pester will run all of the *.Tests.ps1 files that it finds in the directory where it downloads the GitHub repo which is referred to using the variable $(Build.SourcesDirectory). It will then output the results to a json file called Test-Pester.XML ready for publishing.&lt;/p>
&lt;p>However, as dbachecks has a number of dependent modules, this task was not suitable. I spoke with Chris Gardner  &lt;a class="link" href="https://chrislgardner.github.io/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/HalbaradKenafin" target="_blank" rel="noopener"
>t&lt;/a>  from Black Marble at the PowerShell Conference and he says that this can be resolved so look out for the update. Chris is a great guy and always willing to help, you can often find him in the &lt;a class="link" href="http://slack.poshcode.org/" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a> answering questions and helping people&lt;/p>
&lt;p>But as you can use PowerShell in VSTS tasks, this is not a problem although you need to write your PowerShell using try catch to make sure that your task fails when your PowerShell errors. This is the code I use to install the modules&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;&lt;/p>
&lt;p># Set location to module home path in artifacts directory
try {
Set-Location $(Build.SourcesDirectory)
Get-ChildItem
}
catch {
Write-Error &amp;ldquo;Failed to set location&amp;rdquo;&lt;/p>
&lt;p>}&lt;/p>
&lt;p># Get the Module versions
Install-Module Configuration -Scope CurrentUser -Force
$Modules = Get-ManifestValue -Path .\dbachecks.psd1 -PropertyName RequiredModules&lt;/p>
&lt;p>$PesterVersion = $Modules.Where{$&lt;em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;Pester&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$PSFrameworkVersion = $Modules.Where{$&lt;/em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;PSFramework&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$dbatoolsVersion = $Modules.Where{$_.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;dbatools&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)&lt;/p>
&lt;p># Install Pester
try {
Write-Output &amp;ldquo;Installing Pester&amp;rdquo;
Install-Module Pester -RequiredVersion $PesterVersion -Scope CurrentUser -Force -SkipPublisherCheck
Write-Output &amp;ldquo;Installed Pester&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install Pester $($_)&amp;rdquo;
}
# Install dbatools
try {
Write-Output &amp;ldquo;Installing PSFramework&amp;rdquo;
Install-Module PSFramework -RequiredVersion $PsFrameworkVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed PSFramework&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install PSFramework $($_)&amp;rdquo;
}
# Install dbachecks
try {
Write-Output &amp;ldquo;Installing dbatools&amp;rdquo;
Install-Module dbatools -RequiredVersion $dbatoolsVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed dbatools&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbatools $($_)&amp;rdquo;
}&lt;/p>
&lt;p># Add current folder to PSModulePath
try {
Write-Output &amp;ldquo;Adding local folder to PSModulePath&amp;rdquo;
$ENV:PSModulePath = $ENV:PSModulePath + &amp;ldquo;;$pwd&amp;rdquo;
Write-Output &amp;ldquo;Added local folder to PSModulePath&amp;rdquo; &lt;br>
$ENV:PSModulePath.Split(&amp;rsquo;;&amp;rsquo;)
}
catch {
Write-Error &amp;ldquo;Failed to add $pwd to PSModulePAth - $_&amp;rdquo;
}&lt;/p>
&lt;p>I use the &lt;a class="link" href="https://github.com/PoshCode/Configuration" target="_blank" rel="noopener"
>Configuration module&lt;/a> from &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>Joel Bennett&lt;/a> to get the required module versions for the required modules and then add the path to $ENV:PSModulePath so that the modules will be imported. I think this is because the modules did not import correctly without it.&lt;/p>
&lt;p>Once I have the modules I can then run Pester as follows&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Installing dbachecks&amp;rdquo;
Import-Module .\dbachecks.psd1
Write-Output &amp;ldquo;Installed dbachecks&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbachecks $($_)&amp;rdquo;
}
$TestResults = Invoke-Pester .\tests -ExcludeTag Integration,IntegrationTests -Show None -OutputFile $(Build.SourcesDirectory)\Test-Pester.XML -OutputFormat NUnitXml -PassThru&lt;/p>
&lt;p>if ($TestResults.failedCount -ne 0) {
Write-Error &amp;ldquo;Pester returned errors&amp;rdquo;
}&lt;/p>
&lt;p>As you can see I import the dbachecks module from the local folder, run Invoke-Pester and output the results to an XML file and check that there are no failing tests.&lt;/p>
&lt;p>Whether you use the task or PowerShell the next step is to Publish the test results so that they are displayed in the build results in VSTS.&lt;/p>
&lt;p>Click on the + sign next to Phase 1 and search for Publish&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/12-publish-test-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/12-publish-test-results.png"
loading="lazy"
alt="12 - publish test results.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the Publish Test Results task and leave everything as default unless you have renamed the xml file. This means that on the summary page you will see some test results&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/13-Test-on-sumary-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/13-Test-on-sumary-page.png"
loading="lazy"
alt="13 - Test on sumary page.png"
>&lt;/a>&lt;/p>
&lt;p>and on the tests tab you can see more detailed information and drill down into the tests&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/14-detailed-test-report.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/14-detailed-test-report.png"
loading="lazy"
alt="14 - detailed test report.png"
>&lt;/a>&lt;/p>
&lt;h2 id="trigger">Trigger&lt;/h2>
&lt;p>The next step is to trigger a build when a commit is pushed to the development branch. Click on Triggers and tick enable continuous integration&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/15-Trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/15-Trigger.png"
loading="lazy"
alt="15 Trigger.png"
>&lt;/a>&lt;/p>
&lt;h2 id="saving-the-build-definition">Saving the Build Definition&lt;/h2>
&lt;p>I would normally save the build definition regularly and ensure that there is a good message in the comment. I always tell clients that this is like a commit message for your build process so that you can see the history of the changes for the build definition.&lt;/p>
&lt;p>You can see the history on the edit tab of the build definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/16-build-history.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/16-build-history.png"
loading="lazy"
alt="16 - build history.png"
>&lt;/a>&lt;/p>
&lt;p>If you want to compare or revert the build definition this can be done using the hamburger menu as shown below.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/17-build-history-compare-revert.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/17-build-history-compare-revert.png"
loading="lazy"
alt="17 - build history compare revert.png"
>&lt;/a>&lt;/p>
&lt;h2 id="update-the-module-version">Update the Module Version&lt;/h2>
&lt;p>Now we need to create a build definition for the master branch to update the module version and sign the code ready for publishing to the PowerShell Gallery when we commit or merge to master&lt;/p>
&lt;p>Create a new build definition as above but this time choose the master branch&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/18-master-build.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/18-master-build.png"
loading="lazy"
alt="18 - master build.png"
>&lt;/a>&lt;/p>
&lt;p>Again choose an empty process and name it sensibly, click the + sign next to Phase 1 and search for PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/19-PowerShell-task.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/19-PowerShell-task.png"
loading="lazy"
alt="19 - PowerShell task.png"
>&lt;/a>&lt;/p>
&lt;p>I change the version to 2 and use this code. Note that the commit message has ***NO_CI*** in it. Putting this in a commit message tells VSTS not to trigger a build for this commit.&lt;/p>
&lt;p>$manifest = Import-PowerShellDataFile .\dbachecks.psd1
[version]$version = $Manifest.ModuleVersion
Write-Output &amp;ldquo;Old Version - $Version&amp;rdquo;
# Add one to the build of the version number
[version]$NewVersion = &amp;ldquo;{0}.{1}.{2}&amp;rdquo; -f $Version.Major, $Version.Minor, ($Version.Build + 1)
Write-Output &amp;ldquo;New Version - $NewVersion&amp;rdquo;
# Update the manifest file
try {
Write-Output &amp;ldquo;Updating the Module Version to $NewVersion&amp;rdquo;
$path = &amp;ldquo;$pwd\dbachecks.psd1&amp;rdquo;
(Get-Content .\dbachecks.psd1) -replace $version, $NewVersion | Set-Content .\dbachecks.psd1 -Encoding string
Write-Output &amp;ldquo;Updated the Module Version to $NewVersion&amp;rdquo;
}
catch {
Write-Error &amp;ldquo;Failed to update the Module Version - $_&amp;rdquo;
}&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Updating GitHub&amp;rdquo;
git config user.email &amp;ldquo;&lt;a class="link" href="mailto:mrrobsewell@outlook.com" >mrrobsewell@outlook.com&lt;/a>&amp;rdquo;
git config user.name &amp;ldquo;SQLDBAWithABeard&amp;rdquo;
git add .\dbachecks.psd1
git commit -m &amp;ldquo;Updated Version Number to $NewVersion ***NO_CI***&amp;rdquo;&lt;/p>
&lt;p>git push https://$(RobsGitHubPAT)@github.com/sqlcollaborative/dbachecks.git HEAD:master
Write-Output &amp;ldquo;Updated GitHub &amp;quot;&lt;/p>
&lt;p>}
catch {
$_ | Fl -Force
Write-Output &amp;ldquo;Failed to update GitHub&amp;rdquo;
}&lt;/p>
&lt;p>I use Get-Content Set-Content as I had errors with the Update-ModuleManifest but Adam Murray &lt;a class="link" href="https://github.com/muzzar78" target="_blank" rel="noopener"
>g&lt;/a> | &lt;a class="link" href="https://twitter.com/muzzar78" target="_blank" rel="noopener"
>t&lt;/a> uses this code to update the version using the BuildID from VSTS&lt;/p>
&lt;p>$newVersion = New-Object version -ArgumentList 1, 0, 0, $env:BUILD_BUILDID
$Public = @(Get-ChildItem -Path $ModulePath\Public\*.ps1)
$Functions = $public.basename
Update-ModuleManifest -Path $ModulePath\$ModuleName.psd1 -ModuleVersion $newVersion -FunctionsToExport $Functions&lt;/p>
&lt;p>You can commit your change by adding your PAT token as a variable under the variables tab. Don’t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/20-variables.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/20-variables.png"
loading="lazy"
alt="20 - variables.png"
>&lt;/a>&lt;/p>
&lt;h2 id="sign-the-code-with-a-certificate">Sign the code with a certificate&lt;/h2>
&lt;p>The SQL Collaborative uses a code signing certificate from &lt;a class="link" href="https://digicert.com/" target="_blank" rel="noopener"
>DigiCert&lt;/a> who allow MVPs to use one for free to sign their code for open source projects, Thank You. We had to upload the certificate to the secure files store in the VSTS library. Click on library, secure files and the blue +Secure File button&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/21-secure-file-store.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/21-secure-file-store.png"
loading="lazy"
alt="21 - secure file store.png"
>&lt;/a>&lt;/p>
&lt;p>You also need to add the password as a variable under the variables tab as above. Again don’t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>Then you need to add a task to download the secure file. Click on the + sign next to Phase 1 and search for secure&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/22-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/22-download-secure-file.png"
loading="lazy"
alt="22 download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>choose the file from the drop down&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/23-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/23-download-secure-file.png"
loading="lazy"
alt="23 - download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>Next we need to import the certificate and sign the code. I use a PowerShell task for this with the following code&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;
# read in the certificate from a pre-existing PFX file
# I have checked this with @IISResetMe and this does not go in the store only memory
$cert = [System.Security.Cryptography.X509Certificates.X509Certificate2]::new(&amp;quot;$(Agent.WorkFolder)\_temp\dbatools-code-signing-cert.pfx&amp;rdquo;,&amp;quot;$(CertPassword)&amp;quot;)&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Signing Files&amp;rdquo;
# find all scripts in your module&amp;hellip;
Get-ChildItem -Filter *.ps1 -Include *.ps1 -Recurse -ErrorAction SilentlyContinue |
# &amp;hellip;that do not have a signature yet&amp;hellip;
Where-Object {
($_ | Get-AuthenticodeSignature).Status -eq &amp;lsquo;NotSigned&amp;rsquo;
} |
# and apply one
# (note that we added -WhatIf so no signing occurs. Remove this only if you
# really want to add digital signatures!)
Set-AuthenticodeSignature -Certificate $cert
Write-Output &amp;ldquo;Signed Files&amp;rdquo;
}
catch {
$_ | Format-List -Force
Write-Error &amp;ldquo;Failed to sign scripts&amp;rdquo;
}&lt;/p>
&lt;p>which will import the certificate into memory and sign all of the scripts in the module folder.&lt;/p>
&lt;h2 id="publish-your-artifact">Publish your artifact&lt;/h2>
&lt;p>The last step of the master branch build publishes the artifact (your signed module) to VSTS ready for the release task. Again, click the + sign next to Phase one and choose the Publish Artifact task not the deprecated copy and publish artifact task and give the artifact a useful name&lt;/p>
&lt;h2 id="24---publish-artifactpngassetsuploads20180524-publish-artifactpngassetsuploads20180524-publish-artifactpng">&lt;a class="link" href="assets/uploads/2018/05/24-publish-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/24-publish-artifact.png"
loading="lazy"
alt="24 - publish artifact.png"
>&lt;/a>&lt;/h2>
&lt;p>Don’t forget to set the trigger for the master build as well following the same steps as the development build above&lt;/p>
&lt;h2 id="publish-to-the-powershell-gallery">Publish to the PowerShell Gallery&lt;/h2>
&lt;p>Next we create a release to trigger when there is an artifact ready and publish to the PowerShell Gallery.&lt;/p>
&lt;p>Click the Releases tab and New Definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/25-Reelase-creation.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/25-Reelase-creation.png"
loading="lazy"
alt="25 - Reelase creation"
>&lt;/a>&lt;/p>
&lt;p>Choose an empty process and name the release definition appropriately&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/26-Release-name-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/26-Release-name-empty-process.png"
loading="lazy"
alt="26 Release name empty process.png"
>&lt;/a>&lt;/p>
&lt;p>Now click on the artifact and choose the master build definition. If you have not run a build you will get an error like below but dont worry click add.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/27-add-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/27-add-artifact.png"
loading="lazy"
alt="27 - add artifact.png"
>&lt;/a>&lt;/p>
&lt;p>Click on the lightning bolt next to the artifact to open the continuous deployment trigger&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Choose-lightning-bolt.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Choose-lightning-bolt.png"
loading="lazy"
alt="28 - Choose lightning bolt"
>&lt;/a>&lt;/p>
&lt;p>and turn on Continuous Deployment so that when an artifact has been created with an updated module version and signed code it is published to the gallery&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Continuous-deployment-trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Continuous-deployment-trigger.png"
loading="lazy"
alt="28 - Continuous deployment trigger"
>&lt;/a>&lt;/p>
&lt;p>Next, click on the environment and name it appropriately and then click on the + sign next to Agent Phase and choose a PowerShell step&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/29-PowerShell-Publish-step.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/29-PowerShell-Publish-step.png"
loading="lazy"
alt="29 - PowerShell Publish step"
>&lt;/a>&lt;/p>
&lt;p>You may wonder why I dont choose the PowerShell Gallery Packager task. There are two reasons. First I need to install the required modules for dbachecks (dbatools, PSFramework, Pester) prior to publishing and second it appears that the API Key is stored in plain text&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png"
loading="lazy"
alt="30 - PowerShell Gallery Publisher"
>&lt;/a>&lt;/p>
&lt;p>I save my API key for the PowerShell Gallery as a variable again making sure to tick the padlock to make it a secret&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/31-API-Key-variable.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/31-API-Key-variable.png"
loading="lazy"
alt="31 - API Key variable.png"
>&lt;/a>&lt;/p>
&lt;p>and then use the following code to install the required modules and publish the module to the gallery&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser -Force
Install-Module Pester -Scope CurrentUser -SkipPublisherCheck -Force
Install-Module PSFramework -Scope CurrentUser -Force&lt;/p>
&lt;p>Publish-Module -Path &amp;ldquo;$(System.DefaultWorkingDirectory)/Master - Version Update, Signing and Publish Artifact/dbachecks&amp;rdquo; -NuGetApiKey &amp;ldquo;$(GalleryApiKey)&amp;rdquo;&lt;/p>
&lt;p>Thats it 🙂&lt;/p>
&lt;p>Now we have a process that will automatically run our Pester tests when we commit or merge to the development branch and then update our module version number and sign our code and publish to the PowerShell Gallery when we commit or merge to the master branch&lt;/p>
&lt;h2 id="added-extra--dashboard">Added Extra – Dashboard&lt;/h2>
&lt;p>I like to create dashboards in VSTS to show the progress of the various definitions. You can do this under the dashboard tab. Click edit and choose or search for widgets and add them to the dashboard&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/32-Dashboard.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png"
loading="lazy"
alt="32 - Dashboard.png"
>&lt;/a>&lt;/p>
&lt;h2 id="added-extra--badges">Added Extra – Badges&lt;/h2>
&lt;p>You can also enable badges for displaying on your readme in GitHub (or VSTS). For the build defintions this is under the options tab.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/33-Build-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/33-Build-badges.png"
loading="lazy"
alt="33 - Build badges"
>&lt;/a>&lt;/p>
&lt;p>for the release definitions, click the environment and then options and integrations&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/34-Release-Badge.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/34-Release-Badge.png"
loading="lazy"
alt="34 - Release Badge"
>&lt;/a>&lt;/p>
&lt;p>You can then copy the URL and use it in your readme &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>like this on dbachecks&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/35-dbachecks-readme-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/35-dbachecks-readme-badges.png"
loading="lazy"
alt="35 - dbachecks readme badges.png"
>&lt;/a>&lt;/p>
&lt;p>The SQL Collaborative has joined the preview of enabling public access to VSTS projects as &lt;a class="link" href="https://blogs.msdn.microsoft.com/devops/2018/04/27/vsts-public-projects-limited-preview/" target="_blank" rel="noopener"
>detailed in this blog post&lt;/a> So you can &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/dbachecks%20Team/_build" target="_blank" rel="noopener"
>see the dbachecks build and release without the need to log in&lt;/a> and soon &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbatools/_build" target="_blank" rel="noopener"
>the dbatools process as well&lt;/a>&lt;/p>
&lt;p>I hope you found this useful and if you have any questions or comments please feel free to contact me&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Checking Availability Groups with dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-availability-groups-with-dbachecks/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-availability-groups-with-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/04/VSTS-results.png" alt="Featured image of post Checking Availability Groups with dbachecks" />&lt;p>It’s been 45 days since we released dbachecks&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Since then there have been 25 releases to the PowerShell Gallery!! Today release 1.1.119 was released 🙂 There have been over 2000 downloads of the module already.&lt;/p>
&lt;p>In the beginning we had 80 checks and 108 configuration items, today we have 84 checks and 125 configuration items!&lt;/p>
&lt;p>If you have already installed dbachecks it is important to make sure that you update regularly. You can do this by running&lt;/p>
&lt;p>Update-Module dbachecks&lt;/p>
&lt;p>If you want to try dbachecks, you can install it from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> by running&lt;/p>
&lt;p>Install-Module dbachecks # -Scope CurrentUser # if not running as admin&lt;/p>
&lt;p>You can read more about installation and read a number of blog posts about using different parts of dbachecks at this link &lt;a class="link" href="https://dbatools.io/installing-dbachecks/" target="_blank" rel="noopener"
>https://dbatools.io/installing-dbachecks/&lt;/a>&lt;/p>
&lt;h2 id="hadr-tests">HADR Tests&lt;/h2>
&lt;p>Today we updated the HADR tests to add the capability to test multiple availability groups and fix a couple of bugs&lt;/p>
&lt;p>Once you have installed dbachecks you will need to set some configuration so that you can perform the tests. You can see all of the configuration items and their values using&lt;/p>
&lt;p>Get-DbcConfig | Out-GridView&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/get-config.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/get-config.png"
loading="lazy"
alt="get-config.png"
>&lt;/a>&lt;/p>
&lt;p>You can set the values with the Set-DbcConfig command. It has intellisense to make things easier 🙂 To set the values for the HADR tests&lt;/p>
&lt;p>Set-DbcConfig -Name app.cluster -Value sql1
Set-DbcConfig -Name app.computername -Value sql0,sql1
Set-DbcConfig -Name app.sqlinstance -Value sql0,sql1
Set-DbcConfig -Name domain.name -Value TheBeard.Local
Set-DbcConfig -Name skip.hadr.listener.pingcheck -Value $true&lt;/p>
&lt;ul>
&lt;li>app.cluster requires one of the nodes of the cluster.&lt;/li>
&lt;li>app.computername requires the windows computer names of the machines to run operating system checks against&lt;/li>
&lt;li>app.sqlinstance requires the instance names of the SQL instances that you want to run SQL checks against (These are default instances but it will accept SERVER\INSTANCE)&lt;/li>
&lt;li>domain.name requires the domain name the machines are part of&lt;/li>
&lt;li>skip.hadr.listener.pingcheck is a boolean value which defines whether to skip the listener ping check or not. As this is in Azure I am skipping the check by setting the value to $true&lt;/li>
&lt;li>policy.hadr.tcpport is set to default to 1433 but you can also set this configuration if your SQL is using a different port&lt;/li>
&lt;/ul>
&lt;p>NOTE – You can find all the configuration items that can skip tests by running&lt;/p>
&lt;p>Get-DbcConfig -Name skip*&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/skips.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/skips.png"
loading="lazy"
alt="skips.png"
>&lt;/a>&lt;/p>
&lt;p>Now we have set the configuration (For the HADR checks – There are many more configurations for other checks that you can set) you can run the checks with&lt;/p>
&lt;p>Invoke-DbcCheck -Check HADR&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/check-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/check-results.png"
loading="lazy"
alt="check results.png"
>&lt;/a>&lt;/p>
&lt;p>This runs the following checks&lt;/p>
&lt;ul>
&lt;li>Each node on the cluster should be up&lt;/li>
&lt;li>Each resource on the cluster should be online&lt;/li>
&lt;li>Each SQL instance should be enabled for Always On&lt;/li>
&lt;li>Connection check for the listener and each node
&lt;ul>
&lt;li>Should be pingable (unless skip.hadr.listener.pingcheck is set to true)&lt;/li>
&lt;li>Should be able to run SQL commands&lt;/li>
&lt;li>Should be the correct domain name&lt;/li>
&lt;li>Should be using the correct tcpport&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Each replica should not be in unknown state&lt;/li>
&lt;li>Each synchronous replica should be synchronised&lt;/li>
&lt;li>Each asynchronous replica should be synchonising&lt;/li>
&lt;li>Each database should be synchronised (or synchronising) on each replica&lt;/li>
&lt;li>Each database should be failover ready on each replica&lt;/li>
&lt;li>Each database should be joined to the availability group on each replica&lt;/li>
&lt;li>Each database should not be suspended on each replica&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event running&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event set to auto start&lt;/li>
&lt;/ul>
&lt;p>(Apologies folk over the pond, I use the Queens English 😉 )&lt;/p>
&lt;p>This is good for us to be able to run this check at the command line but we can do more.&lt;/p>
&lt;p>We can export the results and display them with PowerBi. Note we need to add -PassThru so that the results go through the pipeline and that I used -Show Fails so that only the titles of the Describe and Context blocks and any failing tests are displayed to the screen&lt;/p>
&lt;p>Invoke-DbcCheck -Check HADR -Show Fails -PassThru | Update-DbcPowerBiDataSource -Environment HADR-Test
Start-DbcPowerBi&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/results.png"
loading="lazy"
alt="results.png"
>&lt;/a>&lt;/p>
&lt;p>This will create a file at C:\Windows\Temp\dbachecks and open the PowerBi report. You will need to refresh the data in the report and then you will see&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/dbachecks.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/dbachecks.png"
loading="lazy"
alt="dbachecks.png"
>&lt;/a>&lt;/p>
&lt;p>Excellent, everything passed 🙂&lt;/p>
&lt;h2 id="saving-configuration-for-reuse">Saving Configuration for reuse&lt;/h2>
&lt;p>We can save our configuration using Export-DbcConfig which will export the configuration to a json file&lt;/p>
&lt;p>Export-DbcConfig -Path Git:\PesterTests\MyHADRTestsForProd.json&lt;/p>
&lt;p>so that we can run this particular set of tests with this comfiguration by importing the configuration using Import-DbcConfig&lt;/p>
&lt;p>Import-DbcConfig -Path -Path Git:\PesterTests\MyHADRTestsForProd.json
Invoke-DbcCheck -Check HADR&lt;/p>
&lt;p>In this way you can set up different check configurations for different use cases. This also enables you to make use of the checks in your CI/CD process. For example, I have a GitHub repository for creating a domain, a cluster and a SQL 2017 availability group using VSTS. I have saved a dbachecks configuration to my repository and as part of my build I can import that configuration, run the checks and output them to XML for consumption by the publish test results task of VSTS&lt;/p>
&lt;p>After copying the configuration to the machine, I run&lt;/p>
&lt;p>Import-Dbcconfig -Path C:\Windows\Temp\FirstBuild.json
Invoke-DbcCheck-AllChecks -OutputFile PesterTestResultsdbachecks.xml -OutputFormat NUnitXml&lt;/p>
&lt;p>in my build step and then use the publish test results task and VSTS does the rest 🙂&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/VSTS-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/VSTS-results.png"
loading="lazy"
alt="VSTS results.png"
>&lt;/a>&lt;/p></description></item><item><title>Easily Splatting PowerShell with VS Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/easily-splatting-powershell-with-vs-code/</link><pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/easily-splatting-powershell-with-vs-code/</guid><description>&lt;img src="https://pbs.twimg.com/media/DX8UjepX0AYnDMS?format=jpg&name=large" alt="Featured image of post Easily Splatting PowerShell with VS Code" />&lt;p>So I always like to show splatting PowerShell commands when I am presenting sessions or workshops and realised that I had not really blogged about it. (This blog is for &lt;a class="link" href="https://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>@dbafromthecold&lt;/a> who asked me to 🙂 )&lt;/p>
&lt;h2 id="what-is-splatting">What is Splatting?&lt;/h2>
&lt;p>Well you will know that when you call a PowerShell function you can use intellisense to get the parameters and sometimes the parameter values as well. This can leave you with a command that looks like this on the screen&lt;/p>
&lt;pre>&lt;code>Start-DbaMigration -Source $Source -Destination $Destination -BackupRestore -NetworkShare $Share -WithReplace -ReuseSourceFolderStructure -IncludeSupportDbs -NoAgentServer -NoAudits -NoResourceGovernor -NoSaRename -NoBackupDevices
&lt;/code>&lt;/pre>
&lt;p>It goes on and on and on and while it is easy to type once, it is not so easy to see which values have been chosen. It is also not so easy to change the values.&lt;/p>
&lt;p>By Splatting the parameters it makes it much easier to read and also to alter. So instead of the above you can have&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$startDbaMigrationSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Source = $Source
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NetworkShare = $Share
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoAgentServer = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoResourceGovernor = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WithReplace = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ReuseSourceFolderStructure = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Destination = $Destination
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoAudits = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BackupRestore = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoSaRename = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IncludeSupportDbs = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoBackupDevices = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbaMigration @startDbaMigrationSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is much easier on the eye, but if you dont know what the parameters are (and are too lazy to use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/get-help?view=powershell-6" target="_blank" rel="noopener"
>Get-Help&lt;/a> – Hint You should always use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/get-help?view=powershell-6" target="_blank" rel="noopener"
>Get-Help&lt;/a> ) or like the convenience and efficiency of using the intellisense, this might feel like a backward step that slows your productivity in the cause of easy on the eye code.&lt;/p>
&lt;p>Enter &lt;a class="link" href="https://github.com/SeeminglyScience/EditorServicesCommandSuite" target="_blank" rel="noopener"
>EditorServicesCommandSuite&lt;/a> by SeeminglyScience for VS Code. Amongst the things it makes available to you is easy splatting and people are always impressed when I show it&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can install it from the PowerShell Gallery like all good modules using&lt;/p>
&lt;pre>&lt;code>Install-Module EditorServicesCommandSuite -Scope CurrentUser
&lt;/code>&lt;/pre>
&lt;p>and then add it to your VSCode PowerShell profile usually found at &lt;code>C:\Users\USERNAME\Documents\WindowsPowerShell\Microsoft.VSCode_profile.ps1&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\# Place this in your VSCode profile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module EditorServicesCommandSuite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-EditorCommand -Module EditorServicesCommandSuite
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and now creating a splat is as easy as this.&lt;/p>
&lt;p>Write the command, leave the cursor on a parameter, hit F1 – Choose PowerShell : Show Additional Commands (or use a keyboard shortcut) type splat press enter. Done 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So very easy 🙂&lt;/p>
&lt;p>Happy Splatting 🙂&lt;/p></description></item><item><title>Announcing dbachecks – Configurable PowerShell Validation For Your SQL Instances</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-dbachecks-configurable-powershell-validation-for-your-sql-instances/</link><pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-dbachecks-configurable-powershell-validation-for-your-sql-instances/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/09-PowerBi.png" alt="Featured image of post Announcing dbachecks – Configurable PowerShell Validation For Your SQL Instances" />&lt;p>For the last couple of months members of the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> team have been working on a new PowerShell module called &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This open source PowerShell module will enable you to validate your SQL Instances. Today it is released for you all to start to use 🙂&lt;/p>
&lt;h2 id="validate-your-sql-instances">Validate Your SQL Instances?&lt;/h2>
&lt;p>What do I mean by validate your SQL Instances? You want to know if your SQL Instances are (still) set up in the way that you want them to be or that you have not missed any configurations when setting them up. With dbachecks you can use any or all of the 80 checks to ensure one or many SQL Instances are as you want them to be. Using Pester, dbachecks will validate your SQL Instance(s) against default settings or ones that you configure yourself.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Installation is via the PowerShell Gallery. You will need to open PowerShell on a machine connected to the internet and run&lt;/p>
&lt;p>Install-Module dbachecks&lt;/p>
&lt;p>If you are not running your process as admin or you only want (or are able) to install for your own user account you will need to&lt;/p>
&lt;p>Install-Module -Scope CurrentUser&lt;/p>
&lt;p>This will also install the PSFramework module used for configuration (and other things beneath the hood) and the latest version (4.2.0 – released on Sunday!) of Pester&lt;/p>
&lt;p>Once you have installed the module you can see the commands available by running&lt;/p>
&lt;p>Get-Command -Module dbachecks&lt;/p>
&lt;p>To be able to use these (and any PowerShell) commands, your first step should always be Get-Help&lt;/p>
&lt;p>Get-Help Send-DbcMailMessage&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/01a-get-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01a-get-help.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="80-checks">80 Checks&lt;/h2>
&lt;p>At the time of release, dbachecks has 80 checks. You can see all of the checks by running&lt;/p>
&lt;p>Get-DbcCheck&lt;/p>
&lt;p>(Note this has nothing to do with DBCC CheckDb!) Here is the output of&lt;/p>
&lt;p>Get-DbcCheck | Select Group, UniqueTag&lt;/p>
&lt;p>so you can see the current checks&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Group&lt;/strong>&lt;/th>
&lt;th>&lt;strong>UniqueTag&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>AgentServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>DbaOperator&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>FailsafeOperator&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>DatabaseMailProfile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>FailedJob&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatabaseCollation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>SuspectPage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>TestLastBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>TestLastBackupVerifyOnly&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>ValidDatabaseOwner&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>InvalidDatabaseOwner&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastGoodCheckDb&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>IdentityUsage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>RecoveryModel&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DuplicateIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>UnusedIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DisabledIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatabaseGrowthEvent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>PageVerify&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoClose&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoShrink&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastFullBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastDiffBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastLogBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>VirtualLogFile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LogfileCount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LogfileSize&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>FileGroupBalanced&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoCreateStatistics&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoUpdateStatistics&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoUpdateStatisticsAsynchronously&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatafileAutoGrowthType&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>Trustworthy&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>OrphanedUser&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>PseudoSimple&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AdHocWorkloads&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Domain&lt;/strong>&lt;/td>
&lt;td>DomainName&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Domain&lt;/strong>&lt;/td>
&lt;td>OrganizationalUnit&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>ClusterHealth&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>ClusterServerHealth&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>System.Object[]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SqlEngineServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SqlBrowserServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>TempDbConfiguration&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>AdHocWorkload&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>BackupPathAccess&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>DAC&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>NetworkLatency&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>LinkedServerConnection&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>MaxMemory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>OrphanedFile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>ServerNameMatch&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>MemoryDump&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SupportedBuild&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SaRenamed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>DefaultBackupCompression&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionStopped&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionRunning&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionRunningAllowed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>OLEAutomation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>WhoIsActiveInstalled&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>LogShipping&lt;/strong>&lt;/td>
&lt;td>LogShippingPrimary&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>LogShipping&lt;/strong>&lt;/td>
&lt;td>LogShippingSecondary&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>PowerPlan&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>InstanceConnection&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>SPN&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>DiskCapacity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>PingComputer&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>SystemFull&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserFull&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserDiff&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserLog&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>CommandLog&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>SystemIntegrityCheck&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserIntegrityCheck&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserIndexOptimize&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>OutputFileCleanup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>DeleteBackupHistory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>PurgeJobHistory&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="108-configurations">108 Configurations&lt;/h2>
&lt;p>One of the things I have been talking about in my presentation “Green is Good Red is Bad” is configuring Pester checks so that you do not have to keep writing new tests for the same thing but with different values.&lt;/p>
&lt;p>For example, a different user for a database owner. The code to write the test for the database owner is the same but the value might be different for different applications, environments, clients, teams, domains etc. I gave a couple of different methods for achieving this.&lt;/p>
&lt;p>With dbachecks we have made this much simpler enabling you to set configuration items at run-time or for your session and enabling you to export and import them so you can create different configs for different use cases&lt;/p>
&lt;p>There are 108 configuration items at present. You can see the current configuration by running&lt;/p>
&lt;p>Get-DbcConfig&lt;/p>
&lt;p>which will show you the name of the config, the value it is currently set and the description&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/01-configs.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-configs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see all of the configs and their descriptions here&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Name&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>agent.databasemailprofile&lt;/strong>&lt;/td>
&lt;td>Name of the Database Mail Profile in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatoremail&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatorname&lt;/strong>&lt;/td>
&lt;td>Name of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.failsafeoperator&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.checkrepos&lt;/strong>&lt;/td>
&lt;td>Where Pester tests/checks are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.computername&lt;/strong>&lt;/td>
&lt;td>List of Windows Servers that Windows-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.localapp&lt;/strong>&lt;/td>
&lt;td>Persisted files live here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.maildirectory&lt;/strong>&lt;/td>
&lt;td>Files for mail are stored here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlcredential&lt;/strong>&lt;/td>
&lt;td>The universal SQL credential if Trusted/Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlinstance&lt;/strong>&lt;/td>
&lt;td>List of SQL Server instances that SQL-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.wincredential&lt;/strong>&lt;/td>
&lt;td>The universal Windows if default Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>command.invokedbccheck.excludecheck&lt;/strong>&lt;/td>
&lt;td>Invoke-DbcCheck: The checks that should be skipped by default.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.domaincontroller&lt;/strong>&lt;/td>
&lt;td>The domain controller to process your requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.name&lt;/strong>&lt;/td>
&lt;td>The Active Directory domain that your server is a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.organizationalunit&lt;/strong>&lt;/td>
&lt;td>The OU that your server should be a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.failurethreshhold&lt;/strong>&lt;/td>
&lt;td>Number of errors that must be present to generate an email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.from&lt;/strong>&lt;/td>
&lt;td>Email address the email reports should come from&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.smtpserver&lt;/strong>&lt;/td>
&lt;td>Store the name of the smtp server to send email reports&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.subject&lt;/strong>&lt;/td>
&lt;td>Subject line of the email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.to&lt;/strong>&lt;/td>
&lt;td>Email address to send the report to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.datadir&lt;/strong>&lt;/td>
&lt;td>Destination server data directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.defaultbackupcompreesion&lt;/strong>&lt;/td>
&lt;td>Default Backup Compression check should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.diffmaxhours&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of hours before Diff Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.fullmaxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before Full Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logdir&lt;/strong>&lt;/td>
&lt;td>Destination server log directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logmaxminutes&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of minutes before Log Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.newdbgraceperiod&lt;/strong>&lt;/td>
&lt;td>The number of hours a newly created database is allowed to not have backups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.testserver&lt;/strong>&lt;/td>
&lt;td>Destination server for backuptests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.build.warningwindow&lt;/strong>&lt;/td>
&lt;td>The number of months prior to a build being unsupported that you want warning about&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.authscheme&lt;/strong>&lt;/td>
&lt;td>Auth requirement (Kerberos, NTLM, etc)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingcount&lt;/strong>&lt;/td>
&lt;td>Number of times to ping a server to establish average response time&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingmaxms&lt;/strong>&lt;/td>
&lt;td>Maximum response time in ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dacallowed&lt;/strong>&lt;/td>
&lt;td>DAC should be allowed $true or disallowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoclose&lt;/strong>&lt;/td>
&lt;td>Auto Close should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autocreatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Create Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoshrink&lt;/strong>&lt;/td>
&lt;td>Auto Shrink should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatisticsasynchronously&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics Asynchronously should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filebalancetolerance&lt;/strong>&lt;/td>
&lt;td>Percentage for Tolerance for checking for balanced files in a filegroups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthexcludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from the file growth check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthtype&lt;/strong>&lt;/td>
&lt;td>Growth Type should be &amp;lsquo;kb&amp;rsquo; or &amp;lsquo;percent&amp;rsquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthvalue&lt;/strong>&lt;/td>
&lt;td>The auto growth value (in kb) should be equal or higher than this value. Example: A value of 65535 means at least 64MB.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilecount&lt;/strong>&lt;/td>
&lt;td>The number of Log files expected on a database&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizecomparison&lt;/strong>&lt;/td>
&lt;td>How to compare data and log file size, options are maximum or average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizepercentage&lt;/strong>&lt;/td>
&lt;td>Maximum percentage of Data file Size that logfile is allowed to be.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.maxvlf&lt;/strong>&lt;/td>
&lt;td>Max virtual log files&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dbcc.maxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before DBCC CHECKDB is considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.diskspace.percentfree&lt;/strong>&lt;/td>
&lt;td>Percent disk free&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dump.maxcount&lt;/strong>&lt;/td>
&lt;td>Maximum number of expected dumps&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.hadr.tcpport&lt;/strong>&lt;/td>
&lt;td>The TCPPort for the HADR check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.identity.usagepercent&lt;/strong>&lt;/td>
&lt;td>Maxmimum percentage of max of identity column&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from invalid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should not be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.network.latencymaxms&lt;/strong>&lt;/td>
&lt;td>Max network latency average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.database&lt;/strong>&lt;/td>
&lt;td>The database where Ola&amp;rsquo;s maintenance solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.installed&lt;/strong>&lt;/td>
&lt;td>Checks to see if Ola Hallengren solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizeenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizescheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.oleautomation&lt;/strong>&lt;/td>
&lt;td>OLE Automation should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.pageverify&lt;/strong>&lt;/td>
&lt;td>Page verify option should be set to this value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from standard recovery model check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.type&lt;/strong>&lt;/td>
&lt;td>Standard recovery model&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.storage.backuppath&lt;/strong>&lt;/td>
&lt;td>Enables tests to check if servers have access to centralized backup location&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from valid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.whoisactive.database&lt;/strong>&lt;/td>
&lt;td>Which database should contain the sp_WhoIsActive stored procedure&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredstoppedsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should not be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.validrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that can be be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.backup.testing&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run Test-DbaLastBackup by default (it&amp;rsquo;s not read-only)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.ping&lt;/strong>&lt;/td>
&lt;td>Skip the ping check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.remoting&lt;/strong>&lt;/td>
&lt;td>Skip PowerShell remoting check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.filegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.datafilegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.dbcc.datapuritycheck&lt;/strong>&lt;/td>
&lt;td>Skip data purity check in last good dbcc command&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.diffbackuptest&lt;/strong>&lt;/td>
&lt;td>Skip the Differential backup test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logshiptesting&lt;/strong>&lt;/td>
&lt;td>Skip the logshipping test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdb1118&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Trace Flag 1118&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilecount&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Count&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilegrowthpercent&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Growth in Percent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesizemax&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files Max Size&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesonc&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files on C&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="running-a-check">Running A Check&lt;/h2>
&lt;p>You can quickly run a single check by calling Invoke-DbcCheck.&lt;/p>
&lt;p>Invoke-DbcCheck -SqlInstance localhost -Check FailedJob&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/02-failed-jobs.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/02-failed-jobs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Excellent, my agent jobs have not failed 🙂&lt;/p>
&lt;p>Invoke-DbcCheck -SqlInstance localhost -Check LastGoodCheckDb&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/03-dbcc-check.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/03-dbcc-check.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Thats good, all of my databases have had a successful DBCC CHECKDB within the last 7 days.&lt;/p>
&lt;h2 id="setting-a-configuration">Setting a Configuration&lt;/h2>
&lt;p>To save me from having to specify the instance I want to run my tests against I can set the app.sqlinstance config to the instances I want to check.&lt;/p>
&lt;p>Set-DbcConfig -Name app.sqlinstance -Value localhost, &amp;rsquo;localhost\PROD1&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/04-setting-instances-config.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/04-setting-instances-config.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then whenever I call Invoke-DbcCheck it will run against those instances for the SQL checks&lt;/p>
&lt;p>So now if I run&lt;/p>
&lt;p>Invoke-DbcCheck -Check LastDiffBackup&lt;/p>
&lt;p>I can see that I dont have a diff backup for the databases on both instances. Better stop writing this and deal with that !!&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/05-last-backup.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/05-last-backup.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The configurations are stored in the registry but you can export them and then import them for re-use easily. I have written another blog post about that.&lt;/p>
&lt;h2 id="the-show-parameter">The Show Parameter&lt;/h2>
&lt;p>Getting the results of the tests on the screen is cool but if you are running a lot of tests against a lot of instances then you might find that you have 3 failed tests out of 15000! This will mean a lot of scrolling through green text looking for the red text and you may find that your PowerShell buffer doesnt hold all of your test results leaving you very frustrated.&lt;/p>
&lt;p>dbachecks supports the Pester Show parameter enabling you to filter the output of the results to the screen. The available values are Summary, None, Fails, Inconclusive, Passed, Pending and Skipped&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/06-show.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/06-show.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>in my opinion by far the most useful one is Fails as this will show you only the failed tests with the context to enable you to see which tests have failed&lt;/p>
&lt;p>Invoke-DbcCheck -Check Agent -Show Fails&lt;/p>
&lt;p>If we check all of the checks tagged as Agent we can easily see that most passed but The Job That Fails (surprisingly) failed. All of the other tests that were run for the agent service, operators, failsafe operator, database mail and all other agent jobs all passed in the example below&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/07-Jobs-that-filed.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/07-Jobs-that-filed.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="test-results-are-for-other-people-as-well">Test Results are for other People as well&lt;/h2>
&lt;p>It is all very well and good being able to run tests and get the results on our screen. It will be very useful for people to be able to validate a new SQL instance for example or run a morning check or the first step of an incident response. But test results are also useful for other people so we need to be able to share them&lt;/p>
&lt;p>We have created a Power Bi Dashboard that comes with the dbachecks module to enable easy sharing of the test results. You can also send the results via email using Send-DbcMailMessage. we have an &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks/issues/270" target="_blank" rel="noopener"
>open issue for putting them into a database&lt;/a> that we would love you to help resolve.&lt;/p>
&lt;p>To get the results into PowerBi you can run&lt;/p>
&lt;p>Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Production&lt;/p>
&lt;p>This will run all of the dbachecks using your configuration for your Production environment, output only the failed tests to the screen and save the results in your windows\temp\dbachecks folder with a suffix of Production&lt;/p>
&lt;p>If you then used a different configuration for your development environment and ran&lt;/p>
&lt;p>Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Development&lt;/p>
&lt;p>it will run all of the dbachecks using your configuration for your Development environment, output only the failed tests to the screen and save the results in your windows\temp\dbachecks folder with a suffix of Development and you would end up with two files in the folder&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/08-test-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/08-test-results.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can then simply run&lt;/p>
&lt;p>Start-DbcPowerBi&lt;/p>
&lt;p>and as long as you have the (free) Powerbi Desktop then you will see this. You will need to refresh the data to get your test results&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/09-PowerBi.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/09-PowerBi.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Of course it is Powerbi so you can publish this report. Here it is so that you can click around and see what it looks like&lt;/p>
&lt;h2 id="its-open-source--we-want-your-ideas-issues-new-code">It’s Open Source – We Want Your Ideas, Issues, New Code&lt;/h2>
&lt;p>dbachecks is open-source &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks" target="_blank" rel="noopener"
>available on GitHub for anyone to contribute&lt;/a>&lt;/p>
&lt;p>We would love you to contribute. Please open issues for new tests, enhancements, bugs. Please fork the repository and add code to improve the module. please give feedback to make this module even more useful&lt;/p>
&lt;p>You can also come in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> and join the dbachecks channel and get advice, make comments or just join in the conversation&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>There are many more introduction blog posts covering different areas at&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://dbachecks.io/install" target="_blank" rel="noopener"
>dbachecks.io/install&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="thank-you">Thank You&lt;/h2>
&lt;p>I want to say thank you to all of the people who have enabled dbachecks to get this far. These wonderful people have used their own time to ensure that you have a useful tool available to you for free&lt;/p>
&lt;p>Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a>&lt;/p>
&lt;p>Fred Weinmann &lt;a class="link" href="https://twitter.com/FredWeinmann" target="_blank" rel="noopener"
>@FredWeinmann&lt;/a>&lt;/p>
&lt;p>Cláudio Silva &lt;a class="link" href="https://twitter.com/ClaudioESSilva" target="_blank" rel="noopener"
>@ClaudioESSilva&lt;/a>&lt;/p>
&lt;p>Stuart Moore &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a>&lt;/p>
&lt;p>Shawn Melton &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>&lt;/p>
&lt;p>Garry Bargsley &lt;a class="link" href="https://twitter.com/gbargsley" target="_blank" rel="noopener"
>@gbargsley&lt;/a>&lt;/p>
&lt;p>Stephen Bennett &lt;a class="link" href="https://twitter.com/staggerlee011" target="_blank" rel="noopener"
>@staggerlee011&lt;/a>&lt;/p>
&lt;p>Sander Stad &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>@SQLStad&lt;/a>&lt;/p>
&lt;p>Jess Pomfret &lt;a class="link" href="https://twitter.com/jpomfret" target="_blank" rel="noopener"
>@jpomfret&lt;/a>&lt;/p>
&lt;p>Jason Squires &lt;a class="link" href="https://twitter.com/js0505" target="_blank" rel="noopener"
>@js0505&lt;/a>&lt;/p>
&lt;p>Shane O’Neill &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>@SOZDBA&lt;/a>&lt;/p>
&lt;p>Tony Wilhelm &lt;a class="link" href="https://twitter.com/TonyWSQL" target="_blank" rel="noopener"
>@TonyWSQL&lt;/a>&lt;/p>
&lt;p>and all of the other people who have contributed in the dbachecks Slack channel&lt;/p></description></item><item><title>dbachecks – Configuration Deep Dive</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-configuration-deep-dive/</link><pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-configuration-deep-dive/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/03-autocomplete.png" alt="Featured image of post dbachecks – Configuration Deep Dive" />&lt;p>Today is the day that &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/?p=8997" >we have announced dbachecks&lt;/a>  a PowerShell module enabling you to validate your SQL Instances. You can read more about it &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/?p=8997" >here where you can learn how to install it and see some simple use cases&lt;/a>&lt;/p>
&lt;h2 id="108-configurations">108 Configurations&lt;/h2>
&lt;p>One of the things I have been talking about &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/write-your-first-pester-test-today/" >in my presentation “Green is Good Red is Bad”&lt;/a> is configuring Pester checks so that you do not have to keep writing new tests for the same thing but with different values.&lt;/p>
&lt;p>For example, a different user for a database owner. The code to write the test for the database owner is the same but the value might be different for different applications, environments, clients, teams, domains etc. I gave a couple of different methods for achieving this.&lt;/p>
&lt;p>With dbachecks we have made this much simpler enabling you to set configuration items at run-time or for your session and enabling you to export and import them so you can create different configs for different use cases&lt;/p>
&lt;p>There are 108 configuration items at present. You can see the current configuration by running&lt;/p>
&lt;p>Get-DbcConfig&lt;/p>
&lt;p>which will show you the name of the config, the value it is currently set and the description
&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-configs.png"
loading="lazy"
>&lt;/p>
&lt;p>You can see all of the configs and their descriptions here&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Name&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>agent.databasemailprofile&lt;/strong>&lt;/td>
&lt;td>Name of the Database Mail Profile in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatoremail&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatorname&lt;/strong>&lt;/td>
&lt;td>Name of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.failsafeoperator&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.checkrepos&lt;/strong>&lt;/td>
&lt;td>Where Pester tests/checks are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.computername&lt;/strong>&lt;/td>
&lt;td>List of Windows Servers that Windows-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.localapp&lt;/strong>&lt;/td>
&lt;td>Persisted files live here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.maildirectory&lt;/strong>&lt;/td>
&lt;td>Files for mail are stored here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlcredential&lt;/strong>&lt;/td>
&lt;td>The universal SQL credential if Trusted/Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlinstance&lt;/strong>&lt;/td>
&lt;td>List of SQL Server instances that SQL-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.wincredential&lt;/strong>&lt;/td>
&lt;td>The universal Windows if default Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>command.invokedbccheck.excludecheck&lt;/strong>&lt;/td>
&lt;td>Invoke-DbcCheck: The checks that should be skipped by default.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.domaincontroller&lt;/strong>&lt;/td>
&lt;td>The domain controller to process your requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.name&lt;/strong>&lt;/td>
&lt;td>The Active Directory domain that your server is a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.organizationalunit&lt;/strong>&lt;/td>
&lt;td>The OU that your server should be a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.failurethreshhold&lt;/strong>&lt;/td>
&lt;td>Number of errors that must be present to generate an email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.from&lt;/strong>&lt;/td>
&lt;td>Email address the email reports should come from&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.smtpserver&lt;/strong>&lt;/td>
&lt;td>Store the name of the smtp server to send email reports&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.subject&lt;/strong>&lt;/td>
&lt;td>Subject line of the email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.to&lt;/strong>&lt;/td>
&lt;td>Email address to send the report to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.datadir&lt;/strong>&lt;/td>
&lt;td>Destination server data directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.defaultbackupcompreesion&lt;/strong>&lt;/td>
&lt;td>Default Backup Compression check should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.diffmaxhours&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of hours before Diff Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.fullmaxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before Full Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logdir&lt;/strong>&lt;/td>
&lt;td>Destination server log directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logmaxminutes&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of minutes before Log Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.newdbgraceperiod&lt;/strong>&lt;/td>
&lt;td>The number of hours a newly created database is allowed to not have backups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.testserver&lt;/strong>&lt;/td>
&lt;td>Destination server for backuptests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.build.warningwindow&lt;/strong>&lt;/td>
&lt;td>The number of months prior to a build being unsupported that you want warning about&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.authscheme&lt;/strong>&lt;/td>
&lt;td>Auth requirement (Kerberos, NTLM, etc)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingcount&lt;/strong>&lt;/td>
&lt;td>Number of times to ping a server to establish average response time&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingmaxms&lt;/strong>&lt;/td>
&lt;td>Maximum response time in ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dacallowed&lt;/strong>&lt;/td>
&lt;td>DAC should be allowed $true or disallowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoclose&lt;/strong>&lt;/td>
&lt;td>Auto Close should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autocreatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Create Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoshrink&lt;/strong>&lt;/td>
&lt;td>Auto Shrink should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatisticsasynchronously&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics Asynchronously should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filebalancetolerance&lt;/strong>&lt;/td>
&lt;td>Percentage for Tolerance for checking for balanced files in a filegroups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthexcludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from the file growth check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthtype&lt;/strong>&lt;/td>
&lt;td>Growth Type should be &amp;lsquo;kb&amp;rsquo; or &amp;lsquo;percent&amp;rsquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthvalue&lt;/strong>&lt;/td>
&lt;td>The auto growth value (in kb) should be equal or higher than this value. Example: A value of 65535 means at least 64MB.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilecount&lt;/strong>&lt;/td>
&lt;td>The number of Log files expected on a database&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizecomparison&lt;/strong>&lt;/td>
&lt;td>How to compare data and log file size, options are maximum or average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizepercentage&lt;/strong>&lt;/td>
&lt;td>Maximum percentage of Data file Size that logfile is allowed to be.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.maxvlf&lt;/strong>&lt;/td>
&lt;td>Max virtual log files&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dbcc.maxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before DBCC CHECKDB is considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.diskspace.percentfree&lt;/strong>&lt;/td>
&lt;td>Percent disk free&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dump.maxcount&lt;/strong>&lt;/td>
&lt;td>Maximum number of expected dumps&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.hadr.tcpport&lt;/strong>&lt;/td>
&lt;td>The TCPPort for the HADR check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.identity.usagepercent&lt;/strong>&lt;/td>
&lt;td>Maxmimum percentage of max of identity column&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from invalid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should not be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.network.latencymaxms&lt;/strong>&lt;/td>
&lt;td>Max network latency average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.database&lt;/strong>&lt;/td>
&lt;td>The database where Ola&amp;rsquo;s maintenance solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.installed&lt;/strong>&lt;/td>
&lt;td>Checks to see if Ola Hallengren solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizeenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizescheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.oleautomation&lt;/strong>&lt;/td>
&lt;td>OLE Automation should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.pageverify&lt;/strong>&lt;/td>
&lt;td>Page verify option should be set to this value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from standard recovery model check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.type&lt;/strong>&lt;/td>
&lt;td>Standard recovery model&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.storage.backuppath&lt;/strong>&lt;/td>
&lt;td>Enables tests to check if servers have access to centralized backup location&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from valid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.whoisactive.database&lt;/strong>&lt;/td>
&lt;td>Which database should contain the sp_WhoIsActive stored procedure&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredstoppedsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should not be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.validrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that can be be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.backup.testing&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run Test-DbaLastBackup by default (it&amp;rsquo;s not read-only)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.ping&lt;/strong>&lt;/td>
&lt;td>Skip the ping check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.remoting&lt;/strong>&lt;/td>
&lt;td>Skip PowerShell remoting check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.filegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.datafilegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.dbcc.datapuritycheck&lt;/strong>&lt;/td>
&lt;td>Skip data purity check in last good dbcc command&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.diffbackuptest&lt;/strong>&lt;/td>
&lt;td>Skip the Differential backup test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logshiptesting&lt;/strong>&lt;/td>
&lt;td>Skip the logshipping test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdb1118&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Trace Flag 1118&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilecount&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Count&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilegrowthpercent&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Growth in Percent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesizemax&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files Max Size&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesonc&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files on C&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>So there are a lot of configurations that you can use. A lot are already set by default but all of them you can configure for the values that you need for your own estate.&lt;/p>
&lt;p>The configurations are stored in the registry at HKCU:\Software\Microsoft\WindowsPowerShell\PSFramework\&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-registry.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="first-configurations">First Configurations&lt;/h2>
&lt;p>First I would run this so that you can see all of the configs in a seperate window (note this does not work on PowerShell v6)&lt;/p>
&lt;pre>&lt;code>Get-DbcConfig | Out-GridView
&lt;/code>&lt;/pre>
&lt;p>Lets start with the first configurations that you will want to set. This should be the Instances and the Hosts that you want to check&lt;/p>
&lt;p>You can get the value of the configuration item using&lt;/p>
&lt;pre>&lt;code>Get-DbcConfigValue -Name app.sqlinstance
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/02-config.png"
loading="lazy"
>&lt;/p>
&lt;p>as you can see in the image, nothing is returned so we have no instances configured at present. We have added tab completion to the name parameter so that you can easily find the right one&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/03-autocomplete.png"
loading="lazy"
>&lt;/p>
&lt;p>If you want to look at more information about the configuration item you can use&lt;/p>
&lt;pre>&lt;code>Get-DbcConfig -Name app.sqlinstance
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/04-config.png"
loading="lazy"
>&lt;/p>
&lt;p>which shows you the name, current value and the description&lt;/p>
&lt;p>So lets set our first configuration for our SQL instance to localhost. I have included a video so you can see the auto-complete in action as well&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name app.sqlinstance localhost
&lt;/code>&lt;/pre>
&lt;p>This configuration will be used for any SQL based checks but not for any windows based ones like Services, PowerPlan, SPN, DiskSpace, Cluster so lets set the app.computername configuration as well&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/05-windows-config.png"
loading="lazy"
>&lt;/p>
&lt;p>This means that when we run invoke-DbcCheck with AllChecks or by specifying a check, it will run against the local machine and default instance unless we specify a sqlinstance when calling Invoke-DbcCheck. So the code below will not use the configuration for app.sqlinstance.&lt;/p>
&lt;pre>&lt;code>Invoke-DbcCheck -SqlInstance TheBeard
&lt;/code>&lt;/pre>
&lt;h2 id="exclude-a-check">Exclude a Check&lt;/h2>
&lt;p>You can exclude a check using the -ExcludeCheck parameter of Invoke-DbcConfig. In the example below I am running all of the Server checks but excluding the SPN as we are not on a domain&lt;/p>
&lt;pre>&lt;code>Invoke-DbcCheck -Check Server -ExcludeCheck SPN
&lt;/code>&lt;/pre>
&lt;p>There is a configuration setting to exclude checks as well. (Be careful this will exclude them even if you specifically specify a check using Invoke-DbcCheck but we do give you a warning!)&lt;/p>
&lt;p>So now I can run&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value SPN
Invoke-DbcCheck -Check Server
&lt;/code>&lt;/pre>
&lt;p>and all of the server checks except the SPN check will run against the local machine and the default instance that I have set in the config&lt;/p>
&lt;h2 id="creating-an-environment-config-and-exporting-it-to-use-any-time-we-like">Creating an environment config and exporting it to use any time we like&lt;/h2>
&lt;p>So lets make this a lot more useful. Lets create a configuration for our production environment and save it to disk (or even source control it!) so that we can use it again and again. We can also then pass it to other members of our team or even embed it in an automated process or our CI/CD system&lt;/p>
&lt;p>Lets build up a configuration for a number of tests for my “production” environment. I will not explain them all here but let you read through the code and the comments to see what has been set. You will see that some of them are due to me running the test on a single machine with one drive.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># The computername we will be testing
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.computername -Value localhost
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The Instances we want to test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlinstance -Value &amp;#39;localhost&amp;#39; ,&amp;#39;localhost\PROD1&amp;#39;,&amp;#39;localhost\PROD2&amp;#39;, &amp;#39;localhost\PROD3&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The database owner we expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.validdbowner.name -Value &amp;#39;dbachecksdemo\dbachecks&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># the database owner we do NOT expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.invaliddbowner.name -Value &amp;#39;sa&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should backups be compressed by default?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.defaultbackupcompreesion -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Do we allow DAC connections?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.dacallowed -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What recovery model should we have?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.type -value FULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth type be?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthtype -Value kb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What authentication scheme are we expecting?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.connection.authscheme -Value &amp;#39;NTLM&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatorname -Value &amp;#39;DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator email should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatoremail -Value &amp;#39;DBATeam@TheBeard.Local&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which failsafe operator shoudl be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.failsafeoperator -Value &amp;#39;DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is the whoisactive stored procedure?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.whoisactive.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a Full backup?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.fullmaxdays -Value 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a DIFF backup (in hours) ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.diffmaxhours -Value 26
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a log backup (in minutes)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.logmaxminutes -Value 30
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my domain name?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;WORKGROUP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is my Ola database?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.ola.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which database should not be checked for recovery model
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.excludedb -Value &amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;tempdb&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my SQL Credential
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlcredential -Value $null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files on c?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilesonc -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files count?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilecount -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Checks should be excluded?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value LogShipping,ExtendedEvent, HADR, PseudoSimple,spn
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># How many months before a build is unsupported do I want to fail the test?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.build.warningwindow -Value 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-Dbcconfig | ogv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>When I run this I get&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/08-configuration.png"
loading="lazy"
>&lt;/p>
&lt;p>I can then export this to disk (to store in source control) using&lt;/p>
&lt;pre>&lt;code>Export-DbcConfig -Path C:\Users\dbachecks\Desktop\production_config.json
&lt;/code>&lt;/pre>
&lt;p>and I have a configuration file&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/09-configuration-json.png"
loading="lazy"
>&lt;/p>
&lt;p>which I can use any time to set the configuration for dbachecks using the Import-DbcConfig command (But this doesn’t work in VS Codes integrated terminal – which occasionally does odd things, this appears to be one of them)&lt;/p>
&lt;pre>&lt;code>Import-DbcConfig -Path C:\Users\dbachecks\Desktop\production_config.json
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/10-import-configuration.png"
loading="lazy"
>&lt;/p>
&lt;p>So I can import this configuration and run my checks with it any time I like. This means that I can create many different test configurations for my many different environment or estate configurations.&lt;/p>
&lt;p>Yes, I know “good/best practice” says we should use the same configuration for all of our instances but we know that isn’t true. We have instances that were set up 15 years ago that are still in production. We have instances from the companies our organisation has bought over the years that were set up by system administrators. We have instances that were set up by shadow IT and now we have to support but cant change.&lt;/p>
&lt;p>As well as those though, we also have different environments. Our development or test environment will have different requirements to our production environments.&lt;/p>
&lt;p>In this hypothetical situation the four instances for four different applications have 4 development containers which are connected to using SQL Authentication. We will need a different configuration.&lt;/p>
&lt;h2 id="sql-authentication">SQL Authentication&lt;/h2>
&lt;p>We can set up SQL Authentication for connecting to our SQL Instances using the app.sqlcredential configuration. this is going to hold a PSCredential object for SQL Authenticated connection to your instance. If this is set the checks will always try to use it. Yes this means that the same username and password is being used for each connection. No there is currently no way to choose which instances use it and which don’t. This may be a limitation but as you will see further down you can still do this with different configurations&lt;/p>
&lt;p>To set the  SQL Authentication run&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name app.sqlcredential -Value (Get-Credential)
&lt;/code>&lt;/pre>
&lt;p>This will give a prompt for you to enter the credential&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/11-prompt-for-credenial.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="development-environment-configuration">Development Environment Configuration&lt;/h2>
&lt;p>So now we know how to set a SQL Authentication configuration we can create our development environment configuration like so. As you can see below the values are different for the checks and more checks have been skipped. I wont explain it all, if it doesn’t make sense ask a question in the comments or in the dbachecks in SQL Server Community Slack&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#region Dev Config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The Instances we want to test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlinstance -Value &amp;#39;localhost,1401&amp;#39; ,&amp;#39;localhost,1402&amp;#39;,&amp;#39;localhost,1403&amp;#39;, &amp;#39;localhost,1404&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my SQL Credential
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlcredential -Value (Get-Credential)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The database owner we expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.validdbowner.name -Value &amp;#39;sa&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What authentication scheme are we expecting?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.connection.authscheme -Value &amp;#39;SQL&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># the database owner we do NOT expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.invaliddbowner.name -Value &amp;#39;dbachecksdemo\dbachecks&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should backups be compressed by default?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.defaultbackupcompreesion -Value $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth type be?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthtype -Value kb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth value be higher than (Mb)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthvalue -Value 64
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Do we allow DAC connections?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.dacallowed -Value $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum latency (ms)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.network.latencymaxms -Value 100
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What recovery model should we have?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.type -value Simple
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is the whoisactive stored procedure?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.whoisactive.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my domain name?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;WORKGROUP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which database should not be checked for recovery model
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.excludedb -Value &amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;tempdb&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files on c?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilesonc -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files count?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilecount -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># How many months before a build is unsupported do I want to fail the test?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.build.warningwindow -Value 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Checks should be excluded?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value LogShipping,ExtendedEvent, HADR, SaReNamed, PseudoSimple,spn, DiskSpace, DatabaseCollation,Agent,Backup,UnusedIndex,LogfileCount,FileGroupBalanced,LogfileSize,MaintenanceSolution,ServerNameMatch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Export-DbcConfig -Path C:\Users\dbachecks\Desktop\development_config.json
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="using-the-different-configurations">Using The Different Configurations&lt;/h2>
&lt;p>Now I have two configurations, one for my Production Environment and one for my development environment. I can run my checks whenever I like (perhaps you will automate this in some way)&lt;/p>
&lt;ul>
&lt;li>Import the production configuration&lt;/li>
&lt;li>Run my tests with that configuration and create a json file for my Power Bi labelled production&lt;/li>
&lt;li>Import the development configuration (and enter the SQL authentication credential)&lt;/li>
&lt;li>Run my tests with that configuration and create a json file for my Power Bi labelled development&lt;/li>
&lt;li>Start Power Bi to show those results&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Import the production config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\production_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the production json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Import the development config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\development_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the development json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Development
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Open the PowerBi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbcPowerBi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have published the Power Bi so that you can see what it would like and have a click around (maybe you can see improvements you would like to contribute)&lt;/p>
&lt;p>now we can see how each environment is performing according to our settings for each environment&lt;/p>
&lt;h2 id="combining-configurations-into-one-result-set">Combining Configurations Into One Result Set&lt;/h2>
&lt;p>As you saw above, by using the Environment parameter of Update-DbcPowerBiDataSource you can add different environments to one report. But if I wanted to have a report for my application APP1 showing both production and development environments but they have different configurations how can I do this?&lt;/p>
&lt;p>Here’s how.&lt;/p>
&lt;ul>
&lt;li>Create a configuration for the production environment (I have used the production configuration one from above but only localhost for the instance)&lt;/li>
&lt;li>Export it using to  C:\Users\dbachecks\Desktop\APP1-Prod_config.json&lt;/li>
&lt;li>Create a configuration for the development environment (I have used the development configuration one from above but only localhost,1401 for the instance)&lt;/li>
&lt;li>Export it using to  C:\Users\dbachecks\Desktop\APP1-Dev_config.json&lt;/li>
&lt;/ul>
&lt;p>Then run&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Import the production config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\APP1-Prod_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the production json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment APP1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Import the development config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\APP1-Dev_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the development json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment APP1 -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbcPowerBi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that this time there is an Append on the last Invoke-DbcCheck this creates a single json file for the PowerBi and the results look like this. Now we have the results for our application and both the production environment localhost and the development container localhost,1401&lt;/p>
&lt;h2 id="its-open-source--we-want-your-ideas-issues-new-code">It’s Open Source – We Want Your Ideas, Issues, New Code&lt;/h2>
&lt;p>dbachecks is open-source &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks" target="_blank" rel="noopener"
>available on GitHub for anyone to contribute&lt;/a>&lt;/p>
&lt;p>We would love you to contribute. Please open issues for new tests, enhancements, bugs. Please fork the repository and add code to improve the module. please give feedback to make this module even more useful&lt;/p>
&lt;p>You can also come in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> and join the dbachecks channel and get advice, make comments or just join in the conversation&lt;/p>
&lt;h2 id="thank-you">Thank You&lt;/h2>
&lt;p>I want to say thank you to all of the people who have enabled dbachecks to get this far. These wonderful people have used their own time to ensure that you have a useful tool available to you for free&lt;/p>
&lt;p>Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a>&lt;/p>
&lt;p>Fred Weinmann &lt;a class="link" href="https://twitter.com/FredWeinmann" target="_blank" rel="noopener"
>@FredWeinmann&lt;/a>&lt;/p>
&lt;p>Cláudio Silva &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>@ClaudioESSilva&lt;/a>&lt;/p>
&lt;p>Stuart Moore &lt;a class="link" href="https://github.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a>&lt;/p>
&lt;p>Shawn Melton &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>&lt;/p>
&lt;p>Garry Bargsley &lt;a class="link" href="https://twitter.com/gbargsley" target="_blank" rel="noopener"
>@gbargsley&lt;/a>&lt;/p>
&lt;p>Stephen Bennett &lt;a class="link" href="https://twitter.com/staggerlee011" target="_blank" rel="noopener"
>@staggerlee011&lt;/a>&lt;/p>
&lt;p>Sander Stad &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>@SQLStad&lt;/a>&lt;/p>
&lt;p>Jess Pomfret &lt;a class="link" href="https://twitter.com/jpomfret" target="_blank" rel="noopener"
>@jpomfret&lt;/a>&lt;/p>
&lt;p>Jason Squires &lt;a class="link" href="https://twitter.com/js0505" target="_blank" rel="noopener"
>@js0505&lt;/a>&lt;/p>
&lt;p>Shane O’Neill &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>@SOZDBA&lt;/a>&lt;/p>
&lt;p>and all of the other people who have contributed in the dbachecks Slack channel&lt;/p></description></item><item><title>Using the AST in Pester for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</link><pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Pester-results-1.png" alt="Featured image of post Using the AST in Pester for dbachecks" />&lt;p>TagLine – My goal – Chrissy will appreciate Unit Tests one day 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>Cláudio Silva&lt;/a> has improved my &lt;a class="link" href="https://blog.robsewell.com/a-pretty-powerbi-pester-results-template-file/" target="_blank" rel="noopener"
>PowerBi For Pester&lt;/a> file and made it beautiful and whilst we were discussing this we found that if the Pester Tests were not formatted correctly the Power Bi looked … well rubbish to be honest! Chrissy asked if we could enforce some rules for writing our Pester tests.&lt;/p>
&lt;p>The rules were&lt;/p>
&lt;p>The Describe title should be in double quotes&lt;br>
The Describe should use the plural Tags parameter&lt;br>
The Tags should be singular&lt;br>
The first Tag should be a unique tag in Get-DbcConfig&lt;br>
The context title should end with $psitem&lt;br>
The code should use Get-SqlInstance or Get-ComputerName&lt;br>
The Code should use the forEach method&lt;br>
The code should not use $_&lt;br>
The code should contain a Context block&lt;/p>
&lt;p>She asked me if I could write the Pester Tests for it and this is how I did it. I needed to look at the Tags parameter for the Describe. It occurred to me that this was a job for the Abstract Syntax Tree (AST). I don’t know very much about the this but I sort of remembered reading a blog post by &lt;a class="link" href="http://www.lazywinadmin.com/2016/08/powershellpester-make-sure-your.html" target="_blank" rel="noopener"
>Francois-Xavier Cat about using it with Pester&lt;/a> so I went and read that and &lt;a class="link" href="https://stackoverflow.com/questions/39909021/parsing-powershell-script-with-ast" target="_blank" rel="noopener"
>found an answer on Stack Overflow&lt;/a> as well. These looked just like what I needed so I made use of them. Thank you very much to Francois-Xavier and wOxxOm for sharing.&lt;/p>
&lt;p>The first thing I did was to get the Pester Tests which we have located in a checks folder and loop through them and get the content of the file with the Raw parameter&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Describes titles and tags&amp;quot; {
&lt;/code>&lt;/pre>
&lt;p>Then I decided to look at the Describes using the method that wOxxOm (I know no more about this person!) showed.&lt;/p>
&lt;pre>&lt;code>$Describes = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\]\] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'describe'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
$tagIdx = $CE.IndexOf(($CE |Where ParameterName -eq'Tags') ) + 1
$tags = if ($tagIdx -and $tagIdx -lt $CE.Count) {
$CE\[$tagIdx\].Extent
}
New-Object PSCustomObject -Property @{
Name = $secondString
Tags = $tags
}
}
&lt;/code>&lt;/pre>
&lt;p>As I understand it, this code is using the Parser on the $check (which contains the code from the file) and finding all of the Describe commands and creating an object of the title of the Describe with the StaticType equal to String and values from the Tag parameter.&lt;/p>
&lt;p>When I ran this against the database tests file I got the following results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-describes-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Then it was a simple case of writing some tests for the values&lt;/p>
&lt;pre>&lt;code>@($describes).Foreach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$title Should Use a double quote after the Describe&amp;quot; {
$PSItem.Name.ToString().Startswith('&amp;quot;')| Should be $true
$PSItem.Name.ToString().Endswith('&amp;quot;')| Should be $true
}
It &amp;quot;$title should use a plural for tags&amp;quot; {
$PsItem.Tags| Should Not BeNullOrEmpty
}
# a simple test for no esses apart from statistics and Access!!
if ($null -ne $PSItem.Tags) {
$PSItem.Tags.Text.Split(',').Trim().Where{($_ -ne '$filename') -and ($_ -notlike '\*statistics\*') -and ($_ -notlike '\*BackupPathAccess\*') }.ForEach{
It &amp;quot;$PsItem Should Be Singular&amp;quot; {
$_.ToString().Endswith('s')| Should Be $False
}
}
It &amp;quot;The first Tag Should Be in the unique Tags returned from Get-DbcCheck&amp;quot; {
$UniqueTags -contains $PSItem.Tags.Text.Split(',') \[0\].ToString()| Should Be $true
}
}
else {
It &amp;quot;You haven't used the Tags Parameter so we can't check the tags&amp;quot; {
$false| Should be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The Describes variable is inside @() so that if there is only one the ForEach Method will still work. The unique tags are returned from our command Get-DbcCheck which shows all of the checks. We will have a unique tag for each test so that they can be run individually.&lt;/p>
&lt;p>Yes, I have tried to ensure that the tags are singular by ensuring that they do not end with an s (apart from statistics) and so had to not check  BackupPathAccess and statistics. Filename is a variable that we add to each Describe Tags so that we can run all of the tests in one file. I added a little if block to the Pester as well so that the error if the Tags parameter was not passed was more obvious&lt;/p>
&lt;p>I did the same with the context blocks as well&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Contexts&amp;quot; {
## Find the Contexts
$Contexts = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\] \] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'Context'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
New-Object PSCustomObject -Property @{
Name = $secondString
}
}
@($Contexts).ForEach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$Title Should end with `$psitem So that the PowerBi will work correctly&amp;quot; {
$PSItem.Name.ToString().Endswith('psitem&amp;quot;')| Should Be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This time we look for the Context command and ensure that the string value ends with psitem as the PowerBi parses the last value when creating columns&lt;/p>
&lt;p>Finally I got all of the code and check if it matches some coding standards&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Code&amp;quot; {
## This just grabs all the code
$AST = \[System.Management.Automation.Language.Parser\] ::ParseInput($Check, \[ref\]$null, \[ref\]$null)
$Statements = $AST.EndBlock.statements.Extent
## Ignore the filename line
@($Statements.Where{$_.StartLineNumber -ne 1}).ForEach{
$title = \[regex\]::matches($PSItem.text, &amp;quot;Describe(. *)-Tag&amp;quot;).groups\[1\].value.Replace('&amp;quot;', '').Replace ('''', '').trim()
It &amp;quot;$title Should Use Get-SqlInstance or Get-ComputerName&amp;quot; {
($PSItem.text -Match 'Get-SqlInstance') -or ($psitem.text -match 'Get-ComputerName')| Should be $true
}
It &amp;quot;$title Should use the ForEach Method&amp;quot; {
($Psitem.text -match 'Get-SqlInstance\\).ForEach {') -or ($Psitem.text -match 'Get-ComputerName\\). ForEach{')| Should Be $true# use the \ to escape the )
}
It &amp;quot;$title Should not use `$_&amp;quot; {
($Psitem.text -match '$_')| Should Be $false
}
It &amp;quot;$title Should Contain a Context Block&amp;quot; {
$Psitem.text -match 'Context'| Should Be $True
}
}
&lt;/code>&lt;/pre>
&lt;p>I trim the title from the Describe block so that it is easy to see where the failures (or passes) are with some regex and then loop through each statement apart from the first line to ensure that the code is using our internal commands Get-SQLInstance or Get-ComputerName to get information, that we are looping through each of those arrays using the ForEach method rather than ForEach-Object and using $psitem rather than $_ to reference the “This Item” in the array and that each Describe block has a context block.&lt;/p>
&lt;p>This should ensure that any new tests that are added to the module follow the guidance we have set up on the Wiki and ensure that the Power Bi results still look beautiful!&lt;/p>
&lt;p>Anyone can run the tests using&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\\tests\\Unit.Tests.ps1 -show Fails
&lt;/code>&lt;/pre>
&lt;p>before they create a Pull request and it looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Pester-results-1.png"
loading="lazy"
>&lt;/p>
&lt;p>if everything is Green then they can submit their Pull Request 🙂 If not they can see quickly that something needs to be fixed. (fail early 🙂 )&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-fails.png"
loading="lazy"
alt="03 fails.png"
>&lt;/p></description></item><item><title>Converting a Datarow to a JSON object with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-a-datarow-to-a-json-object-with-powershell/</link><pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-a-datarow-to-a-json-object-with-powershell/</guid><description>&lt;p>This is just a quick post. As is frequent with these they are as much for me to refer to in the future and also because the very act of writing it down will aid me in remembering. I encourage you to do the same. Share what you learn because it will help you as well as helping others.&lt;/p>
&lt;p>Anyway, I was writing some Pester tests for a module that I was writing when I needed some sample data. I have &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>written before about using Json for this purpose&lt;/a> This function required some data from a database so I wrote the query to get the data and used &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> to run the query against the database using &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase" target="_blank" rel="noopener"
>Get-DbaDatabase&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance $Instance -Database $Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Simple enough. I wanted to be able to Mock &lt;code>$variable.&lt;/code> I wrapped the code above in a function, let’s call it &lt;code>Run-Query&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Run-Query {(Param $query)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance $Instance -Database $Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Which meant that I could easily separate it for mocking in my test. I ran the code and investigated the $variable variable to ensure it had what I wanted for my test and then decided to convert it into JSON using &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/convertto-json?view=powershell-5.1?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>ConvertTo-Json&lt;/a>&lt;/p>
&lt;p>Lets show what happens with an example using WideWorldImporters and a query I found on &lt;a class="link" href="https://littlekendra.com/2016/09/13/deadlock-code-for-the-wideworldimporters-sample-database/" target="_blank" rel="noopener"
>Kendra Littles blogpost about deadlocks&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SELECT Top 10 CityName, StateProvinceName, sp.LatestRecordedPopulation, CountryName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM Application.Cities AS city
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN Application.StateProvinces AS sp on
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">city.StateProvinceID = sp.StateProvinceID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN Application.Countries AS ctry on
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sp.CountryID=ctry.CountryID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE sp.StateProvinceName = N&amp;#39;Virginia&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ORDER BY CityName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance rob-xps -Database WideWorldImporters
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If I investigate the &lt;code>$variable&lt;/code> variable I get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/data-results.png"
loading="lazy"
alt="data results"
>&lt;/p>
&lt;p>The results were just what I wanted so I thought I will just convert them to JSON and save them in a file and bingo I have some test data in a mock to ensure my code is doing what I expect. However, when I run&lt;/p>
&lt;p>&lt;code>$variable | ConvertTo-Json&lt;/code>&lt;/p>
&lt;p>I get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/json-error.png"
loading="lazy"
alt="json error.png"
>&lt;/p>
&lt;p>and thats just for one row!&lt;/p>
&lt;p>The way to resolve this is to only select the data that we need. The easiest way to do this is to exclude the properties that we don’t need&lt;/p>
&lt;p>&lt;code>$variable | Select-Object * -ExcludeProperty ItemArray, Table, RowError, RowState, HasErrors | ConvertTo-Json&lt;/code>&lt;/p>
&lt;p>which gave me what I needed and a good use case for -ExcludeProperty&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/json-fixed.png"
loading="lazy"
alt="json fixed.png"
>&lt;/p></description></item><item><title>Handling Missing Instances when Looping with Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/handling-missing-instances-when-looping-with-pester/</link><pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/handling-missing-instances-when-looping-with-pester/</guid><description>&lt;p>In my previous posts about &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>writing your first Pester Test&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/2-ways-to-loop-through-collections-in-pester/" target="_blank" rel="noopener"
>looping through instances&lt;/a> I described how you can start to validate that your SQL Server is how YOU want it to be.&lt;/p>
&lt;h2 id="unavailable-machines">Unavailable machines&lt;/h2>
&lt;p>Once you begin to have a number of tests for a number of instances you want to be able to handle any machines that are not available cleanly otherwise you might end up with something like this.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-error.png"
loading="lazy"
alt="01 - error.png"
>&lt;/p>
&lt;p>In this (made up) example we loop through 3 instances and try to check the DNS Server entry is correct but for one of them we get a massive error and if we had created a large number of tests for each machine we would have a large number of massive errors.&lt;/p>
&lt;h2 id="empty-collection">Empty Collection&lt;/h2>
&lt;p>If we don’t successfully create our collection we might have an empty collection which will give us a different issue. No tests&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/02-no-tests.png"
loading="lazy"
alt="02 - no tests.png"
>&lt;/p>
&lt;p>If this was in amongst a whole number of tests we would not have tested anything in this Describe block and might be thinking that our tests were OK because we had no failures of our tests. We would be wrong!&lt;/p>
&lt;h2 id="dealing-with-empty-collections">Dealing with Empty Collections&lt;/h2>
&lt;p>One way of dealing with empty collections is to test that they have more than 0 members&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($instances.count -gt 0) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Tests in here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - The collection is empty. Did you set `$Instances correctly?&amp;#34;}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice the backtick ` before the $ to escape it in the Write-Warning. An empty collection now looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/03-uh-oh.png"
loading="lazy"
alt="03 - uh-oh.png"
>&lt;/p>
&lt;p>Which is much better and provides useful information to the user&lt;/p>
&lt;h2 id="dealing-with-unavailable-machines">Dealing with Unavailable Machines&lt;/h2>
&lt;p>If we want to make sure we dont clutter up our test results with a whole load of failures when a machine is unavailable we can use similar logic.&lt;/p>
&lt;p>First we could check if it is responding to a ping (assuming that ICMP is allowed by the firewall and switches) using&lt;/p>
&lt;p>&lt;code>Test-Connection -ComputerName $computer -Count 1 -Quiet -ErrorAction SilentlyContinue&lt;/code>&lt;/p>
&lt;p>This will just try one ping and do it quietly only returning True or False and if there are any errors it shouldn’t mention it&lt;/p>
&lt;p>In the example above I am using PSRemoting and we should make sure that that is working too. So whilst I could use&lt;/p>
&lt;p>&lt;code>Test-WSMan -ComputerName $computer&lt;/code>&lt;/p>
&lt;p>this only checks if a WSMAN connection is possible and not other factors that could be affecting the ability to run remote sessions. Having been caught by this before I have always used &lt;a class="link" href="http://www.leeholmes.com/blog/2009/11/20/testing-for-powershell-remoting-test-psremoting/" target="_blank" rel="noopener"
>this function from Lee Holmes&lt;/a> (Thank you Lee) and thus can use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $computer = $_.Split(&amp;#39;\\&amp;#39;)\[0\]# To get the computername if there is an instance name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if machine responds to ping
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!(Test-Connection-ComputerName $computer-Count 1-Quiet -ErrorAction SilentlyContinue))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - $Computer is not responding to a ping - aborting the tests for this machine&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if PSremoting is possible for this machine
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Requires Test-PSRemoting by Lee Holmes http://www.leeholmes.com/blog/2009/11/20/testing-for-powershell-remoting-test-psremoting/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!(Test-PsRemoting$computer))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - $Computer is not able to use PSRemoting - aborting the tests for this machine&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Testing Instance $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Put tests in here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which provides a result like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/04-better-handling.png"
loading="lazy"
alt="04 - better handling.png"
>&lt;/p>
&lt;p>Which is much better I think 🙂&lt;/p>
&lt;h2 id="let-dbatools-do-the-error-handling-for-you">Let dbatools do the error handling for you&lt;/h2>
&lt;p>If your tests are only using the dbatools module then there is built in error handling that you can use. By default dbatools returns useful messages rather than the exceptions from PowerShell (You can enable the exceptions using the -EnableExceptions parameter if you want/need to) so if we run our example from the previous post it will look like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/05-dbatools-handling.png"
loading="lazy"
alt="05 - dbatools handling.png"
>&lt;/p>
&lt;p>which is fine for a single command but we don’t really want to waste time and resources repeatedly trying to connect to an instance if we know it is not available if we are running multiple commands against each instance.&lt;/p>
&lt;h2 id="dbatools-at-the-beginning-of-the-loop">dbatools at the beginning of the loop&lt;/h2>
&lt;p>We can use &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a>to perform a check at the beginning of the loop as we discussed in the &lt;a class="link" href="https://blog.robsewell.com/2-ways-to-loop-through-collections-in-pester/" target="_blank" rel="noopener"
>previous post&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!((Test-DbaConnection-SqlInstance $_ -WarningAction SilentlyContinue).ConnectSuccess))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - we cannot connect to $_ - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that we have used &lt;code>-WarningAction SilentlyContinue&lt;/code> to hide the warnings from the command this tiime. Our test now looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/06-dbatools-test-dbaconnection.png"
loading="lazy"
alt="06 - dbatools test-dbaconnection.png"
>&lt;/p>
&lt;p>&lt;code>Test-DbaConnection&lt;/code> performs a number of tests so you can check for ping SQL version, domain name and remoting if you want to exclude tests on those basis&lt;/p>
&lt;h2 id="round-up">Round Up&lt;/h2>
&lt;p>In this post we have covered some methods of ensuring that your Pester Tests return what you expect. You don’t want empty collections of SQL Instances making you think you have no failed tests when you have not actually run any tests.&lt;/p>
&lt;p>You can do this by checking how many instances are in the collection&lt;/p>
&lt;p>You also dont want to keep running tests against a machine or instance that is not responding or available.&lt;/p>
&lt;p>You can do this by checking a ping with &lt;code>Test-Connection&lt;/code> or if remoting is required by using the &lt;code>Test-PSRemoting&lt;/code> function from Lee Holmes&lt;/p>
&lt;p>If you want to use dbatools exclusively you can use &lt;code>Test-DbaConnection&lt;/code>&lt;/p>
&lt;p>Here is a framework to put your tests inside. You will need to provide the values for the $Instances and place your tests inside the Describe Block&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($instances.count -gt 0) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TestConnection = Test-DbaConnection-SqlInstance $_ -WarningAction SilentlyContinue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if machine responds to ping
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.IsPingable))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - $_ is not responding to a ping - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if we have remote access to the machine
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.PsRemotingAccessible))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - $_ is not able to use PSRemoting - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if we have SQL connection to the Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.ConnectSuccess))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - we cannot connect to SQL on $_ - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Testing Instance $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Now put your tests in here - seperate them with context blocks if you want to
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Networks&amp;#34; { }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## If the collection is empty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - The collection is empty. Did you set `$Instances correctly?&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>2 Ways to Loop through collections in Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</link><pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</guid><description>&lt;p>In my last post I showed you &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>how to write your first Pester test&lt;/a> to validate something. Here’s a recap&lt;/p>
&lt;ul>
&lt;li>Decide the information you wish to test&lt;/li>
&lt;li>Understand how to get it with PowerShell&lt;/li>
&lt;li>Understand what makes it pass and what makes it fail&lt;/li>
&lt;li>Write a Pester Test&lt;/li>
&lt;/ul>
&lt;p>You probably have more than one instance that you want to test, so how do you loop through a collection of instances? There are a couple of ways.&lt;/p>
&lt;h2 id="getting-the-latest-version-of-the-module">Getting the Latest Version of the Module&lt;/h2>
&lt;p>Steve Jones wrote about getting the latest version of Pester and the correct way to do it. You can &lt;a class="link" href="https://voiceofthedba.com/2017/11/27/installing-pester/" target="_blank" rel="noopener"
>find the important information here&lt;/a>&lt;/p>
&lt;h2 id="test-cases">Test Cases&lt;/h2>
&lt;p>The first way is to use the Test Case parameter of the It command (the test) which I have written about when &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>using TDD for Pester here&lt;/a>&lt;/p>
&lt;p>Lets write a test first to check if we can successfully connect to a SQL Instance. Running&lt;/p>
&lt;p>&lt;code>Find-DbaCommand connection&lt;/code>&lt;/p>
&lt;p>shows us that the &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a> command is the one that we want from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>. We should always run Get-Help to understand how to use any PowerShell command. This shows us that the results will look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-gethelp-test-dbaconnection.png"
loading="lazy"
alt="01 - gethelp test-dbaconnection"
>&lt;/p>
&lt;p>So there is a ConnectSuccess result which returns True or false. Our test can look like this for a single instance&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to ROB-XPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    It &amp;#34;Connects successfully to ROB-XPS&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        (Test-DbaConnection-SqlInstance ROB-XPS).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which gives us some test results that look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/successful-test.png"
loading="lazy"
alt="successful test.png"
>&lt;/p>
&lt;p>which is fine for one instance but we want to check many.&lt;/p>
&lt;p>We need to gather the instances into a $Instances variable. In my examples I have hard coded a list of SQL Instances but you can, and probably should, use a more dynamic method, maybe the results of a query to a configuration database. Then we can fill our TestCases variable which can be done like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we can write our test like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to SQL Instances&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Put the TestCases &amp;#39;Name&amp;#39; in &amp;lt;&amp;gt; and add the TestCases parameter
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Connects successfully to &amp;lt;Instance&amp;gt;&amp;#34; -TestCases $TestCases {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Add a Parameter to the test with the same name as the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param($Instance)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write the test using the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Test-DbaConnection -SqlInstance $Instance).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Within the title of the test we refer to the instance inside &amp;lt;&amp;gt; and add the parameter TestCases with a value of the $TestCases variable. We also need to add a Param() to the test with the same name and then use that variable in the test.&lt;/p>
&lt;p>This looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/Testcases-test.png"
loading="lazy"
alt="Testcases test.png"
>&lt;/p>
&lt;h2 id="pester-is-powershell">Pester is PowerShell&lt;/h2>
&lt;p>The problem with  Test Cases is that we can only easily loop through one collection, but as Pester is just PowerShell we can simply use ForEach if we wanted to loop through multiple ones, like instances and then databases.&lt;/p>
&lt;p>I like to use the ForEach method as it is slightly quicker than other methods. It will only work with PowerShell version 4 and above. Below that version you need to pipe the collection to For-EachObject.&lt;/p>
&lt;p>Lets write a test to see if our databases have trustworthy set on. We can do this using the Trustworthy property returned from &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase/" target="_blank" rel="noopener"
>&lt;code>Get-DbaDatabase&lt;/code>&lt;/a>&lt;/p>
&lt;p>We loop through our Instances using the ForEach method and create a Context for each Instance to make the test results easier to read. We then place the call to &lt;code>Get-DbaDatabase &lt;/code>inside braces and loop through those and check the Trustworthy property&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing user databases&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the instances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Create a Context for each Instance.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing User Databases on $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the User databases on the instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Get-DbaDatabase -SqlInstance $_ -ExcludeAllSystemDb).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Refer to the database name and Instance name inside a $()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Database $($_.Name) on Instance $($_.Parent.Name) should not have TRUSTWORTHY ON&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $_.Trustworthy | Should Be $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and it looks like this&lt;/p>
&lt;h2 id="testdatabasetrustworthypnghttpsblogrobsewellcomassetsuploads201711testdatabasetrustworthypng">&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/testdatabasetrustworthy.png"
loading="lazy"
alt="testdatabasetrustworthy.png"
>&lt;/h2>
&lt;p>So there you have two different ways to loop through collections in your Pester tests. Hopefully this can help you to write some good tests to validate your environment.&lt;/p>
&lt;p>Happy Pestering&lt;/p>
&lt;h2 id="spend-a-whole-day-with-chrissy--i-at-sqlbits">Spend a Whole Day With Chrissy &amp;amp; I at SQLBits&lt;/h2>
&lt;p>If you would like to spend a whole day with Chrissy LeMaire and I at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> in London in February – we have a pre-con on the Thursday&lt;/p>
&lt;p>You can find out more about the pre-con &lt;a class="link" href="http://sqlps.io/bitsprecon" target="_blank" rel="noopener"
>sqlps.io/bitsprecon&lt;/a>&lt;/p>
&lt;p>and you can register at &lt;a class="link" href="http://sqlps.io/bitsreg" target="_blank" rel="noopener"
>sqlps.io/bitsreg&lt;/a>&lt;/p></description></item><item><title>2 Ways to Loop through collections in Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</link><pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</guid><description>&lt;p>In my last post I showed you &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>how to write your first Pester test&lt;/a> to validate something. Here’s a recap&lt;/p>
&lt;ul>
&lt;li>Decide the information you wish to test&lt;/li>
&lt;li>Understand how to get it with PowerShell&lt;/li>
&lt;li>Understand what makes it pass and what makes it fail&lt;/li>
&lt;li>Write a Pester Test&lt;/li>
&lt;/ul>
&lt;p>You probably have more than one instance that you want to test, so how do you loop through a collection of instances? There are a couple of ways.&lt;/p>
&lt;h2 id="getting-the-latest-version-of-the-module">Getting the Latest Version of the Module&lt;/h2>
&lt;p>Steve Jones wrote about getting the latest version of Pester and the correct way to do it. You can &lt;a class="link" href="https://voiceofthedba.com/2017/11/27/installing-pester/" target="_blank" rel="noopener"
>find the important information here&lt;/a>&lt;/p>
&lt;h2 id="test-cases">Test Cases&lt;/h2>
&lt;p>The first way is to use the Test Case parameter of the It command (the test) which I have written about when &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>using TDD for Pester here&lt;/a>&lt;/p>
&lt;p>Lets write a test first to check if we can successfully connect to a SQL Instance. Running&lt;/p>
&lt;p>&lt;code>Find-DbaCommand connection&lt;/code>&lt;/p>
&lt;p>shows us that the &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a> command is the one that we want from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>. We should always run Get-Help to understand how to use any PowerShell command. This shows us that the results will look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-gethelp-test-dbaconnection.png"
loading="lazy"
alt="01 - gethelp test-dbaconnection"
>&lt;/p>
&lt;p>So there is a ConnectSuccess result which returns True or false. Our test can look like this for a single instance&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to ROB-XPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    It &amp;#34;Connects successfully to ROB-XPS&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        (Test-DbaConnection-SqlInstance ROB-XPS).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which gives us some test results that look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/successful-test.png"
loading="lazy"
alt="successful test.png"
>&lt;/p>
&lt;p>which is fine for one instance but we want to check many.&lt;/p>
&lt;p>We need to gather the instances into a $Instances variable. In my examples I have hard coded a list of SQL Instances but you can, and probably should, use a more dynamic method, maybe the results of a query to a configuration database. Then we can fill our TestCases variable which can be done like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we can write our test like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to SQL Instances&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Put the TestCases &amp;#39;Name&amp;#39; in &amp;lt;&amp;gt; and add the TestCases parameter
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Connects successfully to &amp;lt;Instance&amp;gt;&amp;#34; -TestCases $TestCases {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Add a Parameter to the test with the same name as the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param($Instance)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write the test using the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Test-DbaConnection -SqlInstance $Instance).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Within the title of the test we refer to the instance inside &amp;lt;&amp;gt; and add the parameter TestCases with a value of the $TestCases variable. We also need to add a Param() to the test with the same name and then use that variable in the test.&lt;/p>
&lt;p>This looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/Testcases-test.png"
loading="lazy"
alt="Testcases test.png"
>&lt;/p>
&lt;h2 id="pester-is-powershell">Pester is PowerShell&lt;/h2>
&lt;p>The problem with  Test Cases is that we can only easily loop through one collection, but as Pester is just PowerShell we can simply use ForEach if we wanted to loop through multiple ones, like instances and then databases.&lt;/p>
&lt;p>I like to use the ForEach method as it is slightly quicker than other methods. It will only work with PowerShell version 4 and above. Below that version you need to pipe the collection to For-EachObject.&lt;/p>
&lt;p>Lets write a test to see if our databases have trustworthy set on. We can do this using the Trustworthy property returned from &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase/" target="_blank" rel="noopener"
>&lt;code>Get-DbaDatabase&lt;/code>&lt;/a>&lt;/p>
&lt;p>We loop through our Instances using the ForEach method and create a Context for each Instance to make the test results easier to read. We then place the call to &lt;code>Get-DbaDatabase &lt;/code>inside braces and loop through those and check the Trustworthy property&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing user databases&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the instances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Create a Context for each Instance.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing User Databases on $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the User databases on the instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Get-DbaDatabase -SqlInstance $_ -ExcludeAllSystemDb).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Refer to the database name and Instance name inside a $()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Database $($_.Name) on Instance $($_.Parent.Name) should not have TRUSTWORTHY ON&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $_.Trustworthy | Should Be $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and it looks like this&lt;/p>
&lt;h2 id="testdatabasetrustworthypnghttpsblogrobsewellcomassetsuploads201711testdatabasetrustworthypng">&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/testdatabasetrustworthy.png"
loading="lazy"
alt="testdatabasetrustworthy.png"
>&lt;/h2>
&lt;p>So there you have two different ways to loop through collections in your Pester tests. Hopefully this can help you to write some good tests to validate your environment.&lt;/p>
&lt;p>Happy Pestering&lt;/p>
&lt;h2 id="spend-a-whole-day-with-chrissy--i-at-sqlbits">Spend a Whole Day With Chrissy &amp;amp; I at SQLBits&lt;/h2>
&lt;p>If you would like to spend a whole day with Chrissy LeMaire and I at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> in London in February – we have a pre-con on the Thursday&lt;/p>
&lt;p>You can find out more about the pre-con &lt;a class="link" href="http://sqlps.io/bitsprecon" target="_blank" rel="noopener"
>sqlps.io/bitsprecon&lt;/a>&lt;/p>
&lt;p>and you can register at &lt;a class="link" href="http://sqlps.io/bitsreg" target="_blank" rel="noopener"
>sqlps.io/bitsreg&lt;/a>&lt;/p></description></item><item><title>Write Your first Pester Test Today</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/write-your-first-pester-test-today/</link><pubDate>Thu, 16 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/write-your-first-pester-test-today/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>dbatools with SQL on Docker and running SQL queries</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-with-sql-on-docker-and-running-sql-queries/</link><pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-with-sql-on-docker-and-running-sql-queries/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>$srv.Query($Query)&lt;/p>
&lt;p>$srv.Query($Query).column1&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>A Pretty PowerBi Pester Results Template File</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-pretty-powerbi-pester-results-template-file/</link><pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-pretty-powerbi-pester-results-template-file/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>TSQL2sDay – Get-PostRoundup</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</link><pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>#TSQL2sDay – Starting Out with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-starting-out-with-powershell/</link><pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-starting-out-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>TSQL2sday #94 Lets get all Posh!</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</link><pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</guid><description>&lt;p>Write-Output &amp;ldquo;What are you going to automate today?&amp;rdquo;&lt;/p>
&lt;p> &lt;/p>
&lt;p>Welcome to T-SQL Tuesday for September 2017!&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/08/tsql2sday.jpg"
loading="lazy"
alt="tsql2sday"
>
&lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>T-SQL Tuesday&lt;/a> is a chance for you to join in the SQL Server community and write a blog post on a suggested topic. It makes for a great way to find a bunch of blog posts showing the same subject from many different viewpoints. Please join in and write a blog post, maybe it&amp;rsquo;s your first ever, maybe you haven&amp;rsquo;t blogged for a while but even if you blog every day come and join the party and share your knowledge.&lt;/p>
&lt;p>To participate:&lt;/p>
&lt;ol>
&lt;li>Write a post on the topic below&lt;/li>
&lt;li>Schedule the post to go live on Tuesday, September 12th (between zero am and midnight, UTC)&lt;/li>
&lt;li>Include the &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2010/06/01/t-sql-tuesday-007-and-t-sql-tuesday-has-a-logo.aspx" target="_blank" rel="noopener"
>TSQL Tuesday logo&lt;/a> in the top of your post&lt;/li>
&lt;li>Link the post back to this one (it’s easier if you comment on this post and link it)&lt;/li>
&lt;li>Optional: Tweet a link to your post using the &lt;a class="link" href="https://twitter.com/hashtag/TSQL2sday?src=hash" target="_blank" rel="noopener"
>#tsql2sday hash tag on Twitter&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Extra credit: if you’d like to host your own TSQL Tuesday in the future, &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2017/01/03/t-sql-tuesday-rules-of-engagement.aspx" target="_blank" rel="noopener"
>read the full rules for info on how to sign up&lt;/a>. Just like I did but don&amp;rsquo;t forget its your month!!&lt;/p>
&lt;h2 id="this-months-topic-lets-get-all-posh---what-are-you-going-to-automate-today">This month’s topic: Let&amp;rsquo;s get all Posh - What are you going to automate today?&lt;/h2>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/PowerShell.png"
loading="lazy"
alt="PowerShell"
>
It is no surprise to those that know me that I will choose PowerShell as the topic for this month. I am passionate about PowerShell because it has enabled me to have the career I have today and to visit numerous countries all around the world, meet people and talk about PowerShell. By my reckoning &lt;a class="link" href="http://tsqltuesday.com/?s=PowerShell" target="_blank" rel="noopener"
>searching the TSQL Tuesday website&lt;/a> it has been over 3 years since we had a topic specific to PowerShell. So I would like you to blog about PowerShell and SQL Server (or other interesting data platform products)&lt;/p>
&lt;p>If you don&amp;rsquo;t know or use PowerShell GREAT! That&amp;rsquo;s awesome.&lt;/p>
&lt;p>Please spend an hour or so with it and tell us how you got on and what and how you learned. Just like &lt;a class="link" href="https://www.brentozar.com/archive/2017/07/live-blogging-erik-vs-PowerShell/" target="_blank" rel="noopener"
>Erik and Brent did&lt;/a>. You could install one of the community modules like &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>, &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> , &lt;a class="link" href="https://www.PowerShellgallery.com/packages/SQLDiagAPI" target="_blank" rel="noopener"
>SQLDiagAPI&lt;/a>  or the Microsoft ones &lt;a class="link" href="https://www.PowerShellgallery.com/packages/Sqlserver" target="_blank" rel="noopener"
>sqlserver&lt;/a> or &lt;a class="link" href="https://github.com/Microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>SSRS&lt;/a> and try them out and tell us what you learned.&lt;/p>
&lt;p>If you want help whilst doing this please make use of the #PowerShellhelp channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a>&lt;/p>
&lt;p>This will be of so much benefit to all people who don&amp;rsquo;t use PowerShell and want to start to learn about it.&lt;/p>
&lt;p>If you do use PowerShell and SQL then either tell the tale of the best thing you have automated or a beginners post to show people how to start using PowerShell. I have heard many stories and am looking forward to tales of&lt;/p>
&lt;ul>
&lt;li>testing backups&lt;/li>
&lt;li>doing migrations&lt;/li>
&lt;li>resetting log shipping&lt;/li>
&lt;li>creating things in the cloud and on premises&lt;/li>
&lt;li>SQL on Linux with PowerShell on Linux&lt;/li>
&lt;li>using Pester for testing&lt;/li>
&lt;li>automating manual tasks&lt;/li>
&lt;li>automating incident knowledge gathering&lt;/li>
&lt;li>continuous integration and delivery&lt;/li>
&lt;/ul>
&lt;p>and many more. I will read all of them and do a write up of them later next week.&lt;/p>
&lt;p>Invoke-Coffee&lt;/p>
&lt;p>Start-BlogWriting -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Get-BlogProofRead&lt;/p>
&lt;p>Post-Blog -Date ‘September 12th 2017’ -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Write-Tweet -Hashtag ‘TSQL2sday’ -Message &amp;lsquo;This is my cool blogpost&amp;rsquo;&lt;/p>
&lt;p> &lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/keep-calm-and-PowerShell.jpg"
loading="lazy"
alt="keep calm and PowerShell.jpg"
>&lt;/p></description></item><item><title>Using Get-SQLDiagFix to get information from the SQL Server Diagnostic API with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-get-sqldiagfix-to-get-information-from-the-sql-server-diagnostic-api-with-powershell/</link><pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-get-sqldiagfix-to-get-information-from-the-sql-server-diagnostic-api-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Creating a PowerShell Module and TDD for Get-SQLDiagRecommendations</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</link><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>VSCode – PowerShell extension 1.4.0 new command Out-CurrentFile</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vscode-powershell-extension-1.4.0-new-command-out-currentfile/</link><pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vscode-powershell-extension-1.4.0-new-command-out-currentfile/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>dbatools at #SQLSatDublin</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-at-#sqlsatdublin/</link><pubDate>Wed, 21 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-at-#sqlsatdublin/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>VS Code – Automatic Dynamic PowerShell Help</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-automatic-dynamic-powershell-help/</link><pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-automatic-dynamic-powershell-help/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</link><pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png" alt="Featured image of post PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value" />&lt;p>I was chatting on the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Community Slack&lt;/a> with my friend Sander Stad &lt;a class="link" href="http://www.sqlstad.nl/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>t&lt;/a> about some functions he is writing for the amazing PowerShell SQL Server Community module &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>. He was asking my opinion as to how to enable user choice or options for Agent Schedules and I said that he should validate the input of the parameters. He said that was difficult as if the parameter was Weekly the frequency values required would be different from if the parameter was Daily or Monthly. That’s ok, I said, you can still validate the parameter.&lt;/p>
&lt;p>You can read more about Parameters either online &lt;a class="link" href="https://msdn.microsoft.com/en-us/powershell/reference/5.1/microsoft.powershell.core/about/about_parameters" target="_blank" rel="noopener"
>here&lt;/a> or &lt;a class="link" href="https://msdn.microsoft.com/en-us/powershell/reference/5.1/microsoft.powershell.core/about/about_functions_advanced_parameters" target="_blank" rel="noopener"
>here&lt;/a> or by running&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Get-Help About_Parameters
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-Help About_Functions_Parameters
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can also find more help information with&lt;/p>
&lt;p>&lt;code>Get-Help About_*Parameters*&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png"
loading="lazy"
alt="01 more help.PNG"
>&lt;/a>&lt;/p>
&lt;p>This is not a post about using Parameters, &lt;a class="link" href="https://www.google.co.uk/search?q=powershell&amp;#43;about&amp;#43;paramters&amp;amp;ie=&amp;amp;oe=#safe=strict&amp;amp;q=powershell&amp;#43;parameters&amp;amp;spf=370" target="_blank" rel="noopener"
>google for those&lt;/a> but this is what I showed him.&lt;/p>
&lt;p>Lets create a simple function that accepts 2 parameters Word and Number&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can run it with any parameters&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/02-any-parameters.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/02-any-parameters.png"
loading="lazy"
alt="02 any parameters"
>&lt;/a>&lt;/p>
&lt;p>If we wanted to restrict the Word parameter to only accept Sun, Moon or Earth we can use the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/ms714434%28v=vs.85%29.aspx" target="_blank" rel="noopener"
>ValidateSetAttribute&lt;/a> as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now if we try and set a value for the $Word parameter that isn’t sun moon or earth then we get an error&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/03-parameter-error.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/03-parameter-error.png"
loading="lazy"
alt="03 parameter error.PNG"
>&lt;/a>&lt;/p>
&lt;p>and it tells us that the reason for the error is that TheBeard! does not belong to the set sun, moon, earth.&lt;/p>
&lt;p>But what Sander wanted was to validate the value of the second parameter depending on the value of the first one. So lets say we wanted&lt;/p>
&lt;ul>
&lt;li>If word is sun, number must be 1 or 2&lt;/li>
&lt;li>If word is moon, number must be 3 or 4&lt;/li>
&lt;li>If word is earth, number must be 5 or 6&lt;/li>
&lt;/ul>
&lt;p>We can use the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/system.management.automation.validatescriptattribute%28v=vs.85%29.aspx" target="_blank" rel="noopener"
>ValidateScriptAttribute&lt;/a>  to do this. This requires a script block which returns True or False. You can access the current parameter with &lt;code>$_&lt;/code> so we can use a script block like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The function now looks like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateScript({
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        })]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It will still fail if we use the wrong “Word” in the same way but now if we enter earth and 7 we get this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/04-parameter-error.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/04-parameter-error.png"
loading="lazy"
alt="04 parameter error.PNG"
>&lt;/a>&lt;/p>
&lt;p>But if we enter sun and 1 or moon and 3 or earth and 5 all is well&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/05-working.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/05-working.png"
loading="lazy"
alt="05 working"
>&lt;/a>&lt;/p>
&lt;p>I would add one more thing. We should always write PowerShell functions that are easy for our users to self-help. Of course, this means write good help for the function. here is a great place to start from June Blender&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/06-june.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/06-june.png"
loading="lazy"
alt="06 June.PNG"
>&lt;/a>&lt;/p>
&lt;p>In this example, the error message&lt;/p>
&lt;blockquote>
&lt;p>Test-validation : Cannot validate argument on parameter ‘number’. The ”&lt;br>
if($word -eq ‘Sun’){$_ -eq 1 -or $_ -eq 2}&lt;br>
elseif($word -eq ‘Moon’){$_ -eq 3 -or $_ -eq 4}&lt;br>
elseif($word -eq ‘earth’){$_ -eq 5 -or $_ -eq 6}&lt;br>
” validation script for the argument with value “7” did not return a result of True. Determine why the validation script failed, and then try the&lt;br>
command again.&lt;br>
At line:1 char:39&lt;/p>
&lt;ul>
&lt;li>Test-validation -Word “earth” -number 007&lt;br>
+                                       ~~~&lt;/li>
&lt;li>CategoryInfo          : InvalidData: (:) [Test-validation], ParameterBindingValidationException&lt;/li>
&lt;li>FullyQualifiedErrorId : ParameterArgumentValidationError,Test-validation&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>is not obvious to a none-coder so we could make it easier. As we are passing in a script block we can just add a comment like this. I added a spare line above and below to make it stand out a little more&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateScript({
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            # Sun Accepts 1 or 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Moon Accepts 3 or 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Earth Accepts 5 or 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        })]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now if you enter the wrong parameter you get this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/07-more-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/07-more-help.png"
loading="lazy"
alt="07 more help.PNG"
>&lt;/a>&lt;/p>
&lt;p>which I think makes it a little more obvious&lt;/p></description></item><item><title>PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</link><pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Export SQL User Permissions to T-SQL script using PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/export-sql-user-permissions-to-t-sql-script-using-powershell-and-dbatools/</link><pubDate>Mon, 10 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/export-sql-user-permissions-to-t-sql-script-using-powershell-and-dbatools/</guid><description>&lt;p>NOTE - Updated November 2022 for this site and the correct command name.&lt;/p>
&lt;p>There are times when DBA’s are required to export database user permissions to a file. This may be for a number of reasons. Maybe for DR purposes, for auditing, for transfer to another database or instance. Sometimes we need to create a new user with the same permissions as another user or perhaps nearly the same permissions. I was having a conversation with my good friend and &lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>MVP Cláudio Silva&lt;/a> and we were talking about how &lt;a class="link" href="https://docs.dbatools.io/Export-DbaUser" target="_blank" rel="noopener"
>Export-DbaUser&lt;/a> from &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> could help in these situations and he suggested that I blogged about it so here it is.&lt;/p>
&lt;p>The &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> (for those that don’t know) is a PowerShell module written by amazing folks in the community designed to make administrating your SQL Server significantly easier using PowerShell. The instructions for installing it are &lt;a class="link" href="https://dbatools.io/getting-started/" target="_blank" rel="noopener"
>available here&lt;/a> It comprises of 182 separate commands at present&lt;/p>
&lt;p>Cláudio wrote &lt;a class="link" href="https://docs.dbatools.io/Export-DbaUser" target="_blank" rel="noopener"
>Export-DbaUser&lt;/a> to solve a problem. You should always start with Get-Help whenever you are starting to use a new PowerShell command&lt;/p>
&lt;p>&lt;code>Get-Help Export-DbaUser -ShowWindow&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/01-get-help.png"
loading="lazy"
alt="01 - get help.PNG"
>&lt;/p>
&lt;p>The command exports users creation and its permissions to a T-SQL file or host. Export includes user, create and add to role(s), database level permissions, object level permissions and also the Create Role statements for any roles, although the script does not create IF NOT EXISTS statements which would be an improvement. It also excludes the system databases so if you are scripting users who need access to those databases then that needs to be considered. Cláudio is aware of these and is looking at improving the code to remove those limitations.&lt;/p>
&lt;p>It takes the following parameters&lt;/p>
&lt;ul>
&lt;li>SqlInstance&lt;br>
The SQL Server instance name. SQL Server 2000 and above supported.&lt;/li>
&lt;li>User&lt;br>
Export only the specified database user(s). If not specified will export all users from the database(s)&lt;/li>
&lt;li>DestinationVersion&lt;br>
Which SQL version the script should be generated using. If not specified will use the current database compatibility level&lt;/li>
&lt;li>FilePath&lt;br>
The filepath to write to export the T-SQL.&lt;/li>
&lt;li>SqlCredential&lt;br>
Allows you to login to servers using alternative credentials&lt;/li>
&lt;li>NoClobber&lt;br>
Do not overwrite the file&lt;/li>
&lt;li>Append&lt;br>
Append to the file&lt;/li>
&lt;li>Databases&lt;br>
Not in the help but a dynamic parameter allowing you to specify one or many databases&lt;/li>
&lt;/ul>
&lt;p>Lets take a look at it in action&lt;/p>
&lt;p>&lt;code>Export-DbaUser -SqlInstance SQL2016N2 -FilePath C:\temp\SQL2016N2-Users.sql&lt;/code>
&lt;code>Notepad C:\temp\SQL2016N2-Users.sql&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/02-export-user-server.png"
loading="lazy"
alt="02 - Export user server.PNG"
>&lt;/p>
&lt;p>Lets take a look at a single database&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -FilePath C:\temp\SQL2016N2-Fadetoblack.sql -Databases Fadetoblack
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad C:\temp\SQL2016N2-Fadetoblack.sql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/03-single-database.png"
loading="lazy"
alt="03 single database.PNG"
>&lt;/p>
&lt;p>This is so cool and so easy. It is possible to do this in T-SQL. I found this script on &lt;a class="link" href="http://www.sqlservercentral.com/scripts/Security/71562/" target="_blank" rel="noopener"
>SQLServerCentral&lt;/a> for example which is 262 lines and would then require some mouse action to save to a file&lt;/p>
&lt;p>We can look at a single user as well. Lets see what Lars Ulrich can see on the FadeToBlack database&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/04-export-lars.png"
loading="lazy"
alt="04 - export lars.PNG"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [FadetoBlack]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CREATE USER [UlrichLars] FOR LOGIN [UlrichLars] WITH DEFAULT_SCHEMA=[dbo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GRANT CONNECT TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DENY INSERT ON [dbo].[Finances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DENY SELECT ON [dbo].[RealFinances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GRANT SELECT ON [dbo].[Finances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So he can select data from the Finances table but cannot insert and cannot read the RealFinances data. Now lets suppose a new manager comes in and he wants to be able to look at the data in this database. As the manager though he wants to be able to read the RealFinances table  and insert into the Finances table. He requests that we add those permissions to the database. We can create the T-SQL for Lars user and then do a find and replace for &lt;code>UlrichLars&lt;/code> with &lt;code>TheManager&lt;/code> , &lt;code>DENY INSERT ON [dbo].[Finances]&lt;/code> with &lt;code>GRANT INSERT ON [dbo].[Finances]&lt;/code> and &lt;code>DENY SELECT ON [dbo].[RealFinances]&lt;/code> with &lt;code>GRANT SELECT ON [dbo].[RealFinances]&lt;/code> and save to a new file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$LarsPermsFile = &amp;#39;C:\temp\SQL2016N2-Lars-Fadetoblack.sql&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPermsFile = &amp;#39;C:\temp\SQL2016N2-Manager-Fadetoblack.sql&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -FilePath $LarsPermsFile -User UlrichLars -Databases Fadetoblack
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = Get-Content $LarsPermsFile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## replace permissions
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;DENY INSERT ON [dbo].[Finances]&amp;#39;,&amp;#39;GRANT INSERT ON [dbo].[Finances]&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;DENY SELECT ON [dbo].[RealFinances]&amp;#39;,&amp;#39;GRANT SELECT ON [dbo].[RealFinances]&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;UlrichLars&amp;#39;,&amp;#39;TheManager&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-Content -path $ManagerPermsFile -Value $ManagerPerms
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I will open this in Visual Studio Code Insiders using&lt;/p>
&lt;p>&lt;code>code-insiders $LarsPermsFile , $ManagerPermsFile&lt;/code>&lt;/p>
&lt;p>if you are not using the insiders preview remove the “-insiders”&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/05-code-insiders.png"
loading="lazy"
alt="05 - code insiders.PNG"
>&lt;/p>
&lt;p>You can right click on the Lars file and click select for compare and then right click on the Managers file and select compare with Lars File and get a nice colour coded diff&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/06-compare.gif"
loading="lazy"
alt="06 - compare.gif"
>&lt;/p>
&lt;p>Perfect, we can run that code and complete the request. When we impersonate Lars we get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/07-lars.png"
loading="lazy"
alt="07 - lars.PNG"
>&lt;/p>
&lt;p>but when we run as the manager we get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/08-the-manager.png"
loading="lazy"
alt="08 - the manager.PNG"
>&lt;/p>
&lt;p>Excellent! All is well.&lt;/p>
&lt;p>It turns out that there is another Fadetoblack database on a SQL2000 instance which for reasons lost in time never had its data imported into the newer database. It is still used for reporting purposes. The manager needs to have the same permissions as on the SQL2016N2 instance. Obviously the T-SQL we have just created will not work as that syntax did not exist for SQL 2000 but Cláudio has thought of that too. We can use the DestinationVersion parameter to create the SQL2000 (2005,2008/20008R2,2012,2014,2016) code&lt;/p>
&lt;p>We just run&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -Databases FadetoBlack -User TheManager  -FilePath C:\temp\S
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">QL2016N2-Manager-2000.sql  -DestinationVersion SQLServer2000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Notepad C:\temp\SQL2016N2-Manager-2000.sql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and our SQL2000 compatible code is created&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/09-manager-2000.png"
loading="lazy"
alt="09- manager 2000.PNG"
>&lt;/p>
&lt;p>Simply awesome. Thank you Cláudio&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>NOTE – The major 1.0 release of dbatools due in the summer 2017 may have breaking changes which will stop the above code from working. There are also new commands coming which may replace this command. This blog post was written using dbatools version 0.8.942 You can check your version using&lt;/p>
&lt;p>&lt;code>Get-Module dbatools&lt;/code>&lt;/p>
&lt;p>and update it using an Administrator PowerShell session with&lt;/p>
&lt;p>&lt;code>Update-Module dbatools&lt;/code>&lt;/p>
&lt;p>You may find that you get no output from Update-Module as you have the latest version. If you have not installed the module from the PowerShell Gallery using&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>Then you can use&lt;/p>
&lt;p>&lt;code>Update-dbatools&lt;/code>&lt;/p></description></item><item><title>Testing the Identity Column usage in SQL Server with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-the-identity-column-usage-in-sql-server-with-powershell-and-dbatools/</link><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-the-identity-column-usage-in-sql-server-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Pester with Get-DbaLastGoodCheckDb from dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-get-dbalastgoodcheckdb-from-dbatools/</link><pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-get-dbalastgoodcheckdb-from-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Getting SQLServers Last Known Good DBCC Checkdb with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sqlservers-last-known-good-dbcc-checkdb-with-powershell-and-dbatools/</link><pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sqlservers-last-known-good-dbcc-checkdb-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Test the SQL Server database collation with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-the-sql-server-database-collation-with-powershell-and-dbatools/</link><pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-the-sql-server-database-collation-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Getting SQL Server File Sizes and Space Used with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-file-sizes-and-space-used-with-dbatools/</link><pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-file-sizes-and-space-used-with-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Test your Sqlserver backups on Linux with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-your-sqlserver-backups-on-linux-with-powershell-and-dbatools/</link><pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-your-sqlserver-backups-on-linux-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Pester with dbatools Test-DbaLastBackup</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-dbatools-test-dbalastbackup/</link><pubDate>Sat, 25 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-dbatools-test-dbalastbackup/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Taking dbatools Test-DbaLastBackup a little further</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/taking-dbatools-test-dbalastbackup-a-little-further/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/taking-dbatools-test-dbalastbackup-a-little-further/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Testing Your SQL Server Backups the Easy Way with PowerShell &amp; dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-your-sql-server-backups-the-easy-way-with-powershell-dbatools/</link><pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-your-sql-server-backups-the-easy-way-with-powershell-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Restoring an entire SQL Server user databases with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/restoring-an-entire-sql-server-user-databases-with-powershell-using-dbatools/</link><pubDate>Sat, 18 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/restoring-an-entire-sql-server-user-databases-with-powershell-using-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Quickly Creating Test Users in SQL Server with PowerShell using the sqlserver module and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/02/remove-them-all.png" alt="Featured image of post Quickly Creating Test Users in SQL Server with PowerShell using the sqlserver module and dbatools" />&lt;p>One of the most visited posts on my blog is nearly two and half years old now – &lt;!-- raw HTML omitted -->Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users&lt;!-- raw HTML omitted -->. I thought it was time to update it and use the &lt;!-- raw HTML omitted -->latest sqlserver module&lt;!-- raw HTML omitted --> and the &lt;!-- raw HTML omitted -->dbatools module&lt;!-- raw HTML omitted -->.&lt;/p>
&lt;p>You can get the latest version of the sqlserver module by installing SSMS 2016. The &lt;!-- raw HTML omitted -->PASS PowerShell Virtual Chapter&lt;!-- raw HTML omitted --> have created a short link to make this easier for you to remember: &lt;!-- raw HTML omitted -->&lt;a class="link" href="https://sqlps.io/dl" target="_blank" rel="noopener"
>https://sqlps.io/dl&lt;/a>&lt;!-- raw HTML omitted -->
Once you have downloaded and installed SSMS you can load the module.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Import-Module sqlserver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is one situation where you will get an error loading the sqlserver module into PowerShell. If you have the SQLPS module already imported then you will get the following error:&lt;/p>
&lt;blockquote>
&lt;p>Import-Module : The following error occurred while loading the extended type data file:&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/sqlserver-module-error.png"
loading="lazy"
alt="sqlserver-module-error"
>&lt;/p>
&lt;p>In that case you will need to remove the SQLPS module first.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Remove-Module sqlps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module sqlserver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The original post dealt with creating a number of test users for a database and assigning them to different roles quickly and easily.
First let’s quickly create a list of Admin users and a list of Service Users and save them in a text file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$i = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">while ($I -lt 100) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Beard_Service_User$i&amp;#34; | Out-File &amp;#39;C:\temp\Users.txt&amp;#39; -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $i++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$i = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">while ($I -lt 10) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Beard_Service_Admin_$i&amp;#34; | Out-File &amp;#39;C:\temp\Admins.txt&amp;#39; -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $i++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now that we have those users in files we can assign them to a variable by using &lt;code>Get-Content&lt;/code>&lt;/p>
&lt;p>&lt;code>$Admins = Get-Content 'C:\temp\Admins.txt'&lt;/code>&lt;/p>
&lt;p>Of course we can use any source for our users&lt;/p>
&lt;ul>
&lt;li>a database&lt;/li>
&lt;li>an excel file&lt;/li>
&lt;li>Active Directory&lt;/li>
&lt;li>or even just type them in.&lt;/li>
&lt;/ul>
&lt;p>We can use the &lt;code>Add-SQLLogin&lt;/code> command from the sqlserver module to add our users as SQL Logins, but at present we cannot add them as database users and assign them to a role.&lt;br>
If we want to add a Windows Group or a Windows User to our SQL Server we can do so using:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Add-SqlLogin -ServerInstance $Server -LoginName $User -LoginType WindowsUser -DefaultDatabase tempdb -Enable -GrantConnectSql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that we need to enable and grant connect SQL to the user.&lt;/p>
&lt;p>If we want to add a SQL login the code is pretty much the same but we either have to enter the password in an authentication box or pass in a PSCredential object holding the username and password. Keeping credentials secure in PowerShell scripts is outside the scope of this post and the requirement is for none-live environments so we will pass in the same password for all users as a string to the script. You may want or be required to achieve this in a different fashion.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Pass = ConvertTo-SecureString -String $Password -AsPlainText -Force
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $Pass
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Add-SqlLogin -ServerInstance $Server -LoginName $User -LoginType $LoginType -DefaultDatabase tempdb -Enable -GrantConnectSql -LoginPSCredential $Credential
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can ensure that we are not trying to add logins that already exist using&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if(!($srv.Logins.Contains($User)))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The &lt;code>$srv&lt;/code> is a &lt;!-- raw HTML omitted -->SQL Server Management Server Object&lt;!-- raw HTML omitted --> which you can create using a snippet. I blogged about &lt;!-- raw HTML omitted -->snippets here&lt;!-- raw HTML omitted --> and you can find my &lt;!-- raw HTML omitted -->list of snippets on GitHub here&lt;!-- raw HTML omitted -->. However, today I am going to use the &lt;!-- raw HTML omitted -->dbatools module &lt;!-- raw HTML omitted -->to create a SMO Server Object using the &lt;!-- raw HTML omitted -->Connect-DbaInstance command&lt;!-- raw HTML omitted --> and assign the server and the database to a variable:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Create a SQL Server SMO Object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = Connect-DbaInstance -SqlInstance $server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $srv.Databases[$Database]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once we have our Logins we need to create our database users:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$usr = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.User&amp;#39;) ($db, $User)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$usr.Login = $User
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$usr.Create()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and add them to a database role.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#Add User to the Role
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db.roles[$role].AddMember($User)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I created a little function to call in the script and then simply loop through our users and admins and call the function.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($User in $Users) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Add-UserToRole -Password $Password -User $user -Server $server -Role $Userrole -LoginType SQLLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($User in $Admins) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Add-UserToRole -Password $Password -User $user -Server $server -Role $adminrole -LoginType SQLLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To check that they have been added correctly I simply use the &lt;!-- raw HTML omitted -->Get-DbaRoleMember&lt;!-- raw HTML omitted -->;command from dbatools and output it to &lt;!-- raw HTML omitted -->Out-GridView&lt;!-- raw HTML omitted --> using the alias ogv as I am on the command line:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Get-DbaRoleMember -SqlInstance $server |ogv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which looks like this:&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/get-dbarole-memebr.png"
loading="lazy"
alt="get-dbarole-memebr"
>&lt;/p>
&lt;p>Once we need to clean up the logins and users we can use the &lt;!-- raw HTML omitted -->Get-SQLLogin&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Remove-SQLLogin&lt;!-- raw HTML omitted --> commands from the sqlserver module to remove the logins and if we do that first we can then use the dbatools command &lt;!-- raw HTML omitted -->Remove-SQLOrphanuser&lt;!-- raw HTML omitted --> to remove the orphaned users 🙂 (I thought that was rather cunning!)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">(Get-SqlLogin -ServerInstance $server).Where{$_.Name -like &amp;#39;*Beard_Service_*&amp;#39;}|Remove-SqlLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Remove-SQLOrphanUser -SqlServer $Server -databases $database
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Remove-SQLLogin will prompt for confirmation and the result of the Remove-SQLOrphanUser looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/remove-them-all.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>When you are looking at doing this type of automation with PowerShell, you should remember always to make use of &lt;!-- raw HTML omitted -->Get-Command&lt;!-- raw HTML omitted -->, &lt;!-- raw HTML omitted -->Get-Help&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Get-Member&lt;!-- raw HTML omitted -->. That will enable you to work out how to do an awful lot. I have a short video on youtube about this:&lt;/p>
&lt;p>{% include youtubePlayer.html id=&amp;ldquo;zC-KpI89fkg&amp;rdquo; %}&lt;/p>
&lt;p>and when you get stuck come and ask in the SQL Server Slack at &lt;!-- raw HTML omitted -->&lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;!-- raw HTML omitted -->. You will find a powershellhelp channel in there.&lt;br>
Here is the complete code:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="lnt">71
&lt;/span>&lt;span class="lnt">72
&lt;/span>&lt;span class="lnt">73
&lt;/span>&lt;span class="lnt">74
&lt;/span>&lt;span class="lnt">75
&lt;/span>&lt;span class="lnt">76
&lt;/span>&lt;span class="lnt">77
&lt;/span>&lt;span class="lnt">78
&lt;/span>&lt;span class="lnt">79
&lt;/span>&lt;span class="lnt">80
&lt;/span>&lt;span class="lnt">81
&lt;/span>&lt;span class="lnt">82
&lt;/span>&lt;span class="lnt">83
&lt;/span>&lt;span class="lnt">84
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-v" data-lang="v">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#Requires -module sqlserver&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#Requires -module dbatools&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">###&lt;/span> &lt;span class="nc">Define&lt;/span> &lt;span class="nv">some&lt;/span> &lt;span class="nv">variables&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Password&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Database&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;TheBeardsDatabase&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Admins&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Content&lt;/span> &lt;span class="s1">&amp;#39;C:&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">emp\Admins.txt&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Users&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Content&lt;/span> &lt;span class="s1">&amp;#39;C:&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">emp\Users.txt&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;SQLLogin&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">userrole&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nv">nbsp&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="s1">&amp;#39;Users&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">adminrole&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;Admin&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">#&lt;/span> &lt;span class="nc">Create&lt;/span> &lt;span class="nv">a&lt;/span> &lt;span class="nc">SQL&lt;/span> &lt;span class="nc">Server&lt;/span> &lt;span class="nc">SMO&lt;/span> &lt;span class="nc">Object&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Connect&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">DbaSqlServer&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">SqlServer&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Databases&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Database&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">function&lt;/span> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">param&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Role&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;SQLLogin&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;WindowsGroup&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;WindowsUser&amp;#34;&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Logins&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Contains&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)))&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;SQLLogin&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nc">Pass&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">ConvertTo&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SecureString&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">String&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">AsPlainText&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Force&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nc">Credential&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">New&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Object&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">TypeName&lt;/span> &lt;span class="nc">System&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Management&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Automation&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">PSCredential&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ArgumentList&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Pass&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SqlLogin&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ServerInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginName&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">DefaultDatabase&lt;/span> &lt;span class="nv">tempdb&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Enable&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">GrantConnectSql&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginPSCredential&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Credential&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">elseif&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;WindowsGroup&amp;#39;&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="k">or&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;WindowsUser&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SqlLogin&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ServerInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginName&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">DefaultDatabase&lt;/span> &lt;span class="nv">tempdb&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Enable&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">GrantConnectSql&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Contains&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)))&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">#&lt;/span> &lt;span class="nc">Add&lt;/span> &lt;span class="nv">user&lt;/span> &lt;span class="nv">to&lt;/span> &lt;span class="nv">database&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">New&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Object&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Microsoft.SqlServer.Management.Smo.User&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Login&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Create&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cp">#Add User to the Role&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nv">roles&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">role&lt;/span>&lt;span class="p">].&lt;/span>&lt;span class="nc">AddMember&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">foreach&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Users&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">user&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Role&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Userrole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="nc">SQLLogin&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">foreach&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Admins&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">user&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Role&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">adminrole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="nc">SQLLogin&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">DbaRoleMember&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">SqlInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="nv">ogv&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Happy Automating!&lt;/p></description></item><item><title>SQL VNext sp_configure on Windows and Linux with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-vnext-sp_configure-on-windows-and-linux-with-dbatools/</link><pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-vnext-sp_configure-on-windows-and-linux-with-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>2016 - That was a Year :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2016-that-was-a-year-/</link><pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2016-that-was-a-year-/</guid><description>&lt;p>Its the time of year for reflection and I have had the most amazing 2016, I am blessed that I love what I do so much. I thoroughly enjoy writing and talking and sharing and commenting and supporting and cherishing all the SQL and PowerShell things. &lt;a class="link" href="http://sqldbawithabeard.com/2016/10/29/powerbi-and-api-visualising-my-checkins/" target="_blank" rel="noopener"
>I wrote about using Power Bi to display my checkins&lt;/a>. I only started this in June and this is where I have been :-)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/01/swarm.png"
loading="lazy"
alt="swarm"
>&lt;/p>
&lt;p>I learnt about &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> and ended the year incorporating it into &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a>. I also started using &lt;a class="link" href="https://github.com/SQLDBAWithABeard" target="_blank" rel="noopener"
>GitHub&lt;/a> It is quite surprising to me how much time I now spend using both. I also had to start learning &lt;a class="link" href="https://msdn.microsoft.com/en-us/PowerShell/dsc/overview" target="_blank" rel="noopener"
>DSC&lt;/a> for the client I was working with because as &amp;rsquo;the PowerShell guy&amp;rsquo; I was the one who could the easiest. I learnt things and &lt;a class="link" href="http://sqldbawithabeard.com/2016/01/31/PowerShell-pester-the-script-failed-due-to-call-depth-overflow/" target="_blank" rel="noopener"
>then forgot them causing me to find this Pester post via google later in the year!!&lt;/a> (That&amp;rsquo;s a big reason for blogging by the way)&lt;/p>
&lt;p>Early in the year we organised with &lt;a class="link" href="http://www.sqlsaturday.com/496/EventHome.aspx" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://www.facebook.com/mark.pryce.maher/videos/10153333580360863/?pnref=story.unseen-section" target="_blank" rel="noopener"
>https://www.facebook.com/mark.pryce.maher/videos/10153333580360863/?pnref=story.unseen-section&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>The Beard says&lt;/p>
&lt;blockquote>
&lt;p>When you go to an event -  Say thank you to the organisers and volunteers&lt;/p>
&lt;/blockquote>
&lt;p>and a TERRIBLE thing happened - I broke my DBA Team mug&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/WP_20160223_07_51_03_Pro.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Luckily the fine folk at &lt;a class="link" href="http://www.red-gate.com/" target="_blank" rel="noopener"
>redgate&lt;/a> sorted me out with a replacement from deep in the stores somewhere and gave it to me at SQL Saturday Exeter :-) Thank you.&lt;/p>
&lt;p>I spoke at the PowerShell Conference Europe and met and made some great friends which lead to me speaking at the PowerShell Monday in Munich and the Dutch PowerShell Usergroup. SQL Saturday Dublin was a blast, its a wonderful city, Manchester had a whole PowerShell Track :-) and Cambridge was memorable for the appalling journey as well as the chance to share a stage with &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy&lt;/a>. PowerShell Conference Asia in the sovereign city-state of Singapore was such a good event and place. Lastly of course was Slovenia with its fantastic Christmas lights and awesome event organisation. I visited some user groups too. Southampton run by my good friends &lt;a class="link" href="https://twitter.com/sqldiplomat" target="_blank" rel="noopener"
>John Martin&lt;/a> and &lt;a class="link" href="https://twitter.com/steph_middleton" target="_blank" rel="noopener"
>Steph Middleton&lt;/a> Congratulations to John on his first MVP award yesterday, Cardiff for the Return of the Battle of the Beards with Terry McCann and Tobiasz Koprowski where the projector threw its toys out of the pram and Birmingham in the school hall which was slightly chilly (theres a joke there for some people)&lt;/p>
&lt;p>Amazing things happened&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>And that&amp;rsquo;s the biggest and bestest thing about this year. Some amazing new friends and spending time with all my other friends. I started writing out a list but was terrified I would have missed someone out, so to all my friends&lt;/p>
&lt;p>THANK YOU for a brilliant 2016 and 2017 shall be just as good :-)&lt;/p>
&lt;p>Here are a few of my pics from the year with a lot of my friends&lt;/p>
&lt;p>[gallery type=&amp;ldquo;circle&amp;rdquo; columns=&amp;ldquo;9&amp;rdquo; ids=&amp;ldquo;3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3077,3075,3074,3073,3067,3068,3069,3070,3071,3072,3066,3065,3064,3063,3062,3061,3055,3056,3057,3058,3059,3060,3054,3053,3052,3051,3050,3049,2943,2950,2897,2923,3046,2924,2927,3047,2933,3048&amp;rdquo;]&lt;/p></description></item><item><title>Enabling Cortana for dbareports PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/enabling-cortana-for-dbareports-powerbi/</link><pubDate>Sun, 13 Nov 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/enabling-cortana-for-dbareports-powerbi/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png" alt="Featured image of post Enabling Cortana for dbareports PowerBi" />&lt;p>Last week at the Birmingham user group I gave a presentation about PowerShell and SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/saved-image-from-tweetium-8.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/saved-image-from-tweetium-8.jpg"
loading="lazy"
alt="saved-image-from-tweetium-8"
>&lt;/a>&lt;/p>
&lt;p>It was a very packed session as I crammed in the &lt;a class="link" href="https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/30/sql-powershell-july-2016-update/" target="_blank" rel="noopener"
>new sqlserver module&lt;/a>, &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> 🙂 On reflection I think this is a bit too much for a one hour session but at the end of the session I demo’d live Cortana using the dbareports dataset and returning a Cortana PowerBi page.&lt;/p>
&lt;p>As always it took a couple of goes to get it right but when it goes correctly it is fantastic. I call it a salary increasing opportunity! Someone afterwards asked me how it was done so I thought that was worth a blog post&lt;/p>
&lt;p>There is a video below but the steps are quite straightforward.&lt;/p>
&lt;h2 id="add-cortana-specific-pages">Add Cortana Specific Pages&lt;/h2>
&lt;p>Whilst you can just enable Cortana to access your dataset, as shown later in this post, which enables Cortana to search available datasets and return an appropriate visualisation it is better to provide specific pages for Cortana to use and display. You can do this in PowerBi Desktop&lt;/p>
&lt;p>Start by adding a new page in your report by clicking on the plus button&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/add-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/add-page.png"
loading="lazy"
alt="add page.PNG"
>&lt;/a>&lt;/p>
&lt;p>and then change the size of the report page by clicking on the paintbrush icon in the visualisation page.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/page-size.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/page-size.png"
loading="lazy"
alt="page-size"
>&lt;/a>&lt;/p>
&lt;p>This creates a page that is optimised for Cortana to display and also will be the first place that Cortana will look to answer the question&lt;/p>
&lt;blockquote>
&lt;p>Power BI first looks for answers in &lt;a class="link" href="https://powerbi.microsoft.com/en-us/documentation/powerbi-service-cortana-desktop-entity-cards/" target="_blank" rel="noopener"
>Answer Pages&lt;/a> and then searches your datasets and reports for other answers and displays them in the form of visualizations. The highest-scoring results display first as &lt;em>best matches&lt;/em>, followed by links to other possible answers and applications. Best matches come from Power BI Answer Pages or Power BI reports.&lt;/p>
&lt;/blockquote>
&lt;p>Rename the page so that it contains the words or phrase you expect to be in the question such as “Servers By Version” You will help Cortana and PowerBi to get your results better if you use some of the column names in your dataset&lt;/p>
&lt;p>Then it is just another report page and you can add visualisations just like any other page&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-page.png"
loading="lazy"
alt="cortana page.PNG"
>&lt;/a>&lt;/p>
&lt;h2 id="make-cortana-work-for-you-and-your-users">Make Cortana work for you and your users&lt;/h2>
&lt;p>If your users are likely to use a number of different words in their questions you can assist Cortana to find the right answer by adding alternate names. So maybe if your page is sales by store you might add shop, building, results, amount, orders. This is also useful when Cortana doesn’t understand the correct words as you will notice in the screenshot below I have added “service” for “servers” and “buy” for “by” to help get the right answer. You can add these alternate words by clicking the paintbrush under visualisations and then Page Information&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-additional.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-additional.png"
loading="lazy"
alt="cortana-additional"
>&lt;/a>&lt;/p>
&lt;h2 id="publish-your-pbix-file-to-powerbicom">Publish your PBIX file to PowerBi.com&lt;/h2>
&lt;p>To publish your PowerBi report to &lt;a class="link" href="https://powerbi.com" target="_blank" rel="noopener"
>PowerBi.com&lt;/a> either via the Publish button in &lt;a class="link" href="http://go.microsoft.com/fwlink/?LinkID=521662" target="_blank" rel="noopener"
>PowerBi desktop&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/publish.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/publish.png"
loading="lazy"
alt="publish"
>&lt;/a>&lt;/p>
&lt;p>or by using the &lt;a class="link" href="https://github.com/DevScope/powerbi-powershell-modules" target="_blank" rel="noopener"
>PowerBiPS module&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Install-Module -Name PowerBIPS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Grab the token, will require a sign in
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $authToken = Get-PBIAuthToken –Verbose
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Import-PBIFile –authToken $authToken –filePath “Path to PBIX file” –verbose
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="enable-cortana">Enable Cortana&lt;/h2>
&lt;p>In your browser log into &lt;a class="link" href="https://powerbi.com" target="_blank" rel="noopener"
>https://powerbi.com&lt;/a> and then click on the cog and then settings&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/powerbicom.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/powerbicom.png"
loading="lazy"
alt="powerbicom.PNG"
>&lt;/a>&lt;/p>
&lt;p>then click on Datasets&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/settings.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/settings.png"
loading="lazy"
alt="settings"
>&lt;/a>&lt;/p>
&lt;p>Then choose the dataset – in this case dbareports SQL Information sample and click the tick box to Allow Cortana to access the this dataset and then click apply&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/dataset-settings.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/dataset-settings.png"
loading="lazy"
alt="dataset settings.PNG"
>&lt;/a>&lt;/p>
&lt;h2 id="use-cortana-against-your-powerbi-data">Use Cortana against your PowerBi data&lt;/h2>
&lt;p>You can type into the Cortana search box and it will offer the opportunity for you to choose your PowerBi data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search.png"
loading="lazy"
alt="cortana-search"
>&lt;/a>&lt;/p>
&lt;p>but it is so much better when you let it find the answer 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-11.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-11.png"
loading="lazy"
alt="cortana-search-1"
>&lt;/a>&lt;/p>
&lt;p>and if you want to go to the PowerBi report there is a handy link at the bottom of the Cortana page&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png"
loading="lazy"
alt="cortana-search-2"
>&lt;/a>&lt;/p>
&lt;p>I absolutely love this, I was so pleased when I got it to work and the response when I show people is always one of wonder for both techies and none-techies alike&lt;/p>
&lt;h2 id="the-conditions-for-cortana-to-work">The conditions for Cortana to work&lt;/h2>
&lt;p>You will need to have added your work or school Microsoft ID to the computer or phone that you want to use Cortana on and that account must be able to access the dataset either because it is the dataset owner or because a dashboard using that dataset has been shared with that account.&lt;/p>
&lt;p>&lt;strong>&lt;a class="link" href="https://powerbi.microsoft.com/en-us/documentation/powerbi-service-cortana-enable/" target="_blank" rel="noopener"
>From this page on PowerBi.com&lt;/a>&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>When a new dataset or custom Cortana Answer Page is added to Power BI and enabled for Cortana it can take up to 30 minutes for results to begin appearing in Cortana. Logging in and out of Windows 10, or otherwise restarting the Cortana process in Windows 10, will allow new content to appear immediately.&lt;/p>
&lt;/blockquote>
&lt;h2 id="its-not-perfect">It’s not perfect!&lt;/h2>
&lt;p>When you start using Cortana to query your data you will find that at times it is very frustrating. My wife was in fits of giggles listening to me trying to record the video below as Cortana refused to understand that I was saying “servers” and repeatedly searched Bing for “service” Whilst you can negate the effect by using the alternate names for the Q and A settings it is still a bit hit and miss at times.&lt;/p>
&lt;h2 id="it-is-amazing">It is amazing&lt;/h2>
&lt;p>There is something about giving people the ability to just talk to their device in a meeting and for example with dbareports ask&lt;/p>
&lt;blockquote>
&lt;p>Which clients are in Bolton&lt;/p>
&lt;/blockquote>
&lt;p>or&lt;/p>
&lt;blockquote>
&lt;p>When was the last backup for client The Eagles&lt;/p>
&lt;/blockquote>
&lt;p>and get the information they require and a link to the report in PowerBi.com. I am certain that the suits will be absolutely delighted at being able to show off in that way which is why I call it a salary increasing opportunity 🙂&lt;/p>
&lt;h2 id="we-would-love-you-to-come-and-join-us-at-the-sql-community-collaborative">We would love YOU to come and join us at the SQL Community Collaborative&lt;/h2>
&lt;p>Help us make &lt;code>dbatools&lt;/code>, &lt;code>dbareports&lt;/code> and &lt;code>Invoke-SQLCmd2&lt;/code> even better. You can join in by forking the repos in GitHub and writing your code and then performing a PR but we would much rather that you came and discussed new requests in our Trello boards, raised issues in GitHub and generally discussed the modules in the SQL Server Community Slack &lt;code>#dbatools&lt;/code> &lt;code>#dbareports&lt;/code>. We are also looking for assistance with our wiki pages, Pester tests and appveyor integration for our builds and any comments people want to make&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/sqlcollaborative/" target="_blank" rel="noopener"
>SQL Server Collaborative GitHub Organisation holding the modules.&lt;/a> Go here to raise issues, fork the repositories or download the code&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>dbatools Trello for discussion about new cmdlets&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> where you can find #dbatools and #dbareports as well as over 1100 people discussing all aspects of the Data Platform, events, jobs, presenting&lt;/p>
&lt;p>COME AND JOIN US&lt;/p></description></item><item><title>The SQL Server Community Collaborative GitHub Organisation is born</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</link><pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" alt="Featured image of post The SQL Server Community Collaborative GitHub Organisation is born" />&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and I are the creators of two GitHub repositories for SQL Server and PowerShell called &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a>&lt;/p>
&lt;p>If you are working with SQL Server I highly recommend that you take a look at the vast number of commands available to you at &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> which will help you complete tasks within SQL Server especially for Instance migrations and also a growing number of best practice implementations&lt;/p>
&lt;p>Both of these modules are not just the work of one person any more. We have over 20 people who have collaborated on the modules THANK YOU ALL and more that have provided guidance and comments via the Slack Channels in the SQL Server Community Slack &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a> and via the Trello boards &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>https://dbatools.io/trello&lt;/a> and &lt;a class="link" href="https://dbareports/trello" target="_blank" rel="noopener"
>https://dbareports/trello&lt;/a>&lt;/p>
&lt;p>At SQL Saturday Cambridge this weekend I was proud to join Chrissy in her presentation as we talked about both modules. Heres a fabulous picture of us with Buck Woody&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg"
loading="lazy"
alt="wp_20160910_10_14_58_pro"
>&lt;/a>&lt;/p>
&lt;p>We had discussed previously that it didn’t feel quite right that these community tools were under our own personal accounts and it also caused some administration issues with allowing access. So with that in mind after a naming discussion in the slack channel we created an organisation to hold them both&lt;/p>
&lt;h2 id="sql-server-community-collaborative"> SQL Server Community Collaborative&lt;/h2>
&lt;p>is born at &lt;a class="link" href="https://github.com/sqlcollaborative" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative&lt;/a>&lt;/p>
&lt;p>Nothing much changes except the name. we have even found that all the old links work and GitHub desktop updated. We will continue to make great commands with all of our fantastic collaborators. Discussions will happen in Slack and organisation in Trello and we will continue to grow and learn and teach and share and create together.&lt;/p>
&lt;p>We would love you to come and join us&lt;/p></description></item><item><title>Remove-SQLDatabaseSafely My First Contribution to DBATools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</link><pubDate>Wed, 20 Jul 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</guid><description>&lt;p>What is DBA Tools?&lt;/p>
&lt;blockquote>
&lt;p>A collection of modules for SQL Server DBAs. It initially started out as ‘sqlmigration’, but has now grown into a collection of various commands that help automate DBA tasks and encourage best practices.&lt;/p>
&lt;/blockquote>
&lt;p>You can read more about &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>here&lt;/a> and it is &lt;a class="link" href="https://github.com/ctrlbold/dbatools" target="_blank" rel="noopener"
>freely available for download on GitHub&lt;/a> I thoroughly recommend that &lt;a class="link" href="https://www.youtube.com/watch?v=PciYdDEBiDM" target="_blank" rel="noopener"
>you watch this quick video&lt;/a> to see just how easy it is to migrate an entire SQL instance in one command (&lt;a class="link" href="https://www.youtube.com/watch?v=kQYUrSlb0wg" target="_blank" rel="noopener"
>Longer session here&lt;/a> )&lt;/p>
&lt;p>Installing it is as easy as&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>which will get you over 80 commands . Visit &lt;a class="link" href="https://dbatools.io/functions/" target="_blank" rel="noopener"
>https://dbatools.io/functions/&lt;/a> to find out more information about them&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png"
loading="lazy"
alt="cmdlets"
>&lt;/a>&lt;/p>
&lt;p>The journey to &lt;code>Remove-SQLDatabaseSafely&lt;/code> started with William Durkin &lt;a class="link" href="http://williamdurkin.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/sql_williamd" target="_blank" rel="noopener"
>t&lt;/a> who presented to the &lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>SQL South West User Group&lt;/a>  (&lt;a class="link" href="http://www.sqlsaturday.com/269/Sessions/Details.aspx?sid=28201" target="_blank" rel="noopener"
>You can get his slides here)&lt;/a>&lt;/p>
&lt;p>Following that session  I wrote a Powershell Script to gather information about the last used date for databases &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-one/" >which I blogged about here&lt;/a> and then a T-SQL script to take a final backup and create a SQL Agent Job to restore from that back up &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-two-2/" >which I blogged about here&lt;/a> The team have used this solution (updated to load the DBA Database and a report instead of using Excel) ever since and it proved invaluable when a read-only database was dropped and could quickly and easily be restored with no fuss.&lt;/p>
&lt;p>I was chatting with Chrissy LeMaire who founded DBATools &lt;a class="link" href="https://blog.netnerds.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>t&lt;/a> about this process and when she asked for contributions in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> I offered my help and she suggested I write this command. I have learnt so much. I thoroughly enjoyed and highly recommend working on projects collaboratively to improve your skills. It is amazing to work with such incredible professional PowerShell people.&lt;/p>
&lt;p>I went back to the basics and thought about what was required and watched one of my favourite videos again. &lt;a class="link" href="https://sqlps.io/backuprant" target="_blank" rel="noopener"
>Grant Fritcheys Backup Rant&lt;/a>&lt;/p>
&lt;p>I decided that the process should be as follows&lt;/p>
&lt;ol>
&lt;li>Performs a DBCC CHECKDB&lt;/li>
&lt;li>Database is backed up WITH CHECKSUM&lt;/li>
&lt;li>Database is restored with VERIFY ONLY on the source&lt;/li>
&lt;li>An Agent Job is created to easily restore from that backup&lt;/li>
&lt;li>The database is dropped&lt;/li>
&lt;li>The Agent Job restores the database&lt;/li>
&lt;li>performs a DBCC CHECKDB and drops the database for a final time&lt;/li>
&lt;/ol>
&lt;p>This (hopefully) passes all of Grants checks. This is how I created the command&lt;/p>
&lt;p>I check that the SQL Agent is running otherwise we wont be able to run the job. I use a while loop with a timeout like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$agentservice = Get-Service -ComputerName $ipaddr -Name $serviceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($agentservice.Status -ne &amp;#39;Running&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentservice.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $timeout = new-timespan -seconds 60
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $sw = [diagnostics.stopwatch]::StartNew()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentstatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($dbStatus -ne &amp;#39;Running&amp;#39; -and $sw.elapsed -lt $timeout) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dbStatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There are a lot more checks and logic than I will describe here to make sure that the process is as robust as possible. For example, the script can exit after errors are found using DBCC CHECKDB or continue and label the database backup file and restore job appropriately. Unless the force option is used it will exit if the job name already exists. We have tried to think of everything but if something has been missed or you have suggestions let us know (details at end of post)&lt;/p>
&lt;p>The only thing I didn’t add was a LARGE RED POP UP SAYING ARE YOU SURE YOU WANT TO DROP THIS DATABASE but I considered it!!&lt;/p>
&lt;h2 id="performs-a-dbcc-checkdb">Performs a DBCC CHECKDB&lt;/h2>
&lt;p>Running DBCC CHECKDB with Powershell is as easy as this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$sourceserver = New-Object Microsoft.SQLServer.Management.Smo.Server &amp;#34;ServerName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $sourceserver.databases[$dbname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $db.CheckTables(&amp;#39;None&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.database.checktables.aspx" target="_blank" rel="noopener"
>you can read more on MSDN&lt;/a>&lt;/p>
&lt;h2 id="database-is-backed-up-with-checksum">Database is backed up WITH CHECKSUM&lt;/h2>
&lt;p>Stuart Moore is my go to for doing &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>backups and restores with SMO&lt;/a>&lt;/p>
&lt;p>I ensured that the backup was performed with checksum like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$backup = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Backup
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Action = [Microsoft.SqlServer.Management.SMO.BackupActionType]::Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.BackupSetDescription = &amp;#34;Final Full Backup of $dbname Prior to Dropping&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Checksum = $True
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="database-is-restored-with-verify-only-on-the-source">Database is restored with VERIFY ONLY on the source&lt;/h2>
&lt;p>I used SMO all the way through this command and performed the restore verify only like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$restoreverify = New-Object &amp;#39;Microsoft.SqlServer.Management.Smo.Restore&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Devices.AddDevice($filename, $devicetype)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$result = $restoreverify.SqlVerify($sourceserver)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="an-agent-job-is-created-to-easily-restore-from-that-backup">An Agent Job is created to easily restore from that backup&lt;/h2>
&lt;p>First I created a category for the Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Function New-SqlAgentJobCategory {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ([string]$categoryname,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [object]$jobServer)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!$jobServer.JobCategories[$categoryname]) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Pscmdlet.ShouldProcess($sourceserver, &amp;#34;Creating Agent Job Category $categoryname&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Creating Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category = New-Object Microsoft.SqlServer.Management.Smo.Agent.JobCategory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Parent = $jobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Name = $categoryname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Created Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Exception $_
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> throw &amp;#34;FAILED : To Create Agent Job Category $categoryname - Aborting&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then generated the TSQL for the restore step by using the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.restore.script.aspx" target="_blank" rel="noopener"
>script method on the Restore SMO object&lt;/a>&lt;/p>
&lt;p>This is how to create an Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$job = New-Object Microsoft.SqlServer.Management.Smo.Agent.Job $jobServer, $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Name = $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.OwnerLoginName = $jobowner
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Description = &amp;#34;This job will restore the $dbname database using the final backup located at $filename&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then to add a job step to run the restore command&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$jobStep = new-object Microsoft.SqlServer.Management.Smo.Agent.JobStep $job, $jobStepName $jobStep.SubSystem = &amp;#39;TransactSql&amp;#39; # &amp;#39;PowerShell&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.DatabaseName = &amp;#39;master&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.Command = $jobStepCommmand
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnSuccessAction = &amp;#39;QuitWithSuccess&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnFailAction = &amp;#39;QuitWithFailure&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Pscmdlet.ShouldProcess($destination, &amp;#34;Creating Agent JobStep on $destination&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $null = $jobStep.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.ApplyToTargetServer($destination)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.StartStepID = $jobStartStepid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Alter()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-database-is-dropped">The database is dropped&lt;/h2>
&lt;p>We try 3 different methods to drop the database&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$server.KillDatabase($dbname)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$server.databases[$dbname].Drop()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $server.ConnectionContext.ExecuteNonQuery(&amp;#34;DROP DATABASE &amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-agent-job-restores-the-database">The Agent Job restores the database&lt;/h2>
&lt;p>To run the Agent Job I call the start method of the Job SMO Object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $job = $destserver.JobServer.Jobs[$jobname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($status -ne &amp;#39;Idle&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;amp;quot; Restore Job for $dbname on $destination is $status&amp;amp;quot;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Refresh()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Start-Sleep -Seconds 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we drop the database for the final time with the confidence that we have a safe backup and an easy one click method to restore it from that backup (as long as the backup is in the same location)&lt;/p>
&lt;p>There are further details on the &lt;a class="link" href="https://dbatools.io/functions/remove-sqldatabasesafely/" target="_blank" rel="noopener"
>functions page on dbatools&lt;/a>&lt;/p>
&lt;p>Some videos of it in action are on YouTube &lt;a class="link" href="http://dbatools.io/video" target="_blank" rel="noopener"
>http://dbatools.io/video&lt;/a>&lt;/p>
&lt;p>You can take a look at &lt;a class="link" href="https://github.com/ctrlbold/dbatools/blob/fbd2f19b4442a8065f3cb133d385fde9b2cddea0/functions/Remove-SqlDatabaseSafely.ps1" target="_blank" rel="noopener"
>the code on GitHub here&lt;/a>&lt;/p>
&lt;p>You can install it with&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>You can provide feedback via the &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>Trello Board&lt;/a> or discuss it in the #dbatools channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>Sqlserver Community Slack&lt;/a>&lt;/p>
&lt;p>You too can also become a contributor &lt;a class="link" href="https://dbatools.io/join-us/" target="_blank" rel="noopener"
>https://dbatools.io/join-us/&lt;/a> Come and write a command to make it easy for DBAs to (this bit is up to your imagination).&lt;/p></description></item><item><title>Refreshing A SQL Mirrored Database Using Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</link><pubDate>Mon, 25 Aug 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</guid><description>&lt;p>SQL mirroring is a means of providing high availability for your SQL database. It is available in Standard Edition and although the feature is deprecated it is still widely utilised. &lt;a class="link" href="http://msdn.microsoft.com/en-gb/library/ms189852.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>You can read more about it on MSDN here&lt;/a> and &lt;a class="link" href="http://www.brentozar.com/archive/2013/07/database-mirroring-faq/" target="_blank" rel="noopener"
>Jes Borland wrote a useful post answering many questions here&lt;/a>&lt;/p>
&lt;p>There are situations where you may need to refresh these databases. Disaster Recovery is an obvious one but also during development to provide testing or development environments to test your High Availability implementations, run through disaster scenarios, create run books or ensure that the code changes still work with mirroring. There are other scenarios but this post covers the automation of restoring a mirrored database from a backup.&lt;/p>
&lt;p>I have mentioned before and no doubt I shall again, &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>John Sansom wrote a great post about automation&lt;/a> and I am a strong follower of that principle.&lt;/p>
&lt;p>To refresh a SQL mirror the following steps are required, there are some gotchas that you need to be aware of which I will discuss later&lt;/p>
&lt;ul>
&lt;li>remove mirroring&lt;/li>
&lt;li>restore principle database from backup&lt;/li>
&lt;li>perform a transaction log backup of the principle database&lt;/li>
&lt;li>restore both backups on the mirror server with no recovery&lt;/li>
&lt;li>recreate mirroring&lt;/li>
&lt;li>resolve orphaned users&lt;/li>
&lt;li>check mirroring status&lt;/li>
&lt;/ul>
&lt;p>Regular blog followers will know that I prefer to use Powershell when I can (and where it is relevant to do so) and so I have used Powershell to automate all of the steps above&lt;/p>
&lt;p>The script requires some variables to be set up at the beginning. You can easily change this and make the script into a function and call it if you desire, but for this post I shall consider the script as a standalone. The reasoning for this is that I imagine that it will be placed into a run book or stored for use in a repository for specific use and therefore reduces any pre-requisites for using it.&lt;/p>
&lt;p>Set variables as follows, the last three variables set the types for the backup action type and device type and do not need to be altered.&lt;/p>
&lt;pre>&lt;code>\# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
&lt;/code>&lt;/pre>
&lt;p>After some error checking the first thing is to create server and database SMO objects&lt;/p>
&lt;pre>&lt;code>\# Create Server objects $Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer $Mirror = New-Object Microsoft.SQLServer.Management.Smo. server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
&lt;/code>&lt;/pre>
&lt;p>(Added Extra – Use New-ISESnippet to create a SMO Server Snippet and use CTRL + J to find it&lt;/p>
&lt;pre>&lt;code>New-IseSnippet -Title SMO-Server -Description &amp;quot;Create A SQL Server SMO Object&amp;quot; -Text &amp;quot;`$srv = New-Object Microsoft.SqlServer.Management.Smo.Server `$server&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="remove-mirroring">Remove Mirroring&lt;/h4>
&lt;p>Before we can restore the database we need to remove mirroring&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
&lt;/code>&lt;/pre>
&lt;h4 id="restore-principle-database-from-backup">restore principle database from backup&lt;/h4>
&lt;p>Once mirroring has been removed we can restore the database. &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>Stuart Moore’s Great Series&lt;/a> provides all the code you need to backup and restore databases with Powershell. There is however a bug which can catch you out. Here’s the code&lt;/p>
&lt;pre>&lt;code>$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;p>The bug is as follows, if your restore is going to take longer than 10 minutes and you are using an earlier version of SQL than SQL 2012 SP1 CU8 then you will find that the restore fails after 10 minutes. This is the default timeout. You may try to set the&lt;/p>
&lt;pre>&lt;code>$srv.ConnectionContext.StatementTimeout
&lt;/code>&lt;/pre>
&lt;p>Value to a larger value or 0 and this will work after SQL 2012 SP1 CU8 but prior to that you will still face the same error. The simple workaround is to use &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/7985b7ef-ed89-4dfd-b02a-433cc4e30894" target="_blank" rel="noopener"
>Invoke-SQLCmd2&lt;/a> and to script the restore as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="perform-a-transaction-backup-of-the-principle-database">perform a transaction backup of the principle database&lt;/h4>
&lt;p>We need to have a full and transaction log backup to set up mirroring. Again you may need to use the script method if your backup will take longer than 600 seconds.&lt;/p>
&lt;pre>&lt;code>#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = “Log Backup of “ + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object –TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 –ServerInstance $PrincipalServer –Database master –Query $query –ConnectionTimeout 0 # comment out if not used
&lt;/code>&lt;/pre>
&lt;h4 id="restore-both-backups-on-the-mirror-server-with-no-recovery">Restore both backups on the mirror server with no recovery&lt;/h4>
&lt;p>To complete the mirroring set up we need to restore the backups onto the mirror server with no recovery as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="recreate-mirroring">Recreate mirroring&lt;/h4>
&lt;p>You recreate mirroring in the same way as you would if you were using T-SQL simply add the principal endpoint to the mirror, and the mirror and witness endpoints to the principal&lt;/p>
&lt;pre>&lt;code>#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
&lt;/code>&lt;/pre>
&lt;h4 id="resolve-orphaned-users">Resolve orphaned users&lt;/h4>
&lt;p>You will need to resolve any users and permissions on your destination servers. I do not know a way to do this with PowerShell and would be interested if anyone has found a way to replace the password or the SID on a user object, please contact me if you know.&lt;/p>
&lt;p>Many people do this with the &lt;a class="link" href="http://support.microsoft.com/kb/918992" target="_blank" rel="noopener"
>sp_rev_logins stored procedure&lt;/a> which will create the T-SQL for recreating the logins. However, Powershell cannot read the outputs of the message window where the script prints the script. If you know that your logins are staying static then run sp_rev_logins and store the output in a sql file and call it with Invoke-SQLCmd2&lt;/p>
&lt;pre>&lt;code>$SQL = ‘’ #Path to File
Invoke-Sqlcmd2 –ServerInstance $Server –Database master –InputFile $SQL
&lt;/code>&lt;/pre>
&lt;p>The other option is to &lt;a class="link" href="http://dbadiaries.com/how-to-transfer-logins-to-another-sql-server-or-instance" target="_blank" rel="noopener"
>set up a SSIS package following this blog post&lt;/a> and call it from Powershell as follows&lt;/p>
&lt;p>**2020 Edit ** - You should use &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> to do this&lt;/p>
&lt;pre>&lt;code>Invoke-Command –ComputerName $Server –scriptblock {DTExec.exe /File “PATHTOPackage.dtsx”}
&lt;/code>&lt;/pre>
&lt;p>This requires &lt;a class="link" href="http://technet.microsoft.com/en-us/magazine/ff700227.aspx" target="_blank" rel="noopener"
>Powershell Remoting&lt;/a> to have been set up on the server which may or may not be available to you in your environment.&lt;/p>
&lt;p>IMPORTANT NOTE – The script does not include any methods for resolving orphaned users so you will need to test and then add your own solution to the script.&lt;/p>
&lt;h4 id="check-mirroring-status">check mirroring status&lt;/h4>
&lt;p>Lastly you want to check that the script has run successfully and that mirroring is synchronised (I am from the UK!!) To do this I check that time and file used for the last database backup &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/1860/identify-when-a-sql-server-database-was-restored-the-source-and-backup-date/" target="_blank" rel="noopener"
>using this script&lt;/a>&lt;/p>
&lt;pre>&lt;code>#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 1 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize –Wrap
&lt;/code>&lt;/pre>
&lt;p>and that mirroring has synchronised using the following Powershell command&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>Depending on your needs you may add some error checking using the results of the above scripts. As I said at the top of the post, you can turn this script into a function and call it at will or add it to an Agent Job for regular scheduling or just kept in a folder ready to be run when required. The choice is yours but all usual rules apply. Don’t believe anything you read on this blog post, don’t run any scripts on production, test before running any scripts, understand what the code is doing before you run it or I am not responsible if you break anything&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: Refresh Mirrored Database
Author: Rob Sewell https://blog.robsewell.com
Requires: Invoke-SQLCMD2 (included)
Version History:
1.2 22/08/2014
.SYNOPSIS
Refreshes a mirrored database
.DESCRIPTION
This script will refresh a mirrored database, recreate mirroring and chekc status of mirroring.
Further details on the website
Requires the variables at the top of the script to be filled in
IMPORTANT - Orpahaned users are not resolved with this acript without additions. See blog post for options
#&amp;gt;
# Load Invoke-SQLCMD2
#Load the assemblies the script requires
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Management.Common&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoEnum&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Smo&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoExtended &amp;quot; );
[void][System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;Microsoft.SqlServer.ConnectionInfo&amp;quot;)
[System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;System.Windows.Forms&amp;quot;)|Out-Null
# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationFUll = $FileShare + $DBName + 'formirroring.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
######################
&amp;lt;#
.SYNOPSIS
Runs a T-SQL script.
.DESCRIPTION
Runs a T-SQL script. Invoke-Sqlcmd2 only returns message output, such as the output of PRINT statements when -verbose parameter is specified
.INPUTS
None
You cannot pipe objects to Invoke-Sqlcmd2
.OUTPUTS
System.Data.DataTable
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;SELECT login_time AS 'StartTime' FROM sysprocesses WHERE spid = 1&amp;quot;
This example connects to a named instance of the Database Engine on a computer and runs a basic T-SQL query.
StartTime
-----------
2010-08-12 21:21:03.593
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -InputFile &amp;quot;C:\MyFolder\tsqlscript.sql&amp;quot; | Out-File -filePath &amp;quot;C:\MyFolder\tsqlscript.rpt&amp;quot;
This example reads a file containing T-SQL statements, runs the file, and writes the output to another file.
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;PRINT 'hello world'&amp;quot; -Verbose
This example uses the PowerShell -Verbose parameter to return the message output of the PRINT command.
VERBOSE: hello world
.NOTES
Version History
v1.0 - Chad Miller - Initial release
v1.1 - Chad Miller - Fixed Issue with connection closing
v1.2 - Chad Miller - Added inputfile, SQL auth support, connectiontimeout and output message handling. Updated help documentation
v1.3 - Chad Miller - Added As parameter to control DataSet, DataTable or array of DataRow Output type
#&amp;gt;
function Invoke-Sqlcmd2 {
[CmdletBinding()]
param(
[Parameter(Position = 0, Mandatory = $true)] [string]$ServerInstance,
[Parameter(Position = 1, Mandatory = $false)] [string]$Database,
[Parameter(Position = 2, Mandatory = $false)] [string]$Query,
[Parameter(Position = 3, Mandatory = $false)] [string]$Username,
[Parameter(Position = 4, Mandatory = $false)] [string]$Password,
[Parameter(Position = 5, Mandatory = $false)] [Int32]$QueryTimeout = 600,
[Parameter(Position = 6, Mandatory = $false)] [Int32]$ConnectionTimeout = 15,
[Parameter(Position = 7, Mandatory = $false)] [ValidateScript( {test-path $_})] [string]$InputFile,
[Parameter(Position = 8, Mandatory = $false)] [ValidateSet(&amp;quot;DataSet&amp;quot;, &amp;quot;DataTable&amp;quot;, &amp;quot;DataRow&amp;quot;)] [string]$As = &amp;quot;DataRow&amp;quot;
)
if ($InputFile) {
$filePath = $(resolve-path $InputFile).path
$Query = [System.IO.File]::ReadAllText(&amp;quot;$filePath&amp;quot;)
}
$conn = new-object System.Data.SqlClient.SQLConnection
if ($Username)
{ $ConnectionString = &amp;quot;Server={0};Database={1};User ID={2};Password={3};Trusted_Connection=False;Connect Timeout={4}&amp;quot; -f $ServerInstance, $Database, $Username, $Password, $ConnectionTimeout }
else
{ $ConnectionString = &amp;quot;Server={0};Database={1};Integrated Security=True;Connect Timeout={2}&amp;quot; -f $ServerInstance, $Database, $ConnectionTimeout }
&amp;amp;amp;n bsp; $conn.ConnectionString = $ConnectionString
#Following EventHandler is used for PRINT and RAISERROR T-SQL statements. Executed when -Verbose parameter specified by caller
if ($PSBoundParameters.Verbose) {
$conn.FireInfoMessageEventOnUserErrors = $true
$handler = [System.Data.SqlClient.SqlInfoMessageEventHandler] {Write-Verbose &amp;quot;$($_)&amp;quot;}
$conn.add_InfoMessage($handler)
}
$conn.Open()
$cmd = new-object system.Data.SqlClient.SqlCommand($Query, $conn)
$cmd.CommandTimeout = $QueryTimeout
$ds = New-Object system.Data.DataSet
$da = New-Object system.Data.SqlClient.SqlDataAdapter($cmd)
[void]$da.fill($ds)
$conn.Close()
switch ($As) {
'DataSet' { Write-Output ($ds) }
'DataTable' { Write-Output ($ds.Tables) }
'DataRow' { Write-Output ($ds.Tables[0]) }
}
} #Invoke-Sqlcmd2
# Check for existence of Backup file with correct name
If (!(Test-Path $LocationReplace)) {
Write-Output &amp;quot; There is no file called &amp;quot;
Write-Output $LocationReplace
Write-Output &amp;quot;Please correct and re-run&amp;quot;
break
}
# Remove Old Backups
if (Test-Path $locationFull) {
Remove-Item $LocationFUll -Force
}
if (Test-Path $locationTran) {
Remove-Item $LocationTran -Force
}
# Create Server objects
$Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer
$Mirror = New-Object Microsoft.SQLServer.Management.Smo.server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
# If database is on Mirror server fail it over to Principal
if ($DatabasePrincipal.IsAccessible -eq $False) {
$DatabaseMirror.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Failover)
}
# remove mirroring
$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Full Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup
$Backup.Action = $Full
$Backup.BackupSetDescription = &amp;quot;Full Backup of &amp;quot; + $DBName
$Backup.Database = $DatabasePrincipal.Name
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFull, $File)
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = &amp;quot;Log Backup of &amp;quot; + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFUll, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
# Resolve Orphaned Users if needed
#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 20 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize -Wrap
$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre></description></item><item><title>Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</link><pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</guid><description>&lt;p>There is a newer &lt;a class="link" href="https://blog.robsewell.com/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/" target="_blank" rel="noopener"
>up to date version of this post here&lt;/a> using the &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> and the sqlserver module&lt;/p>
&lt;p>But if you want to continue with this way read on!!&lt;/p>
&lt;p>Having created &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Windows Users&lt;/a> or &lt;a class="link" href="https://blog.robsewell.com/creating-sql-user-and-adding-to-server-role-with-powershell/" target="_blank" rel="noopener"
>SQL Users&lt;/a> using the last two days posts, today we shall add them to a role on a database.&lt;/p>
&lt;p>As I discussed &lt;a class="link" href="https://blog.robsewell.com/checking-sql-server-user-role-membership-with-powershell/" target="_blank" rel="noopener"
>previously&lt;/a> I believe that to follow good practice I try to ensure that database permissions are granted by role membership and each role is created with the minimum amount of permissions required for successful execution of the task involved.&lt;/p>
&lt;p>So with each database having the correct roles created and the users created we just need to add the user to the database and to the role. This is easily done with PowerShell.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image70.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image70.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The &lt;code>Add-UserToRole&lt;/code> function takes four parameters Server,Database,User and Role and does a series of error checks.&lt;/p>
&lt;p>With these functions you can easily create a number of Users and add them to database roles quickly and easily and repeatedly.&lt;/p>
&lt;p>If the test team come to you and require 10 Test Users and 3 Test Administrators adding to the test database. I create 2 notepad files&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image71.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image71.png"
loading="lazy"
alt="image"
>&lt;/a>  &lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image72.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image72.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and use them with the &lt;code>Add-SQLAccountToSQLRole&lt;/code> and &lt;code>Add-UserToRole&lt;/code> functions to create the users&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image73.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image73.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Here are the results in PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image74.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image74.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and in SSMS&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image75.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image75.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The Code is here&lt;/p>
&lt;pre>&lt;code>############################################################# ################################
#
# NAME: Add-UserToRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to add user or group to a role on a database
#
# USAGE: Add-UserToRole fade2black Aerosmith Test db_owner
#
Function Add-UserToRole ([string] $server, [String] $Database , [string]$User, [string]$Role)
{
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
#Check Database Name entered correctly
$db = $svr.Databases[$Database]
if($db -eq $null)
{
Write-Output &amp;quot; $Database is not a valid database on $Server&amp;quot;
Write-Output &amp;quot; Databases on $Server are :&amp;quot;
$svr.Databases|select name
break
}
#Check Role exists on Database
$Rol = $db.Roles[$Role]
if($Rol -eq $null)
{
Write-Output &amp;quot; $Role is not a valid Role on $Database on $Server &amp;quot;
Write-Output &amp;quot; Roles on $Database are:&amp;quot;
$db.roles|select name
break
}
if(!($svr.Logins.Contains($User)))
{
Write-Output &amp;quot;$User not a login on $server create it first&amp;quot;
break
}
if (!($db.Users.Contains($User)))
{
# Add user to database
$usr = New-Object ('Microsoft.SqlServer.Management. Smo.User') ($db, $User)
$usr.Login = $User
$usr.Create()
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User was not a login on $Database on $server&amp;quot;
Write-Output &amp;quot;$User added to $Database on $Server and $Role Role&amp;quot;
}
else
{
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User added to $Role Role in $Database on $Server &amp;quot;
}
}
&lt;/code>&lt;/pre></description></item></channel></rss>