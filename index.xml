<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Rob Sewell (aka SQL DBA With A Beard)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/</link><description>Recent content on Rob Sewell (aka SQL DBA With A Beard)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 19 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://sqldbawithabeard.github.io/blogrobsewell/index.xml" rel="self" type="application/rss+xml"/><item><title>SQLBits 2023 in Newport - A beards viewpoint</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-2023-in-newport-a-beards-viewpoint/</link><pubDate>Sun, 19 Mar 2023 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-2023-in-newport-a-beards-viewpoint/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2023/dragonsqlbitslogo.png" alt="Featured image of post SQLBits 2023 in Newport - A beards viewpoint" />&lt;h1 id="what-is-sqlbits">What is SQLBits?&lt;/h1>
&lt;p>&lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> is the largest data platform conference in Europe. It has been running every year since 2007 in a different city in the UK providing sessions into all things data platform. I have frequently &lt;a class="link" href="https://blog.robsewell.com/tags/#sqlbits" target="_blank" rel="noopener"
>written about SQLBits&lt;/a>, it is close to my heart and has had a significant impact on my life, my career and my circle of friends.&lt;/p>
&lt;h2 id="committee">Committee&lt;/h2>
&lt;p>The SQLBits committee is responsible for the running of the conference, the selection of general sessions and training days, helpers, sponsors, venue, dates, child care, theme, logo, the party, the website, charity support, hotels, bars, delegate app, helpers app, sponsors app, food, drinks, entertainment, prizes, swag, t-shirts, mugs, code of conduct, badges, printing, freight, stickers, lanyards, bags,on-site therapist, pens, notepads&amp;hellip; and everything else that goes into making SQLBits the best conference it can be!!&lt;/p>
&lt;h2 id="before-the-conference">Before the conference&lt;/h2>
&lt;p>We have been meeting every week as a committee to plan the conference. Every committee member has also spent a lot of time in meetings, dealing with correspondence, answering questions, and then feeding this back to the whole committee. We received some feedback from one of our largest sponsors that one of the things that the liked about SQLBits was that we are all so passionate about the conference and that it really shows. We are all volunteers and we all have full time jobs, families, and other commitments but we are also determined to make SQLBits the best Microsoft Data Platform conference in the world.&lt;/p>
&lt;h2 id="set-up">Set up&lt;/h2>
&lt;p>We all arrived in Newport on the Sunday or the Monday before the conference to set up. Set up is a massive operation involving a significant number of people who turn the big empty room into the exhibition hall, build all of the sponsor booths, set up all of the rooms with a stage, screens, signage and projectors, ensure that there is wifi, power, and hard-wired internet access in them all. There was also a team taking all of the output from the speakers desk and ensuring that it will be available for the live streams for the online delegates. Whilst all of that is happening, we were unpacking all of the things that had been in storage (or peoples garages) getting all of the t-shirts for the helpers, for the speakers and for the committee. All of the speaker swag and delegate swag was put into a box or a bag by some of the orange shirted helpers.
We also had a &amp;ldquo;Meet the trainer&amp;rdquo; event in the evening which allowed delegates to come and interact with the speakers. This was a great opportunity for delegates to ask questions and get to know the trainers before the training days.&lt;/p>
&lt;p>That was all expected.&lt;/p>
&lt;p>However, there are also things that happens behind the scenes during this time. For example, due to a storm over Northern Europe which impacted flights into and out of Schiphol, London and Bristol Airports as well as the trains running from London to Newport, there was a point on Monday afternoon where we were not sure that over half of our training day speakers for the next day would be able to make it. This lead to a couple of hours of manic phone calls and communication with the speakers as we tried our best to get them to the conference. We were very lucky that with only one exception, everyone made it to the conference. Unfortunately, despite best efforts and a lot of searching, one speaker was unable to get to the UK in time and so we had to switch their rooms to a room with virtual speakers enabled and update all of the schedules and teams involved in providing the content. These are the things that you don&amp;rsquo;t see, but that are part of the magic of ensuring that the conference runs smoothly. I hope all of the delegates and most of the speakers and sponsors have no idea of the things that were happening behind the scenes. I always describe it like a swan, it looks calm and serene on the surface, but underneath the water, there is a lot of paddling going on!&lt;/p>
&lt;h1 id="tuesday">Tuesday&lt;/h1>
&lt;p>For me, Tuesday was a training day. With my fantastic partner in fun and games and sharing - Jess Pomfret &lt;a class="link" href="https://jesspomfret.com" target="_blank" rel="noopener"
>B&lt;/a> &lt;a class="link" href="https://tech.lgbt/@Jpomfret" target="_blank" rel="noopener"
>M&lt;/a> we spent the whole day with about 75 people both in person and online and talked about how to manage large SQL estates. We had a lot of fun and I hope that everyone who attended enjoyed it as much as we did. We had a lot of questions and a lot of interaction with the delegates in both formats and it showed that the system that we had to enable virtual delegates for SQLBits really managed to work well.&lt;/p>
&lt;h1 id="equity-and-inclusivity">Equity and Inclusivity&lt;/h1>
&lt;p>We had a lot of positive feedback from the delegates and we are really pleased that we were able to provide this opportunity for even more people to attend the conference. We are passionate about Diversity, Equity and Inclusivity and the feedback that we have received is that allowing virtual attendees enabled more people to attend the conference and to learn from the speakers. People who would not have been able to attend because of their family commitments or because of the cost of travel and accommodation were able to attend and this is one of our goals for the conference.&lt;/p>
&lt;p>Concentrating on Inclusion and Equity will naturally have a positive impact on our Diversity and our goal is to make SQLBits a conference that is welcoming to everyone. The DE and I teams initiatives such as childcare are beginning to bear fruit and we are seeing more and more people attending the conference with their families, as well as more people from underrepresented groups attending the conference and we are working hard to ensure that we are providing a safe and welcoming environment for everyone.&lt;/p>
&lt;h1 id="getting-everyone-in">Getting everyone in&lt;/h1>
&lt;p>Whilst Jess and I were doing the training day, the rest of the team were ensuring that everyone was able to get in, with a badge, registered with the session that they expected, or the one they wished to change to. Some sessions had a limited number of places and so we had to ensure that the people who were on the waiting list were able to get into the session that they wanted to attend if places became available. We had to print the badges for the people who had signed up in the days before we sent the information to the printers. We had people paying for new tickets right up until Friday!&lt;/p>
&lt;h1 id="wednesday">Wednesday&lt;/h1>
&lt;p>There was another &amp;ldquo;Meet the trainer&amp;rdquo; event on the Tuesday evening and another set of speakers and delegates who were arriving as well as sponsor teams and their freight. Wednesday morning did not see as much of a rush as Tuesday morning, but there was still a lot of people arriving and needing processing or having questions that needed answering. At events like SQLBits there is also a lot of communication and conversation with the venue. Ensuring that there is coffee at the times that everyone comes out of the rooms for breaks and that there is lunch at the right time. When you are thinking about lunch, you also need to think about the sponsors. On General sessions days we need to ensure that they can have lunch before all of the delegates come out of their sessions and they need to spend their time talking with them and demonstrating their products. Wednesday evening was also when the sponsors were able to setup their booths. This, of course, generates a large number of questions that need answering and boxes that need finding and then unpacking.&lt;/p>
&lt;h1 id="evening-events">Evening events&lt;/h1>
&lt;p>Wednesday saw the first of the large evening events. We provided a games night with food. Thursday there was a quiz night with curry and Friday was the Party. As you can imagine, there is a significant amount of organisation required behind the scenes for all of these additional events. Food, drinks, prizes, the folks providing the entertainment and the helpers. The venue, security, transport from the hotels to the venue and back again. All of this needs to be organised and then managed on the day. We had a lot of fun at these events though and find them a great way to end each day and enable delegates who want to, to be able to network with each other and with the sponsors all whilst doing something fun. The party is organised by the wonderful, sparkly Julia and her team and they do a fantastic job of making sure that everyone has a great time.&lt;/p>
&lt;h1 id="general-sessions">General sessions&lt;/h1>
&lt;p>General sessions then add further complexity, more delegates, more speakers, more moving parts that always have the possibility for things to require fixing. I have been a SQLBits helper and runner enough times to know that there were many things requiring attention, this year my responsibility was the agenda and updating the processes behind that when things changed and answering the myriad of questions that come up at the information desk. It is a lot of fun but also a lot of work.&lt;/p>
&lt;h1 id="wrap-up">Wrap up&lt;/h1>
&lt;p>This is a totally raw outpouring of my experience this year, pretty much without filter. Just so that I had it down somewhere in words.&lt;/p></description></item><item><title>SQLBits Agenda and PowerShell, displaying and searching</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-agenda-and-powershell-displaying-and-searching/</link><pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sqlbits-agenda-and-powershell-displaying-and-searching/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2023/dragonsqlbitslogo.png" alt="Featured image of post SQLBits Agenda and PowerShell, displaying and searching" />&lt;h1 id="what-is-sqlbits">What is SQLBits?&lt;/h1>
&lt;p>&lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> is the largest data platform conference in Europe. It has been running every year since 2007 in a different city in the UK providing sessions into all things data platform. I have frequently &lt;a class="link" href="https://blog.robsewell.com/tags/#sqlbits" target="_blank" rel="noopener"
>written about SQLBits&lt;/a>, it is a conference close to my heart and has had a significant impact on my life, my career and my circle of friends.&lt;/p>
&lt;h2 id="where-and-when">Where and when?&lt;/h2>
&lt;p>This year it is in Newport, Wales at the International Convention Centre Wales (ICC) Tuesday 14th to Saturday 18th of March, 2023&lt;/p>
&lt;p>&lt;a class="link" href="https://events.sqlbits.com/2023/begin" target="_blank" rel="noopener"
>You can register to attend here&lt;/a>&lt;/p>
&lt;h2 id="what-is-there-at-sqlbits">What is there at SQLBits?&lt;/h2>
&lt;p>Tuesday and Wednesday are training days with all day sessions provided by subject matter experts including Microsoft Product Group members, Microsoft Valued Professionals, Microsoft Certified Trainers, and other experts. There are 30 options covering all areas of the Data Platform and none-technical sessions as well.&lt;/p>
&lt;p>You can see the &lt;a class="link" href="https://events.sqlbits.com/2023/training-days" target="_blank" rel="noopener"
>training day agenda here&lt;/a>&lt;/p>
&lt;p>Thursday and Friday have 50 minute, 20 minute and 5 minute sessions with a wide range of topics and levels.&lt;/p>
&lt;p>Saturday is the &lt;strong>FREE to attend&lt;/strong> day. It also has 50 minute, 20 minute and 5 minute sessions with a wide range of topics and levels.&lt;/p>
&lt;p>There are about 250 sessions on Thursday, Friday and Saturday&lt;/p>
&lt;p>You can see the &lt;a class="link" href="https://events.sqlbits.com/2023/agenda" target="_blank" rel="noopener"
>general session agenda here&lt;/a>&lt;/p>
&lt;h2 id="what-else-is-there-outside-of-technical-stuff">What else is there outside of technical stuff?&lt;/h2>
&lt;p>Oh My!!&lt;/p>
&lt;p>The biggest benefit is the people, for networking, for answering questions, building relationships with Microsoft product group or local Microsoft, meeting companies who are sponsoring, finding your new job or your new team members, learning and sharing with your peers.&lt;/p>
&lt;p>There is also a pub quiz on Thursday evening, the Friday night costume party, the community zone.&lt;/p>
&lt;h1 id="how-do-i-find-the-sessions">How do I find the sessions?&lt;/h1>
&lt;p>With so many sessions, its hard to find the ones that you want or to get a good overview in the format that you want. So I built a PowerShell module to get that information for you easily in any format you like. (Editor - thats a fib, he built it so that he could write Pester to ensure that speakers were not scheduled when they were not available)&lt;/p>
&lt;h1 id="the-sqlbitsps-module">The SQLBitsPS module&lt;/h1>
&lt;p>You can find the SQLBitsPS PowerShell module on the &lt;a class="link" href="https://www.powershellgallery.com/packages/SQLBitsPS" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211528862-5226d25a-5642-44a3-9c14-f88bfa334aa2.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211528862-5226d25a-5642-44a3-9c14-f88bfa334aa2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>As with all PowerShell modules from the Gallery, you can install it by running&lt;/p>
&lt;p>&lt;code>Install-Module SQLBitsPS&lt;/code>&lt;/p>
&lt;p>I find that a lot of people like to use the &lt;code>ShowWindow&lt;/code> parameter to have the help in another searchable window.&lt;/p>
&lt;p>&lt;code>Get-Help Get-SQLBitsSchedule -ShowWindow&lt;/code>
&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211530034-596f0fc9-ec1d-43fc-bd7a-ff1cf01c7c15.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211530034-596f0fc9-ec1d-43fc-bd7a-ff1cf01c7c15.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="use-the-help">Use the help&lt;/h2>
&lt;p>to find out how to use any PowerShell command you should use Get-Help and this module is no different. The help for the commands is built in and can be accessed with&lt;/p>
&lt;p>&lt;code>Get-Help Get-SQLBitsSchedule&lt;/code>&lt;/p>
&lt;h2 id="getting-the-schedule">Getting the schedule&lt;/h2>
&lt;p>You can just run &lt;code>Get-SQLBitsSchedule&lt;/code> and by default it will get the schedule and if you have the &lt;code>ImportExcel&lt;/code> module available it will write an Excel Workbook with each days agenda on a different sheet and colour code the service sessions like Registration, lunch and coffee breaks&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211530884-1d2b2752-a729-499d-8334-1e4404199002.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211530884-1d2b2752-a729-499d-8334-1e4404199002.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>To save you having to click to open Excel I have added a &lt;code>Show&lt;/code> parameter which will open it for you!&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211531837-2396cfd5-b843-4fd8-8a90-d1e1a06e654f.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211531837-2396cfd5-b843-4fd8-8a90-d1e1a06e654f.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="i-would-like-a-csv-instead">I would like a csv instead&lt;/h2>
&lt;p>The &lt;code>output&lt;/code> parameter gives you a number of options for the format of the output. If you do not have the &lt;code>ImportExcel&lt;/code> module it will default to &lt;code>-output csv&lt;/code> which you can also combine with the &lt;code>Show&lt;/code> parameter&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output csv -show&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211532406-bc928085-ab6f-4d8c-b42e-edc53ce027ca.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211532406-bc928085-ab6f-4d8c-b42e-edc53ce027ca.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="i-would-like-a-html-page-instead">I would like a html page instead&lt;/h2>
&lt;p>It&amp;rsquo;s not awesome but you can also create an HTML page. This may be useful if you wish to print the agenda yourself so that you have a hard copy.&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output html -show&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211533198-9bd8c53f-71b1-4426-bc1f-d7a8e874a86a.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211533198-9bd8c53f-71b1-4426-bc1f-d7a8e874a86a.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h2 id="let-me-decide-what-format-i-want">Let me decide what format I want&lt;/h2>
&lt;p>You can also output a &lt;code>[pscustomobject]&lt;/code> which you may use to PowerShell to your hearts content!!&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output object |Format-Table&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211533959-ee9f2fb5-e4be-45f2-9142-581833ee214f.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211533959-ee9f2fb5-e4be-45f2-9142-581833ee214f.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Maybe you would like to see the sessions that are on Friday at 16:50&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -output object |Where-Object {$_.Day -eq 'Friday' -and $_.StartTime -eq '16:50'} &lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211534901-f75cfc82-71bc-456e-bb2c-306dd753cf9b.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211534901-f75cfc82-71bc-456e-bb2c-306dd753cf9b.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>They look amazing, I recommend Mladen Prajdic session. That one blew me away at Data Grillen and I may very well attend that again.&lt;/p>
&lt;h2 id="i-cant-do-anything-fancy-just-let-me-search">I can&amp;rsquo;t do anything fancy, just let me search&lt;/h2>
&lt;p>If all you want is to search for your favourite speaker then you can use the &lt;code>search&lt;/code> parameter which will perform a wildcard search.&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search Cathrine -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211536336-0202aec6-56f1-4f72-aa5b-4cc15de8f848.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211536336-0202aec6-56f1-4f72-aa5b-4cc15de8f848.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search Monica -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211535867-93496665-3423-4809-a1b3-561d56315594.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211535867-93496665-3423-4809-a1b3-561d56315594.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You can also use it search for topics&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search 'Mental Health' -output object&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211536684-5b9a56e3-a487-40f4-aad7-f3656654c21a.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211536684-5b9a56e3-a487-40f4-aad7-f3656654c21a.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and even to search for wisdom!!&lt;/p>
&lt;p>&lt;code>Get-SQLBitsSchedule -search wisdom -output object &lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://user-images.githubusercontent.com/6729780/211537382-2a0ae647-cdc1-4ccc-82ba-87efe7fb857e.png" target="_blank" rel="noopener"
>&lt;img src="https://user-images.githubusercontent.com/6729780/211537382-2a0ae647-cdc1-4ccc-82ba-87efe7fb857e.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h1 id="i-want-to-make-it-better">I want to make it better&lt;/h1>
&lt;p>Awesome, thank you.&lt;/p>
&lt;p>This is all open-source and you can find it on GitHub at&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/SQLBitsPS" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/SQLBitsPS&lt;/a>&lt;/p>
&lt;p>There are some brief instructions here&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/SQLBitsPS/blob/main/DevelopingREADME.md" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/SQLBitsPS/blob/main/DevelopingREADME.md&lt;/a>&lt;/p>
&lt;h1 id="join-us">Join us&lt;/h1>
&lt;p>&lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> is the largest data platform conference in Europe. It has been running every year since 2007 in a different city in the UK providing sessions into all things data platform.&lt;/p>
&lt;h2 id="where-and-when-1">Where and when?&lt;/h2>
&lt;p>This year it is in Newport, Wales at the International Convention Centre Wales (ICC) Tuesday 14th to Saturday 18th of March, 2023&lt;/p>
&lt;p>&lt;a class="link" href="https://events.sqlbits.com/2023/begin" target="_blank" rel="noopener"
>You can register to attend here&lt;/a>&lt;/p></description></item><item><title>#NewStarNovember - Being a mentor</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/newstarnovember-being-a-mentor/</link><pubDate>Sun, 27 Nov 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/newstarnovember-being-a-mentor/</guid><description>&lt;img src="https://images.unsplash.com/photo-1593132517397-ceb31d77194a?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=764&q=80" alt="Featured image of post #NewStarNovember - Being a mentor" />&lt;p>Thank you to the ever wonderful Ben &lt;a class="link" href="https://www.newstarsofdata.com/tell-us-your-story/" target="_blank" rel="noopener"
>for the suggestion to blog&lt;/a>. Check out #NewStarNovember for more blog posts.&lt;/p>
&lt;h1 id="who-was-your-mentor">Who was your mentor?&lt;/h1>
&lt;p>I have never had an official mentor but I am so very very grateful to all of the people who have helped, supported and inspired me throughout my career.&lt;/p>
&lt;p>I feel so privileged to be able to reach out to so many wonderful people and ask questions and receive advice.&lt;/p>
&lt;h2 id="so-rob-why-do-you-mentor-others">So Rob, Why do you mentor others?&lt;/h2>
&lt;p>I have always been willing to share everything that I know and have been doing so in various formats for many years now. I have officially mentored many people for presentations, through events such as New Stars of Data, Data (née SQL) Grillen, Data Minds, Data Scotland, as well as unofficially because they have asked me.&lt;/p>
&lt;p>Why do I do this? because I enjoy it, because I believe that anyone can give a good presentation and because the more voices we have giving presentations the better that it is for us all.&lt;/p>
&lt;h2 id="whats-the-best-thing-about-mentoring">What&amp;rsquo;s the best thing about mentoring?&lt;/h2>
&lt;p>So many things are fantastic about mentoring.&lt;/p>
&lt;p>You learn so many things. Getting the opinions of different people or watching how others perform similar tasks to you almost always leads to you learning something new. Whether it is the subject they are talking about, or just the way that they use PowerPoint or VS Code, or even the way they have Windows set up there is always something to learn.&lt;/p>
&lt;p>I also get such a warm fuzzy feeling from seeing people blossom as they gain confidence and realise that they can do a fantastic presentation and that it is a mainly a case of learning and practicing new skills.&lt;/p>
&lt;p>I am super proud of the people that I have mentored who have continued to present and have since presented at international conferences.&lt;/p>
&lt;p>I am also equally proud of those who have decided that it was not for them right now and are currently taking a break from presenting.&lt;/p>
&lt;p>I am delighted to see people who deserve it, become MVPs, or get promoted or change jobs. I hope that maybe I had a little impact, although I tell everyone I mentor, they are doing all of the hard work I am just listening and commenting.&lt;/p>
&lt;h2 id="doesnt-it-take-a-lot-of-time">Doesn&amp;rsquo;t it take a lot of time?&lt;/h2>
&lt;p>There is, of course, a time element to being a mentor but I am always happy to give up a few hours each month to help and I am also careful that I don&amp;rsquo;t take on too much and over burden myself.&lt;/p>
&lt;p>For me, being a mentor means giving guidance and setting goals and with a bit of careful planning you can be efficient about it.&lt;/p>
&lt;h2 id="what-else-have-you-learnt">What else have you learnt?&lt;/h2>
&lt;p>I have learnt that everyone is different and that, as a mentor, some of your tactics and procedures will not work for every person. As an example, I have learnt that some people like to have a script that they can use to memorise or to have as an aide whilst others are much happier just with key words.&lt;/p>
&lt;p>I have learnt that time zones make it harder. If it is Sunday evening for me, it is Sunday morning on the west coast of the US. This can make it harder to find times that fit well for both parties.&lt;/p>
&lt;h1 id="what-should-i-do">What should I do?&lt;/h1>
&lt;p>If someone asks or suggests that you do a presentation or become a mentor then I say that you should give it a try. They believe in you and so do I. &lt;a class="link" href="https://www.newstarsofdata.com/" target="_blank" rel="noopener"
>New Stars Of Data&lt;/a> CFP are open and available for mentors as well as new speakers.&lt;/p>
&lt;p>If this blog post makes you think &amp;ldquo;I would like to give this a go&amp;rdquo; at presenting or mentoring, then you can reach out to your local user group. You are a member of your local user group I hope? If not, you can find yours in the &lt;a class="link" href="https://www.meetup.com/en-AU/pro/azuredatatechgroups" target="_blank" rel="noopener"
>Azure Data Community&lt;/a>.&lt;/p>
&lt;p>Don&amp;rsquo;t want to speak in person the first time? You can sign up for &lt;a class="link" href="https://www.newstarsofdata.com/" target="_blank" rel="noopener"
>New Stars Of Data&lt;/a> and you will be presenting virtually on the 2023-05-12. They are also taking mentors for the speakers for this event.&lt;/p>
&lt;p>GOOD LUCK&lt;/p>
&lt;p>I believe in you&lt;/p>
&lt;p>You can do it.&lt;/p></description></item><item><title>#NewStarNovember - Getting into Speaking - It was fatherjack and SQLBits</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/newstarnovember-getting-into-speaking-it-was-fatherjack-and-sqlbits/</link><pubDate>Thu, 24 Nov 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/newstarnovember-getting-into-speaking-it-was-fatherjack-and-sqlbits/</guid><description>&lt;img src="https://images.unsplash.com/photo-1546872006-42c78c0ccb29?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=686&q=80" alt="Featured image of post #NewStarNovember - Getting into Speaking - It was fatherjack and SQLBits" />&lt;p>Thank you to the ever wonderful Ben &lt;a class="link" href="https://www.newstarsofdata.com/tell-us-your-story/" target="_blank" rel="noopener"
>for the suggestion to blog&lt;/a>. Check out #NewStarNovember for more blog posts.&lt;/p>
&lt;h1 id="in-the-beginning">In the beginning&lt;/h1>
&lt;p>It was around May of 2013 that I had written a blog post about spinning up and shutting down an Azure lab with PowerShell after being inspired at my first &lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>SQLBits Conference&lt;/a> (On a side note, I have attended, volunteered or spoken at every one since and this year I was delighted to become a Committee Member - If you have comments/questions/advice please feel free to email me at rob at sqlbits.com). That blog post still exists &lt;a class="link" href="https://blog.robsewell.com/azure/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>At the next SQL SouthWest User Group (as it was known then) Jonathan had said and next meeting we will have a session from Rob about PowerShell and Azure VMs. That was pretty much it. I thought why not give it a go. The worst that happens is that I don&amp;rsquo;t like it and don&amp;rsquo;t ever do it again. (Narrator - exactly the opposite happened - He loved it and does it &lt;a class="link" href="https://sessionize.com/rob-sewell/" target="_blank" rel="noopener"
>at every opportunity&lt;/a>)&lt;/p>
&lt;p>It was not the most brilliant presentation. I learned a lot and blogged about it too &lt;a class="link" href="https://blog.robsewell.com/blog/lessons-learnt-from-my-first-talk-at-sql-southwest/" target="_blank" rel="noopener"
>as you can read here&lt;/a>. But I enjoyed it and it gave me the confidence to do it again and set me on a path to the wonderful life I have now.&lt;/p>
&lt;h1 id="should-you-speak-at-your-user-group">Should you speak at your User Group?&lt;/h1>
&lt;p>Yes&lt;/p>
&lt;p>OK, you want a bit more?&lt;/p>
&lt;p>Yes you definitely should.&lt;/p>
&lt;p>You should try it once.&lt;/p>
&lt;p>Your user group should be filled with some familiar faces of people who you know will support you and only want the best for you.
It will usually be a smaller group than at an event like a Data Saturday or other local to your town/city event.
Your user group leader will be delighted to help and to support you.
If you don&amp;rsquo;t like it, you don&amp;rsquo;t ever have to do it again.&lt;/p>
&lt;h1 id="what-is-the-benefit-of-speaking">What is the benefit of speaking?&lt;/h1>
&lt;p>Why should you put yourself through all of that stress and work to put on a wonderful session? I think there are a number of benefits and most won&amp;rsquo;t come to you from doing a single session.&lt;/p>
&lt;ul>
&lt;li>The first one does. You will know your subject more thoroughly. By preparing a session to present, you will definitely research, you will read blogs, you will try things out, you will want to make sure that you know all there is to know. This means that you will be improving your knowledge on the subject.&lt;/li>
&lt;li>Confidence. Speaking in public will give you more confidence.&lt;/li>
&lt;li>It will improve your communication skills. You will have to be able to convey your message to others&lt;/li>
&lt;li>Some people say that a job interview is like a presentation and you can improve that skill. (I am not sure but &lt;a class="link" href="https://blog.robsewell.com/blog/i-hate-interviews-tsql2sday/" target="_blank" rel="noopener"
>I hate interviews and don&amp;rsquo;t perform well&lt;/a>)&lt;/li>
&lt;li>It will improve your time management skills. You have to do a presentation on Monday, you need to get everything in place in time for that.&lt;/li>
&lt;/ul>
&lt;p>There are plenty of other reasons too.&lt;/p>
&lt;h1 id="what-should-i-do">What should I do?&lt;/h1>
&lt;p>If someone asks or suggests that you do a presentation or become a mentor then I say that you should give it a try. They believe in you and so do I. &lt;a class="link" href="https://www.newstarsofdata.com/" target="_blank" rel="noopener"
>New Stars Of Data&lt;/a> call for papers are open and available for mentors as well as new speakers.&lt;/p>
&lt;p>If this blog post makes you think &amp;ldquo;I would like to give this a go&amp;rdquo; at presenting or mentoring, then you can reach out to your local user group. You are a member of your local user group I hope? If not, you can find yours in the &lt;a class="link" href="https://www.meetup.com/en-AU/pro/azuredatatechgroups" target="_blank" rel="noopener"
>Azure Data Community&lt;/a>.&lt;/p>
&lt;p>Don&amp;rsquo;t want to speak in person the first time? You can sign up for &lt;a class="link" href="https://www.newstarsofdata.com/" target="_blank" rel="noopener"
>New Stars Of Data&lt;/a> and you will be presenting virtually on the 2023-05-12. They are also taking mentors for the speakers for this event.&lt;/p>
&lt;p>GOOD LUCK&lt;/p>
&lt;p>I believe in you&lt;/p>
&lt;p>You can do it.&lt;/p></description></item><item><title>How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</link><pubDate>Thu, 28 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-import-dbatools-from-a-zip-file-from-the-github-release-into-azure-automation-modules-without-an-error/</guid><description>&lt;img src="https://images.unsplash.com/photo-1614791962365-7590111b1b1c?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1469&q=80" alt="Featured image of post How to import dbatools from a zip file from the GitHub release into Azure Automation Modules without an error" />&lt;p>There are a number of methods to import PowerShell modules into Azure automation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>as described in the documentation here&lt;/a>&lt;/p>
&lt;p>You may however miss an important piece of information hidden in that documentation if you are uploading a module from a GitHub release instead of via the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. The name that you refer to the module must match the module name and module folder name in the zip file.&lt;/p>
&lt;h1 id="method-one---from-gallery">Method one - from Gallery&lt;/h1>
&lt;p>This is my preferred method for importing modules into Azure Automation accounts, the only bothersome part is remembering to do it twice, once for 5.1 and once for 7.1 as I am sure that if I forget that will be the one module that I will need!&lt;/p>
&lt;h2 id="find-the-module">Find the module&lt;/h2>
&lt;p>Go to the Module page for the automation account and then Add module and browse the gallery and search for &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> (other modules are available!) and install it&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550108-e6096986-3392-4585-a57a-5c515c2890bf.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>It will take a few moments to install but you will see it in the list with a green tick once it has imported.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181548887-0ec695e4-41b9-45b3-8ab3-a004968c2323.png"
loading="lazy"
alt="image"
>#&lt;/p>
&lt;p>Then it is available in all of my PowerShell 7.1 runbooks in my automation account - Here I have just run &lt;code>Get-DbaToolsConfig&lt;/code> in a test runbook to prove that the module has imported&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181550937-7e89c7b3-31e8-4af1-b965-c82f2f63562f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="method-two---using-the-zip-file-from-a-github-release">Method two - using the zip file from a GitHub Release&lt;/h1>
&lt;p>Sometimes you may wish to not use the PowerShell Gallery to import the modules, maybe you have a custom module that you are not ready to upload to the gallery or maybe the module is just internally developed and not available on the &lt;a class="link" href="https://www.powershellgallery.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a>. In this scenario, you can still import hte module so that it can be used by your runbooks.&lt;/p>
&lt;p>To demonstrate, I will remove the dbatools module from the Automation Account&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181553061-9be2da4d-344d-4027-aa7f-902445cee12b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and download the latest release from GitHub directly&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/dataplat/dbatools/releases/tag/v1.1.118" target="_blank" rel="noopener"
>https://github.com/dataplat/dbatools/releases/tag/v1.1.118&lt;/a>&lt;/p>
&lt;p>If you are unable to use the PowerShell Gallery to get the latest dbatools release, I would always use the official signed release.&lt;/p>
&lt;p>You can then upload the zip from the same Modules page using the Browse for file but here is the &lt;em>important bit&lt;/em> You must update the name of the module. By default Azure will set the name to match the name of the zip file as that is what is expected and indeed mentioned in the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/automation/shared-resources/modules#author-modules?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft documentation here &lt;/a>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181561112-6aecd5e3-efaa-4b2a-84d7-f7e521035d04.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>and once it is imported successfully and I have a green tick&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181564377-df8c707e-24ec-43eb-8d57-702fcb39400b.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>I can run the test - Again I just ran &lt;code>Get-DbaToolsConfig&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181569077-2b2e59e2-4bf1-46b6-851f-2e624cf9c43c.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>This method will work with both PowerShell 5.1 and PowerShell 7.1, you will just have to upload the zip (and remember to rename the module entry) twice.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571123-8acb8ff5-7b36-4b62-91f7-34b3df36a1d8.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571518-909ecc6f-9270-45d2-a7b5-0de4406c88c4.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;h1 id="when-it-goes-wrong">When it goes wrong&lt;/h1>
&lt;p>If you do not rename the module correctly but leave it as the name of file &lt;code>dbatools-signed&lt;/code> in this example&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181571939-b881b4bc-4449-4569-b71a-66142436158a.png"
loading="lazy"
alt="image"
>
.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/6729780/181572041-2fe18929-cc14-40ae-b654-62653206903f.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;blockquote>
&lt;p>Error importing the module dbatools-signed. Import failed with the following error:&lt;br>
Orchestrator.Shared.AsyncModuleImport.ModuleImportException: Cannot import the module of name dbatools-signed, as the module structure was invalid. at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.ExecuteInternal(CodeActivityContext context, Byte[] moduleContent, String moduleName, ModuleLanguage moduleLanguage) at&lt;br>
Orchestrator.Activities.GetModuleMetadataAfterValidationActivity.Execute(CodeActivityContext context) at&lt;br>
System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)&lt;/p>
&lt;/blockquote>
&lt;p>If you get that, just re-upload the zip file and use the correct name in the form.&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>How Do You Show Keystrokes On Screen</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-do-you-show-keystrokes-on-screen/</link><pubDate>Fri, 22 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-do-you-show-keystrokes-on-screen/</guid><description>&lt;img src="https://images.unsplash.com/photo-1494412651409-8963ce7935a7?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1470&q=80" alt="Featured image of post How Do You Show Keystrokes On Screen" />&lt;p>It started with a tweet from Benni De Jagere &lt;a class="link" href="https://bennidejagere.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/BenniDeJagere" target="_blank" rel="noopener"
>Twitter&lt;/a> about how to show the keystrokes on the screen.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="it-depends">It depends&lt;/h1>
&lt;p>The best answer is always &amp;ldquo;it depends&amp;rdquo; and the correct response to this to determine how much to trust this information is &amp;ldquo;what does it depend uponW&amp;rdquo;&lt;/p>
&lt;h1 id="what-does-it-depend-upon">what does it depend upon?&lt;/h1>
&lt;p>It depends upon which programme you are using and wish to demonstrate.&lt;/p>
&lt;h2 id="visual-studio-code-or-azure-data-studio">Visual Studio Code or Azure Data Studio&lt;/h2>
&lt;p>If you are using &lt;a class="link" href="https://code.visualstudio.com/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> or &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/what-is-azure-data-studio?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> then you have it built in.&lt;/p>
&lt;p>You can press &lt;code>CTRL+SHIFT+P&lt;/code> and search for screencast&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/screencast.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/screencast.png"
loading="lazy"
alt="screencast"
>&lt;/a>&lt;/p>
&lt;p>if you toggle this on then the keystrokes are displayed on the screen as you type&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/display.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/display.png"
loading="lazy"
alt="displaying the keystrokes"
>&lt;/a>&lt;/p>
&lt;p>If you &lt;code>CTRL+,&lt;/code> or click on the cog and then settings, you can search for screencast and there are a number of options available. In the screenshot below you can see that the mouse click is highlighted as well.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/withmouse.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/withmouse.png"
loading="lazy"
alt="screencast settings with mouse"
>&lt;/a>&lt;/p>
&lt;h2 id="something-else">Something else&lt;/h2>
&lt;p>If you are wanting to demonstrate in a different application or when switching applications, you can use Carnac - &lt;a class="link" href="http://carnackeys.com/" target="_blank" rel="noopener"
>http://carnackeys.com/&lt;/a>&lt;/p>
&lt;p>Download the latest release and then run setup.exe and there will be a beautiful purple icon in the taskbar which if you click it will open the settings screen.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/carnacsettings.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/carnacsettings.png"
loading="lazy"
alt="carnac settings"
>&lt;/a>&lt;/p>
&lt;p>You can click in any of the squares to decide where you would like the key presses to be displayed and as you can see it works with multiple monitors (although I had some issues with that). You can use the sliders to offset in any direction from the box as well and change the appearance.&lt;/p>
&lt;p>You can even change the colour of the text as well.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/carnacdisplays.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/carnacdisplays.png"
loading="lazy"
alt="change colour"
>&lt;/a>&lt;/p>
&lt;p>To leave the application simple right click on the icon in the task bar and click Exit.&lt;/p>
&lt;p>Happy demonstrating!&lt;/p></description></item><item><title>Kubernetes lab certificates expired</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/kubernetes-lab-certificates-expired/</link><pubDate>Tue, 19 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/kubernetes-lab-certificates-expired/</guid><description>&lt;img src="https://images.unsplash.com/photo-1494412651409-8963ce7935a7?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1470&q=80" alt="Featured image of post Kubernetes lab certificates expired" />&lt;h1 id="it-wont-start">It won&amp;rsquo;t start!&lt;/h1>
&lt;p>I have a 3 node kubernetes cluster running in my office that I have used for my &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/azure-arc/hybrid-data-services?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Arc-enabled data services&lt;/a> presentations over the last year (&lt;a class="link" href="beard.media/presentations" >Side note, my presentations are here&lt;/a>). A few days ago after a power cut I tried to connect to my cluster with &lt;a class="link" href="https://k8slens.dev/" target="_blank" rel="noopener"
>Lens&lt;/a> and was not able to.&lt;/p>
&lt;p>I tried to run &lt;code>kubectl get nodes&lt;/code> but got no response.&lt;/p>
&lt;h2 id="try-on-the-master-node">Try on the master node&lt;/h2>
&lt;p>I used my windows terminal profile that ssh&amp;rsquo;s into the master node and ran&lt;/p>
&lt;p>&lt;code>systemctl status kubelet&lt;/code>&lt;/p>
&lt;p>this resulted in&lt;/p>
&lt;blockquote>
&lt;p>rob@beardlinux:~$ systemctl status kubelet&lt;br>
● kubelet.service - kubelet: The Kubernetes Node Agent&lt;br>
Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)&lt;br>
Drop-In: /etc/systemd/system/kubelet.service.d&lt;br>
└─10-kubeadm.conf&lt;br>
Active: active (running) since Thu 2022-07-07 09:29:00 BST; 8min ago&lt;br>
Docs: &lt;a class="link" href="https://kubernetes.io/docs/home/" target="_blank" rel="noopener"
>https://kubernetes.io/docs/home/&lt;/a>
Main PID: 1201 (kubelet)&lt;br>
Tasks: 15 (limit: 38316)&lt;br>
Memory: 120.3M&lt;br>
CGroup: /system.slice/kubelet.service&lt;br>
└─1201 /usr/bin/kubelet &amp;ndash;bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf &amp;ndash;kubeconfig=/etc/kub&amp;gt;&lt;br>
Jul 07 19:37:47 beardlinux kubelet[1201]: E0707 09:37:47.318044 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found
Jul 07 19:37:47 beardlinux kubelet[1201]: E0707 09:37:47.418240 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;/p>
&lt;/blockquote>
&lt;h2 id="how-many-logs">How many logs?&lt;/h2>
&lt;p>So beardlinux is the master node that we are running on so why can it not be found?&lt;/p>
&lt;p>&lt;code>journalctl -u kubelet -n 50&lt;/code>&lt;/p>
&lt;p>that will show me, i thought. It showed&lt;/p>
&lt;blockquote>
&lt;p>jrob@beardlinux:~$ journalctl -u kubelet -n 50&lt;br>
&amp;ndash; Logs begin at Thu 2022-06-16 14:26:08 BST, end at Thu 2022-07-07 19:38:55 BST. &amp;ndash;&lt;br>
Jul 07 19:38:50 beardlinux kubelet[1201]: E0707 19:38:50.710347 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:50 beardlinux kubelet[1201]: E0707 19:38:50.810556 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:50 beardlinux kubelet[1201]: E0707 19:38:50.910804 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.011102 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.111501 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.211840 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.312180 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.412460 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.512751 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.612983 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.713231 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.813398 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:51 beardlinux kubelet[1201]: E0707 19:38:51.913647 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.013891 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.114153 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.214312 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.314439 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.414546 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.514875 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.615009 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.715310 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.815683 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:52 beardlinux kubelet[1201]: E0707 19:38:52.915917 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:53 beardlinux kubelet[1201]: E0707 19:38:53.016190 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;br>
Jul 07 19:38:53 beardlinux kubelet[1201]: E0707 19:38:53.116399 1201 kubelet.go:2243] node &amp;ldquo;beardlinux&amp;rdquo; not found&lt;/p>
&lt;/blockquote>
&lt;p>Ah :-(&lt;/p>
&lt;p>so after some investigation I found&lt;/p>
&lt;blockquote>
&lt;p>Jul 06 08:03:09 beardlinux kubelet[1021]: I0706 08:03:09.755007 1021 kubelet_node_status.go:71] Attempting to register node beardlinux&lt;br>
Jul 06 08:03:09 beardlinux kubelet[1021]: E0706 08:03:09.755338 1021 kubelet_node_status.go:93] Unable to register node &amp;ldquo;beardlinux&amp;rdquo; with API server: Post &amp;ldquo;https://192.168.2.62:6443/api/v1/nodes&amp;rdquo;: dial tcp 192.168.2.62:6443: connect: connection refused&lt;/p>
&lt;/blockquote>
&lt;p>which lead me to an issue on GitHub where there was a &lt;a class="link" href="https://github.com/kubernetes/kubeadm/issues/1026#issuecomment-768832968" target="_blank" rel="noopener"
>comment&lt;/a> to check for expired certificates&lt;/p>
&lt;h2 id="do-i-have-expired-certificates">Do I have expired certificates?&lt;/h2>
&lt;p>You can check your certificates using&lt;/p>
&lt;p>&lt;code>kubeadm certs check-expiration&lt;/code>&lt;/p>
&lt;p>which resulted in&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/expired-certs.png"
loading="lazy"
alt="expired-certs"
>&lt;/p>
&lt;h2 id="and-renewing-them">And renewing them&lt;/h2>
&lt;p>They are renewed using &lt;code>kubeadm certs renew all&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>root@beardlinux:/home/rob# kubeadm certs renew all&lt;br>
[renew] Reading configuration from the cluster&amp;hellip;&lt;br>
[renew] FYI: You can look at this config file with &amp;lsquo;kubectl -n kube-system get cm kubeadm-config -o yaml&amp;rsquo;&lt;br>
[renew] Error reading configuration from the Cluster. Falling back to default configuration&lt;/p>
&lt;p>certificate embedded in the kubeconfig file for the admin to use and for kubeadm itself renewed&lt;br>
certificate for serving the Kubernetes API renewed&lt;br>
certificate the apiserver uses to access etcd renewed&lt;br>
certificate for the API server to connect to kubelet renewed&lt;br>
certificate embedded in the kubeconfig file for the controller manager to use renewed&lt;br>
certificate for liveness probes to healthcheck etcd renewed&lt;br>
certificate for etcd nodes to communicate with each other renewed&lt;br>
certificate for serving etcd renewed&lt;br>
certificate for the front proxy client renewed&lt;br>
certificate embedded in the kubeconfig file for the scheduler manager to use renewed&lt;/p>
&lt;p>Done renewing certificates. You must restart the kube-apiserver, kube-controller-manager, kube-scheduler and etcd, so that they can use the new certificates.&lt;/p>
&lt;/blockquote>
&lt;p>stopped and started the kubelet&lt;/p>
&lt;blockquote>
&lt;p>root@beardlinux:/home/rob# systemctl stop kubelet
root@beardlinux:/home/rob# systemctl start kubelet&lt;/p>
&lt;/blockquote>
&lt;p>and checked the nodes&lt;/p>
&lt;blockquote>
&lt;p>pwsh 7.2.5&amp;gt; kubectl get nodes&lt;br>
NAME STATUS ROLES AGE VERSION&lt;br>
beardlinux Ready control-plane,master 376d v1.20.2&lt;br>
beardlinux2 Ready &lt;!-- raw HTML omitted --> 376d v1.20.2&lt;br>
beardlinux3 Ready &lt;!-- raw HTML omitted --> 376d v1.20.2&lt;/p>
&lt;/blockquote>
&lt;p>I also had to update my config with the new certificate data to make that work as well.&lt;/p></description></item><item><title>GitHub Action Workflow Protected branch update failed</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/github-action-workflow-protected-branch-update-failed/</link><pubDate>Fri, 15 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/github-action-workflow-protected-branch-update-failed/</guid><description>&lt;img src="https://images.unsplash.com/photo-1580265862291-4251b8c7e836?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1740&q=80" alt="Featured image of post GitHub Action Workflow Protected branch update failed" />&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/blog/community/dev%20containers/powershell/github/Creating-A-Training-Day-Speakers-List-With-GitHub-Actions-From-A-GitHub-Issue/" >The last post&lt;/a> showed how we created an easy process to update a web-page using a GitHub Issue and two GitHub Actions.&lt;/p>
&lt;h1 id="protecting-the-repository">Protecting the repository&lt;/h1>
&lt;p>I opened the repository in the browser and GitHub and was provided with a warning that said&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/protectbranch.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/protectbranch.png"
loading="lazy"
alt="protect your branch"
>&lt;/a>&lt;/p>
&lt;p>Clicking on the protect this branch button gave the reasoning.&lt;/p>
&lt;blockquote>
&lt;p>Protect your most important branches
Branch protection rules define whether collaborators can delete or force push to the branch and set requirements for any pushes to the branch, such as passing status checks or a linear commit history.&lt;/p>
&lt;/blockquote>
&lt;p>So I changed the settings so that a Pull Request is required and needs to be reviewed.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/branchprotected.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/branchprotected.png"
loading="lazy"
alt="all protected"
>&lt;/a>&lt;/p>
&lt;h1 id="breaks-the-workflow">Breaks the workflow&lt;/h1>
&lt;p>I had already altered the workflow trigger for the workflow to generate the speaker-list.json so that it would run when changes to the speakers directory were pushed to the main branch by adding&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_call:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_dispatch:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> push:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> branches:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - main
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> paths:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - speakers/*
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then approved a PR with a change to that directory and saw that the workflow had started.&lt;/p>
&lt;p>Then it failed :-(.&lt;/p>
&lt;p>The error message could be seen in the codespaces with the extension &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=cschleiden.vscode-github-actions" target="_blank" rel="noopener"
>cschleiden.vscode-github-actions&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/pushdenied.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/pushdenied.png"
loading="lazy"
alt="no can do"
>&lt;/a>&lt;/p>
&lt;p>This is the error message&lt;/p>
&lt;blockquote>
&lt;p>Error: To &lt;a class="link" href="https://github.com/dataplat/DataSpeakers" target="_blank" rel="noopener"
>https://github.com/dataplat/DataSpeakers&lt;/a>
! refs/heads/main:refs/heads/main [remote rejected] (protected branch hook declined)
Done
Pushing to &lt;a class="link" href="https://github.com/dataplat/DataSpeakers" target="_blank" rel="noopener"
>https://github.com/dataplat/DataSpeakers&lt;/a>
POST git-receive-pack (604 bytes)
remote: error: GH006: Protected branch update failed for refs/heads/main. &lt;br>
remote: error: At least 1 approving review is required by reviewers with write access. &lt;br>
error: failed to push some refs to &amp;lsquo;&lt;a class="link" href="https://github.com/dataplat/DataSpeakers%27" target="_blank" rel="noopener"
>https://github.com/dataplat/DataSpeakers'&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Of course, because I have now protected my branch, I cannot automatically push changes into the main branch.&lt;/p>
&lt;h1 id="fix-it">Fix it&lt;/h1>
&lt;p>To fix this, I had to create a new PAT token with &lt;code>public_repo&lt;/code> scope and save it as a secret for the workflow to access and update the checkout to use this token.&lt;/p>
&lt;h2 id="create-a-new-pat-token">Create a new PAT token&lt;/h2>
&lt;p>The instructions to do this are found &lt;a class="link" href="https://docs.github.com/en/enterprise-server@3.4/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token" target="_blank" rel="noopener"
>in the docs here&lt;/a>&lt;/p>
&lt;ul>
&lt;li>In the upper-right corner of any page, click your profile photo, then click Settings.&lt;/li>
&lt;li>In the left sidebar, click Developer settings.&lt;/li>
&lt;li>In the left sidebar, click Personal access tokens.&lt;/li>
&lt;li>Click Generate new token.&lt;/li>
&lt;li>Give your token a descriptive name.&lt;/li>
&lt;li>To give your token an expiration.&lt;/li>
&lt;li>Select the scopes, or permissions, you&amp;rsquo;d like to grant this token.&lt;br>
For this scenario just choose &lt;code>public_repo&lt;/code>&lt;/li>
&lt;li>Click Generate token.&lt;/li>
&lt;li>Save the generated token somewhere safe like your password manager. ( You &lt;strong>do&lt;/strong> have a password manager? - Our family use 1Password)&lt;/li>
&lt;/ul>
&lt;h2 id="save-it-as-a-secret-in-the-repository">Save it as a secret in the repository&lt;/h2>
&lt;p>You do not ever ever ever want to store secrets in source control. When using GitHub like this you can store your secrets in the settings of the repository &lt;a class="link" href="https://github.com/Azure/actions-workflow-samples/blob/master/assets/create-secrets-for-GitHub-workflows.md" target="_blank" rel="noopener"
>by following this guide&lt;/a>&lt;/p>
&lt;ul>
&lt;li>navigate to the main page of the repository.&lt;/li>
&lt;li>Under your repository name, click on the &amp;ldquo;Settings&amp;rdquo; tab.&lt;/li>
&lt;li>In the left sidebar, click Secrets.&lt;/li>
&lt;li>On the right bar, click on &amp;ldquo;Add a new secret&amp;rdquo;&lt;/li>
&lt;li>Type a name for your secret in the &amp;ldquo;Name&amp;rdquo; input box. I used &lt;code>REPO_TOKEN&lt;/code>&lt;/li>
&lt;li>Type the value for your secret.&lt;/li>
&lt;li>Click Add secret.&lt;/li>
&lt;/ul>
&lt;h2 id="use-it-in-your-workflow">Use it in your workflow&lt;/h2>
&lt;p>Now that you have saved your secret, you can use it your workflows. To get rid of the protected branch error it is used in the &lt;code>actions/checkout&lt;/code> action like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">- uses: actions/checkout@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fetch-depth: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ref: main
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> token: ${{ secrets.REPO_TOKEN }}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I remembered to do for both workflows!!&lt;/p>
&lt;p>I then created a PR to test it and this time it was able to successfully push changes to the main branch&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/pushcompleted.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/pushcompleted.png"
loading="lazy"
alt="its pushed"
>&lt;/a>&lt;/p>
&lt;p>and you can see &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/commit/80d585ff1de15db22744ad5e7295294260b8fc98" target="_blank" rel="noopener"
>the commit here&lt;/a> or &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/commit/7046d51de7b1d9e9b9f188879a4981a76f35c3c4" target="_blank" rel="noopener"
>the PR&lt;/a> if you wish.&lt;/p>
&lt;h1 id="but-thats-not-all-folks">But thats not all folks&lt;/h1>
&lt;p>This will work correctly for a PR and it will work for the initial workflow that has been called.&lt;/p>
&lt;p>It &lt;em>&lt;strong>will not work&lt;/strong>&lt;/em> for the reusable workflow. When the reusable workflow is called from another workflow it is unable to pick up the token from the secrets. &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/actions/runs/2659979920" target="_blank" rel="noopener"
>In that scenario we get this error&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/gregbrokeit.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/gregbrokeit.png"
loading="lazy"
alt="Greg Broke it"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Input required and not supplied: token&lt;/p>
&lt;/blockquote>
&lt;p>for the &lt;code>actions/checkout@v2&lt;/code> action. This took some tracking down to resolve but finally I found the answer &lt;a class="link" href="https://github.community/t/reusable-workflows-secrets-and-environments/203695/18?u=sqldbawithabeard" target="_blank" rel="noopener"
>in a forum post&lt;/a>&lt;/p>
&lt;p>In the &lt;em>&lt;strong>calling&lt;/strong>&lt;/em> workflow add a &lt;code>secrets&lt;/code> entry and pass in the token secret.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">createSpeakerListJson:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> needs: addNewSpeaker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: dataplat/DataSpeakers/.github/workflows/wesbiteFile.yml@main
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> secrets:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> REPO_TOKEN: ${{ secrets.REPO_TOKEN }}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then at the top of the &lt;em>&lt;strong>reusable workflow&lt;/strong>&lt;/em> define the secrets&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_call:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> secrets:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> REPO_TOKEN:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> required: true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and finally all is well and Dr Greg Low &lt;a class="link" href="https://blog.greglow.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/greglow" target="_blank" rel="noopener"
>Twitter&lt;/a> can be added ;-)&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Creating A Training Day Speakers List with GitHub Action from a GitHub Issue</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-training-day-speakers-list-with-github-action-from-a-github-issue/</link><pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-training-day-speakers-list-with-github-action-from-a-github-issue/</guid><description>&lt;img src="https://images.unsplash.com/photo-1620712943543-bcc4688e7485?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=930&q=80" alt="Featured image of post Creating A Training Day Speakers List with GitHub Action from a GitHub Issue" />&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/blog/community/Training-Day-Speakers-List" >The last post&lt;/a> showed the resource that we created to enable speakers to let events know that they have content for pre-cons/training days. This post will describe how the automation was created using a GitHub Issue and two GitHub Actions.&lt;/p>
&lt;h1 id="what-do-we-need">What do we need?&lt;/h1>
&lt;p>The idea was to have a form for user input that could easily allow a person to add themselves and some information to a web page. The page holds a list of speakers who can present training day sessions for data platform events. &lt;a class="link" href="https://callfordataspeakers.com/precon" target="_blank" rel="noopener"
>The web page can be found here&lt;/a>. This page is generated from a JSON file.&lt;/p>
&lt;h1 id="a-new-repository">A new repository&lt;/h1>
&lt;p>It was decided to use a GitHub repository to hold this information so that it is available publicly as well as via the website.&lt;/p>
&lt;h1 id="create-a-dev-container">Create a dev container&lt;/h1>
&lt;p>It&amp;rsquo;s a brand new repository &lt;code>.devcontainer&lt;/code> directory was created and the files from the &lt;a class="link" href="https://github.com/microsoft/vscode-dev-containers/tree/main/containers/powershell/.devcontainer" target="_blank" rel="noopener"
>Microsoft VS Code Remote / GitHub Codespaces Container Definitions repository PowerShell containers&lt;/a> added. This means that whenever I or anyone else wants to work on the repo the development experience will be the same.&lt;/p>
&lt;h2 id="add-extensions">Add extensions&lt;/h2>
&lt;p>There are a number of default extensions that I install for PowerShell or generic development&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.powershell" target="_blank" rel="noopener"
>ms-vscode.powershell&lt;/a> - because I am working with PowerShell&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=2gua.rainbow-brackets" target="_blank" rel="noopener"
>2gua.rainbow-brackets&lt;/a> - because I like to easily see which opening bracket matches which closing bracket&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=oderwat.indent-rainbow" target="_blank" rel="noopener"
>oderwat.indent-rainbow&lt;/a> - so that I can quickly see the indentations, invaluable with YAML files&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=usernamehw.errorlens" target="_blank" rel="noopener"
>usernamehw.errorlens&lt;/a> - so that linting errors are displayed in the editor alongside the code&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens" target="_blank" rel="noopener"
>eamodio.gitlens&lt;/a> - to make source control easier&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=TylerLeonhardt.vscode-inline-values-powershell" target="_blank" rel="noopener"
>TylerLeonhardt.vscode-inline-values-powershell&lt;/a> - so that you can see inline values when debugging&lt;/li>
&lt;/ul>
&lt;p>I also added two more for this repository as we are using GitHub Actions&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=me-dutour-mathieu.vscode-github-actions" target="_blank" rel="noopener"
>me-dutour-mathieu.vscode-github-actions&lt;/a> - for intellisense for GitHub Action files&lt;/li>
&lt;li>&lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=cschleiden.vscode-github-actions" target="_blank" rel="noopener"
>cschleiden.vscode-github-action&lt;/a> - to be able to start/stop/monitor GitHub Actions from the workspace&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/githubactionsview.png"
loading="lazy"
alt="the view in codespaces of the GitHub Actions"
>&lt;/p>
&lt;h1 id="gather-the-information">Gather the Information&lt;/h1>
&lt;p>People can update repositories using Pull Requests but this needed to be a little more guided and it was decided that it was to be done with &lt;a class="link" href="https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/configuring-issue-templates-for-your-repository#creating-issue-forms" target="_blank" rel="noopener"
>forms via GitHub Issues&lt;/a>&lt;/p>
&lt;h2 id="where-to-put-it">Where to put it?&lt;/h2>
&lt;p>You can create custom GitHub Issues using YAML files in the &lt;code>.github/ISSUE_TEMPLATE&lt;/code> directory. An Add Speaker issue template file was created. The name and the description will be seen on the &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/new/choose" target="_blank" rel="noopener"
>new issues page&lt;/a>.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">name: Add Speaker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">description: Add New Speaker information
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">body:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - type: markdown
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> attributes:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> value: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Please follow the instructions to create a new speaker entry.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> We wil display this on callfordataspeakers.com
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There are a number of &lt;code>-type&lt;/code> entries. &lt;a class="link" href="https://docs.github.com/en/communities/using-templates-to-encourage-useful-issues-and-pull-requests/syntax-for-githubs-form-schema" target="_blank" rel="noopener"
>You can find the definitions in the docs&lt;/a> or you can use the intellisense from the extensions. The types are checkboxes, dropdown, input, markdown, textarea&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/intellisense-ghactions.png"
loading="lazy"
alt="The intellisense showing the type options"
>&lt;/p>
&lt;p>I used the intellisense to build a quick simple form to gather 5 pieces of information&lt;/p>
&lt;ul>
&lt;li>full name&lt;/li>
&lt;li>topics&lt;/li>
&lt;li>regions&lt;/li>
&lt;li>sessionize profile URL&lt;/li>
&lt;li>languages&lt;/li>
&lt;/ul>
&lt;p>You can find &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/blob/main/.github/ISSUE_TEMPLATE/Add-Speaker.yml" target="_blank" rel="noopener"
>the YAML file here&lt;/a> and &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/new?assignees=&amp;amp;labels=&amp;amp;template=Add-Speaker.yml" target="_blank" rel="noopener"
>the issue here&lt;/a>&lt;/p>
&lt;h1 id="process-the-information">Process the information&lt;/h1>
&lt;p>Now that we have a method of gathering the information, the next stage is to process it automagically. For this we are going to be &lt;a class="link" href="https://docs.github.com/en/actions" target="_blank" rel="noopener"
>using GitHub Actions&lt;/a>&lt;/p>
&lt;h2 id="workflow">Workflow&lt;/h2>
&lt;p>GitHub Actions is a platform that can run automated processes called workflows that are defined as YAML files and triggered by events in the repository. We create another directory called &lt;code>workflows&lt;/code> also in the &lt;code>.github&lt;/code> directory.&lt;/p>
&lt;h2 id="triggering-the-workflow">Triggering the workflow&lt;/h2>
&lt;p>Many people are comfortable with a DevOps process that will build, test and deploy code when a pull request is raised and approved, GitHub Actions are able to do more as they can be triggered by any events in the repository.&lt;/p>
&lt;p>You can automatically add labels, close stale issues and much more. There are a large number of events open to you as &lt;a class="link" href="https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows" target="_blank" rel="noopener"
>can be seen here &lt;/a>. Even looking at just issues there are a number of activities types that can be used&lt;/p>
&lt;ul>
&lt;li>opened&lt;/li>
&lt;li>edited&lt;/li>
&lt;li>deleted&lt;/li>
&lt;li>transferred&lt;/li>
&lt;li>pinned&lt;/li>
&lt;li>unpinned&lt;/li>
&lt;li>closed&lt;/li>
&lt;li>reopened&lt;/li>
&lt;li>assigned&lt;/li>
&lt;li>unassigned&lt;/li>
&lt;li>labeled&lt;/li>
&lt;li>unlabeled&lt;/li>
&lt;li>locked&lt;/li>
&lt;li>unlocked&lt;/li>
&lt;li>milestoned&lt;/li>
&lt;li>demilestoned&lt;/li>
&lt;/ul>
&lt;p>(and there are separate ones for issue comments)&lt;/p>
&lt;p>The beginning of the workflow YAML file has the name and then the trigger. This triggers the workflow when an issue is opened.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">name: Add a new speaker json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issues:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> types:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#34;opened&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="getting-all-the-source">Getting all the source&lt;/h2>
&lt;p>The workflow consists of &lt;a class="link" href="https://docs.github.com/en/actions/using-jobs" target="_blank" rel="noopener"
>one or many jobs&lt;/a> that can be run on different runners. The first job is named &lt;code>AddNewSpeaker&lt;/code> and runs on the latest ubuntu version. Each job can have a number of steps and the first step in this scenario is to checkout the latest version of the repository.&lt;/p>
&lt;p>We &lt;strong>&lt;em>use&lt;/em>&lt;/strong> a default &lt;strong>&lt;em>action&lt;/em>&lt;/strong> to checkout and because we push changes back to the repository (more on that later) we choose a &lt;code>fetch-depth&lt;/code> of 0 to get all of the history and the &lt;code>ref&lt;/code> main as that is the branch we are working with.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">jobs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addNewSpeaker:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> runs-on: ubuntu-latest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> steps:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - uses: actions/checkout@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> fetch-depth: 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ref: main
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="being-polite">Being polite&lt;/h2>
&lt;p>costs nothing so this action from Peter Evans can be used to add or update a comment&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Add comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Hi @${{ github.event.issue.user.login }},
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Thank you so much for your Speaker submission.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The Action should be running now and adding it to the webpage. It should should update here.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If it doesn&amp;#39;t - get in touch with Rob on Twitter https://twitter.com/sqldbawithbeard
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="wait-a-minute-how-did-you-work-that-out">wait a minute, how did you work that out?&lt;/h3>
&lt;p>The say thank you comment uses &lt;code>github.event.issue.number&lt;/code> and &lt;code>github.event.issue.user.login&lt;/code> to ensure that the comment goes on the issue that triggered the workflow and thanks the user that created it. To work out what is available, I used this PowerShell step to write out the GitHub context to the logs as JSON&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># You also can print the whole GitHub context to the logs to view more details.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: View the GitHub context
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> run: Write-Host &amp;#34;$GITHUB_CONTEXT&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> env:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> GITHUB_CONTEXT: ${{ toJson(github) }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shell: pwsh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="get-the-info-into-a-file">Get the info into a file&lt;/h2>
&lt;p>Whilst developing, I first saved the issue body to a file so that I could work with it. As I moved forward I forgot and just left the code in and it works. The issue form creates &lt;code>### &amp;lt;label&amp;gt;&lt;/code> and then a blank line and then the data that was entered. This enabled me to use some regex and capture each label, grab the data and put it in a &lt;code>pscustomobject&lt;/code>&lt;/p>
&lt;p>Then I could convert it to Json and save it to a file. I chose to save each speakers information in their own file in case anything else would be needed in the future and also so that if the process failed it only affected this speakers information.&lt;/p>
&lt;p>I also add the speaker file name to a text file that I may make use of at some future point.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Get Speaker Information to file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> run: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Host &amp;#34;What do we have?&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # gci -recurse = this is for troubleshooting because paths are hard
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IssueBody = &amp;#34;${{ github.event.issue.body }}&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write-Host $IssueBody
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IssueBody | Out-File speakers/temp.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # get the temp file contents - I do this so I don&amp;#39;t lose anything
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $file = Get-Content ./speakers/temp.txt -Raw
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # parse the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $regexResult = [regex]::Matches($file, &amp;#39;(?ms)fullname\n\n(?&amp;lt;fullname&amp;gt;.*)\n\n### topics\n\n(?&amp;lt;topics&amp;gt;.*)\n\n### regions\n\n(?&amp;lt;regions&amp;gt;.*)\n\n### Sessionize\n\n(?&amp;lt;Sessionize&amp;gt;.*)\n\n### language\n\n(?&amp;lt;language&amp;gt;.*)\n&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # create an object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerObject = [PSCustomObject]@{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name = $regexResult[0].Groups[&amp;#39;fullname&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> topics = $regexResult[0].Groups[&amp;#39;topics&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> regions = $regexResult[0].Groups[&amp;#39;regions&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sessionize = $regexResult[0].Groups[&amp;#39;Sessionize&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> language = $regexResult[0].Groups[&amp;#39;language&amp;#39;].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #save it to a file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerFileName = $SpeakerObject.name -replace &amp;#39; &amp;#39;, &amp;#39;-&amp;#39; -replace &amp;#39;&amp;#39;&amp;#39;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;/&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\\&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;:&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\*&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\?&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;&amp;#34;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\|&amp;#39;,&amp;#39;-&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $filePath = &amp;#39;./speakers/{0}.json&amp;#39; -f $speakerFileName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $SpeakerObject |ConvertTo-Json | Out-FIle -FilePath $filePath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $speakerFileName | OUt-File ./speakers/list.txt -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> shell: pwsh
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="because-ben-is-a-fantastic-tester">Because Ben is a fantastic tester&lt;/h3>
&lt;p>All the best testers will do unexpected but valid actions and my wonderful friend Ben Weissman (&lt;a class="link" href="https://twitter.com/bweissman" target="_blank" rel="noopener"
>Twitter&lt;/a> &lt;a class="link" href="https://bweissman.azurewebsites.net/" target="_blank" rel="noopener"
>Blog&lt;/a>) added some characters into the full name option that made the file save fail. He added his pronouns, which is awesome but not what I expected for a full name option. This is totally my fault for not considering either using pronouns or that as a user input field that is used in code the data should be validated. I used a few replaces to ensure the file name is acceptable.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$speakerFileName = $SpeakerObject.name -replace &amp;#39; &amp;#39;, &amp;#39;-&amp;#39; -replace &amp;#39;&amp;#39;&amp;#39;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;/&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\\&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;:&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\*&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\?&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;&amp;#34;&amp;#39;,&amp;#39;-&amp;#39; -replace &amp;#39;\|&amp;#39;,&amp;#39;-&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="let-the-user-know-and-commit-the-new-file">Let the user know and commit the new file&lt;/h2>
&lt;p>Next up is another comment, this time to show some progress but also add a link to the created files directory so that the speaker can see it. They can also edit this file if they wish to make any changes. (yes, maybe I should have thought of a way to do it with issues but this is an iterative process).&lt;/p>
&lt;p>I love the &lt;code>EndBug/add-and-commit&lt;/code> action as it enables me to make changes in a workflow and commit those changes safely back to the repository.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - name: Add another comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The Speaker Json has been added https://github.com/dataplat/DataSpeakers/tree/main/speakers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Add &amp;amp; Commit
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: EndBug/add-and-commit@v8.0.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> author_name: Beardy McBeardFace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> author_email: mrrobsewell@outlook.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> message: &amp;#39;The Beard says hooray we have another speaker @${{ github.event.issue.user.login }} - This is an automated message&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="dry">DRY&lt;/h2>
&lt;p>Don&amp;rsquo;t repeat yourself. The idea is to create the JSON file for the web-page from each of the speakers individual json files. People will want to change what they have entered or they will make mistakes, future functionality might require the same steps. With this in mind I created a separate workflow file to create the &lt;code>speaker-list.json&lt;/code> file. This used two different triggers&lt;/p>
&lt;ul>
&lt;li>&lt;code>workflow_calls&lt;/code> so that it can be called from another workflow&lt;/li>
&lt;li>&lt;code>workflow_dispatch&lt;/code> so that it can be run manually&lt;/li>
&lt;/ul>
&lt;p>The other workflow cannot be triggered manually as it relies on an issue to create the required file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">on:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_call:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> workflow_dispatch:
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="only-run-if">Only run if&lt;/h2>
&lt;p>The second workflow file uses a PowerShell action to combine the individual JSONs into a single one and commits that to the repository. It also comments on the issue but it can only do this if the workflow was triggered from the add speaker job and not manually so some conditional logic was required. There were a number of options that I could choose to decide if to run this step but I decided on using the event issue number &lt;code>if: github.event.issue.number != null&lt;/code> as if there was no issue, there was nothing to comment and this would leave this step open to be used in future coding if required.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">- name: Add another comment to the issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/create-or-update-comment@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if: github.event.issue.number != null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> body: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> The speaker-list.json file has been recreated ready for the website https://github.com/dataplat/DataSpeakers/blob/main/website/speaker-list.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> https://callfordataspeakers.com/precon should be updated now
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="calling-another-workflow">Calling another workflow&lt;/h2>
&lt;p>To call another workflow in a job you use the &lt;code>uses:&lt;/code> field and the path to the yaml file and the branch. We also added the &lt;code>needs:&lt;/code> so that this job will run after the &lt;code>addNewSpeaker&lt;/code> has completed.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">createSpeakerListJson:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> needs: addNewSpeaker
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: dataplat/DataSpeakers/.github/workflows/wesbiteFile.yml@main
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="close-the-issue">Close the issue&lt;/h2>
&lt;p>This process needed to be completely automatic and so we use Peter Evans close issue action and tag the speaker and say thankyou as well as closing the issue. We have a &lt;code>needs:&lt;/code> property so that this job will only run following the successful run of the previous two jobs.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">closeIssue:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> needs: [addNewSpeaker,createSpeakerListJson]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> runs-on: ubuntu-latest
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> steps:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Close Issue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> uses: peter-evans/close-issue@v2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> with:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> issue-number: ${{ github.event.issue.number }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> comment: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Hey @${{ github.event.issue.user.login }},
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Closing this issue now that the Action has run successfully.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Thank you so much for adding your information to the list.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It will be active on callfordataspeakers.com shortly.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Please share on social media.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Love and Hugs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Rob and Daniel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @SqlDbaWithABeard @dhmacher
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="show-me-what-it-looks-like">Show me what it looks like&lt;/h1>
&lt;p>You can &lt;a class="link" href="https://github.com/dataplat/DataSpeakers" target="_blank" rel="noopener"
>take a look at the repo&lt;/a> there are a &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues?q=is%3Aissue&amp;#43;is%3Aclosed" target="_blank" rel="noopener"
>number of issues&lt;/a> like &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues/36" target="_blank" rel="noopener"
>this one from Monica Rathbun&lt;/a> (&lt;a class="link" href="https://twitter.com/SQLEspresso" target="_blank" rel="noopener"
>Twitter&lt;/a> - &lt;a class="link" href="https://sqlespresso.com/" target="_blank" rel="noopener"
>Blog&lt;/a>)&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/monissue.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/monissue.png"
loading="lazy"
alt="Monicas Image"
>&lt;/a>&lt;/p>
&lt;p>you can see the workflows &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/actions" target="_blank" rel="noopener"
>running here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2022/07/workflowrun.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/workflowrun.png"
loading="lazy"
alt="workflow run"
>&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Training Day Speakers List</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/training-day-speakers-list/</link><pubDate>Sun, 10 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/training-day-speakers-list/</guid><description>&lt;img src="https://images.unsplash.com/photo-1490127252417-7c393f993ee4?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1770&q=80" alt="Featured image of post Training Day Speakers List" />&lt;p>How do data platform events find Training Day/Pre-Con speakers?&lt;/p>
&lt;p>&lt;a class="link" href="https://callfordataspeakers.com/precon" target="_blank" rel="noopener"
>So we built a thing for speakers to add themselves and for events to find them&lt;/a>&lt;/p>
&lt;p>I think event organisers know who the &lt;em>big names&lt;/em> are and the topics that they can deliver for full day training sessions or pre-cons as they are also known. Finding other speakers and finding speakers who can deliver on different topics is a little more difficult.&lt;/p>
&lt;h1 id="hey-new-speakers">Hey New Speakers&lt;/h1>
&lt;p>With all the &lt;em>*waves hand at world for the last 2 years&lt;/em> going on, there are a number of new speakers who have taken advantage of virtual events like &lt;a class="link" href="https://www.newstarsofdata.com/" target="_blank" rel="noopener"
>New Stars Of Data&lt;/a>, &lt;a class="link" href="https://datagrillen.com/dativerse/" target="_blank" rel="noopener"
>DatiVerse&lt;/a> and other events that have helped to promote and support new speakers. This is truly awesome and I love seeing the pool of speakers growing and all the new voices enriching our learning.&lt;/p>
&lt;p>There are undoubtedly speakers who have content and can provide full day seesions that events and attendees will gladly have if only the organisers knew about the content and/or the speakers knew about the events.&lt;/p>
&lt;h1 id="events-want-your-content">Events want your content&lt;/h1>
&lt;p>This came up on social media and after a quick conversation with Daniel Hutmacher (&lt;a class="link" href="https://twitter.com/dhmacher" target="_blank" rel="noopener"
>Twitter&lt;/a> &lt;a class="link" href="https://sqlsunday.com/" target="_blank" rel="noopener"
>Blog&lt;/a>) we decided to create a resource page that can be found on &lt;a class="link" href="https://callfordataspeakers.com" target="_blank" rel="noopener"
>Call For Data Speakers&lt;/a>.&lt;/p>
&lt;p>Call For Data Speakers enables speakers to sign up to receive an email when a new event is announced. It also enables events to sign up, so that speakers can be notified when there is a call for speakers. So this seemed to be the obvious place to hold a list of speakers that event organisers can contact and show the topics that they can present full day or training day sessions on.&lt;/p>
&lt;h1 id="yes-even-you-please-join">YES even you. Please join.&lt;/h1>
&lt;p>I have created some automation that will make adding (and removing) yourself from this list easy to do. You can just go straight to &lt;a class="link" href="https://github.com/dataplat/DataSpeakers" target="_blank" rel="noopener"
>the repo&lt;/a> and follow the instructions if you dont want to read any more here.&lt;/p>
&lt;p>I see this as a resource for everybody, famouse or not, new or old. I absolutely want &lt;strong>you to add yourself&lt;/strong>, if you have content that can be used to provide a full day of training. Please don&amp;rsquo;t let imposter syndrome get in the way. Right now, all you are doing is listing your idea for people to see. Hopefully soon event organisers will get in touch and say hey I see you present on &amp;hellip; please would you submit to our event for a training day.&lt;/p>
&lt;p>Event organisers - You &lt;strong>do need to reach out to speakers&lt;/strong>. By adding some effort into finding speakers your event will be more rounded and of interest and benefit to a wider numebr of attendees and sponsors. I am talking about pre-con speakers here bu the same applies to general sessions.&lt;/p>
&lt;h1 id="how-do-i-do-it">How do I do it?&lt;/h1>
&lt;p>This process is all automated and driven by GitHub Issues.&lt;/p>
&lt;h2 id="to-add-yourself-as-a-speaker">To add yourself as a speaker&lt;/h2>
&lt;p>Open the &lt;a class="link" href="https://github.com/dataplat/DataSpeakers/issues" target="_blank" rel="noopener"
>Issues Page&lt;/a> and click new issue.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/dataplat/DataSpeakers/main/images/newissue.png"
loading="lazy"
alt="open a new issue"
>&lt;/p>
&lt;p>Click the get started button next to Add Speaker.&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/dataplat/DataSpeakers/main/images/emptyissue.png"
loading="lazy"
alt="empty issue"
>&lt;/p>
&lt;p>Fill in the details, the title can be anything that you like -&lt;/p>
&lt;ul>
&lt;li>Your full name&lt;/li>
&lt;li>topics you can provide training days or pre-cons for (dbatools, Index Tuning, DevOps for example) Add as many as you like.&lt;br>
&lt;strong>Just topics&lt;/strong> not session titles or descriptions, those will be in your sessionize profile then this resource does not need updating so frequently. It is after all just a &amp;ldquo;Here I am, come find me&amp;rdquo; resource.&lt;/li>
&lt;li>regions that you would be willing to present training days or pre-cons in (these match the regions on callfordataspeakers.com)&lt;/li>
&lt;li>Your sessionize profile URl which will show the event organisers the precise sessions that you have and also your contact details/methods&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://raw.githubusercontent.com/dataplat/DataSpeakers/main/images/filledinsessions.png"
loading="lazy"
alt="new speaker info"
>&lt;/p>
&lt;p>Thats it, then press Submit new issue and the automation will do its thing&lt;/p>
&lt;h1 id="what-does-it-look-like">What does it look like?&lt;/h1>
&lt;p>A GitHub Action will run and &lt;a class="link" href="https://callfordataspeakers.com/precon" target="_blank" rel="noopener"
>the web-page&lt;/a> will be updated.&lt;/p>
&lt;p>You can then search for topics, regions, click on any topic to see all the speakers that are happy to present on that topic.&lt;/p>
&lt;p>Click on a speaker and you will be directed to their Sessionize profile page.&lt;/p>
&lt;p>Here is a quick look at the demo page after I had some test data in there!&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/callfordataprecons.png"
loading="lazy"
alt="PreConSpeakers"
>&lt;/p>
&lt;h1 id="what-else-can-i-do">What else can I do?&lt;/h1>
&lt;p>Please promote this resource. It will have no benefit if speakers do not add themselves and event organisers do not know about it.&lt;/p>
&lt;p>I would be really happy if you can keep this in mind if you are organising a data platform event, let any speakers know that this exists so that they can add themselves, share it on social media.&lt;/p>
&lt;p>Many Thanks.&lt;/p></description></item><item><title>GitHub Pages in Dev Containers and Codespaces</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/github-pages-in-dev-containers-and-codespaces/</link><pubDate>Mon, 04 Jul 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/github-pages-in-dev-containers-and-codespaces/</guid><description>&lt;img src="https://images.unsplash.com/photo-1494961104209-3c223057bd26?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1102&q=80" alt="Featured image of post GitHub Pages in Dev Containers and Codespaces" />&lt;h1 id="broken-link">Broken Link&lt;/h1>
&lt;p>It started with a message from Mikey Bronowski ( &lt;a class="link" href="https://www.bronowski.it/blog/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/@MikeyBronowski" target="_blank" rel="noopener"
>Twitter&lt;/a> )&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/mikey-dm.png"
loading="lazy"
alt="message from Mikey"
>&lt;/p>
&lt;p>Now this means that you get to see my awesome &lt;a class="link" href="https://blog.robsewell.com/justsomethingsad" target="_blank" rel="noopener"
>404 page &lt;/a> which makes me laugh every time! It is not a very good look though and does not help people who are reading the blog.&lt;/p>
&lt;h2 id="why-do-something-manual-when-you-can-automate-it">Why do something manual when you can automate it&lt;/h2>
&lt;p>This blog is running on GitHub Pages via a repository. Every time a change is pushed to the repo a GitHub Action runs which rebuilds the jekyll site and makes it available.&lt;/p>
&lt;p>So the easy thing to do is to edit the code to add the corrected link, push the change and have GitHub Pages do its thing. If I wanted to validate it first then I could use docker and containers as discussed in these two blog posts &lt;a class="link" href="2021-04-11-locally-viewing-github-pages-new-data-saturdays.md" >Running GitHub Pages locally&lt;/a> or &lt;a class="link" href="2021-04-15-locally-viewing-github-pages-locally-with-remote-theme.md" >Running GitHub Pages locally with a Remote Theme (this site has a remote theme)&lt;/a>. Then I could see the changes locally before pushing them to the repository.&lt;/p>
&lt;p>But my brain didn&amp;rsquo;t work in that way. Instead it thought &amp;ldquo;Hmmm maybe I could do this in the browser in &lt;a class="link" href="https://github.com/features/codespaces" target="_blank" rel="noopener"
>GitHub Codespaces&lt;/a> and then it could work locally as it will have a dev container (development container) configuration and VS Code will just open that in Docker itself, no need for running docker commands manually and I can write blog posts anywhere there is a browser or VS Code&amp;rdquo;&lt;/p>
&lt;p>The most wonderful Jess Pomfret &lt;a class="link" href="https://jesspomfret.com" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/@jpomfret" target="_blank" rel="noopener"
>Twitter&lt;/a> and I delivered a &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> Training Day at SQL Bits this year which we developed and ran using dev containers. We also presented a session at the &lt;a class="link" href="psconf.eu" >PowerShell Conference Europe&lt;/a> about using dev containers so I had a little knowledge of how it can be done.&lt;/p>
&lt;h1 id="how-easy-is-it-">How easy is it ?&lt;/h1>
&lt;p>It&amp;rsquo;s super super easy. Surprisingly easy.&lt;/p>
&lt;h2 id="open-a-codespace-for-your-repository">Open a codespace for your repository&lt;/h2>
&lt;p>First I went to the repository for my website and opened a codespace by clicking on the green code button and creating a codespace&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/create-codespace.png"
loading="lazy"
alt="the create codespace button"
>&lt;/p>
&lt;h2 id="add-the-development-container-configuration">Add the development container configuration&lt;/h2>
&lt;p>Using &lt;code>CTRL SHIFT + P&lt;/code> to open the command palette and typing codespaces and choosing the Add Development Container Configuration Files&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/add-config.png"
loading="lazy"
alt="Add the configuration"
>&lt;/p>
&lt;p>and follow the prompts&lt;/p>
&lt;ul>
&lt;li>Show All Definitions&lt;/li>
&lt;li>Jekyll&lt;/li>
&lt;li>bullseye (or buster if you use Apples)&lt;/li>
&lt;li>lts&lt;/li>
&lt;/ul>
&lt;h2 id="the-config-files-are-created">The config files are created&lt;/h2>
&lt;p>This will create a &lt;code>.devcontainer&lt;/code> directory with&lt;/p>
&lt;ul>
&lt;li>devcontainer.json&lt;/li>
&lt;li>Dockerfile&lt;/li>
&lt;li>post-create.sh&lt;/li>
&lt;/ul>
&lt;p>Which will do all that you need. You can stop here. You will just need to run &lt;code>jekyll serve&lt;/code> to start the website.&lt;/p>
&lt;h2 id="automatic-regeneration">Automatic regeneration&lt;/h2>
&lt;p>To make it automatically regenerate. I added&lt;/p>
&lt;p>&lt;code>bundle exec jekyll serve --force-polling&lt;/code>&lt;/p>
&lt;p>to the end of the post-create.sh file. This will automatically start the website and regenerate it everytime I make a change :-)&lt;/p>
&lt;h2 id="view-the-logs">View the logs&lt;/h2>
&lt;p>You can watch the logs of the regeneration with View Creation Log from the command palette - Use &lt;code>CTRL SHIFT + P&lt;/code> to open it. Then you can see the log output in real-time.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/view-creation-log.png"
loading="lazy"
alt="look at the logs"
>&lt;/p>
&lt;h2 id="open-the-website-locally">Open the website &amp;ldquo;locally&amp;rdquo;&lt;/h2>
&lt;p>To open the website from inside the devcontainers the ports are exposed via the configuration. In the browser in codepaces there is a port tab and a button to press to open the website and show the updates that you have written.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/port-forwards.png"
loading="lazy"
alt="the ports get forwarded"
>&lt;/p>
&lt;p>If you click that you get a live view of the website so that you can validate that it works.&lt;/p>
&lt;h1 id="and-vs-code">And VS Code?&lt;/h1>
&lt;p>This showed it being created in codespaces in the browser, you can have the same effect in VS Code by adding a &lt;code>.devcontainer&lt;/code> directory and copying the files from the &lt;a class="link" href="https://github.com/microsoft/vscode-dev-containers/tree/v0.238.1/containers/jekyll/.devcontainer" target="_blank" rel="noopener"
>vs code dev containers repo&lt;/a>&lt;/p>
&lt;p>The rest is pretty much the same except the url!&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2022/07/vscode.png"
loading="lazy"
alt="running in vs code"
>&lt;/p>
&lt;h1 id="rather-have-video-">Rather Have Video ?&lt;/h1>
&lt;p>If you prefer video then you can find one on Youtube showing the same process.&lt;/p>
&lt;p>{% include youtubePlayer.html id=&amp;ldquo;aFFmPlbjfCw&amp;rdquo; %}&lt;/p></description></item><item><title>Quickly Creating Test Users in SQL Server using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</link><pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/02/remove-them-all.png" alt="Featured image of post Quickly Creating Test Users in SQL Server using dbatools" /></description></item><item><title>Archives</title><link>https://sqldbawithabeard.github.io/blogrobsewell/archives/</link><pubDate>Sun, 06 Mar 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/archives/</guid><description/></item><item><title>Azure DevOps Pipeline Template Job Names and single quotes</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-devops-pipeline-template-job-names-and-single-quotes/</link><pubDate>Fri, 28 Jan 2022 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-devops-pipeline-template-job-names-and-single-quotes/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Azure DevOps Pipeline Template Job Names and single quotes" />&lt;h1 id="the-job-name-deploy_function_app-appears-more-than-once">The job name Deploy_Function_App appears more than once&lt;/h1>
&lt;p>This was the error I was notified about in a Azure DevOps pipeline when they tried to run it. The error message continued to say that Job Names must be unique within a pipeline.&lt;/p>
&lt;h2 id="set-up">Set Up&lt;/h2>
&lt;p>There is a centralised repository of Azure DevOps Pipeline Template Jobs that call the Bicep modules with the required values in the same repo to deploy Azure Infrastructure.&lt;/p>
&lt;p>The error was received in the pipeline that was created to make use of these template jobs and deploy a whole projects worth of infrastructure.&lt;/p>
&lt;p>It looked like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2022/01/bemoreuniquenames.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2022/01/uniquenames.png"
loading="lazy"
alt="unique"
>&lt;/a>&lt;/p>
&lt;p>When I looked at the template job it had&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">jobs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - job: Deploy_Function_App
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ${{ if eq(parameters[&amp;#39;dependsOnLogAnalytics&amp;#39;], true) }}:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dependsOn:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Resource_Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Log_Analytics
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ${{ if eq(parameters[&amp;#39;dependsOnLogAnalytics&amp;#39;], false) }}:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dependsOn:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Resource_Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pool:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> vmImage: windows-latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="so-you-fixed-it">So you fixed it?&lt;/h2>
&lt;p>I can see that the job name will always be &lt;code>Deploy_Function_App&lt;/code> so I just need to paramatarise it. For this example, I am going to say it was a parameter called suffix, and the code looked like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">jobs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - job: Deploy_Function_App${{ parameters.suffix }}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ${{ if eq(parameters[&amp;#39;dependsOnLogAnalytics&amp;#39;], true) }}:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dependsOn:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Resource_Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Log_Analytics
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ${{ if eq(parameters[&amp;#39;dependsOnLogAnalytics&amp;#39;], false) }}:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> dependsOn:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - Deploy_Resource_Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pool:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> vmImage: windows-latest
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>A quick Pull Request, which was approved and then pushed and I said &amp;ldquo;Hey, all fixed, try again&amp;rdquo;. This is the response I got - It failed again&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2022/01/bemoreuniquenames.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2022/01/uniquenames.png"
loading="lazy"
alt="unique"
>&lt;/a>&lt;/p>
&lt;p>Job Deploy_Function_App_speechtotext&amp;rsquo; has an invalid name. Valid names may only contain alphanumeric characters and &amp;lsquo;_&amp;rsquo; and may not start with a number.&lt;/p>
&lt;p>I had to look at it for a few minutes before I spotted the error! The job name sure looks like it only has alphanumeric characters and my YAML is perfectly valid so the string must be properly quoted. I mean it must be properly quoted otherwise it would fail right?&lt;/p>
&lt;p>Wrong&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - job: Deploy_Function_App${{ parameters.suffix }}&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is only one single quote here which we did not notice!&lt;/p>
&lt;p>Altering it to this worked.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - job: &amp;#39;Deploy_Function_App${{ parameters.suffix }}&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Hopefully that might help someone. (No doubt I will find this in a search in a few months time when I do it again!!)&lt;/p>
&lt;p>Happy automating&lt;/p></description></item><item><title>What does JS_InvalidFilePath error mean in Azure DevOps?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/what-does-js_invalidfilepath-error-mean-in-azure-devops/</link><pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/what-does-js_invalidfilepath-error-mean-in-azure-devops/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post What does JS_InvalidFilePath error mean in Azure DevOps? " />&lt;h1 id="cant-find-loc-string-for-key-js_invalidfilepath">Can't find loc string for key: JS_InvalidFilePath&lt;/h1>
&lt;p>This was the error I received in my Azure DevOps pipeline when I tried to run it.&lt;/p>
&lt;p>When I investigated further it said&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">##[debug]workingDirectory=/home/vsts/work/1/s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[debug]check path : /home/vsts/work/1/s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[warning]Can\&amp;#39;t find loc string for key: JS_InvalidFilePath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[debug]Processed: ##vso[task.issue type=warning;]Can\&amp;#39;t find loc string for key: JS_InvalidFilePath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[debug]task result: Failed
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[error]JS_InvalidFilePath /home/vsts/work/1/s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[debug]Processed: ##vso[task.issue type=error;]JS_InvalidFilePath /home/vsts/work/1/s
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##[debug]Processed: ##vso[task.complete result=Failed;]JS_InvalidFilePath /home/vsts/work/1/s
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="what-is-going-on">What is going on?&lt;/h1>
&lt;p>I was trying to run a simple Azure PowerShell task and had defined it like this (I used VS Code with the Azure Pipelines extension and made use of the intellisense). I had defined it like this.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - task: AzurePowerShell@5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: deploy
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> displayName: Deploy from cache
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inputs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureSubscription: &amp;#39;azurePAYGconnection&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Inline: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $date = Get-Date -Format yyyyMMddHHmmsss
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $deploymentname = &amp;#39;deploy_testRg_{0}&amp;#39; -f $date # name of the deployment seen in the activity log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TemplateFile = &amp;#39;BicepFiles\Deployments\TheTestResourceGroup.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> New-AzDeployment -Name $deploymentname -Location uksouth -TemplateFile $TemplateFile -Verbose # -WhatIf
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azurePowerShellVersion: &amp;#39;LatestVersion&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> env:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SYSTEM_ACCESSTOKEN: $(system.accesstoken)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pwsh: true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> enabled: true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which gave me no errors, the YAML is correct (yes, I was suprised too!). The Azure Pipeline definition does not raise an error either in VS Code or in Azure DevOps.&lt;/p>
&lt;h1 id="what-was-missing">What was missing?&lt;/h1>
&lt;p>I had not put &lt;code>ScriptType: 'InlineScript'&lt;/code> and this is what caused that odd error.&lt;/p>
&lt;p>The correct definition was&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> - task: AzurePowerShell@5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: deploy
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> displayName: Deploy from cache
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> inputs:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureSubscription: &amp;#39;azurePAYGconnection&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ScriptType: &amp;#39;InlineScript&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Inline: |
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $date = Get-Date -Format yyyyMMddHHmmsss
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $deploymentname = &amp;#39;deploy_testRg_{0}&amp;#39; -f $date # name of the deployment seen in the activity log
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TemplateFile = &amp;#39;BicepFiles\Deployments\TheTestResourceGroup.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> New-AzDeployment -Name $deploymentname -Location uksouth -TemplateFile $TemplateFile -Verbose # -WhatIf
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azurePowerShellVersion: &amp;#39;LatestVersion&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> env:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SYSTEM_ACCESSTOKEN: $(system.accesstoken)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pwsh: true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> enabled: true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Hopefully that might help someone. (No doubt I will find this in a search in a few months time when I do it again!!)&lt;/p>
&lt;p>Happy automating&lt;/p></description></item><item><title>Deploying a Bicep Module from a private repository without a connection to the repository</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-bicep-module-from-a-private-repository-without-a-connection-to-the-repository/</link><pubDate>Tue, 02 Nov 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-bicep-module-from-a-private-repository-without-a-connection-to-the-repository/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Deploying a Bicep Module from a private repository without a connection to the repository" />&lt;h1 id="using-a-private-module-repository">Using a private module repository&lt;/h1>
&lt;p>From Bicep version 0.4.1008 you can save and version your Bicep modules in repositories. &lt;a class="link" href="https://msftplayground.com/2021/11/using-private-repositories-for-bicep-modules/" target="_blank" rel="noopener"
>You can read more about how to do it here&lt;/a>. This is really useful for reusing modules and modularising large corporate infrastructure environments.&lt;/p>
&lt;p>You can control how a single resource (think of a storage account) is deployed across your environment and ensure that all requirements are followed (the storage account must have public access disabled, must have private endpoints and must have the one production network allowed). This is really useful and since it has been available we have used this to deploy infrastructure.&lt;/p>
&lt;h1 id="so-whats-the-problem-">So whats the problem ?&lt;/h1>
&lt;p>When you need to use a module from the repository, you refer to the repository when you define the module path.&lt;/p>
&lt;p>&lt;code>module storage 'br:bearddemoacr.azurecr.io/bicep/storage/storagev2:0.0.2' = {&lt;/code>&lt;/p>
&lt;p>This says I want to deploy something we will call &lt;code>storage&lt;/code> and you can find the definition called &lt;code>bicep/storage/storagev2&lt;/code> in a Bicep Repository (&lt;code>br&lt;/code>) at &lt;code>bearddemoacr.azurecr.io&lt;/code> and we will use the tag &lt;code>0.0.2&lt;/code>. The rest of the properties will then be written.&lt;/p>
&lt;p>On the client that you use to do the deployment, Bicep will &lt;code>restore&lt;/code> the required information from the Bicep Repository and use that to perform the deployments. By default, it uses the path &lt;code>~/.bicep&lt;/code> on Linux/Mac and &lt;code>$HOME\.bicep&lt;/code> on Windows.&lt;/p>
&lt;p>If you take a look in that directory, you will see the files that have been restored for use.&lt;/p>
&lt;p>![cachecontents]({{ &amp;ldquo;/assets/uploads/2021/Bicep/cachecontents.png&amp;rdquo; | relative_url }})&lt;/p>
&lt;p>But this relies on the client that is performing the deployment having connectivity and being able to authenticate to the Azure Container Registry (ACR) that is holding the Bicep Modules.&lt;/p>
&lt;h1 id="why-would-the-client-not-have-access">Why would the client not have access?&lt;/h1>
&lt;p>There are a number of situations where the deployment client (a workstation, a devops pipeline agent) may not have access to the ACR. The development and testing of the Bicep Modules may take place in a development Azure subscription which has no connectivity to the production Azure subscription. The production environment may be in Azure Government Cloud or it may be in a customers Azure subscription and opening a connection to an ACR in another subscription in another network may be prohibitively complicated and time consuming due to the process required to gain approvals and perform the actions to open the required paths or (more likely) is simply not allowed.&lt;/p>
&lt;h1 id="bicep_cache_directory-environment-variable-to-the-rescue">BICEP_CACHE_DIRECTORY environment variable to the rescue&lt;/h1>
&lt;p>There is an environment variable called BICEP_CACHE_DIRECTORY that defines the path that is used to hold the restored bicep artifacts. This means that we can do two things to enable us to continue to use a Bicep Repository with all of the benefits but still be able to deploy the infrastructure.&lt;/p>
&lt;h1 id="cache-the-files">Cache the files&lt;/h1>
&lt;p>Firstly, as part of the build process we can set the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> path and perform a &lt;code>bicep restore&lt;/code> on the Bicep Resource file. This will restore all of the referenced modules to the path. We can then package this directory with our deployment bicep file and transfer them to the deployment environment.&lt;/p>
&lt;h1 id="deploy-the-bicep">Deploy the Bicep&lt;/h1>
&lt;p>Then when we extract the package we can set the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> to the directory holding the cached files and deploy our bicep as we would normally. Even though the files reference the Bicep Repository by name, the deployment will use the cache. I even tested it by deleting the images from the Bicep Repository completely (after I had run &lt;code>bicep restore&lt;/code> of course) and I was able to deploy from the cache without issue.&lt;/p>
&lt;p>Hopefully, this wil help someone somewhere as the &lt;code>BICEP_CACHE_DIRECTORY&lt;/code> variable is not wildly known or documented.&lt;/p>
&lt;p>Happy automating&lt;/p></description></item><item><title>When you REALLY want to see your Azure DevOps Secret Variable Values</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/when-you-really-want-to-see-your-azure-devops-secret-variable-values/</link><pubDate>Tue, 10 Aug 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/when-you-really-want-to-see-your-azure-devops-secret-variable-values/</guid><description>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/michael-dziedzic-1bjsASjhfkE-unsplash.jpg" alt="Featured image of post When you REALLY want to see your Azure DevOps Secret Variable Values" />&lt;h1 id="i-really-needed-to-see-the-values">I REALLY needed to see the values&lt;/h1>
&lt;p>The problem was that I had code in an Azure DevOps PowerShell task which was using a Service Principal to do some things in Azure and it was failing.&lt;/p>
&lt;p>The pipeline had some things a little like this, it got a number of values from a key vault, set them to variables and used them in a custom function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$somevalue = (Get-AzKeyVaultSecret -vaultName $KeyVaultName -name &amp;#39;AGeneratedName&amp;#39;).SecretValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$somecredential = New-Object System.Management.Automation.PSCredential (&amp;#39;dummy&amp;#39;, $somevalue )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$something = $somecredential.GetNetworkCredential().Password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Do-SomethingSpecial -MyThing $something
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I was getting an error saying &amp;ldquo;forbidden - *** does not have access&amp;rdquo; or similar&lt;/p>
&lt;p>Thing is, I knew that &lt;code>$something&lt;/code> did have access as I could run the same code from my workstation and it did the logging in for &lt;code>$something&lt;/code> so the error must be in the values that I was passing into the function. (there were more values than this but that is not important)&lt;/p>
&lt;p>All I needed to do was to see what values had been passed to the function and I could resolve this little issue. But these were secret variables. Helpfully kept out of the logs by Azure DevOps hence the *** so what to do?&lt;/p>
&lt;p>I thought - I know what I will do, I will write the Parameter values from the function out as Verbose, call the function with &lt;code>-Verbose&lt;/code> and then delete the run to clear up the logs.&lt;/p>
&lt;p>I added&lt;/p>
&lt;p>&lt;code>Write-Verbose ($PSBoundParameters | Out-String)&lt;/code>&lt;/p>
&lt;p>to my function, called it with verbose in the pipeline and got&lt;/p>
&lt;blockquote>
&lt;p>Name       Value&lt;br>
- -         - -&lt;br>
MyThing       ***&lt;/p>
&lt;/blockquote>
&lt;p>Awesome.&lt;/p>
&lt;p>Write it to a file and read it back. This is a tactic that you can read about that works but it puts the secrets on disk on the agent and I did not want to do that.&lt;/p>
&lt;p>I thought I would be even cleverer and this time I added to my function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$WhatsMyThing = $MyThing + &amp;#39;-1&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Verbose &amp;#34;My thing is $WhatsMyThing&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Thats bound to work.&lt;/p>
&lt;p>My how I laughed when in the logs I had&lt;/p>
&lt;blockquote>
&lt;p>My Thing is  ***-1&lt;/p>
&lt;/blockquote>
&lt;p>Right. I thought.&lt;/p>
&lt;p>This IS IT.&lt;/p>
&lt;p>I WILL SHOW YOU AZURE DEVOPS&lt;/p>
&lt;p>I added to my function&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$WhatsMyThing =[Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes($$MyThing ))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Verbose &amp;#34;My thing is $WhatsMyThing&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This converted the value of MyThing into a base64 encoded value which I could see in the logs.&lt;/p>
&lt;blockquote>
&lt;p>My Thing is VGhlIEJlYXJkIGlzIExhdWdoaW5nIGF0IHlvdS4gWW91IHRoaW5rIEkgd291bGQgcHV0IHNvbWV0aGluZyByZWFsIGluIGhlcmU/IEdvb2QgdHJ5Lg==&lt;/p>
&lt;/blockquote>
&lt;p>and then I could decode it on my workstation with&lt;/p>
&lt;p>&lt;code>[System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String('ValueFromLogs'))&lt;/code>&lt;/p>
&lt;p>and learn that despite two people looking at the values we couldnt tell the difference between AGeneratedName and AnotherGeneratedName and they were the wrong way around!!!!&lt;/p>
&lt;p>But at least I know now a good way to get those secret values.&lt;/p>
&lt;p>If you do this, dont forget to delete the pipeline run from Azure DevOps so that the encoded value is not left in the logs for anyone to read.&lt;/p>
&lt;p>Every day is a learning day.&lt;/p></description></item><item><title>How to deploy an Azure Arc Enabled SQL Managed Instance in AKS</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-deploy-an-azure-arc-enabled-sql-managed-instance-in-aks/</link><pubDate>Sat, 03 Jul 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-deploy-an-azure-arc-enabled-sql-managed-instance-in-aks/</guid><description>&lt;img src="https://raw.githubusercontent.com/SQLDBAWithABeard/Beard-Aks-AEDS/main/images/connecteddc.png" alt="Featured image of post How to deploy an Azure Arc Enabled SQL Managed Instance in AKS" />&lt;h1 id="want-to-play-before-ga-">Want to play before GA ?&lt;/h1>
&lt;p>Azure SQL enabled by Azure Arc will be generally available at the end of the month following the announcement &lt;a class="link" href="https://azure.microsoft.com/en-us/blog/bring-cloud-experiences-to-data-workloads-anywhere-with-azure-sql-enabled-by-azure-arc?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can read more about &lt;a class="link" href="https://azure.microsoft.com/en-us/services/azure-arc/hybrid-data-services?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Arc-enabled Data Services &lt;/a>&lt;/p>
&lt;p>I have been playing with it for a few months, mainly in a Kubernetes cluster running on my NUCs in my office but Azure Arc is available in so many places, all the public clouds, your own data center (or NUCs in your office :-) ) so if you want to try it out and you do not want to build your own Kubernetes cluster then you can use &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/kubernetes-service?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>AKS&lt;/a> in Azure.&lt;/p>
&lt;h1 id="how-can-i-do-that-">How can I do that ?&lt;/h1>
&lt;p>One way is to use the &lt;a class="link" href="https://azurearcjumpstart.io/azure_arc_jumpstart/azure_arc_data?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Arc Jumpstart website&lt;/a> which has many templates for many scenarios.&lt;/p>
&lt;p>I like playing with &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Bicep&lt;/a> which is a domain-specific language or DSL for deploying Azure resources.&lt;/p>
&lt;p>I have &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Beard-Aks-AEDS" target="_blank" rel="noopener"
>created a repository on GitHub &lt;/a> which you can use to create your own AKS cluster with an Azure Arc Enabled directly connected Data Controller and SQL Managed Instance either 1 node replica or 3 node replica.&lt;/p>
&lt;p>There is even the code to create an Azure Virtual Machine and install the required tooling if you need it.&lt;/p>
&lt;p>All of the details and instructions are in the read me file so feel free to go and make use of it and you can have a resource group that looks like this&lt;/p>
&lt;p>&lt;img src="https://raw.githubusercontent.com/SQLDBAWithABeard/Beard-Aks-AEDS/main/images/portalresources.png"
loading="lazy"
alt="portal"
>&lt;/p>
&lt;p>Just dont forget to delete the Resource Group once you have finished!!&lt;/p>
&lt;p>You can create it any time you like with the code :-)&lt;/p>
&lt;p>Happy Azure Arc SQL Managed Instance playing!&lt;/p></description></item><item><title>Flexing My Bicep - Reusable code with modules for deploying an Azure SQL Server</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-reusable-code-with-modules-for-deploying-an-azure-sql-server/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-reusable-code-with-modules-for-deploying-an-azure-sql-server/</guid><description>&lt;img src="https://datasaturdays.com/assets/design/twitter/c.twitter%201r.png" alt="Featured image of post Flexing My Bicep - Reusable code with modules for deploying an Azure SQL Server" />&lt;h1 id="reusable-code">Reusable code&lt;/h1>
&lt;p>We looked at a simple deployment of an Azure SQL Server and a database in the last blog post. You would like to reuse this code though, you will want to create more SQL Instances and SQL databases in the future. With Bicep, you can use modules and parameters to do this.&lt;/p>
&lt;p>You can create a module for your SQL Instance. I look up &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers/databases?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>the resource information from the documentation&lt;/a> and create a file named SQLInstance.bicep. I put it in a Resources directory.&lt;/p>
&lt;h1 id="parameters">Parameters&lt;/h1>
&lt;p>At the top of the file you need to define parameters to enabled you to pass in different values for the deployment. You can find information about &lt;a class="link" href="https://github.com/Azure/bicep/blob/main/docs/spec/parameters.md" target="_blank" rel="noopener"
>Bicep parameters in the docs on GitHub&lt;/a>.&lt;/p>
&lt;p>You define a parameter using the keyword &lt;code>param&lt;/code>. At a minimum you need a name and a datatype. An obvious one for this usecase would be the name of the SQL Instance which could be defined as&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param SqlInstanceName string
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Perhaps your organisation has a requirement for all of the data to be stored in a particular region. You might want to have a default value for your location parameter. You can define a default parameter by assigning it with an equals sign.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param location string = &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Some parameters that you would like to use will only allow certain values. You can define those as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">@allowed([
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#39;Disabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param transparentDataEncryption string = &amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">targetScope = &amp;#39;resourceGroup&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param SqlInstanceName string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param location string = &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param tags object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param administratorLogin string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param administratorLoginPassword string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param minimalTlsVersion string = &amp;#39;1.0&amp;#39; // 1.0,1.1,1.2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param publicNetworkAccess string = &amp;#39;Disabled&amp;#39; // &amp;#39;Disabled&amp;#39;,&amp;#39;Enabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ActiveDirectoryAdminUser string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ActiveDirectoryAdminUserSid string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param tenantid string
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param azureADOnlyAuthentication bool = false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ExternalAdministratorPrincipalType string // User Application Group
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param sqlauditActionsAndGroups array //BATCH_COMPLETED_GROUP,,SUCCESSFUL_DATABASE_AUTHENTICATION_GROUP,FAILED_DATABASE_AUTHENTICATION_GROUP maybe some of these too but the logs will get large,APPLICATION_ROLE_CHANGE_PASSWORD_GROUP,BACKUP_RESTORE_GROUP,DATABASE_LOGOUT_GROUP,DATABASE_OBJECT_CHANGE_GROUP,DATABASE_OBJECT_OWNERSHIP_CHANGE_GROUP,DATABASE_OBJECT_PERMISSION_CHANGE_GROUP,DATABASE_OPERATION_GROUP,DATABASE_PERMISSION_CHANGE_GROUP,DATABASE_PRINCIPAL_CHANGE_GROUP,DATABASE_PRINCIPAL_IMPERSONATION_GROUP,DATABASE_ROLE_MEMBER_CHANGE_GROUP,FAILED_DATABASE_AUTHENTICATION_GROUP,SCHEMA_OBJECT_ACCESS_GROUP,SCHEMA_OBJECT_CHANGE_GROUP,SCHEMA_OBJECT_OWNERSHIP_CHANGE_GROUP,SCHEMA_OBJECT_PERMISSION_CHANGE_GROUP,SUCCESSFUL_DATABASE_AUTHENTICATION_GROUP,USER_CHANGE_PASSWORD_GROUP,BATCH_STARTED_GROUP,BATCH_COMPLETED_GROUP
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param SqldatabaseNames array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param dbSkuName string // for example GP_Gen5_2, BC_Gen5_10, HS_Gen5_8, P5, S0 etc
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param collation string = &amp;#39;SQL_Latin1_General_CP1_CI_AS&amp;#39; //
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param maxSizeBytes int // The max size of the database expressed in bytes.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param zoneRedundant bool = false // Whether or not this database is zone redundant, which means the replicas of this database will be spread across multiple availability zones.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param licenseType string = &amp;#39;LicenseIncluded&amp;#39; // The license type to apply for this database. LicenseIncluded if you need a license, or BasePrice if you have a license and are eligible for the Azure Hybrid Benefit. - LicenseIncluded or BasePrice
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: SqlInstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: tags
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> identity: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> type: &amp;#39;SystemAssigned&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: administratorLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: administratorLoginPassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> minimalTlsVersion: minimalTlsVersion
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: publicNetworkAccess
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administrators: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorType: &amp;#39;ActiveDirectory&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> login: ActiveDirectoryAdminUser
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sid: ActiveDirectoryAdminUserSid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tenantId: tenantid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureADOnlyAuthentication: azureADOnlyAuthentication
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> principalType: ExternalAdministratorPrincipalType
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">// SQL Databases
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">resource symbolicname &amp;#39;Microsoft.Sql/servers/databases@2020-11-01-preview&amp;#39; = [for item in SqldatabaseNames:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> parent: sql
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: tags
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sku: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: dbSkuName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> collation: collation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> maxSizeBytes: maxSizeBytes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> zoneRedundant: zoneRedundant
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> licenseType: licenseType
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Invalid Template Deployment with my Bicep</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/invalid-template-deployment-with-my-bicep/</link><pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/invalid-template-deployment-with-my-bicep/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Invalid Template Deployment with my Bicep" />&lt;h1 id="an-error">An Error&lt;/h1>
&lt;p>Did I tear my bicep? No but I got an error. Whilst trying to deploy a network with Bicep using Azure DevOps I received the error&lt;/p>
&lt;blockquote>
&lt;p>Error: Code=InvalidTemplateDeployment; Message=The template deployment &amp;lsquo;deploy_bicep003_20210505094331&amp;rsquo; is not valid according to the validation procedure. The tracking id is &amp;lsquo;4bdec1fe-915d-4735-a1c1-7b56fbba0dc2&amp;rsquo;. See inner errors for details.&lt;/p>
&lt;/blockquote>
&lt;p>Unfortunately that was all that I had. I had to find the inner error for details&lt;/p>
&lt;h1 id="try-the-deployment-log-on-the-resource-group">Try the deployment log on the Resource Group&lt;/h1>
&lt;p>As I know that the Bicep deployments are logged in Azure under the Resource Groups deployment I looked there first but there were no entries (obviously Rob, there had been no deployment)&lt;/p>
&lt;p>So I navigated to the home page of the Azure Portal and searched for Activity log.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylog.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylog.png"
loading="lazy"
alt="activitylog"
>&lt;/a>&lt;/p>
&lt;p>I searched for the name of the deployment &lt;code>deploy_bicep003_20210505094331&lt;/code> and saw&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogsearch.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogsearch.png"
loading="lazy"
alt="activitylogsearch"
>&lt;/a>&lt;/p>
&lt;p>clicking on the link showed me this with the relevant information hidden in the JSON&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogdetails.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/activitylogdetails.png"
loading="lazy"
alt="activitylogdetails"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Resource name {&amp;rsquo;name&amp;rsquo;:&amp;lsquo;subnet1&amp;rsquo;,&amp;lsquo;addressPrefix&amp;rsquo;:&amp;lsquo;10.0.0.0/24&amp;rsquo;}.name is invalid.&lt;/p>
&lt;/blockquote>
&lt;p>Bingo.&lt;/p>
&lt;p>I had made a mistake in my resource definition for the subnets. I had used&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">subnets: [for item in subnets:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item}.name&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addressPrefix: &amp;#39;${item}.addressPrefix&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>where I should have used&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">subnets: [for item in subnets:{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;${item.name}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> addressPrefix: &amp;#39;${item.addressPrefix}&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Every day is a learning day.&lt;/p></description></item><item><title>Flexing My Bicep - Deploy an Azure SQL Database -Intro to Azure Bicep IaC</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-deploy-an-azure-sql-database-intro-to-azure-bicep-iac/</link><pubDate>Thu, 20 May 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/flexing-my-bicep-deploy-an-azure-sql-database-intro-to-azure-bicep-iac/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/Bicep/xavier-von-erlach-ooR1jY2yFr4-unsplash.jpg" alt="Featured image of post Flexing My Bicep - Deploy an Azure SQL Database -Intro to Azure Bicep IaC" />&lt;h1 id="starting-working-out">Starting working out?&lt;/h1>
&lt;p>It is important to keep a healthy body and mind, especially when my life is so sedentary these days. Getting exercise is good for both. This blog post has nothing to do with exercise though (apart from maybe exercising the mind)&lt;/p>
&lt;h1 id="project-bicep">Project Bicep&lt;/h1>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/bicep-overview?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Bicep&lt;/a> is a language for declaring and deploying Azure Resources. Like &lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>Terraform&lt;/a> it enables you to define your infrastructure as code.&lt;/p>
&lt;h2 id="why-use-bicep-instead">WHy use Bicep instead?&lt;/h2>
&lt;p>I really like being able to control infrastructure with code. I have used &lt;a class="link" href="https://blog.robsewell.com/tags/#terraform" target="_blank" rel="noopener"
>Terraform to deploy infrastructure&lt;/a> and almost exclusively on Azure. I have created and altered many environments for clients over the past couple of years using Terraform. I have also used ARM templates but found them confusing and unwieldly to use.&lt;/p>
&lt;h2 id="existing-state">Existing State&lt;/h2>
&lt;p>Terraform will deploy the required changes to your infrastructure by comparing the existing state which is stored in a state file with the expected state which is created by running the plan command. If someone alters the Azure resource via the portal, Azure CLI or Azure PowerShell all kinds of mayhem can occur normally failure in deployment and time spent troubleshooting. It is possible to use the &lt;a class="link" href="https://www.terraform.io/docs/cli/commands/import.html" target="_blank" rel="noopener"
>&lt;code>import&lt;/code> command in Terraform&lt;/a> to get the existing resource state into the state file so that the comparison is performed against the existing state of the resource but this requires a lot of manual intervention.&lt;/p>
&lt;p>Bicep deploys the changes by comparing the existing state of the Azure resources with the expected state in the code. This, for me, is a super benefit and reduces the complications of those type of errors.&lt;/p>
&lt;h2 id="latest-api-support">Latest API support&lt;/h2>
&lt;p>Terraform resources have a lag between features or properties from Azure being made available and those features or properties being incorporated into the Terraform resource. This has lead to me requiring my deployments to have additional Azure CLI, Azure PowerShell or worse both steps to achieve what I need.&lt;/p>
&lt;p>Bicep immediately supports all preview and GA versions for Azure Services, I don&amp;rsquo;t have to wait and all the things I can do are available to me.&lt;/p>
&lt;h2 id="authoring">Authoring&lt;/h2>
&lt;p>I love &lt;a class="link" href="https://code.visualstudio.com" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> and there is a &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-bicep&amp;amp;WT.mc_id=devops-13338-abewan" target="_blank" rel="noopener"
>super extension&lt;/a> that makes authoring a joy.&lt;/p>
&lt;h2 id="what-if-support">What If Support&lt;/h2>
&lt;p>I have written before about the &lt;a class="link" href="https://blog.robsewell.com/blog/powershell/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/" target="_blank" rel="noopener"
>importance of WhatIf for PowerShell functions and how to implement it&lt;/a> and Bicep has &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/template-deploy-what-if?tabs=azure-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>What If for deployments&lt;/a> so that you can validate that the code you have written will perform the tasks that you expect.&lt;/p>
&lt;h2 id="deployments-recorded-in-azure">Deployments recorded in Azure&lt;/h2>
&lt;p>The changes that I make with Bicep are recorded in Azure and I can find them in the deployments for the Resource Group&lt;/p>
&lt;h2 id="cost">Cost&lt;/h2>
&lt;p>Bicep is free :-)&lt;/p>
&lt;h1 id="deploy-an-azure-sql-database-rob">Deploy an Azure SQL Database Rob&lt;/h1>
&lt;p>OK, let&amp;rsquo;s see an example. I would like to deploy an Azure SQL Database into a Resource Group. I will need an Azure SQL Server resource and an Azure SQL Database resource. The &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Templates site&lt;/a> has the examples that I need. The &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure SQL Server page&lt;/a> shows the Bicep code I need and the explanations of the expected values.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource symbolicname &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tags: {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> identity: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> type: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> minimalTlsVersion: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> encryptionIdentityId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> keyId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administrators: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorType: &amp;#39;ActiveDirectory&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> principalType: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> login: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sid: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> tenantId: &amp;#39;string&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> azureADOnlyAuthentication: bool
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a file with a &lt;code>.bicep&lt;/code> extension in VS Code&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/bicepfile.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/bicepfile.png"
loading="lazy"
alt="bicepfile"
>&lt;/a>&lt;/p>
&lt;p>and add only the required values. (NOTE - this is just an example and I would never recommend that you would put the password for anything in a file in plain text, we will cover how to handle secrets later. )&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;beardsqlrand01&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;sysadmin&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;dbatools.IO&amp;#39; // DON&amp;#39;T DO THIS - EVER
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="validate-the-deployment-with-whatif">Validate the deployment with WhatIf&lt;/h2>
&lt;p>I created an empty Resource Group for my test&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-AzResourceGroup -Name &amp;#39;BicepTest&amp;#39; -Location &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Next, I am going to check that the code that I have written will perform the actions that I expect. I am hoping to get&lt;/p>
&lt;ul>
&lt;li>An Azure SQL Instance called beardsqlrand01&lt;/li>
&lt;li>In the location North Europe&lt;/li>
&lt;li>With an admin login and password as stated in the file (NO Don&amp;rsquo;t ever do this in Production)&lt;/li>
&lt;/ul>
&lt;p>I do this using the Azure PowerShell command &lt;code>New-AzResourceGroupDeployment&lt;/code> and give it the Resource Group Name and the path to the file&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Validate the deployment with Whatif
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The first thing this does is check the status of the resources in the resource group&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatif.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatif.png"
loading="lazy"
alt="whatif"
>&lt;/a>&lt;/p>
&lt;p>then it provides a list of what it will do. In this example there is only one resource.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifresult.png"
loading="lazy"
alt="whatifresult"
>&lt;/a>&lt;/p>
&lt;p>This tells us that there will be a creation of 1 resource and that the values are as I expect them. As I am happy with that I can then deploy the infrastructure by changing the &lt;code>WhatIf&lt;/code> value to false&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Deploy the changes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="deployment-can-be-seen-in-the-azure-portal">Deployment can be seen in the Azure Portal&lt;/h1>
&lt;p>If I look in the Azure Portal, I can see the deployment is happening.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploying.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploying.png"
loading="lazy"
alt="portaldeploying"
>&lt;/a>&lt;/p>
&lt;p>Once it has finished I get an output on the screen&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/deploymentresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/deploymentresult.png"
loading="lazy"
alt="deploymentresult"
>&lt;/a>&lt;/p>
&lt;p>and when I look in the portal at the deployment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploymentresult.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portaldeploymentresult.png"
loading="lazy"
alt="portaldeploymentresult"
>&lt;/a>&lt;/p>
&lt;p>and my resource has been created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/portalsqlresource.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/portalsqlresource.png"
loading="lazy"
alt="portalsqlresource"
>&lt;/a>&lt;/p>
&lt;h2 id="add-a-database">Add a database&lt;/h2>
&lt;p>I have my Azure SQL Instance, next I need a database. I look up &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/templates/microsoft.sql/servers/databases?tabs=bicep?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>the resource information&lt;/a> and add the required information to my bicep file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">resource sql &amp;#39;Microsoft.Sql/servers@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;beardsqlrand01&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLogin: &amp;#39;sysadmin&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> administratorLoginPassword: &amp;#39;dbatools.IO&amp;#39; // DON&amp;#39;T DO THIS - EVER
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> version: &amp;#39;12.0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> publicNetworkAccess: &amp;#39;Disabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> resource bearddatabase &amp;#39;databases@2020-11-01-preview&amp;#39; = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;BicepDatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> location: &amp;#39;northeurope&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> sku: {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> name: &amp;#39;Basic&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> properties: {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is a super simple example. The database resource is defined within the SQL Instance resource with a name and a SKU.&lt;/p>
&lt;p>We validate it in exactly the same way as before. This time we will see that we can incrementally add or change resources to our deployment and validate what will happen.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Validate the deployment with Whatif
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This time the result looks a little different as we already have a resource in the Resource Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifdatabase.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/whatifdatabase.png"
loading="lazy"
alt="whatifdatabase"
>&lt;/a>&lt;/p>
&lt;p>At the top it gives you three types of changes&lt;/p>
&lt;ul>
&lt;li>Create&lt;/li>
&lt;li>NoChange&lt;/li>
&lt;li>Ignore&lt;/li>
&lt;/ul>
&lt;p>It shows at the bottom that the changes are&lt;/p>
&lt;blockquote>
&lt;p>Resource changes: 1 to create, 1 no change, 1 to ignore.&lt;/p>
&lt;/blockquote>
&lt;p>This tells you that it will create the Azure SQL Database, it will not change the Azure SQL Server and there is no change to the master database.&lt;/p>
&lt;p>I am happy with that validation, so I deploy the changes, again using the same code as before.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Deploy the changes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DeploymentConfig = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ResourceGroupName = &amp;#39;BicepTest&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> TemplateFile = &amp;#39;.\SimpleSqlDatabase\SqlInstance.bicep&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WhatIf = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-AzResourceGroupDeployment @DeploymentConfig
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If I look in the portal I can see the deployment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployment.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployment.png"
loading="lazy"
alt="databasedeployment"
>&lt;/a>&lt;/p>
&lt;p>and once it has completed I can see the database in the Portal&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployed.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/Bicep/databasedeployed.png"
loading="lazy"
alt="databasedeployed"
>&lt;/a>&lt;/p>
&lt;p>Thats all there is to Bicep.&lt;/p>
&lt;ul>
&lt;li>Find the resource information in the docs&lt;/li>
&lt;li>Define your deployment in code&lt;/li>
&lt;li>Validate your deployment with WhatIf&lt;/li>
&lt;li>Deploy your changes&lt;/li>
&lt;/ul>
&lt;h1 id="remove-the-resource-group">Remove the Resource Group&lt;/h1>
&lt;p>Now that my test has finished I will remove the Resource Group. If you are following along, this is how to do that&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Remove-AzResourceGroup -Name BicepTest -Force
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h1 id="all-of-the-code">All of the code&lt;/h1>
&lt;p>I have added all of the code for this blog post to my GitHub here &lt;a class="link" href="https://github.com/SQLDBAWithABeard/BeardBicep/tree/main/SimpleSqlDatabase" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/BeardBicep/tree/main/SimpleSqlDatabase&lt;/a> so that you can follow along.&lt;/p>
&lt;h1 id="next-steps">Next steps&lt;/h1>
&lt;p>Now that you have an introduction to Bicep and can see how useful and powerful it can be, we will expand on this in the following blog posts.&lt;/p></description></item><item><title>Viewing GitHub Pages Locally With a Remote Theme</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-github-pages-locally-with-a-remote-theme/</link><pubDate>Thu, 15 Apr 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-github-pages-locally-with-a-remote-theme/</guid><description>&lt;img src="https://datasaturdays.com/assets/design/twitter/c.twitter%201r.png" alt="Featured image of post Viewing GitHub Pages Locally With a Remote Theme" />&lt;h1 id="a-different-method-for-my-own-site">A different method for my own site&lt;/h1>
&lt;p>This blog post is for Mikey Bronowski &lt;a class="link" href="https://twitter.com/mikeybronowski" target="_blank" rel="noopener"
>t&lt;/a> - &lt;a class="link" href="https://www.bronowski.it/blog/" target="_blank" rel="noopener"
>b&lt;/a> and Jonathan Allen &lt;a class="link" href="https://twitter.com/fatherjack" target="_blank" rel="noopener"
>t&lt;/a> - &lt;a class="link" href="https://fatherjack.github.io/" target="_blank" rel="noopener"
>b&lt;/a> after a twitter discussion a few weeks ago.&lt;/p>
&lt;blockquote>
&lt;p>How can I see my GitHub Pages site locally when I use a remote theme?&lt;/p>
&lt;/blockquote>
&lt;h2 id="do-you-need-to">Do you need to?&lt;/h2>
&lt;p>My first answer is do you need to see them? Once you have your theme set up as you like, you can view your blog in Visual Studio Code using the keyboard shortcut &lt;code>CTRL + K, V&lt;/code> and you can see a live preview of your post as you type.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>However, I appreciate that at some point you will probably want to see what your site looks like locally, so I decided to look at the blog posts in the theme locally for this blog. My &lt;a class="link" href="_posts%5c2021-04-10-locally-viewing-github-pages-new-data-saturdays.md" >last post&lt;/a> showed how I do this with the &lt;a class="link" href="https://datasaturdays.com" target="_blank" rel="noopener"
>Data Saturdays web-site&lt;/a> but I get an error when running this for my site because it cant find the gem sources. This is because I am using a remote theme for my blog.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/nogemsources.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/nogemsources.png"
loading="lazy"
alt="nogemsources"
>&lt;/a>&lt;/p>
&lt;p>What I could do is work out how to get these in the right place, but I am lazy! Whilst researching for the Data Saturdays site, I had found another docker container, the official Jekyll one &lt;a class="link" href="https://hub.docker.com/r/jekyll/jekyll" target="_blank" rel="noopener"
>https://hub.docker.com/r/jekyll/jekyll&lt;/a>. I wondered if I could use that.&lt;/p>
&lt;h2 id="which-version-to-use">Which version to use?&lt;/h2>
&lt;p>First we need to know which version of Jekyll GitHub Pages is using. You can find all of that information here &lt;a class="link" href="https://pages.github.com/versions/" target="_blank" rel="noopener"
>https://pages.github.com/versions/&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/githubpagesversions.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/githubpagesversions.jpg"
loading="lazy"
alt="ghpagesversions"
>&lt;/a>&lt;/p>
&lt;p>So we need to use 3.9.0&lt;/p>
&lt;p>so I ran&lt;/p>
&lt;p>&lt;code>docker pull jekyll/jekyll:3.9&lt;/code>&lt;/p>
&lt;p>but&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/noimage.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/noimage.jpg"
loading="lazy"
alt="noimage"
>&lt;/a>&lt;/p>
&lt;p>so I tried 3.8.6 and it worked for me.&lt;/p>
&lt;p>&lt;code>docker pull jekyll/jekyll:3.8.6&lt;/code>&lt;/p>
&lt;h1 id="set-up">Set up&lt;/h1>
&lt;p>Let&amp;rsquo;s back up a bit and set the environment up. I am using Docker on Windows Subsystem for Linux 2 (WSL2) I installed it &lt;a class="link" href="https://code.visualstudio.com/blogs/2020/03/02/docker-in-wsl2" target="_blank" rel="noopener"
>using this guide&lt;/a>. I believe this will work using native Docker, you would just need to replace the &lt;code>$PWD&lt;/code> in the example below with a dot &lt;code>.&lt;/code>&lt;/p>
&lt;p>Once that is installed and the image is pulled, I can then run my blog locally using&lt;/p>
&lt;p>&lt;code>docker run --rm --volume=$PWD:/srv/jekyll -p 4001:4000 jekyll/jekyll:3.8 jekyll serve&lt;/code>&lt;/p>
&lt;p>or if not using WSL2&lt;/p>
&lt;p>&lt;code>docker run --rm --volume=.:/srv/jekyll -p 4001:4000 jekyll/jekyll:3.8 jekyll serve&lt;/code>&lt;/p>
&lt;p>The &lt;code>--rm&lt;/code> means that the container will be removed when it is stopped, &lt;code>--volume=&amp;quot;$PWD:/srv/jekyll&amp;quot;&lt;/code> maps the current directory locally to the &lt;code>/srv/jekyll&lt;/code> directory in the container so I need to change the directory to my local repository for my blog. &lt;code>-p 4001:4000&lt;/code> says map port 4001 on my machine to port 4000 on the container. This means that I can view the blog locally at https://localhost:4001. &lt;code>jekyll serve&lt;/code> will build the site and run it for me.&lt;/p>
&lt;h2 id="of-course-there-is-tweaking">Of course, there is tweaking&lt;/h2>
&lt;p>We have to make a few changes to make this work easily. When I run the site locally with this command I get the following error and the site would not build.&lt;/p>
&lt;blockquote>
&lt;p>Liquid Exception: No repo name found. Specify using PAGES_REPO_NWO environment variables, &amp;lsquo;repository&amp;rsquo; in your configuration, or set up an &amp;lsquo;origin&amp;rsquo; git remote pointing to your github.com repository. in /_layouts/default.html&lt;br>
ERROR: YOUR SITE COULD NOT BE BUILT:&lt;br>
No repo name found. Specify using PAGES_REPO_NWO environment variables, &amp;lsquo;repository&amp;rsquo; in your configuration, or set up an &amp;lsquo;origin&amp;rsquo; git remote pointing to yocom repository.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/jekyllerror.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/jekyllerror.jpg"
loading="lazy"
alt="jekyllerror"
>&lt;/a>&lt;/p>
&lt;p>to fix this add the following to your &lt;code>_config.yml&lt;/code> file&lt;/p>
&lt;p>&lt;code>repository: GITHUBUSERNAME/REPONAME&lt;/code>&lt;/p>
&lt;p>mine is&lt;/p>
&lt;p>&lt;code>repository: SQLDBAWithABeard/robsewell&lt;/code>&lt;/p>
&lt;p>Then when I run the container I get another warning&lt;/p>
&lt;blockquote>
&lt;p>GitHub Metadata: No GitHub API authentication could be found. Some fields may be missing or have incorrect data.&lt;/p>
&lt;/blockquote>
&lt;p>This does not really matter as the site still builds but another warning&lt;/p>
&lt;blockquote>
&lt;p>Auto-regeneration may not work on some Windows versions.
Please see: &lt;a class="link" href="https://github.com/Microsoft/BashOnWindows/issues/216" target="_blank" rel="noopener"
>https://github.com/Microsoft/BashOnWindows/issues/216&lt;/a>
If it does not work, please upgrade Bash on Windows or run Jekyll with &amp;ndash;no-watch.&lt;/p>
&lt;/blockquote>
&lt;p>means that the site will not auto-regenerate when you make a change and save the file.&lt;/p>
&lt;p>We fix these errors by adding&lt;/p>
&lt;p>&lt;code>github: [metadata]&lt;/code>&lt;/p>
&lt;p>to the &lt;code>_config.yml&lt;/code> file&lt;/p>
&lt;p>and running the container with an extra switch for the jekyll command &lt;code>--force_polling&lt;/code>&lt;/p>
&lt;h2 id="so-now-it-works">So now it works?&lt;/h2>
&lt;p>So with the additional data in the &lt;code>_config.yml&lt;/code> file and the new command&lt;/p>
&lt;p>&lt;code>docker run --rm --volume=&amp;quot;$PWD:/srv/jekyll&amp;quot; -p 4001:4000 jekyll/jekyll:3.8 jekyll serve --force_polling&lt;/code>&lt;/p>
&lt;p>the site will build. You will still get the warning for auto-regeneration but it works. The purple arrow and the yellow box show the file that was changed and that it regenerated.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/regenerate.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/regenerate.jpg"
loading="lazy"
alt="regenerate"
>&lt;/a>&lt;/p>
&lt;p>It will only regenerate whilst running for blog post changes and not for configuration changes, such as altering the &lt;code>_config.yml&lt;/code> file. If you want to see those, you will have to stop the container and re-run it.&lt;/p>
&lt;p>There is one last problem however. When you write your blog posts in Jekyll you name the file YYYY-MM-DD-Nameoffile.md this will give the post time of YYYY-MM-DD but the file for this blog post is named with a date in the future and by default it doesn&amp;rsquo;t show. The green box shows the file name but there is no corresponding blog post.&lt;/p>
&lt;p>To fix this we add another entry to the &lt;code>_config.yml&lt;/code> file&lt;/p>
&lt;p>&lt;code>future: true&lt;/code>&lt;/p>
&lt;p>This will tell Jekyll to show the posts with a data in the future. Unless you wish to show future posts on your blog when it is live, you will have to remember to change this to&lt;/p>
&lt;p>&lt;code>future: false&lt;/code>&lt;/p>
&lt;p>when you push your changes to GitHub so that your blog behaves as expected but now you can see your current blog post and write away and be able to see how it will look in your theme&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/futureposts.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/futureposts.jpg"
loading="lazy"
alt="futureposts"
>&lt;/a>&lt;/p>
&lt;h1 id="lets-make-it-even-better">Let&amp;rsquo;s make it even better&lt;/h1>
&lt;p>When you run the container, it will need to download all of the things it needs to run the site. This can take a little time.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/downloadingthings.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/downloadingthings.jpg"
loading="lazy"
alt="downloadingthings"
>&lt;/a>&lt;/p>
&lt;p>It would be better if we had our own image that had all of those already downloaded for us. Let&amp;rsquo;s create our own image. We need to run our container without the &lt;code>rm&lt;/code> option this time as we need it not to be removed when we stop it.&lt;/p>
&lt;p>&lt;code>docker run -volume=&amp;quot;$PWD:/srv/jekyll&amp;quot; -p 4001:4000 jekyll/jekyll:3.8 jekyll serve&lt;/code>&lt;/p>
&lt;p>Once it has finished downloading and installing all that it needs and generated the site press &lt;code>CTRL +C&lt;/code> to stop the container and run&lt;/p>
&lt;p>&lt;code>docker ps -a&lt;/code>&lt;/p>
&lt;p>which will show you all of containers.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/dockerps.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/dockerps.jpg"
loading="lazy"
alt="dockerps"
>&lt;/a>&lt;/p>
&lt;p>Use the first 3 characters of the container. In my example it is &lt;code>760&lt;/code>. If you have more than one, look for the one with the &lt;code>jekyll/jekyll:3.8.6&lt;/code> as the image.&lt;/p>
&lt;p>Then we can create our own image using&lt;/p>
&lt;p>&lt;code>docker commit 760 myblogimage&lt;/code>&lt;/p>
&lt;p>replace &lt;code>760&lt;/code> with your own container.&lt;/p>
&lt;p>Once you have created the image, you can remove the stopped container with&lt;/p>
&lt;p>&lt;code>docker rm 760&lt;/code>&lt;/p>
&lt;p>Again, replace &lt;code>760&lt;/code> with your own container.&lt;/p>
&lt;h2 id="quicker-run">Quicker run&lt;/h2>
&lt;p>Now you can use your own image and the container will not need to download and install all of the things. Replace &lt;code>jekyll/jekyll:3.8&lt;/code> with &lt;code>myblogimage&lt;/code>&lt;/p>
&lt;p>&lt;code>docker run --rm --volume=&amp;quot;$PWD:/srv/jekyll&amp;quot; -p 4001:4000 myblogimage jekyll serve --force_polling&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/muchquicker.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/muchquicker.jpg"
loading="lazy"
alt="muchquicker"
>&lt;/a>&lt;/p>
&lt;p>Happy local blog writing.&lt;/p></description></item><item><title>TSQL2sDay - Do I use Notebooks?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-do-i-use-notebooks/</link><pubDate>Tue, 13 Apr 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-do-i-use-notebooks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/images/TSQL2sDay150x150.jpg" alt="Featured image of post TSQL2sDay - Do I use Notebooks?" />&lt;h1 id="do-i-use-notebooks">Do I use Notebooks?&lt;/h1>
&lt;p>T-SQL Tuesday is the brainchild of Adam Machanic (&lt;a class="link" href="http://dataeducation.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/adammachanic?lang=en" target="_blank" rel="noopener"
>Twitter&lt;/a>). The first T-SQL Tuesday invitation was in December 2009 and it is still going strong. It is a monthly blog party on the second Tuesday of each month. Currently, Steve Jones (&lt;a class="link" href="https://voiceofthedba.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/way0utwest" target="_blank" rel="noopener"
>Twitter&lt;/a>) organises the event and maintains &lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>a website with all previous posts&lt;/a>. Everyone is welcome to participate in this monthly blog post.&lt;/p>
&lt;p>This month’s T-SQL Tuesday is hosted by Steve. Steve says:&lt;/p>
&lt;blockquote>
&lt;p>I want you to write about how you have used, or would like to use, a Jupyter notebook. This seemed to be exciting for many people at first, but I haven’t seen a lot of uptake from users in general. So I’m curious if you are using them.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://www.sqlservercentral.com/blogs/tsql2sday-137-invite-using-notebooks-every-day" target="_blank" rel="noopener"
>The original post is here.&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlservercentral.com/blogs/tsql2sday-137-invite-using-notebooks-every-day" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/a>&lt;/p>
&lt;h1 id="am-i-using-notebooks-">Am I using Notebooks ?&lt;/h1>
&lt;p>Hehe. I LOVE notebooks. I use them all of the time and every day.&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://blog.robsewell.com/categories/#jupyter-notebooks" target="_blank" rel="noopener"
>I have written a few posts about them as well&lt;/a>.&lt;/li>
&lt;li>I have a repository on GitHub with many notebooks &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>https://beard.media/Notebooks&lt;/a>.&lt;/li>
&lt;li>I have given presentations about notebooks &lt;a class="link" href="https://beard.media/presentations" target="_blank" rel="noopener"
>https://beard.media/presentations&lt;/a>&lt;/li>
&lt;li>I have videos on my youtube channel about notebooks &lt;a class="link" href="https://beard.media/notebooksyoutube" target="_blank" rel="noopener"
>https://beard.media/notebooksyoutube&lt;/a>&lt;/li>
&lt;li>I have written a &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook/0.0.20201008.1" target="_blank" rel="noopener"
>PowerShell Module&lt;/a> to create Notebooks []&lt;/li>
&lt;/ul>
&lt;p>I have assisted clients with using notebooks to&lt;/p>
&lt;ul>
&lt;li>Integrate new team members&lt;/li>
&lt;li>Create a repository of incident response notebooks &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/" target="_blank" rel="noopener"
>dynamically created with Azure DevOps&lt;/a>&lt;/li>
&lt;li>Create a repository of daily tasks notebooks&lt;/li>
&lt;li>Create a repository of common large scale changes&lt;/li>
&lt;li>Off-load DBA requests to Service Desk with notebooks&lt;/li>
&lt;li>Use notebooks to demonstrate changes to Product Owners and other teams&lt;/li>
&lt;li>Use notebooks for diagnosis by customers&lt;/li>
&lt;li>Use notebooks to investigate Azure environments and Azure Data Services&lt;/li>
&lt;li>and more&lt;/li>
&lt;/ul>
&lt;p>I use notebooks to validate dbachecks PRs, to demonstrate &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/tree/master/notebooks/NotDotNet/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/tree/master/notebooks/NotDotNet/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a> with docker that anyone can use.&lt;/p>
&lt;p>I am thoroughly looking forward to seeing what other people do with notebooks. I love how the community helps us all to develop and move forward by sharing.&lt;/p>
&lt;h1 id="all-this-and">All this and&lt;/h1>
&lt;p>&lt;a class="link" href="https://www.advancinganalytics.co.uk/" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2021/nodatascientist.png"
loading="lazy"
alt="nodatascientist"
>&lt;/a>&lt;br>
Thank you - &lt;a class="link" href="https://www.advancinganalytics.co.uk/" target="_blank" rel="noopener"
>https://www.advancinganalytics.co.uk/&lt;/a>&lt;/p></description></item><item><title>Viewing GitHub Pages Locally For Data Saturdays</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-github-pages-locally-for-data-saturdays/</link><pubDate>Sun, 11 Apr 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-github-pages-locally-for-data-saturdays/</guid><description>&lt;img src="https://datasaturdays.com/assets/design/twitter/c.twitter%201r.png" alt="Featured image of post Viewing GitHub Pages Locally For Data Saturdays" />&lt;h1 id="data-saturdays-has-new-clothes">Data Saturdays Has New Clothes!&lt;/h1>
&lt;p>The Data Saturdays Admins asked the community to vote on their favourite logo for the Data Saturdays website. After over 400 votes the results came in.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/datasaturdays/status/1380152923498352644" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/newdatasaturdayclothes.jpg"
loading="lazy"
alt="newclothes"
>&lt;/a>&lt;/p>
&lt;p>Denny Cherry &amp;amp; Associates Consulting &lt;a class="link" href="https://www.dcac.com/" target="_blank" rel="noopener"
>https://www.dcac.com/&lt;/a> generously supported Data Saturdays and paid for the artist to design the logo and create the artifacts via &lt;a class="link" href="https://99designs.com" target="_blank" rel="noopener"
>99designs.com&lt;/a>. THANK YOU Denny and many thanks to Monica Rathbun &lt;a class="link" href="https://twitter.com/SQLEspresso" target="_blank" rel="noopener"
>twitter&lt;/a> - &lt;a class="link" href="https://sqlespresso.com/" target="_blank" rel="noopener"
>blog&lt;/a> for all of the hard work in organising and administering all of the requirements and handling all of the communication with the artists.&lt;/p>
&lt;h1 id="now-we-have-to-update-the-web-site">Now we have to update the web-site&lt;/h1>
&lt;p>The next challenge we face is to update the website. As the website is hosted on GitHub Pages using Jekyll, this means that we can easily update the website by updating the code and letting GitHub actions build the new site but we have no way of checking the way that it looks before we push the changes. With such a radical change required, I felt that it would be a good idea to explore how to do this locally.&lt;/p>
&lt;h2 id="install-everything-you-need-locally">Install everything you need locally&lt;/h2>
&lt;p>I examined the requirements to create a local development environment and this meant installing Jekyll and Ruby and a host of other things, there appeared to be a whole bundle of quirks and strange errors that may or may not need to be handled so I quickly went off that idea!!&lt;/p>
&lt;h2 id="docker-to-the-rescue">Docker to the rescue&lt;/h2>
&lt;p>This is a fantastic use case for using a Docker container. I can host all of the required bits inside a container, spin it up and down as I need it and I don&amp;rsquo;t have to worry about polluting my machine with software and settings or the pain of having to configure it to work.&lt;/p>
&lt;p>Also, other people have already done a lot of the work so I dont have to.&lt;/p>
&lt;p>I am running Docker in WSL2. I followed these &lt;a class="link" href="https://code.visualstudio.com/blogs/2020/03/02/docker-in-wsl2" target="_blank" rel="noopener"
>instructions&lt;/a> to set it up. It doesn&amp;rsquo;t take very long.&lt;/p>
&lt;p>With thanks to Hans Kristian Flaatten &lt;a class="link" href="https://github.com/Starefossen" target="_blank" rel="noopener"
>GitHub&lt;/a> - &lt;a class="link" href="https://twitter.com/Starefossen" target="_blank" rel="noopener"
>Twitter&lt;/a> who has created &lt;a class="link" href="https://github.com/Starefossen/docker-github-pages" target="_blank" rel="noopener"
>this docker image&lt;/a> it is as easy as running this from the local directory of the site repository&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker run -it --rm -v &amp;#34;$PWD&amp;#34;:/usr/src/app -p &amp;#34;4000:4000&amp;#34; starefossen/github-pages
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you are not using WSL but native Docker on Windows, then the command to run is slightly different&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker run -it --rm -v .:/usr/src/app -p &amp;#34;4000:4000&amp;#34; starefossen/github-pages
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>As soon as the container has started running and built the site I can see my changes locally in my browser at &lt;code>http://localhost:4000/&lt;/code> There are a few warnings as it builds that can be ignored. These are due to the autoomatic dynamic page generation code.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com//assets/uploads/2021/localdev.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/localdev.jpg"
loading="lazy"
alt="localdev"
>&lt;/a>&lt;/p>
&lt;h1 id="develop-and-test">Develop and Test&lt;/h1>
&lt;p>Now I can make changes to the code in the website and save the file and the site will update. In the below video, you can see that I have updated the favicon so that the new logo appears.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>I shall go back to editing the site now.&lt;/p>
&lt;h1 id="a-little-feature-if-you-are-working-on-your-event-page">A little &amp;lsquo;Feature&amp;rsquo; if you are working on your event page&lt;/h1>
&lt;p>If you are following the wiki documentation to create or edit your event, you will find there is a little complication. When you click on yours or any event link on the front page it will take you to a page that starts &lt;code>http://0.0.0.0:4000/&lt;/code> like &lt;a class="link" href="http://0.0.0.0:4000/2021-04-17-datasaturday0005/" target="_blank" rel="noopener"
>http://0.0.0.0:4000/2021-04-17-datasaturday0005/&lt;/a>. This will not work on a Windows machine so you will have to replace &lt;code>0.0.0.0&lt;/code> in the address bar with &lt;code>localhost&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/0000.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/0000.jpg"
loading="lazy"
alt="0000"
>&lt;/a>&lt;/p>
&lt;p>and then it will work&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2021/localhostworks.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2021/localhostworks.jpg"
loading="lazy"
alt="localhostworks"
>&lt;/a>&lt;/p>
&lt;h1 id="data-saturdays">Data Saturdays&lt;/h1>
&lt;p>You can find the &lt;a class="link" href="https://datasaturdays.com" target="_blank" rel="noopener"
>Data Saturdays web-site here&lt;/a>. There is a list of all of the upcoming and past Data Saturdays events available.&lt;/p></description></item><item><title>Creating a New Data Saturdays event</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-new-data-saturdays-event/</link><pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-new-data-saturdays-event/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/datasaturdays.png" alt="Featured image of post Creating a New Data Saturdays event" />&lt;h1 id="creating-a-new-data-saturdays-event">Creating a New Data Saturdays Event&lt;/h1>
&lt;p>There&amp;rsquo;s a new process to create a Data Saturdays Event page, so I thought I would write an explanation and a run through&lt;/p>
&lt;h2 id="what-is-data-saturdays-">What is Data Saturdays ?&lt;/h2>
&lt;p>Firstly, not everyone will know what a Data Saturday event is, so lets start with that. There are two parts to it.&lt;/p>
&lt;p>A Data Saturday is an event that provides (usually free) training and information sessions about Azure Data and SQL Server. At present they are hosted online.&lt;/p>
&lt;p>The Data Saturdays resource is an &lt;a class="link" href="https://github.com/sqlcollaborative/datasaturdays" target="_blank" rel="noopener"
>open-source repository&lt;/a> which enables event organisers to easily build a web presence as an entry point into their event. It integrates with other free event management solutions such as &lt;a class="link" href="https://sessionize.com" target="_blank" rel="noopener"
>Sessionize&lt;/a> enabling Call For Speakers, easily integrating the schedule, room links and speaker walls. The website is &lt;a class="link" href="https://datasaturdays.com" target="_blank" rel="noopener"
>https://datasaturdays.com&lt;/a>&lt;/p>
&lt;p>Here is a screenshot of the first Data Saturday &amp;ldquo;in&amp;rdquo; Pordenone.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/datasaturday1.png"
loading="lazy"
alt="Pordenone"
>&lt;/p>
&lt;p>The marvelous &lt;a class="link" href="https://twitter.com/spaghettidba" target="_blank" rel="noopener"
>Gianluca Sartori&lt;/a> and I started this to enable Pordenone to hold an event. We open-sourced the &lt;a class="link" href="https://github.com/sqlcollaborative/datasaturdays" target="_blank" rel="noopener"
>code&lt;/a> and hosted it in the &lt;a class="link" href="https://github.com/sqlcollaborative/" target="_blank" rel="noopener"
>SQL Collaborative GitHub organisation&lt;/a> alongside community tools such as &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with a &lt;a class="link" href="https://github.com/sqlcollaborative/DataSaturdays/blob/main/LICENSE" target="_blank" rel="noopener"
>MIT licence&lt;/a> so that it is free for anyone to use and to collaborate with. The website is hosted on &lt;a class="link" href="https://pages.github.com/" target="_blank" rel="noopener"
>GitHub Pages&lt;/a> which generates static pages using &lt;a class="link" href="https://docs.github.com/en/github/working-with-github-pages/setting-up-a-github-pages-site-with-jekyll" target="_blank" rel="noopener"
>Jekyll&lt;/a>. We figured that this not only enabled a quick free solution but also offered opportunities for people to enrich their skills by collaborating.&lt;/p>
&lt;p>We wanted to include other community leaders to assist with guiding the project and we were proud that everyone we asked to be involved accepted. The people who are Admins of the project (who can approve changes to the code and therefore the website) in addition to Gianluca and I are : -&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://twitter.com/way0utwest" target="_blank" rel="noopener"
>Steve Jones&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/sqlespresso" target="_blank" rel="noopener"
>Monica Rathbun&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/_randolph_west" target="_blank" rel="noopener"
>Randolph West&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/intoleranse" target="_blank" rel="noopener"
>Johan Ludvig Brattås&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/amtwo" target="_blank" rel="noopener"
>Andy Mallon&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/sqlzelda" target="_blank" rel="noopener"
>Elizabeth Noble&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/Warwick_Rudd" target="_blank" rel="noopener"
>Warwick Rudd&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://twitter.com/sqlatspeed" target="_blank" rel="noopener"
>Matt Gordon&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>We have now enabled 10 Data Saturday events to exist, which we still think is amazing! However with growth comes challenges.&lt;/p>
&lt;h2 id="creating-an-event-the-old-way">Creating an event the old way&lt;/h2>
&lt;p>The old method of creating an event involved the organiser providing the required information and an admin creating the static HTML page. Copying and pasting, ensuring that the template stayed the same but the detail was altered. Of course, when things are done manually humans can make errors and we made errors. The beauty of hosting the website in code in GitHub is that we can quickly change the code when we notice and fix them but this was not ideal.&lt;/p>
&lt;h2 id="automation-automation-automation-">Automation Automation AUTOMATION !&lt;/h2>
&lt;p>I love automation, I get a real buzz out of taking manual monotonous tasks and automating them. I looked at the process we were following and took the bait and decided to automate it. I have created a data-driven process for creating and updating the event web-page and the rest of this blog post is an accompaniment to &lt;a class="link" href="https://github.com/sqlcollaborative/DataSaturdays/wiki" target="_blank" rel="noopener"
>the official documentation in the Wiki in the Data Saturdays GitHub repository&lt;/a>. I might also blog about how I did it.&lt;/p>
&lt;p>If you wish to just watch a video, you can find that here&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="creating-a-new-data-saturday-event">Creating a New Data Saturday Event&lt;/h2>
&lt;p>How do you create a new event? The steps are laid out in the &lt;a class="link" href="https://github.com/sqlcollaborative/DataSaturdays/wiki" target="_blank" rel="noopener"
>wiki&lt;/a>&lt;/p>
&lt;h3 id="tooling">Tooling&lt;/h3>
&lt;p>We suggest that you use &lt;a class="link" href="http://aka.ms/vscode" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> as the editor to make these changes. Visual Studio Code is a superb free lightweight cross-platform code editor. To reduce the frustration we also suggest that you add the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml" target="_blank" rel="noopener"
>YAML Extension&lt;/a> to Visual Studio Code as this will help to identify any problems with YAML.&lt;/p>
&lt;h3 id="fork-the-data-saturdays-repository">Fork the Data Saturdays Repository&lt;/h3>
&lt;p>I have previously written a blog post that &lt;a class="link" href="https://blog.robsewell.com/blog/source%20control/jupyter%20notebooks/azure%20data%20studio/dbatools/dbachecks/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/" target="_blank" rel="noopener"
>explains how to contribute to an open-source repository which you can also use as reference for some of these steps&lt;/a>&lt;/p>
&lt;p>We are using GitHub as the source control for the website, so you will need to signup for a &lt;a class="link" href="https://github.com/" target="_blank" rel="noopener"
>GitHub account&lt;/a> if you do not have one already. This is free. Once you have that, navigate to the &lt;a class="link" href="https://github.com/sqlcollaborative/datasaturdays" target="_blank" rel="noopener"
>Data Saturdays repository&lt;/a> and click on the Fork button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/fork.png"
loading="lazy"
alt="fork"
>&lt;/p>
&lt;p>It will ask you where you want to fork it and you should choose your own GitHub account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/forkwhere.png"
loading="lazy"
alt="forkwhere"
>&lt;/p>
&lt;p>It will only take a few seconds and you will have a fork of the repository in your own account.&lt;/p>
&lt;h3 id="clone-the-repository-to-your-machine">Clone the Repository to your machine&lt;/h3>
&lt;p>To work with the code, you need to clone it to your own machine (There are other options like &lt;a class="link" href="https://github.com/features/codespaces" target="_blank" rel="noopener"
>codespaces&lt;/a> which I love, but we will leave that for another time) Click on the green Code button and copy the URL using the button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/cloneweb.png"
loading="lazy"
alt="cloneweb"
>&lt;/p>
&lt;p>then in Visual Studio Code &lt;code>CTRL + SHIFT + P&lt;/code> will open the Command Palette and search for clone&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/clonevs.png"
loading="lazy"
alt="clonevs"
>&lt;/p>
&lt;p>If you do not see Git:Clone you will need to install git from &lt;a class="link" href="https://git-scm.com/downloads" target="_blank" rel="noopener"
>https://git-scm.com/downloads&lt;/a>&lt;/p>
&lt;h3 id="create-a-new-branch">Create a new branch&lt;/h3>
&lt;p>You create a new branch to hold your changes by clicking on the branch name in the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/branchchoose.png"
loading="lazy"
alt="branchchoose"
>&lt;/p>
&lt;p>and give it a new name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/newbranch.png"
loading="lazy"
alt="newbranch"
>&lt;/p>
&lt;h3 id="create-the-markdown-file">Create the Markdown File&lt;/h3>
&lt;p>Now you can start to create the data for your event. First you need to see what the next available number is. Check the &lt;code>_data/events&lt;/code> directory to see what has gone before you.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/getnextnumber.png"
loading="lazy"
alt="getnextnumber"
>&lt;/p>
&lt;p>In the &lt;code>_posts&lt;/code> directory, create a new file with the following naming convention &lt;code>YYYY-MM-DD-datasaturdayXXXX.md&lt;/code> where &lt;code>XXXX&lt;/code> is the next number available. An example name is &lt;code>2021-06-12-datasaturday0007.md&lt;/code>&lt;/p>
&lt;p>In the file you place the following content&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">---
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">layout: post
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">title: &amp;#34;The Name of the Data Saturday in double quotes&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">subtitle: &amp;#34;Data Saturday&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">tags: [event]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">comments: false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">data: datasaturdayXXXX
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">---
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The 3 dashes are important to keep. The name must be in double quotes and the data must match your number. It should look like this.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/markdown.png"
loading="lazy"
alt="markdown"
>&lt;/p>
&lt;p>Save the file.&lt;/p>
&lt;h3 id="create-the-data-file">Create the data file.&lt;/h3>
&lt;p>This is the most important file. This file is the one that will feed the page that you use. This is the file that you will update as your event timeline progresses.&lt;/p>
&lt;p>In the &lt;code>_data/events&lt;/code> directory create a new file named &lt;code>datasaturdayXXXX.yml&lt;/code> (The XXXX is your number again) example &lt;code>datasaturday0007.yml&lt;/code>&lt;/p>
&lt;p>In this file paste all the following&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">name: &amp;#34;This is the name of your event inside the double quotes&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">date: The date of your event in YYYY-MM-DD HH:mm:ss TZ IE 2021-06-12 08:00:00 -0000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">description: &amp;#34;Your event description inside double quotes, you may use HTML.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">You MUST escape double quotes with a backslash \
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(Look in the repo or wiki for examples of how to enter images)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Line breaks need to be entered as &amp;lt;br&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">registrationurl: This is your registration URL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">join:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> description: Click on the room you want to join. You can change rooms at any time to attend the sessions that you prefer.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> rooms:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Room 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> url: you can add more rooms if you have a virtual event. You can remove these if you do not know yet.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">scheduleurl: This is your schedule URL from Sessionize. You can leave this blank until you have it.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sponsors:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - link: https://yoursponsorlink
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> image: your sponsor image
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> height: image height if required
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">speakerlisturl: This is your Call For Speakers URL when you start, once you have chosen your sessions change this to your Sessionize SpeakerWall API URL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">callforspeakers: true (until your call for speaker finishes!)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">volunteerrequesturl: If you want a link for people to volunteer place it here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">organizers:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - name: Your name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> twitter: https://twitter.com/TWITTERNAME
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> email: Contact email or not
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now you have to fill in your own data. The fields have explanations in them, the wiki has descriptions and you can always refer back to this blog post also. Some are obvious like name and date, some will take a little thought like description and some you won&amp;rsquo;t have yet like your Sessionize API URLs.&lt;/p>
&lt;p>This file can be altered any time that you like during your event timeline as more information becomes available or you wish to change things. Each time, you can create a Pull Request to the Data Saturdays repository but before that &lt;strong>It is really important&lt;/strong> that you check your YAML.&lt;/p>
&lt;p>Once your data file is ready&lt;/p>
&lt;h3 id="check-your-yaml">Check your YAML&lt;/h3>
&lt;p>If you have followed our advice and used Visual Studio Code and the YAML extension then you can check that your YAML is correctly formed by looking at the problems tab&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/noproblem.png"
loading="lazy"
alt="noproblem"
>&lt;/p>
&lt;p>The example above has no problems so the YAML is correct. If it is not you will see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/problem.png"
loading="lazy"
alt="problem"
>&lt;/p>
&lt;p>Normally with YAML the problem is spaces, try to line up the text until the problem goes away.&lt;/p>
&lt;h3 id="sync-your-local-repository-with-github">Sync your local repository with GitHub&lt;/h3>
&lt;p>Once your changes have been made, you will need to commit them with a commit message. We suggest that it is something relevant to your event&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/commit.png"
loading="lazy"
alt="commit"
>&lt;/p>
&lt;p>Then you will need to press the publish button in Visual Studio Code to publish this branch to GitHub&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/publish.png"
loading="lazy"
alt="publish"
>&lt;/p>
&lt;h3 id="create-a-pull-request-in-the-data-saturdays-repository">Create a Pull Request in the Data Saturdays Repository&lt;/h3>
&lt;p>Last step is to create a Pull Request. Open your browser at your local GitHub repository. You will see a green button saying compare and pull request.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/createpr.png"
loading="lazy"
alt="createpr"
>&lt;/p>
&lt;p>When you click that it will automatically open a pull request for you. Add some details about who you are and your event and an admin will then review it and merge it. Once it has been merged, the site will be rebuilt and will include your new event page.&lt;/p>
&lt;h3 id="continue-to-update-your-event">Continue to update your event&lt;/h3>
&lt;p>AS you progress along your event timeline, you will need to edit the data file and create a new Pull Request. You will do this&lt;/p>
&lt;ul>
&lt;li>When you get a new sponsor&lt;/li>
&lt;li>When you have enough volunteers&lt;/li>
&lt;li>When your Call for Speaker closes&lt;/li>
&lt;li>When your event is published and you have your SpeakerWall and Schedule API URLs from Sessionize&lt;/li>
&lt;li>To add links to your virtual rooms&lt;/li>
&lt;li>To add your feedback links&lt;/li>
&lt;li>After your event has finished&lt;/li>
&lt;/ul>
&lt;p>As you change those things, create new Pull Requests, and they are merged, your event page will be updated.&lt;/p></description></item><item><title>Microsoft Values The Community</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/microsoft-values-the-community/</link><pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/microsoft-values-the-community/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2021/MSCommunity.png" alt="Featured image of post Microsoft Values The Community" />&lt;h1 id="what-happens-next">What Happens Next?&lt;/h1>
&lt;p>When PASS announced that operations would cease, a common question was &amp;ldquo;OK, so what happens now? To SQL Saturdays?, to the summit?, to the local user groups?&amp;rdquo; The answers to some of those questions will lie in other conversations but for right now, let&amp;rsquo;s talk about Local User Groups.&lt;/p>
&lt;h1 id="user-groups">User Groups&lt;/h1>
&lt;p>User groups are a fantastic way to expand your knowledge and your network. A place to find like minded people performing similar roles that you can learn from and get support from.&lt;/p>
&lt;p>Attending my local user group for the first time really helped me to improve. &lt;a class="link" href="https://blog.robsewell.com/blog/you-have-to-start-somewhere/" target="_blank" rel="noopener"
>At the time I was really struggling in my job with no idea how to get support from people who &lt;strong>know&lt;/strong> what should be done.&lt;/a> I joined the group, I made many friends and I learnt a lot. My OneNote is full of notes I have taken during User Group sessions. I became involved in running the user group and the associated SQL Saturday and then became aware of the wider community.&lt;/p>
&lt;p>We are always very proud of the number of speakers who started their speaking career at our user group and have gone to great things. I too, &lt;a class="link" href="https://blog.robsewell.com/blog/lessons-learnt-from-my-first-talk-at-sql-southwest/" target="_blank" rel="noopener"
>started my speaking career at our user group&lt;/a>.&lt;/p>
&lt;p>Our little user group in Exeter in the UK (or in Teams these days!) and user groups in general have a big place in my heart and I am a strong supporter of them. (If you would like a speaker, please always feel free to get in touch with me.) so I too, wondered&lt;/p>
&lt;blockquote>
&lt;p>What is going to happen to the user groups now?&lt;/p>
&lt;/blockquote>
&lt;h1 id="microsoft-values-the-community">Microsoft Values The Community&lt;/h1>
&lt;p>Microsoft have announced the support that they will be giving to user groups. You can watch Buck Woody &lt;a class="link" href="https://twitter.com/BuckWoodyMSFT" target="_blank" rel="noopener"
>t&lt;/a> explain everything that the Microsoft Data Platform is doing to empower the community on Youtube &lt;a class="link" href="https://youtu.be/obFlSwpIihc" target="_blank" rel="noopener"
>here&lt;/a>. (While you are there, I suggest subscribing to the channel, it&amp;rsquo;s really awesome)&lt;/p>
&lt;p>Microsoft always has and always will support the technical professionals who use their products and they recognise that at the grass roots, the local user groups are the core of the community.&lt;/p>
&lt;h1 id="so-microsoft-are-taking-over-the-user-groups">So Microsoft are taking over the User Groups?&lt;/h1>
&lt;p>NO.&lt;/p>
&lt;p>Microsoft&amp;rsquo;s philosophy is that local user groups should be Community-owned but they can be Microsoft-empowered. They have created a series of assets, resources, and benefits for user group leaders to run their groups. I am astonished at the scale of what has been achieved in a short amount of time. There are a lot of benefits that will make it easier for user groups to have a stable presence and all the tools that they need to enable their user group .&lt;/p>
&lt;h1 id="what-is-being-offered-">What is being offered ?&lt;/h1>
&lt;p>If you want to skip right to the sign up please fill out the form linked &lt;a class="link" href="https://cloudblogs.microsoft.com/sqlserver/2020/12/22/resources-for-the-sql-server-and-azure-data-community?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>on this page&lt;/a>&lt;/p>
&lt;p>The Azure Data Community will provide&lt;/p>
&lt;ul>
&lt;li>The Community Landing Page &lt;a class="link" href="aka.ms/datacommunity?WT.mc_id=DP-MVP-5002693" >aka.ms/datacommunity&lt;/a> which is central gateway for useful Azure Data Community resources from blog posts and videos to the user groups.&lt;/li>
&lt;li>Meetup Pro fees, fully paid for by Microsoft saving user groups leaders from paying out of their own pocket or finding sponsorship.&lt;/li>
&lt;li>A centralised way to find groups and events in the Data Community &lt;a class="link" href="https://www.meetup.com/pro/azuredatatechgroups/" target="_blank" rel="noopener"
>https://www.meetup.com/pro/azuredatatechgroups/&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/datacommunity.png"
loading="lazy"
alt="Community"
>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Full Microsoft Teams subscriptions with all the bells &amp;amp; whistles for qualified Community Groups using a customisable template for the user group to define as they wish. This will be fantastic for running virtual events, sharing slides and demo code as well as keping in touch wiht your fellow user group members&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Community Leader Collaboration (via Teams &amp;amp; Meetup) enabling all the user groups leaders to be able to communicate, collaborate and share resources.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="do-i-have-to-use-this-">Do I have to use this ?&lt;/h1>
&lt;p>NO.&lt;/p>
&lt;p>You are in charge, if you already run your user group and don&amp;rsquo;t need these resources, let the team know and they will get you listed on the community gateway site.&lt;/p>
&lt;h1 id="what-are-the-requirements">What are the requirements?&lt;/h1>
&lt;p>Throughout the duration of the Group’s participation in the Program, the Group will:&lt;/p>
&lt;ol>
&lt;li>Have a group leader and a designated co-leader who have each accepted these T&amp;amp;Cs.&lt;/li>
&lt;li>Not charge other members a fee to attend Group meetings, except in cases in which the venue and/or hosting costs (e.g., food and beverages) are passed through to members.&lt;/li>
&lt;li>Maintain a published code of conduct that is easily accessible from the Group’s home page. See guidance &lt;a class="link" href="https://aka.ms/atg/guidance?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://aka.ms/atg/guidance&lt;/a>.&lt;/li>
&lt;li>Maintain a regular meeting cadence including having meetings at least six times per year that relate to or cover Azure Data products &amp;amp; services or relate to Diversity, Equity &amp;amp; Inclusion (DE&amp;amp;I) or Professional Development targeted to data professionals.&lt;/li>
&lt;li>Comply with Program’s Code of Conduct located at &lt;a class="link" href="https://aka.ms/atg/code_of_conduct?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://aka.ms/atg/code_of_conduct&lt;/a>.&lt;/li>
&lt;li>Adhere to Microsoft’s Trademark and Brand guidelines, when using any Microsoft trademarks or referring to Microsoft’s software, products or services (see &lt;a class="link" href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general.aspx&lt;/a>.&lt;/li>
&lt;/ol>
&lt;h1 id="which-technologies-do-these-benefits-apply-to">Which technologies do these benefits apply to?&lt;/h1>
&lt;ul>
&lt;li>SQL Server (on Windows, Linux, and in Containers, on-premises and in Microsoft Azure)&lt;/li>
&lt;li>Azure Data Lake&lt;/li>
&lt;li>Azure Cosmos DB&lt;/li>
&lt;li>Azure HDInsight, Hadoop and Spark on Azure&lt;/li>
&lt;li>Azure Search&lt;/li>
&lt;li>Data Warehousing (Azure SQL Data Warehouse, Fast Track and APS)&lt;/li>
&lt;li>Azure Stream Analytics&lt;/li>
&lt;li>Cortana Intelligence Suite&lt;/li>
&lt;li>Information Management (ADF, SSIS, and Data Sync)&lt;/li>
&lt;li>SQL Server Reporting Services and Analysis Services&lt;/li>
&lt;li>SQL Server Machine Learning Services&lt;/li>
&lt;li>Azure Database for MySQL&lt;/li>
&lt;li>Azure Database for PostgreSQL&lt;/li>
&lt;li>Azure SQL (Database, Pools, Serverless, Hyperscale, Managed Instance, Virtual Machines)&lt;/li>
&lt;li>Azure SQL Edge&lt;/li>
&lt;li>Big Data Clusters&lt;/li>
&lt;li>Azure Databricks&lt;/li>
&lt;li>Azure Arc Enabled Data Services&lt;/li>
&lt;li>Azure Synapse Analytics&lt;/li>
&lt;li>Azure Data Catalog&lt;/li>
&lt;/ul>
&lt;p>Sign up vis the form linked &lt;a class="link" href="https://cloudblogs.microsoft.com/sqlserver/2020/12/22/resources-for-the-sql-server-and-azure-data-community?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>on this page&lt;/a>&lt;/p>
&lt;p>Thank you to all of those people involved in making this happen.&lt;/p></description></item><item><title>Tooling for TSql2sDay</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tooling-for-tsql2sday/</link><pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tooling-for-tsql2sday/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/images/TSQL2sDay150x150.jpg" alt="Featured image of post Tooling for TSql2sDay" />&lt;h1 id="tooling-for-tsql2sday">Tooling for TSQL2sDay&lt;/h1>
&lt;p>T-SQL Tuesday is the brainchild of Adam Machanic (&lt;a class="link" href="http://dataeducation.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/adammachanic?lang=en" target="_blank" rel="noopener"
>Twitter&lt;/a>). The first T-SQL Tuesday invitation was in December 2009 and it is still going strong. It is a monthly blog party on the second Tuesday of each month. Currently, Steve Jones (&lt;a class="link" href="https://voiceofthedba.com/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/way0utwest" target="_blank" rel="noopener"
>Twitter&lt;/a>) organises the event and maintains &lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>a website with all previous posts&lt;/a>. Everyone is welcome to participate in this monthly blog post.&lt;/p>
&lt;p>This month’s T-SQL Tuesday is hosted by Mikey Bronowski ( &lt;a class="link" href="https://www.bronowski.it/blog/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/@MikeyBronowski" target="_blank" rel="noopener"
>Twitter&lt;/a> ). Mikey says:&lt;/p>
&lt;blockquote>
&lt;p>Without tools, most of the work would be much harder to do or could not be done at all. Write a blog post about the most helpful and effective tools you use or know of.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://www.bronowski.it/blog/2021/02/t-sql-tuesday-135-the-outstanding-tools-of-the-trade-that-make-your-job-awesome/" target="_blank" rel="noopener"
>The original post is here.&lt;/a>&lt;/p>
&lt;p>I miss Mikey, I worked in an office with him until the end of 2019. We used to sit next to each other which meant that I required some tools of my own!&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1113346708631629824" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/mikeyredgatewall.png"
loading="lazy"
alt="Twitter"
>&lt;/a>&lt;/p>
&lt;p>We had a lot of fun and worked hard in Yorkshire (although he never learnt to make a proper cup of tea!) and both of us learnt new sayings&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/MikeyBronowski/status/1247998435644456960" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/mikeytea.png"
loading="lazy"
alt="Twitter"
>&lt;/a>&lt;/p>
&lt;h2 id="tools">Tools&lt;/h2>
&lt;p>Writing that gave me an idea for this blog post. Of course, I could have written about PowerShell, Azure Data Studio, dbatools, dbachecks or many of the other tools I use to deliver change and automate. You will find several good posts in this TSQL2sday series from people like &lt;a class="link" href="https://jesspomfret.com/t-sql-tuesday-135/" target="_blank" rel="noopener"
>Jess Pomfret&lt;/a> and &lt;a class="link" href="https://jqmartin.info/2021/02/09/t-sql-tuesday-135-tools-of-the-trade/" target="_blank" rel="noopener"
>John Martin&lt;/a> showing some of those.&lt;/p>
&lt;p>Instead, I am going to share some of my working from home tools that I cannot do without.&lt;/p>
&lt;h3 id="coffee">Coffee&lt;/h3>
&lt;p>Hello, my name is Rob and I drink a lot of coffee! I like to have coffee, I drink a lot of it so we got a coffee machine to make it easier.&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com//assets/uploads/2021/CoffeeMachine.jpg"
loading="lazy"
alt="Coffee"
>&lt;/p>
&lt;p>It takes beans, which we get delivered via Amazon and turns them into any sort of coffee you like with a press of a button.&lt;/p>
&lt;h3 id="standing-desk">Standing Desk&lt;/h3>
&lt;p>Spending a lot of time sitting down without moving much is not much good you and also really easy to do when you are working from home so I got a standing desk from &lt;a class="link" href="https://www.autonomous.ai/standing-desks/smartdesk-2-business" target="_blank" rel="noopener"
>Autonomous&lt;/a> Which I love. I normally start my morning sitting down, stand up for the standup! Then I will alternate throughout the day between sitting and standing or using my &lt;a class="link" href="https://www.autonomous.ai/office-chairs/ergonomic-stool" target="_blank" rel="noopener"
>wibbly wobbly Autonomous stool&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/standingdesk.jpg"
loading="lazy"
alt="Standingdesk"
>&lt;/p>
&lt;h3 id="bicycle">Bicycle&lt;/h3>
&lt;p>With Covid I was not able to play any cricket last year. I really enjoyed playing cricket. I have played it since I was very small and having a reason to be out in the open, expending some energy and getting my competitive juices flowing was good for me. I have cycled in the past and enjoyed it. With the cricket team I cycled from John o&amp;rsquo; Groats to Lands End for charity a few years ago, so I bought a bike and now I again have a reason to go out in the fresh air and get my competitive juices going again, although I only compete against myself and compare my results on Strava with my previous times. Last year I started riding in April and rode 2897 miles. This gets me out into the beautiful south west UK countryside, expends some energy and keeps me moving, which I think is a good thing!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/bikeride.jpg"
loading="lazy"
alt="bikeride"
>&lt;/p>
&lt;h3 id="zwift">Zwift&lt;/h3>
&lt;p>I told you a little fib, well maybe I just neglected the whole story. I &lt;em>did&lt;/em> ride 2897 last year but not all of them are outside. I found that I really enjoy cycling in the morning when I wake up but its not really safe when it is so dark or pleasant to do when the weather is rough, so I have a cycle trainer which I connect to Zwift. This enables me to ride with other people from all over the globe and explore various worlds, both real representations of London, New York and Paris and the virtual world of Watopia where you can see dolphins, whales, shipwrecks, dinosaurs or ride up and through a volcano. This can be really fun and certainly makes it easier for me to cycle more regularly. It has a number of gamifications and even allows you to ride through a tube station at midnight ! (note this was not at midnight but The Jam didnt sing about the tube station at 6-30am!!)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2021/tubestation.jpg"
loading="lazy"
alt="bikeride"
>&lt;/p>
&lt;h2 id="most-important-of-all-the-people">Most Important of all The People&lt;/h2>
&lt;p>The most important tool though is the most useful.&lt;/p>
&lt;p>The community.&lt;/p>
&lt;p>The people who take their time to share knowledge, whether by blog posts, presentations, answering #sqlhelp on Twitter or just replying to a DM or an email. Those who organise virtual events or user groups, open source projects and community tooling like Data Saturdays and those who get paid for it as vendor evangelists or Microsoft or other companies employees.&lt;/p>
&lt;p>The sheer range of knowledge that is readily and freely available with a simple courteous question is amazing and has certainly saved me a bunch of time and helped me out of some difficult to solve situations. Remember to be polite and appreciative of the time that they take out of their day and you will find they are willing to share their knowhow and help.&lt;/p>
&lt;p>Thank you to all of those people&lt;/p></description></item><item><title>Using PowerShell to Automate StreamLabs OBS and Show Your Webcam in PowerPoint</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-automate-streamlabs-obs-and-show-your-webcam-in-powerpoint/</link><pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-automate-streamlabs-obs-and-show-your-webcam-in-powerpoint/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/09/scottwitter.png" alt="Featured image of post Using PowerShell to Automate StreamLabs OBS and Show Your Webcam in PowerPoint" />&lt;h2 id="it-started-with-a-tweet">It started with a tweet&lt;/h2>
&lt;p>As with many things in my life it started with a tweet&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/sammydeprez/status/1307674009669074945" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/scottwitter.png"
loading="lazy"
alt="Twitter"
>&lt;/a>&lt;/p>
&lt;p>That looks awesome, I thought, so I watched the YouTube video.Scott has written a C# application that would change the scene depending on some text in the PowerPoint slide notes. Then, by applying a Chroma filter to the display capture and placing the webcam capture appropriately, when the slide changed, the Obs scene changed and the webcam became embedded in the slide!!!!!!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>It is truly awesome but it is for Obs and I use StreamLabs and I wondered if it could be done with PowerShell.&lt;/p>
&lt;p>(If you just want the code, &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/PowerPointSlobs.ps1" target="_blank" rel="noopener"
>you can find it here&lt;/a>)&lt;/p>
&lt;h2 id="listen-to-powerpoint-events-with-powershell">Listen to PowerPoint Events with PowerShell&lt;/h2>
&lt;h3 id="create-a-com-object">Create a Com Object&lt;/h3>
&lt;p>The first thing that we need to do is to find out when the PowerPoint Slide has changed.&lt;/p>
&lt;p>You can create a PowerPoint Com Object with&lt;/p>
&lt;pre>&lt;code>$Application = New-Object -ComObject PowerPoint.Application
&lt;/code>&lt;/pre>
&lt;p>and make it visible with&lt;/p>
&lt;pre>&lt;code>$Application.Visible = 'MsoTrue'
&lt;/code>&lt;/pre>
&lt;h3 id="get-the-slide-number-and-notes">Get the Slide Number and Notes&lt;/h3>
&lt;p>Next step is to get the slide number. It is not truly required for the code, but I like to print it out so that I know which slide I was on for trouble shooting.&lt;/p>
&lt;p>Looking at &lt;a class="link" href="https://github.com/shanselman/PowerPointToOBSSceneSwitcher/blob/accf2c40d0f1cbb31287751bd7be4ae2fe0d3bb7/Program.cs#L34" target="_blank" rel="noopener"
>Scotts code here&lt;/a> I worked out that the slide number via PowerShell was&lt;/p>
&lt;pre>&lt;code>$slideNumber = $PowerPoint.SlideShowWindows[1].view.Slide.SlideIndex
&lt;/code>&lt;/pre>
&lt;p>The notes (by looking at &lt;a class="link" href="https://github.com/shanselman/PowerPointToOBSSceneSwitcher/blob/accf2c40d0f1cbb31287751bd7be4ae2fe0d3bb7/Program.cs#L37" target="_blank" rel="noopener"
>code&lt;/a>) can be accessed at&lt;/p>
&lt;pre>&lt;code>$notes = $PowerPoint.SlideShowWindows[1].View.Slide.NotesPage.Shapes[2].TextFrame.TextRange.Text
&lt;/code>&lt;/pre>
&lt;p>then parse the notes to get the scene name which is defined as &lt;code>OBS:SceneName&lt;/code>&lt;/p>
&lt;pre>&lt;code>$SceneName = ($notes -split &amp;quot;`r&amp;quot;)[0] -replace 'OBS:', ''
&lt;/code>&lt;/pre>
&lt;p>The first part gets the first line and it was thanks to Andreas on twitch who got this working, Thank you Andreas.&lt;/p>
&lt;h3 id="listen-to-an-event">Listen to an Event&lt;/h3>
&lt;p>With PowerShell, you can subscribes to events and take action when they fire. The event that we are going to subscribe to is called &lt;code>SlideShowNextSlide&lt;/code>&lt;/p>
&lt;pre>&lt;code>$subscriber = Register-ObjectEvent -InputObject $PowerPoint -EventName SlideShowNextSlide -Action $action
&lt;/code>&lt;/pre>
&lt;p>We have defined an $action variable in the code but we need to provide an action and this is where things got a little tricky.&lt;/p>
&lt;h2 id="automating-streamlabs-obs">Automating StreamLabs OBS&lt;/h2>
&lt;p>In Scotts code he uses OBS.WebSocket.NET to control OBS. Excellent, PowerShell and .NET.Unfrotunately, StreamLabs uses an RPC-based API &lt;a class="link" href="https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html" target="_blank" rel="noopener"
>https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html&lt;/a>&lt;/p>
&lt;p>This documentation specifies&lt;/p>
&lt;blockquote>
&lt;p>You can access services&amp;rsquo; methods and properties by sending JSON-RPC messages to the named pipe slobs.&lt;/p>
&lt;/blockquote>
&lt;h3 id="thank-you-keith-hill">Thank you Keith Hill&lt;/h3>
&lt;p>So Rob traversed a rabbit warren of investigation to understand how to send messages to this API with PowerShell and eventually stumbled across the marvelous Keith Hill &lt;a class="link" href="https://rkeithhill.wordpress.com/" target="_blank" rel="noopener"
>blog&lt;/a> &lt;a class="link" href="https://twitter.com/r_keith_hill" target="_blank" rel="noopener"
>twitter&lt;/a> and a blog post from 2014&lt;/p>
&lt;p>&lt;a class="link" href="https://rkeithhill.wordpress.com/2014/11/01/windows-powershell-and-named-pipes/" target="_blank" rel="noopener"
>https://rkeithhill.wordpress.com/2014/11/01/windows-powershell-and-named-pipes/&lt;/a>&lt;/p>
&lt;h3 id="create-a-connection-and-send-and-receive-messages">Create a connection and send and receive messages&lt;/h3>
&lt;p>Now I had everything I needed to create a connection to SLOBS via named pipes. SLOBS needs to be started here!&lt;/p>
&lt;pre>&lt;code># Create Client
$npipeClient = New-Object System.IO.Pipes.NamedPipeClientStream($Env:ComputerName, 'slobs', [System.IO.Pipes.PipeDirection]::InOut, [System.IO.Pipes.PipeOptions]::None, [System.Security.Principal.TokenImpersonationLevel]::Impersonation)
$npipeClient.Connect()
$npipeClient
# Create Reader and writer and send and receive message
$pipeReader = New-Object System.IO.StreamReader($npipeClient)
$pipeWriter = New-Object System.IO.StreamWriter($npipeClient)
$pipeWriter.AutoFlush = $true
# Send message
$pipeWriter.WriteLine($scenesMessage)
# Receive message
$pipeReader.ReadLine()
&lt;/code>&lt;/pre>
&lt;h3 id="which-messages">Which messages?&lt;/h3>
&lt;p>Next I needed to get the messages to send formatted correctly. Looking at the &lt;a class="link" href="https://stream-labs.github.io/streamlabs-obs-api-docs/docs/index.html#examples" target="_blank" rel="noopener"
>API docs&lt;/a> I saw&lt;/p>
&lt;pre>&lt;code>{
&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,
&amp;quot;id&amp;quot;: 1,
&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,
&amp;quot;params&amp;quot;: {
&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>So I was able to get the current available scenes with&lt;/p>
&lt;pre>&lt;code>$scenesMessage = '{&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,&amp;quot;id&amp;quot;: 6,&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,&amp;quot;params&amp;quot;: {&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;}}'
$pipeWriter.WriteLine($scenesMessage)
($pipeReader.ReadLine() | ConvertFrom-Json).result | Select Name, id
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/getslobsscenes.png"
loading="lazy"
alt="Get SLOBS Scenes"
>&lt;/p>
&lt;h3 id="change-scenes">Change Scenes&lt;/h3>
&lt;p>The last part of the jigsaw was to change the scene via the named pipe connection&lt;/p>
&lt;pre>&lt;code>$scenesMessage = '{&amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;,&amp;quot;id&amp;quot;: 6,&amp;quot;method&amp;quot;: &amp;quot;getScenes&amp;quot;,&amp;quot;params&amp;quot;: {&amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;}}'
$pipeWriter.WriteLine($scenesMessage)
$scenes = ($pipeReader.ReadLine() | ConvertFrom-Json).result | Select Name, id
$SceneId = ($scenes | Where Name -eq $SceneName).id
$MakeSceneActiveMessage = '{ &amp;quot;jsonrpc&amp;quot;: &amp;quot;2.0&amp;quot;, &amp;quot;id&amp;quot;: 1, &amp;quot;method&amp;quot;: &amp;quot;makeSceneActive&amp;quot;, &amp;quot;params&amp;quot;: { &amp;quot;resource&amp;quot;: &amp;quot;ScenesService&amp;quot;,&amp;quot;args&amp;quot;: [&amp;quot;' + $SceneId + '&amp;quot;]}}'
$pipeWriter.WriteLine($MakeSceneActiveMessage)
$switchResults = $pipeReader.ReadLine() | ConvertFrom-Json
&lt;/code>&lt;/pre>
&lt;p>Which looks like this :-)&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="setting-up-powerpoint-and-scenes">Setting up PowerPoint and Scenes&lt;/h2>
&lt;p>With the PowerShell set up, we next need to set it up to use the scenes. I followed Scotts example and used &lt;code>OBS:SceneName&lt;/code> as the reference to the Scene. I added this to the first line of the notes on a slide&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/pptxnotes.png"
loading="lazy"
alt="Slide Notes"
>&lt;/p>
&lt;p>and then created a text box with a green fill&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/greenbox.png"
loading="lazy"
alt="Green Box"
>&lt;/p>
&lt;p>In StreamLabs, I set up the scene with the same name, the order of the sources is important. They are displayed from top to bottom, front to back so the Display Capture will be on top of the Sony Camera here&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/sourceorder.png"
loading="lazy"
alt="Source order"
>&lt;/p>
&lt;p>Then I right clicked on the Display Capture and chose Filters&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/choosefilters.png"
loading="lazy"
alt="choose filters"
>&lt;/p>
&lt;p>and chose a Chroma Key filter&lt;/p>
&lt;p>With the PowerPoint in SlideShow mode, I set the Chroma Key filter colour to match the colour of the green box, placed the camera source in the correct location and saved.&lt;/p>
&lt;p>The image below shows form left to right, the Chroma Key settings, the scene in SLOBS and the PowerPoint slideshow&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com//assets/uploads/2020/09/setfilter.png"
loading="lazy"
alt="set filters"
>&lt;/p>
&lt;p>Normally, I would do this on seperate screens of course!&lt;/p>
&lt;p>I set up each slide like this and then I closed the PowerPoint and ran the code, &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/PowerPointSlobs.ps1" target="_blank" rel="noopener"
>you can find it here,&lt;/a>)leaving PowerShell running in the background. This opened PowerPoint and I opened the deck and started the slide show and as I navigate through the slide, the scene changes and so does the webcam position :-)&lt;/p>
&lt;p>You can see a test run below&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>and &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2020/test.pptx" target="_blank" rel="noopener"
>the demo pptx can be found here&lt;/a>&lt;/p></description></item><item><title>#tsql2sday #130 - Automate your stress away - Getting more SSIS Agent Job information</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-130-automate-your-stress-away-getting-more-ssis-agent-job-information/</link><pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-130-automate-your-stress-away-getting-more-ssis-agent-job-information/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/images/TSQL2sDay150x150.jpg" alt="Featured image of post #tsql2sday #130 - Automate your stress away - Getting more SSIS Agent Job information" />&lt;h1 id="automation">Automation&lt;/h1>
&lt;!-- raw HTML omitted -->
&lt;p>This month it is hosted by Elizabeth Noble &lt;!-- raw HTML omitted -->blog&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->twitter&lt;!-- raw HTML omitted -->.&lt;/p>
&lt;p>Thank you Elizabeth&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/p>
&lt;p>Elizabeth asks&lt;/p>
&lt;blockquote>
&lt;p>My invitation to you is I want to know what you have automated to make your life easier?&lt;/p>
&lt;/blockquote>
&lt;h2 id="from-the-past">From the Past&lt;/h2>
&lt;p>I am in the process of migrating my blog to GitHub pages and whilst doing so, I read my first ever technical blog post &lt;a class="link" href="https://blog.robsewell.com/blog/you-have-to-start-somewhere/" target="_blank" rel="noopener"
>You have to start somewhere&lt;/a> In it I mention this blog post by John Sansom &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>The Best Database Administrators Automate Everything&lt;/a> which I am pleased to see is still available nearly a decade later&lt;/p>
&lt;p>Here is a quote from his blog entry&lt;/p>
&lt;blockquote>
&lt;h2 id="automate-everything">Automate Everything&lt;/h2>
&lt;p>That’s right, I said everything. Just sit back and take the &lt;em>time&lt;/em> to consider this point for a moment. Let it wander around your mind whilst you consider the processes and tasks that you could look to potentially automate. Now eliminate the word &lt;em>potentially&lt;/em> from your vocabulary and evaluate how you could automate &lt;strong>e-v-e-r-y-t-h-i-n-g&lt;/strong> that you do.&lt;/p>
&lt;p>Even if you believe that there is only a remote possibility that you will need to repeat a given task, just go ahead and automate it anyway! Chances are that when the need to repeat the process comes around again, you will either be under pressure to get it done, or even better have more important &lt;em>Proactive Mode&lt;/em> tasks/projects to be getting on with&lt;/p>
&lt;/blockquote>
&lt;h2 id="i-love-automation">I love Automation&lt;/h2>
&lt;p>I have tried my best at all times to follow this advice in the last decade and pretty much I am happy that I have managed it.&lt;/p>
&lt;ul>
&lt;li>I use PowerShell (a lot!) to automate all sorts of routine tasks including migrating this blog&lt;/li>
&lt;li>I use &lt;a class="link" href="https://blog.robsewell.com/tags/#jupyter-notebooks" target="_blank" rel="noopener"
>Jupyter Notebooks&lt;/a> to enable myself and others to automate Run Books, Training, Documentation, Demonstrations, Incident Response. You can find my notebooks &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>here&lt;/a>&lt;/li>
&lt;li>I use Azure DevOps to automate infrastructure creation and changes with terraform and delivery of changes to code as well as unit testing.&lt;/li>
&lt;li>I use GitHub actions to create this blog, publish the &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a> module&lt;/li>
&lt;li>I use &lt;a class="link" href="https://chocolatey.org/" target="_blank" rel="noopener"
>Chocolatey&lt;/a> to install and update software&lt;/li>
&lt;li>I have used Desired State Configuration to ensure that infrastructure is as it is expected to be&lt;/li>
&lt;/ul>
&lt;p>At every point I am looking for a means to automate the thing that I am doing because it is almost guaranteed that there will be a time in the future after you have done a thing that there will be a need to do it again or to do it slightly differently.&lt;/p>
&lt;h2 id="whats-the-last-thing-that-you-automated">Whats the last thing that you automated?&lt;/h2>
&lt;p>Following my blog post about &lt;a class="link" href="https://blog.robsewell.com/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/" target="_blank" rel="noopener"
>Notifying a Teams Channel about a SQL Agent Job result&lt;/a> I was asked if this could be tweaked to reduce the time spent getting information about SSIS Execution failures.&lt;/p>
&lt;h3 id="finding-ssis-failures">Finding SSIS failures&lt;/h3>
&lt;p>When you run an SSIS package in an Agent Job and it fails, the Agent Job History shows something along these lines&lt;/p>
&lt;blockquote>
&lt;p>The job failed. The Job was invoked by User MyDomain\MyUserName. The last step to run was step 1 (scheduling ssis package).
Executed as user: NT Service\SQLSERVERAGENT. Microsoft (R) SQL Server Execute Package Utility Version 11.0.5058.0 for 64-bit Copyright (C) Microsoft Corporation. All rights reserved. Started: 4:17:12 PM Package execution on IS Server failed. &lt;strong>Execution ID: 123456789&lt;/strong>, Execution Status:4. To view the details for the execution, right-click on the Integration Services Catalog, and open the [All Executions] report Started: 4:17:12 PM Finished: 4:17:12 PM Elapsed: 4.493 seconds. The package execution failed. The step failed.&lt;/p>
&lt;/blockquote>
&lt;p>The next step is to open SSMS, go to the SSISDb and click through to the SSIS reports and then scroll through to find the package and then the message. This is not particularly efficient and the SSIS reports are not known for their speedy executions!&lt;/p>
&lt;p>This meant that the team member responsible for checking in the morning, could see which instance and which job had failed from the Teams message but then had to manually follow the above steps to find an error message that they could take action on.&lt;/p>
&lt;h3 id="automate-it">Automate it&lt;/h3>
&lt;p>In the SSISDB database there is an &lt;code>event_messages&lt;/code> view so if I could query that and filter by the Execution ID then I could get the message and place it into the Teams message. Now the Teams message contains the error for the SSIS execution and each time this happens it probably saves the team member 4 or 5 minutes :-)&lt;/p>
&lt;p>In the code below, I&lt;/p>
&lt;ol>
&lt;li>
&lt;p>check if the failure comes from an SSIS instance&lt;br>
if($Inst -in ($SSISInstances)){&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Get the Execution ID from the Error message&lt;br>
&lt;code>$ExecutionId = [regex]::matches($BaseerrMessage, 'Execution ID: (\d{3,})').groups[1].value&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create a query for the SSISDB&lt;/p>
&lt;p>&lt;code>$SSISQuery = @&amp;quot;&lt;/code>&lt;br>
&lt;code>SELECT * FROM catalog.event_messages em&lt;/code>&lt;br>
&lt;code>WHERE em.operation_id = $ExecutionId&lt;/code>&lt;br>
&lt;code>AND (em.event_name = 'OnError')&lt;/code>&lt;br>
&lt;code>ORDER BY em.event_message_id;&lt;/code>&lt;br>
&lt;code>&amp;quot;@&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Set the Error Message and the Execution Path to variables&lt;br>
&lt;code>$errMessage = $SSISQueryResults.Message&lt;/code>&lt;br>
&lt;code>$ExecutionPath = $SSISQueryResults.execution_path&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Get the Error Message for none SSIS failures&lt;br>
&lt;code>}else{&lt;/code>&lt;br>
&lt;code>$errMessage = $j.group[-1].Message&lt;/code>&lt;br>
&lt;code>$ExecutionPath = 'the job'&lt;/code>&lt;br>
&lt;code>}&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Create the Teams message&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>You will see that I used &lt;code>SELECT *&lt;/code> because someone will always ask for some extra information in the future!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/images/happyrob.jpg"
loading="lazy"
>&lt;/p>
&lt;p>The full script is below, Happy Automating!&lt;/p>
&lt;pre>&lt;code>$webhookurl = &amp;quot;https://outlook.office.com/webhook/ the rest of it here&amp;quot;
$SSISInstances = # to identify SSIS instances
$ProdInstances = # ALL instances for checking
$startdate = (Get-Date).AddHours(-1)
$AllFailedJobs = foreach ($Instance in $ProdInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs # | Where-Object { $Psitem.Job -match '^Beard-\d\d\d\d\d' -or $Psitem.Job -like 'BeardJob*' } # if you need to filter
$FailedJobs = $jobs | Where-Object { $Psitem.Status -ne 'Succeeded' }
$FailedJobs | Group-Object Job
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;We have $($AllFailedJobs.Count) Failed Jobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
foreach ($j in $AllFailedJobs) {
$Inst = $j.group[-1].SqlInstance
$jName = $j.name
$sname = $j.group[-1].StepName
$edate = $j.group[-1].EndDate
if($Inst -in ($SSISInstances)){
$BaseerrMessage = $j.group[-1].Message
$ExecutionId = [regex]::matches($BaseerrMessage, 'Execution ID: (\d{3,})').groups[1].value
$SSISQuery = @&amp;quot;
SELECT * FROM catalog.event_messages em
WHERE em.operation_id = $ExecutionId
AND (em.event_name = 'OnError')
ORDER BY em.event_message_id;
&amp;quot;@
$SSISQueryResults = Invoke-DbaQuery -SqlInstance $Inst -Database SSISDB -Query $SSISQuery
$errMessage = $SSISQueryResults.Message
$ExecutionPath = $SSISQueryResults.execution_path
}else{
$errMessage = $j.group[-1].Message
$ExecutionPath = 'the job'
}
$Text = @&amp;quot;
# **$Inst**
## **$JName**
- The Job step that failed is - **$sname**
- It failed at - **$edate**
- It failed in $ExecutionPath with the message
- $errMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;in the Last 1 hour&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://blog.robsewell.com/assets/images/sobrob.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
if(-not $AllFailedJobs){
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There were no job failures in the last hour at $ (Get-Date)&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;There were no job failures at $ (Get-Date)&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;in the Last hour&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://blog.robsewell.com/assets/images/happyrob.jpg&amp;quot;
&amp;quot;text&amp;quot; = &amp;quot;All is well&amp;quot;
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
&lt;/code>&lt;/pre></description></item><item><title>The first page with GitHub Pages</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-first-page-with-github-pages/</link><pubDate>Thu, 03 Sep 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-first-page-with-github-pages/</guid><description>&lt;p>Last night I started the experiment that has been in my head for a while now, to move from SQL Dba With A Beard to RobSewell.com&lt;/p>
&lt;p>Thank you Chrissy &lt;a class="link" href="https://blog.netnerds.net/" target="_blank" rel="noopener"
>Blog&lt;/a> &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Twitter&lt;/a> for the push!&lt;/p>
&lt;p>I followed the instructions from her blog post &lt;a class="link" href="https://blog.netnerds.net/2020/08/migrating-my-wordpress-sites-to-github-pages/" target="_blank" rel="noopener"
>Migrating my WordPress sites to GitHub Pages&lt;/a> but chose to use the &lt;a class="link" href="https://github.com/mmistakes/minimal-mistakes" target="_blank" rel="noopener"
>Minimal Mistakes theme&lt;/a>&lt;/p>
&lt;p>I like the search at the top and the &lt;a class="link" href="https://blog.robsewell.com/404.html" target="_blank" rel="noopener"
>404 page :-)&lt;/a>&lt;/p>
&lt;p>Now I need to export the wordpress from SQLDbaWithABeard.com (Its currently running)&lt;/p>
&lt;p>I will still blog on there for a while I think but export it to here also or blog on here and export to there, one or the other&lt;/p></description></item><item><title>Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</link><pubDate>Fri, 21 Aug 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-azure-sql-database-aad-contained-database-users-with-an-spn-using-powershell-secrets-management-azure-key-vault-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/08/image-16.png" alt="Featured image of post Creating Azure SQL Database AAD Contained Database Users with an SPN using PowerShell, Secrets Management, Azure Key Vault, and dbatools" />&lt;p>Following on from my posts about using Secret Management &lt;a class="link" href="https://blog.robsewell.com/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>Good bye Import-CliXml&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/" target="_blank" rel="noopener"
>running programmes as a different user&lt;/a>, I have another use case.&lt;/p>
&lt;p>After creating Azure SQL Databases in an Elastic Pool using a process pretty similar to this one &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>I blogged about last year&lt;/a>, I needed to be able to programmatically create users and assign permissions.&lt;/p>
&lt;h2 id="i-need-a-user-to-login-with">I need a user to login with&lt;/h2>
&lt;p>When I created my Azure SQL Server with Terraform, I set the Azure Admin to be a SPN as you can see in the image from the portal and set it to have an identity using the documentation for &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_server.html" target="_blank" rel="noopener"
>azurerm_mssql_server&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-18.png"
loading="lazy"
>
This allows this user to manage the access for the SQL Server as long as the SQL Server Azure AD identity has Directory Reader privileges. The SQL Server is called temp-beard-sqls and as you can see the identity is assigned to the role.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-11.png"
loading="lazy"
>
The privileges required to do this for a single identity are quite high&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>so now, you can assign an Azure Active Directory Group to that Role and allow less-privileged users to add the identity to this group . The documentation is &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> and there is a tutorial &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-service-principal-tutorial?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> explaining the steps you need to take.&lt;/p>
&lt;h2 id="what-is-an-azure-spn">What is an Azure SPN?&lt;/h2>
&lt;blockquote>
&lt;p>An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/cli/azure/create-an-azure-service-principal-azure-cli?toc=%2Fazure%2Fazure-resource-manager%2Ftoc.json&amp;amp;view=azure-cli-latest&lt;/a>&lt;/p>
&lt;p>I created the SPN using Azure CLI straight from the Azure Portal by clicking this button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and running&lt;/p>
&lt;pre>&lt;code>az ad sp create-for-rbac --name ServicePrincipalName
&lt;/code>&lt;/pre>
&lt;p>This will quickly create a SPN for you and return the password&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes I have deleted this one&lt;/p>
&lt;h2 id="add-azure-key-vault-to-secret-management">Add Azure Key Vault to Secret Management&lt;/h2>
&lt;p>In my previous posts, I have been using the Default Key Vault which is limited to your local machine and the user that is running the code. It would be better to use Azure Key Vault to store the details for the SPN so that it safely stored in the cloud and not on my machine and also so that anyone (or app) that has permissions to the vault can use it.&lt;/p>
&lt;p>First you need to login to Azure in PowerShell (You will need to have the AZ* modules installed)&lt;/p>
&lt;pre>&lt;code>Connect-AzAccount
&lt;/code>&lt;/pre>
&lt;p>Be aware, the login box can appear behind the VS Code or Azure Data Studio window!&lt;/p>
&lt;p>Once connected, if you have several Azure subscriptions, you can list them with&lt;/p>
&lt;pre>&lt;code>Get-AzSubscription
&lt;/code>&lt;/pre>
&lt;p>You can choose your subscription with&lt;/p>
&lt;pre>&lt;code>$AzureSubscription = Set-AzContext -SubscriptionName &amp;quot;NAME OF SUBSCRIPTION&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>For the Secret Management Module to manage the Azure Key Vault, you first need to register it.&lt;/p>
&lt;p>Ensure that you have permissions to connect by following the details in the network security documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/network-security?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/network-security&lt;/a> and the secure access documentation &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/key-vault/general/secure-your-key-vault&lt;/a>&lt;/p>
&lt;p>Then you can run &lt;code>Register-SecretVault&lt;/code> . You need to provide the local name for the key vault, the module name &lt;code>Az.KeyVault&lt;/code>, and a &lt;code>VaultParameters&lt;/code> hashtable with the KeyVault name and the Azure Subscription ID. You can register other types of Key Vaults to the Secret Management module in this way and they will require different values for the &lt;code>VaultParameters&lt;/code> parameter.&lt;/p>
&lt;pre>&lt;code>$KeyVaultName = 'beard-key-vault'
Register-SecretVault -Name BeardKeyVault -ModuleName Az.KeyVault -VaultParameters @{ AZKVaultName = $KeyVaultName; SubscriptionId = $AzureSubscription.Subscription.Id }
&lt;/code>&lt;/pre>
&lt;h2 id="adding-the-spn-details-to-the-azure-key-vault">Adding the SPN details to the Azure Key Vault&lt;/h2>
&lt;p>Using the values for AppID – (Note NOT the display name) and the values for the password from the Azure CLI output or by creating a new secret for the SPN with PowerShell or via the portal. You can use the following code to add the SPN details and the tenantid to the Azure Key Vault using the Secret Management module&lt;/p>
&lt;pre>&lt;code>$ClientId = Read-Host &amp;quot;Enter ClientID&amp;quot; -AsSecureString
$SecretFromPortal = Read-Host &amp;quot;Enter Client Secret&amp;quot; -AsSecureString
$tenantid = Read-Host &amp;quot;Enter TenantId&amp;quot; -AsSecureString
Set-Secret -Vault BeardKeyVault -Name service-principal-guid -Secret $ClientId
Set-Secret -Vault BeardKeyVault -Name service-principal-secret -SecureStringSecret $SecretFromPortal
Set-Secret -Vault BeardKeyVault -Name Tenant-Id -Secret $tenantid
&lt;/code>&lt;/pre>
&lt;p>You can also do this with the Az.KeyVault module by following the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/key-vault/secrets/quick-create-powershell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>You can see the secrets in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>and also at the command line with the Secret Management module using&lt;/p>
&lt;pre>&lt;code>Get-SecretInfo -Vault RegisteredNameOfVault
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="can-my-user-connect">Can my user connect?&lt;/h2>
&lt;p>If I try to connect in Azure Data Studio to my Azure SQL Database with my AAD account to the temp-sql-db-beard database. It fails.&lt;/p>
&lt;p>By the way a great resource for troubleshooting the SQL error 18456 failure states can be found here &lt;a class="link" href="https://sqlblog.org/2020/07/28/troubleshooting-error-18456" target="_blank" rel="noopener"
>https://sqlblog.org/2020/07/28/troubleshooting-error-18456&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-13.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="dbatools-to-the-rescue-">dbatools to the rescue 🙂&lt;/h2>
&lt;p>dbatools is an open source community collaboration PowerShell module for administrating SQL Server. You can find more about it at &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.io&lt;/a> and get the book that Chrissy and I are writing about dbatools at &lt;a class="link" href="http://dbatools.io%5Cbook" target="_blank" rel="noopener"
>dbatools.io\book&lt;/a>&lt;/p>
&lt;p>You can connect to Azure SQL Database with an Azure SPN using the following code. It will get the secrets from the Azure Key Vault that have been set above and create a connection. Lets see if I can run a query as the SPN.&lt;/p>
&lt;pre>&lt;code>$SqlInstance = 'temp-beard-sqls.database.windows.net'
$databasename = 'master'
$appid = Get-Secret -Vault BeardKeyVault -Name service-principal-guid -AsPlainText
$Clientsecret = Get-Secret -Vault BeardKeyVault -Name service-principal-secret
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = Get-Secret -Vault BeardKeyVault -Name Sewells-Tenant-Id -AsPlainText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
Invoke-DbaQuery -SqlInstance $AzureSql -Database master -SqlCredential $credential -Query &amp;quot;Select SUSER_NAME() as 'username'&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Excellent 🙂&lt;/p>
&lt;h2 id="add-a-user-to-the-user-database">Add a user to the user database&lt;/h2>
&lt;p>I can then add my user to the temp-sql-db-beard Database. I need to create a new connection to the user database as you cannot use the &lt;code>USE [DatabaseName]&lt;/code> statement&lt;/p>
&lt;pre>&lt;code>$Userdatabasename = 'temp-sql-db-beard'
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $Userdatabasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre>
&lt;p>Whilst you can use dbatools to create new users in Azure SQL Database at present you cant create AAD users. You can run a T-SQL Script to do this though. This script will create a contained database user in the database. I have added the role membership also but this can also be done with &lt;a class="link" href="https://docs.dbatools.io/#Add-DbaDbRoleMember" target="_blank" rel="noopener"
>Add-DbaDbRoleMember&lt;/a> from dbatools&lt;/p>
&lt;pre>&lt;code>$Query = @&amp;quot;
CREATE USER [rob@sewells-consulting.co.uk] FROM EXTERNAL PROVIDER
ALTER ROLE db_datareader ADD MEMBER [rob@sewells-consulting.co.uk]
&amp;quot;@
Invoke-DbaQuery -SqlInstance $AzureSql -Database $Userdatabasename -SqlCredential $credential -Query $Query
&lt;/code>&lt;/pre>
&lt;p>Lets check the users on the database with dbatools&lt;/p>
&lt;pre>&lt;code>Get-DbaDbUser -SqlInstance $AzureSql -Database $Userdatabasename |Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>I have my user and it is of type External user. Lets see if I can connect&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Bingo 🙂&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>Because I dont like to see awesome people struggling with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/08/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Here is the same code using just the Az.KeyVault module&lt;/p>
&lt;pre>&lt;code>$appid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-guid&amp;quot;).SecretValueText
$Clientsecret = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;service-principal-secret&amp;quot;).SecretValue
$credential = New-Object System.Management.Automation.PSCredential ($appid,$Clientsecret)
$tenantid = (Get-AzKeyVaultSecret -vaultName &amp;quot;beard-key-vault&amp;quot; -name &amp;quot;Sewells-Tenant-Id&amp;quot;).SecretValueText
$AzureSQL = Connect-DbaInstance -SqlInstance $SqlInstance -Database $databasename -SqlCredential $credential -Tenant $tenantid -TrustServerCertificate
&lt;/code>&lt;/pre></description></item><item><title>Notifying a Teams Channel of a SQL Agent Job result</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</link><pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/notifying-a-teams-channel-of-a-sql-agent-job-result/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-18.png" alt="Featured image of post Notifying a Teams Channel of a SQL Agent Job result" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>yesterdays post about creating an overview of SQL Agent Job Results and sending it to a Teams channel&lt;/a>, I was given another challenge&lt;/p>
&lt;blockquote>
&lt;p>Can you write a job step that I can add to SQL Agent jobs that can send the result of that job to a Teams Channel&lt;/p>
&lt;p>A person with a need&lt;/p>
&lt;/blockquote>
&lt;p>The use case was for some migration projects that had steps that were scheduled via SQL Agent Jobs and instead of the DBA having to estimate when they would finish and keep checking so that they could let the next team know that it was time for their part to start, they wanted it to notify a Teams channel. This turned out especially useful as the job finished earlier than expected at 3am and the off-shore team could begin their work immediately.&lt;/p>
&lt;h2 id="using-sql-agent-job-tokens-with-powershell">Using SQL Agent Job tokens with PowerShell&lt;/h2>
&lt;p>You can use &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/ssms/agent/use-tokens-in-job-steps?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>SQL Agent job tokens in Job step commands to reference the existing instance or job&lt;/a> but I did not know if you could use that with PowerShell until I read &lt;a class="link" href="https://littlekendra.com/2009/12/02/sql-2008-agent-jobs-tokens-work-in-powershell/" target="_blank" rel="noopener"
>Kendra Little’s blog post from 2009&lt;/a>.&lt;/p>
&lt;p>Thank you Kendra&lt;/p>
&lt;h2 id="nothing-is-ever-as-easy-as-you-think">Nothing is ever as easy as you think&lt;/h2>
&lt;p>So I thought, this is awesome, I can create a function and pass in the Instance and the JobId and all will be golden.&lt;/p>
&lt;p>Nope&lt;/p>
&lt;h2 id="job_id--jobid">job_id &amp;lt;&amp;gt; $(JobID)&lt;/h2>
&lt;p>If we look in the sysjobs table at the Agent Job that we want to notify Teams about the result.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>We can see that the job_id is&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>If we look at the JobId property with PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-15.png?resize=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>We get&lt;/p>
&lt;pre>&lt;code>dc5937c3-766f-47b7-a5a5-48365708659a
&lt;/code>&lt;/pre>
&lt;p>Awesome, they are the same&lt;/p>
&lt;p>But&lt;/p>
&lt;p>If we look at the value of the $(JobID) SQL Agent Job Token,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>we get&lt;/p>
&lt;pre>&lt;code>C33759DC6F76B747A5A548365708659A
&lt;/code>&lt;/pre>
&lt;p>which makes matching it to the JobId tricky&lt;/p>
&lt;p>I tried all sorts of ways of casting and converting this value in SQL and PowerShell and in the end I just decided to manually convert the value&lt;/p>
&lt;pre>&lt;code> $CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
&lt;/code>&lt;/pre>
&lt;h2 id="send-the-information-to-teams">Send the information to Teams&lt;/h2>
&lt;p>Following the &lt;a class="link" href="https://blog.robsewell.com/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/" target="_blank" rel="noopener"
>same pattern as yesterdays post&lt;/a>, I created a function to send a message, depending on the outcome of the job and post it to the Teams function.&lt;/p>
&lt;p>Again, I used Enter-PsSession to run the Teams notification from a machine that can send the message. (I have also included the code to do this without requiring that below so that you can send the message from the same machine that runs the job if required)&lt;/p>
&lt;p>This code below is saved on a UNC share or the SQL Server as SingleNotifyTeams.ps1&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$NotifyCommand = {
$parameters = @{
&amp;quot;URI&amp;quot; = $Using:webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $Using:TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre>
&lt;p>Then it can be called in a SQL Agent job step, again following the guidelines at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a>&lt;/p>
&lt;p>It is called slightly differently as you ned to pass in the SQL Agent tokens as parameters to the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-16.png"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>powershell.exe -File path to Notify-TeamsSQLAgentJob.ps1 -SQLInstance $(ESCAPE_SQUOTE(SRVR)) -JobID $(ESCAPE_NONE(JOBID))
&lt;/code>&lt;/pre>
&lt;h2 id="sql-agent-job-step-success-and-failure">SQL Agent Job Step Success and Failure&lt;/h2>
&lt;p>We need to take another step to ensure that this works as expected. We have to change the On Failure action for each job step to the “Go To Notify Teams” step&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-17.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="making-people-smile">Making people smile&lt;/h2>
&lt;p>You can also add images (make sure the usage rights allow) so that the success notification can look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>and the failure looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Happy Automating !&lt;/p>
&lt;p>Here is the code that does not require remoting to another server to send the message&lt;/p>
&lt;pre>&lt;code>Param(
$SqlInstance,
$JobID
)
$webhookurl = &amp;quot;https://outlook.office.com/webhook/5a8057cd-5e1a-4c84-9227-74a309f1c738@b122247e-1ebf-4b52-b309-c2aa7436fc6b/IncomingWebhook/affb85f05804438eb7ffb57665879248/f32fc7e6-a998-4670-8b33-635876559b80&amp;quot;
function Notify-TeamsSQlAgentJob {
Param(
$SQLInstance,
$JobID,
$webhookurl
)
$SQLInstance = $SQLInstance
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$CharArray = $JobID.ToCharArray()
$JobGUID = $CharArray[8] + $CharArray[9] + $CharArray[6] + $CharArray[7] + $CharArray[4] + $CharArray[5] + $CharArray[2] + $CharArray[3] + '-' + $CharArray[12] + $CharArray[13] + $CharArray[10] + $CharArray[11] + '-' + $CharArray[16] + $CharArray[17] + $CharArray[14] + $CharArray[15] + '-' + $CharArray[18] + $CharArray[19] + $CharArray[20] + $CharArray[21] + '-' + $CharArray[22] + $CharArray[23] + $CharArray[24] + $CharArray[25] + $CharArray[26] + $CharArray[27] + $CharArray[28] + $CharArray[29] + $CharArray[30] + $CharArray[31] + $CharArray[32] + $CharArray[33]
$Job = Get-DbaAgentJob -SQlInstance $SQLInstance | Where jobid -eq $JobGuiD
$JobName = $Job.Name
$Jobsteps = Get-DbaAgentJobStep -SQlInstance $SQLInstance -Job $JobName
$JobStepNames = $Jobsteps.Name -join ' , '
$JobStartDate = $job.JobSteps[0].LastRunDate
$JobStatus = $job.LastRunOutcome
$lastjobstepid = $jobsteps[-1].id
$Jobstepsmsg = $Jobsteps | Out-String
$JobStepStatus = ($Jobsteps | Where-Object {$_.id -ne $lastjobstepid -and $_.LastRunDate -ge $JobStartDate} ).ForEach{
&amp;quot; $($_.Name) - $($_.LastRunDate) **$($_.LastRunOutCome)**
&amp;quot;
}
$Text = @&amp;quot;
# **$SqlInstance**
## **$JobName**
$jobstepMsg
Started at $JobStartDate
- The individual Job Steps status was
$JobStepStatus
&amp;quot;@
if (( $jobsteps | Where id -ne $lastjobstepid).LastRunOutcome -contains 'Failed') {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;There was a Job Failure&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Failed&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Work to do - Please investigate the following job by following the steps in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://fit93a.db.files.1drv.com/y4mTOWSzX1AfIWx-VdUgY_Qp3wqebttT7FWSvtKK-zAbpTJuU560Qccv1_Z_Oxd4T4zUtd5oVZGJeS17fkgbl1dXUmvbldnGcoThL-bnQYxrTrMkrJS1Wz2ZRV5RVtZS9f4GleZQOMuWXP1HMYSjYxa6w09nEyGg1masI-wKIZfdnEF6L8r83Q9BB7yIjlp6OXEmccZt99gpb4Qti9sIFNxpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
else {
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;The Job Succeeded&amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;All is well - Please continue with the next step in the plan at LINKTOPLAN&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://6f0bzw.db.files.1drv.com/y4mvnTDG9bCgNWTZ-2_DFl4-ZsUwpD9QIHUArsGF66H69zBO8a--FlflXiF7lrL2H3vgya0ogXIDx59hn62wo2tt3HWMbqnnCSp8yPmM1IFNwZMzgvSZBEs_n9B0v4h4M5PfOY45GVSjeFh8md140gWHaFpZoL4Vwh-fD7Zi3djU_r0PduZwNBVGOcoB6SMJ1m4NmMmemWr2lzBn57LutDkxw&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$msg = 'ServerName = ' + $SQLInstance + 'JobId = ' + $JobID
Write-Host $msg
Notify-TeamsSQLAgentJob -SQlInstance $SqlInstance -JobID $JobID -webhookurl $webhookurl
&lt;/code>&lt;/pre></description></item><item><title>Sending a SQL Agent Job results overview to a Microsoft Teams Channel</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</link><pubDate>Tue, 28 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sending-a-sql-agent-job-results-overview-to-a-microsoft-teams-channel/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-11.png" alt="Featured image of post Sending a SQL Agent Job results overview to a Microsoft Teams Channel" />&lt;p>Microsoft Teams is fantastic for collaboration. It enables groups of people, teams if you like to be able to communicate, collaborate on documents, hold meetings and much much more.&lt;/p>
&lt;h2 id="sql-agent-job-overview">SQL Agent Job Overview&lt;/h2>
&lt;p>Using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> we can create a simple script to gather the results of Agent Jobs form a list of instances. Maybe it would be good to be able to get the job runs results every 12 hours so that at 6am in the morning the early-bird DBA can quickly identify if there are any failures that need immediate action and at 6pm , the team can check that everything was ok before they clock off.&lt;/p>
&lt;p>Here is an example of such a script&lt;/p>
&lt;pre>&lt;code>$SqlInstances = (Get-Vm -ComputerName BEARDNUC,BEARDNUC2).Where{$_.State -eq 'Running' -and $_.Name -like '*SQL*'}.Name
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and an example of running it.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-2.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-teams-channel">Create a Teams Channel&lt;/h2>
&lt;p>If you have permissions, you can create a new Teams channel by clicking on the 3 ellipses and add channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Then fill in the blanks&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-webhook-connector-for-the-channel">Create a Webhook Connector for the channel&lt;/h2>
&lt;p>Next, you need to have a connector for the channel, click on the 3 ellipses for the channel and click on connectors&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Then you can choose the Incoming Webhook connector and click configure&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>Give the connector a name and upload an image if you wish and click create&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The resulting screen will give you a URL that you can copy. If you need to find it again, then use the 3 ellipses again, click connectors and look at configured. You can then choose the webhook that you have created and click manage and you will find the URL.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-8.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="send-to-teams-using-powershell">Send to Teams using PowerShell&lt;/h2>
&lt;p>Now you can send a message to that Teams channel using PowerShell. You will need to add the webhook URL from your Teams connector&lt;/p>
&lt;pre>&lt;code>[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = &amp;quot;&amp;quot;
$Text = @&amp;quot;
# Here is a Title
and a message
Image is from
https://www.flickr.com/photos/157270154@N05/38494483572
Photo by CreditDebitPro
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;This is my summary&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Something Important &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;I have something to say&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $text
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>The code above will send a message that looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-9.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="running-as-a-sql-agent-job">Running as a SQL Agent Job&lt;/h2>
&lt;p>Now we can run this code as a SQL Agent Job and schedule it. Now, you may not be able to run that code on your SQL Server. It cannot connect to the internet, so how can we contact the Teams webhook?&lt;/p>
&lt;p>There are probably a number of ways to do this but the solution that I took, was to allow a proxy account the ability to use PSRemoting and run the part of the script that connects to Teams on a different machine, that does have connectivity.&lt;/p>
&lt;p>The script I used was as follows. You will need to add in the SQL Instances or better still dynamically gather them from your source of truth. You will need the webhook URL and the name of the server that can connect to Teams&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
$NotifyServer = 'BeardNUC2'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
$NotifyCommand = {
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$webhookurl = $Using:TeamsWebhook
$allJobsMessage = $Using:AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($Using:startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Failures &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($Using:startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
}
$Session = New-PSSession -ComputerName $NotifyServer
Invoke-Command -Session $Session -ScriptBlock $NotifyCommand
&lt;/code>&lt;/pre>
&lt;p>Then, follow the steps at &lt;a class="link" href="http://dbatools.io/agent" target="_blank" rel="noopener"
>dbatools.io/agent&lt;/a> to create an agent job to run the script above on an instance with the dbatools module available to the SQL Service account. Use or create a proxy with permissions on the notify server and create an Agent Job.&lt;/p>
&lt;pre>&lt;code>USE [msdb]
GO
/****** Object: Job [I am a Job that notifies Teams] Script Date: 27/07/2020 20:27:27 ******/
BEGIN TRANSACTION
DECLARE @ReturnCode INT
SELECT @ReturnCode = 0
/****** Object: JobCategory [[Uncategorized (Local)]] Script Date: 27/07/2020 20:27:28 ******/
IF NOT EXISTS (SELECT name FROM msdb.dbo.syscategories WHERE name=N'[Uncategorized (Local)]' AND category_class=1)
BEGIN
EXEC @ReturnCode = msdb.dbo.sp_add_category @class=N'JOB', @type=N'LOCAL', @name=N'[Uncategorized (Local)]'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
END
DECLARE @jobId BINARY(16)
EXEC @ReturnCode = msdb.dbo.sp_add_job @job_name=N'12 Hour Teams Notify',
@enabled=1,
@notify_level_eventlog=0,
@notify_level_email=0,
@notify_level_netsend=0,
@notify_level_page=0,
@delete_level=0,
@description=N'This job will notify Teams every 12 hours',
@category_name=N'[Uncategorized (Local)]',
@owner_login_name=N'THEBEARD\SQL_SVC', @job_id = @jobId OUTPUT
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
/****** Object: Step [Notify Teams] Script Date: 27/07/2020 20:27:28 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N'Notify Teams',
@step_id=1,
@cmdexec_success_code=0,
@on_success_action=1,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N'CmdExec',
@command=N'powershell.exe -File C:\temp\AgentJobs\NotifyTeams.ps1',
@flags=0,
@proxy_name=N'TheBeardIsMighty'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_update_job @job_id = @jobId, @start_step_id = 1
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_add_jobserver @job_id = @jobId, @server_name = N'(local)'
IF (@@ERROR &amp;lt;&amp;gt; 0 OR @ReturnCode &amp;lt;&amp;gt; 0) GOTO QuitWithRollback
COMMIT TRANSACTION
GOTO EndSave
QuitWithRollback:
IF (@@TRANCOUNT &amp;gt; 0) ROLLBACK TRANSACTION
EndSave:
GO
&lt;/code>&lt;/pre>
&lt;p>When the job runs&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>The results are posted to the Teams Channel&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>If you can run the Agent Job on a machine that can connect to Teams and your SQL Instances then you can remove the need to use a remote session by using this code&lt;/p>
&lt;pre>&lt;code>$SQLInstances = 'SQL2005Ser2003','SQL2008Ser12R2','SQL2014Ser12R2','SQL2016N1','SQL2016N2','SQL2016N3','SQL2017N5','SQL2019N20','SQL2019N21','SQL2019N22','SQL2019N5'
$startdate = (Get-Date).AddHours(-12)
$webhookurl = &amp;quot;&amp;quot;
# Import-Module 'C:\Program Files\WindowsPowerShell\Modules\dbatools\1.0.107\dbatools.psd1'
$AllJobs = &amp;quot;
SqlInstance...|...Total...|...Successful...|...FailedJobs...|...FailedSteps...|...Canceled...
---------------------------------------------
&amp;quot;
foreach ($Instance in $SQLInstances) {
Write-Host &amp;quot;Connecting to $instance&amp;quot;
try{
$smo = Connect-DbaInstance $Instance -ErrorAction Stop
Write-Host &amp;quot;Connected successfully to $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed to connect to $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
Write-Host &amp;quot;Getting Agent Jobs on $instance&amp;quot;
try {
$AgentJobs = Get-DbaAgentJobHistory -SqlInstance $smo -EnableException -StartDate $startdate
Write-Host &amp;quot;Successfully got Agent Jobs on $instance&amp;quot;
}
catch {
Write-Host &amp;quot;Failed to get agent jobs on $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
$jobs = $agentJobs
$NumberOfJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}).Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfFailedJobSteps = ($Jobs |Where-Object {$PSitem.StepId -ne 0}| Where-Object {$PSItem.Status -eq 'Failed'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfSuccessfulJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Succeeded'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
$NumberOfCanceledJobs = ($Jobs |Where-Object {$PSitem.StepId -eq 0} | Where-Object {$PSItem.Status -eq 'Canceled'}).StepName.Count.ToString(&amp;quot;00&amp;quot;)
Write-Host &amp;quot;SqlInstance $Instance - Number of Jobs $NumberOfJobs - Number of Successful Jobs $NumberOfSuccessfulJobs - Number of Failed Jobs $NumberOfFailedJobs&amp;quot;
$AllJobs = $AllJobs + &amp;quot;$($Instance.Split('.')[0])..........&amp;lt;b&amp;gt;$NumberOfJobs&amp;lt;/b&amp;gt;................&amp;lt;b&amp;gt;$NumberOfSuccessfulJobs&amp;lt;/b&amp;gt;.........................&amp;lt;b&amp;gt;$NumberOfFailedJobs&amp;lt;/b&amp;gt;............................&amp;lt;b&amp;gt;$NumberOfFailedJobSteps&amp;lt;/b&amp;gt;..............................&amp;lt;b&amp;gt;$NumberOfCanceledJobs&amp;lt;/b&amp;gt;........
&amp;quot;
try{
$smo.ConnectionContext.Disconnect()
Write-Host &amp;quot;Disconnecting $instance&amp;quot;
}
catch{
Write-Host &amp;quot;Failed disconnect from $Instance&amp;quot;
$errorMessage = $_ | Out-String
Write-Host $errorMessage
Continue
}
}
Write-Host &amp;quot;Since $startdate&amp;quot;
Write-Host &amp;quot;$AllJobs&amp;quot;
[System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true }
[Net.ServicePointManager]::SecurityProtocol = [Net.SecurityProtocolType]::Tls12
$allJobsMessage = $AllJobs
$Text = @&amp;quot;
# Overview of SQL Agent Jobs in Production since $($startdate)
$allJobsMessage
&amp;quot;@
$JSONBody = [PSCustomObject][Ordered]@{
&amp;quot;@type&amp;quot; = &amp;quot;MessageCard&amp;quot;
&amp;quot;@context&amp;quot; = &amp;quot;http://schema.org/extensions&amp;quot;
&amp;quot;summary&amp;quot; = &amp;quot;Overview for the last 12 hours&amp;quot;
&amp;quot;themeColor&amp;quot; = '0078D7'
&amp;quot;sections&amp;quot; = @(
@{
&amp;quot;activityTitle&amp;quot; = &amp;quot;Job Results &amp;quot;
&amp;quot;activitySubtitle&amp;quot; = &amp;quot;Overview for the last 12 hours since $($startdate)&amp;quot;
&amp;quot;activityImage&amp;quot; = &amp;quot;https://live.staticflickr.com/4568/38494483572_a98d623854_k.jpg&amp;quot;
&amp;quot;text&amp;quot; = $allJobsMessage
&amp;quot;markdown&amp;quot; = $true
}
)
}
$TeamMessageBody = ConvertTo-Json $JSONBody -Depth 100
$parameters = @{
&amp;quot;URI&amp;quot; = $webhookurl
&amp;quot;Method&amp;quot; = 'POST'
&amp;quot;Body&amp;quot; = $TeamMessageBody
&amp;quot;ContentType&amp;quot; = 'application/json'
}
Invoke-RestMethod @parameters
&lt;/code>&lt;/pre>
&lt;p>Happy automating!&lt;/p></description></item><item><title>Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</link><pubDate>Mon, 20 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-secret-management-module-to-run-ssms-vs-code-and-azure-data-studio-as-another-user/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/runas.png" alt="Featured image of post Using Secret Management module to run SSMS, VS Code and Azure Data Studio as another user" />&lt;p>Following on from &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/" target="_blank" rel="noopener"
>my last post about the Secret Management module&lt;/a>. I was asked another question.&lt;/p>
&lt;blockquote>
&lt;p>Can I use this to run applications as my admin account?&lt;/p>
&lt;p>A user with a beard&lt;/p>
&lt;/blockquote>
&lt;p>It is good practice to not log into your work station with an account with admin privileges. In many shops, you will need to open applications that can do administration tasks with another set of account credentials.&lt;/p>
&lt;p>Unfortunately, people being people, they will often store their admin account credentials in a less than ideal manner (OneNote, Notepad ++ etc) to make it easier for them, so that when they right click and run as a different user, they can copy and paste the password.&lt;/p>
&lt;h2 id="use-the-secret-management-module">Use the Secret Management module&lt;/h2>
&lt;p>Again, I decided to use a notebook to show this as it is a fantastic way to share code and results and because it means that anyone can try it out.&lt;/p>
&lt;p>The notebook may not render on a mobile device.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Using the notebook, I can quickly store my admin password safely and open and run the applications using the credential&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/runas.png"
loading="lazy"
>&lt;/p></description></item><item><title>Good Bye Import-CliXML – Use the Secrets Management module for your labs and demos</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</link><pubDate>Sat, 18 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/good-bye-import-clixml-use-the-secrets-management-module-for-your-labs-and-demos/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/07/image-1.png" alt="Featured image of post Good Bye Import-CliXML – Use the Secrets Management module for your labs and demos" />&lt;p>Don’t want to read all this? There are two dotnet interactive notebooks here with the relevant information for you to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;h2 id="jaap-is-awesome">Jaap is awesome&lt;/h2>
&lt;p>&lt;img src="https://pbs.twimg.com/media/DBbP9lHXYAAopb3?format=jpg&amp;amp;name=4096x4096"
loading="lazy"
>&lt;/p>
&lt;p>I have to start here. For the longest time, whenever anyone has asked me how I store my credentials for use in my demos and labs I have always referred them to Jaap Brassers &lt;a class="link" href="https://twitter.com/Jaap_Brasser" target="_blank" rel="noopener"
>t&lt;/a> blog post&lt;/p>
&lt;p>&lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/&lt;/a>&lt;/p>
&lt;h2 id="joel-is-also-awesome">Joel is also awesome!&lt;/h2>
&lt;p>When people wanted a method of storing credentials that didn&amp;rsquo;t involve files on disk I would suggest Joel Bennett’s &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>t&lt;/a> module BetterCredentials which uses the Windows Credential Manager&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/BetterCredentials/4.5" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/BetterCredentials/4.5&lt;/a>&lt;/p>
&lt;h2 id="microsoft-also-awesome">Microsoft? Also awesome!&lt;/h2>
&lt;p>In February, Microsoft released the SecretManagement module for preview.&lt;/p>
&lt;p>&lt;a class="link" href="https://devblogs.microsoft.com/powershell/secrets-management-development-release?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://devblogs.microsoft.com/powershell/secrets-management-development-release/&lt;/a>&lt;/p>
&lt;p>Sydney &lt;a class="link" href="https://twitter.com/sydneysmithreal" target="_blank" rel="noopener"
>t&lt;/a> gave a presentation at the European PowerShell Conference which you can watch on Youtube.&lt;/p>
&lt;h2 id="good-bye-import-clixml">Good Bye Import-CliXML&lt;/h2>
&lt;p>So now I say, it is time to stop using Import-Clixml for storing secrets and use the Microsoft.PowerShell.SecretsManagement module instead for storing your secrets.&lt;/p>
&lt;h2 id="notebooks-are-as-good-as-blog-posts">Notebooks are as good as blog posts&lt;/h2>
&lt;p>I love notebooks and to show some people who had asked about storing secrets, I have created some. So, because I am efficient lazy I have embedded them here for you to see. You can find them in my Jupyter Notebook repository&lt;/p>
&lt;p>&lt;a class="link" href="https://beard.media/dotnetnotebooks" target="_blank" rel="noopener"
>https://beard.media/dotnetnotebooks&lt;/a>&lt;/p>
&lt;p>in the Secrets folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image-1.png?resize=630%2C349&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-and-using-the-secrets-management-module">Installing and using the Secrets Management Module&lt;/h2>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="using-the-secret-management-module-in-your-scripts">Using the Secret Management Module in your scripts&lt;/h2>
&lt;p>Here is a simple example of using the module to provide the credential for a docker container and then to dbatools to query the container&lt;/p>
&lt;p>These notebooks may not display on a mobile device unfortunately&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>Surprised and Honoured and Proud</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/surprised-and-honoured-and-proud/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/surprised-and-honoured-and-proud/</guid><description>&lt;p>I have always been extremely proud to be a Cloud and Datacenter Management MVP, and lucky enough to be involved with both the PowerShell community as well as the Data Platform community.&lt;/p>
&lt;p>Today, July 1st is the date that many MVPs receive their renewal email to let them know that they have been awarded for another year. There is a lot of F5’ing and frequent checking of emails and “Have you heard yet?” DMs going around.&lt;/p>
&lt;p>When I received the news, I was using Azure DevOps to run PowerShell and Terraform to build an Azure SQL Elastic Pool (yes, I will write a blog post about it!). I love technology and within my work, like many people, I work across many different disciplines. Azure, Azure DevOps, SQL Server and Microsoft Data Platform products are the main focus of my time.&lt;/p>
&lt;p>I didn’t notice the significance of the information.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/image.png?resize=589%2C213&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I was pleased as punch to be renewed again, proud that what I do is recognised by Microsoft, honoured to spend another year as an MVP. Then my friends pointed out the big news that I had missed.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/07/pixpoetry-JD1RqKlqAi0-unsplash.jpg?fit=630%2C423&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/@blackpoetry?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>pixpoetry&lt;/a> on &lt;a class="link" href="https://unsplash.com/s/photos/surprise?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>There are two award categories.&lt;/p>
&lt;p>I have been awarded for both Cloud and Datacenter Management and Data Platform.&lt;/p>
&lt;p>I am beyond words.&lt;/p>
&lt;p>Proud, Surprised and Honoured.&lt;/p>
&lt;p>Thank you to all of the people who help and support me. You help more than you will ever know.&lt;/p>
&lt;p>I am going to go and prop my jaw shut!&lt;/p></description></item><item><title>Running Jupyter Notebooks as Agent Jobs</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-jupyter-notebooks-as-agent-jobs/</link><pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-jupyter-notebooks-as-agent-jobs/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/03/image-22.png" alt="Featured image of post Running Jupyter Notebooks as Agent Jobs" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a great tool for connecting with your data platform whether it is in Azure or on your hardware. &lt;a class="link" href="https://blog.robsewell.com/?s=notebooks" target="_blank" rel="noopener"
>Jupyter Notebooks&lt;/a> are fantastic, you can have words, pictures, code and code results all saved in one document.&lt;/p>
&lt;p>I have created a repository in my GitHub &lt;a class="link" href="https://beard.media/Notebooks" target="_blank" rel="noopener"
>https://beard.media/Notebooks&lt;/a> where I have stored a number of Jupyter notebooks both for Azure Data Studio and the &lt;a class="link" href="https://blog.robsewell.com/new-net-notebooks-are-here-powershell-7-notebooks-are-here/" target="_blank" rel="noopener"
>new .NET interactive&lt;/a> notebooks.&lt;/p>
&lt;p>Another thing that you can do with notebooks is run them as Agent Jobs and save the results of the run.&lt;/p>
&lt;h3 id="notebooks-running-t-sql">Notebooks running T-SQL&lt;/h3>
&lt;p>This works easily for T-SQL notebooks. I am going to &lt;a class="link" href="https://github.com/SQLDBAWithABeard/JupyterNotebooks/blob/master/notebooks/NotDotNet/Audit/AUDIT%20-%20T-SQL%20Gather%20Permissions%20Notebook%20Template.ipynb" target="_blank" rel="noopener"
>use this one&lt;/a> that I created that uses T-SQL to gather permissions using old code that was in a share somewhere. We can run the notebook and get the permissions and save the notebook and the results will be available for all time (unless you delete the notebook!)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image.png?fit=630%2C327&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="sql-agent-extension-in-azure-data-studio">SQL Agent Extension in Azure Data Studio&lt;/h3>
&lt;p>In Azure Data Studio, if you press CTRL + SHIFT + X it will open the Extensions tab&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-1.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-1.png?resize=188%2C300&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can add extra functionality to Azure Data Studio. Search in the top bar for Agent and press the install button to install the extension. You can connect to and instance in the connections tab (CTRL + SHIFT + D) and right click on it and click Manage. This will open up the server dashboard (why isn’t it instance dashboard?)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/7e393013-e088-4dfb-93e4-5e4961931999" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-2.png?fit=630%2C297&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and you will also have the SQL Agent dashboard available&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-3.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-3.png?fit=630%2C353&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Its pretty neat, it has green and red bars against the jobs showing success or failure and the larger the bar the longer the run time. On the left you will see a book. Click that&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-4.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-4.png?fit=630%2C295&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="notebooks-in-agent-jobs">Notebooks in Agent Jobs&lt;/h3>
&lt;p>You can create an Agent Job to run a notebook. As a notebook is just a json file, it can be stored in a database table. This interface will create two tables one to store the templates and one for the results. Click New Notebook Job&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-5.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-5.png?fit=630%2C989&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then navigate to the notebook and select it.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/d312799d-0cf7-4e9f-86ac-11c7f6e4977b" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-6.png?fit=630%2C379&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Choose a database for the storage of the template and the results and one for the execution context.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/a70ffec6-6ed9-43f5-8b4b-b3eed86abecd" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-7.png?fit=630%2C991&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The name of the job will be the file name of the notebook. You can change this but there is a bug where you can only enter one character at a time in the name before it changes focus so beware!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/03d25ab1-ccd9-4c8b-a880-1f6bf1641b42" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-8.png?fit=630%2C157&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Once the job is created, you will see two tables in the storage database notebooks.nb_materialized and notebooks.nb_template&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-9.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-9.png?fit=630%2C790&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The materialised table is empty right now&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-10.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-10.png?fit=630%2C405&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>but the template table has a row for the job which includes the notebook in json format.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/6b019c65-cd07-4295-9b8e-609456829574" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-11.png?fit=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If you click on the jobs in the Notebook Jobs window in the SQL Agent extension, you can see more information about the job run&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/5f93224f-b2a6-4c9c-9e71-a5f3668dcab9" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-12.png?fit=630%2C321&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can also run the job from here. It doesn’t have to be run from here, it is just a normal agent job which you can run or schedule in any normal manner. Running it from here gives a pop-up&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-13.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-13.png?fit=630%2C106&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You have to refresh to see when the job is finished and it will be red if the job failed, green if it succeeded or orange if some cells failed like this!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-14.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-14.png?fit=630%2C270&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>But this is the good bit. Clicking on that icon will open the notebook that was created by that agent job run. Lets see what we get&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/f5376e7e-4150-471c-b018-f7ae440427b1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-15.png?fit=630%2C339&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see that we have the results of the queries that we wrote in the notebook alongside the documentation (or maybe explanation of the expected results)&lt;br>
If we scroll down a little (and change the theme colour so that you can see the error)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-18.png?fit=630%2C135&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Msg , Level , State , Line
Duplicate column names are not permitted in SQL PowerShell. To repeat a column, use a column alias for the duplicate column in the format Column_Name AS New_Name.&lt;/p>
&lt;p>We have got an error from running the code via SQL PowerShell which is how the job is run. This error is also inserted into the notebooks.nb_template table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/391f8b82-204d-4331-9084-2eefa33a5bc8" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-21.png?fit=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I edited the notebook locally to remove that block of code&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/51b34091-962f-4e8b-bc3c-b4b33866ef93" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-19.png?fit=630%2C283&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then edited the job and selected the updated notebook&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/063630fc-98a5-4c82-b6ad-e814bc33324e" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-20.png?fit=630%2C338&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and re-ran the job and got a green tick.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/5ad81496-c6c8-4ddf-8384-d0087f71dd38" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-22.png?fit=630%2C279&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now I can open the notebook from the latest run, but notice that from this view I can also open the previous notebook.&lt;/p>
&lt;p>If I look in the nb_template table, the last_run_notebook_error has cleared&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2020/03/image-23.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-23.png?fit=630%2C450&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and if I look in the nb materialized table I can see two rows, one for each job run. The error from the first run is also stored in this table. The notebook column has the json for the notebook if you wish to access it in a different manner.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/25685dd2-78d6-40cd-8dc8-18e0149feb86" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/03/image-24.png?fit=630%2C267&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Tomorrow, we will see what the job steps look like and how to make this run on an instance which does not and cannot have the required PowerShell.&lt;/p>
&lt;p>Spoiler Alert – May contain dbatools 🙂&lt;/p></description></item><item><title>.NET PowerShell Notebooks – Using Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/.net-powershell-notebooks-using-pester/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/.net-powershell-notebooks-using-pester/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-16.png" alt="Featured image of post .NET PowerShell Notebooks – Using Pester" />&lt;p>&lt;a class="link" href="http://localhost:4001/blog/jupyter%20notebooks/azure%20data%20studio/powershell/pwsh/dbatools/dbachecks/new-net-notebooks-are-here-powershell-7-notebooks-are-here/" target="_blank" rel="noopener"
>My last post&lt;/a> had a lot of information about the new .NET PowerShell notebooks including installation instructions.&lt;/p>
&lt;p>.NET Notebooks are Jupyter Notebooks that use .NET core to enable C#, F# and PowerShell kernels.&lt;/p>
&lt;h2 id="use-cases">Use Cases&lt;/h2>
&lt;p>One of the main benefits that I see for Jupyter Notebooks for Ops folk is that the results of the query are saved with the notebook. This makes them fantastic for Incident resolution.&lt;/p>
&lt;p>If you have an incident at 3am and you know that you will need that information in the wash up meeting the next day instead of copying and pasting results into a OneNote document or a text file, you can simply run the queries in a notebook and save it.&lt;/p>
&lt;p>In the meeting, you can simply open the notebook and the results will be available for everyone to see.&lt;/p>
&lt;p>Even better, if you have a template notebook for those scenarios and you can then compare them to previous occurrences.&lt;/p>
&lt;h2 id="using-pester">Using Pester&lt;/h2>
&lt;p>Using Pester to validate that an environment is as you expect it is a good resource for incident resolution, potentially enabling you to quickly establish an area to concentrate on for the issue. However, if you try to run Pester in a .NET Notebook you will receive an error&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code> | ^ The term 'Get-CimInstance' is not recognized as the name of a
| cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included,
| verify that the path is correct and try again.
&lt;/code>&lt;/pre>
&lt;p>Import-Module: The module to process &amp;lsquo;Pester.psm1&amp;rsquo;, listed in field &amp;lsquo;ModuleToProcess/RootModule&amp;rsquo; of module manifest &amp;lsquo;C:\Users\mrrob\Documents\PowerShell\Modules\Pester\4.9.0\Pester.psd1&amp;rsquo; was not processed because no valid module was found in any module directory. &lt;!-- raw HTML omitted -->
Thats odd, why is it failing there? Dongbo Wang from the PowerShell team explains &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>in the issue that I raised&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Yes, it was the CimCmdlets module from the system32 module path that got imported (via the &lt;code>WinCompat&lt;/code> feature added in PS7). This is because currently the PS kernel don’t ship all the built-in modules along with it …&lt;br>
The built-in modules are not published anywhere and are platform specific, it’s hard for an application that host powershell to ship them along. We have the issue &lt;a class="link" href="https://github.com/PowerShell/PowerShell/issues/11783" target="_blank" rel="noopener"
>PowerShell/PowerShell#11783&lt;/a> to track this work.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/DotNet%20Notebook/01-PesterWontRun.ipynb" target="_blank" rel="noopener"
>You can see all of this including all the results in this notebook that I have created and shared on GitHub and also below as a gist to embed in this blog post&lt;/a>&lt;/p>
&lt;h2 id="sharing-code-and-results-">Sharing Code AND Results 🙂&lt;/h2>
&lt;p>Notebooks – A brilliant way of sharing what you did and the results that you got enabling others to follow along. You can do this with this Notebook. Download it and open it in your Jupyter Lab and you will be able to run it and see all of the errors and the fix on your machine.&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>Use Jupyter Notebooks to Help People on StackOverFlow</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-jupyter-notebooks-to-help-people-on-stackoverflow/</link><pubDate>Sat, 22 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-jupyter-notebooks-to-help-people-on-stackoverflow/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-16.png" alt="Featured image of post Use Jupyter Notebooks to Help People on StackOverFlow" />&lt;p>I am sat in the PowerShell Saturday in Hamburg. You can see me on the right of this picture writing &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/pester/net-powershell-notebooks-using-pester/" target="_blank" rel="noopener"
>my previous blog post!&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/JanDamaschke?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@JanDamaschke&lt;/a> spricht über Asynchrones Logging in &lt;a class="link" href="https://twitter.com/hashtag/powershell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#powershell&lt;/a> mit Classes und Runspaces &lt;img src="https://pbs.twimg.com/media/ERYdg-6XUAAbwBk?format=jpg"
loading="lazy"
> (&lt;a class="link" href="https://twitter.com/hhpsug?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>https://twitter.com/hhpsug?ref_src=twsrc%5Etfw&lt;/a>) &lt;a class="link" href="https://twitter.com/hashtag/pssaturday?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pssaturday&lt;/a>&lt;/p>
&lt;p>— Christoph Burmeister (@chrburmeister) &lt;a class="link" href="https://twitter.com/chrburmeister/status/1231204011270909954?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 22, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I was talking with my friend Mathias Jessen &lt;a class="link" href="https://twitter.com/IISResetMe" target="_blank" rel="noopener"
>@IISResetMe on Twitter&lt;/a> about notebooks and he said that another great use case was to use them on Stack OverFlow&lt;/p>
&lt;p>Now Mathias is an active answerer on Stack OverFlow&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>and he puts a lot of effort into writing his answers, formatting them, including code and results. Basically exactly the same as a Notebook. However, with a Notebook, you can enable people to &lt;strong>&lt;em>run&lt;/em>&lt;/strong> the code as well on their own machines.&lt;/p>
&lt;p>Mathias says he will use notebooks to help people when he answers their PowerShell questions on Stack OverFlow. If you are a Stack OverFlow Answerer then you can too.&lt;/p></description></item><item><title>New .NET Notebooks are here – PowerShell 7 notebooks are here.</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</link><pubDate>Fri, 07 Feb 2020 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/new-.net-notebooks-are-here-powershell-7-notebooks-are-here./</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2020/02/image-13.png" alt="Featured image of post New .NET Notebooks are here – PowerShell 7 notebooks are here." />&lt;p>Data Science folk used Notebooks for documentation and to show re-runnable research. Azure Data Studio included this notebook functionality and &lt;a class="link" href="https://blog.robsewell.com/dbatools/dbachecks/blog/jupyter%20notebooks/azure%20data%20studio/powershell/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>added SQL&lt;/a> kernel where &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbachecks/dbatools/powershell-in-sql-notebooks-in-azure-data-studio//" target="_blank" rel="noopener"
>with a little bit of faffing you could run PowerShell&lt;/a> and then a &lt;a class="link" href="https://blog.robsewell.com/blog/jupyter%20notebooks/azure%20data%20studio/powershell/dbatools/powershell-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>Python kernel that enabled PowerShell&lt;/a>. It seems that notebooks are so cool that everyone is creating them these days! I was browsing twitter when I saw this tweet.&lt;/p>
&lt;blockquote>
&lt;p>.NET Notebooks Preview 2 is here! Preview 2 includes 🎉&lt;a class="link" href="https://twitter.com/PowerShell_Team?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@PowerShell_Team&lt;/a>, &lt;a class="link" href="https://twitter.com/nteractio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@nteractio&lt;/a>, and a new tool. Check out our blog to learn more. Congratulations to &lt;a class="link" href="https://twitter.com/jonsequitur?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@jonsequitur&lt;/a> &lt;a class="link" href="https://twitter.com/colombod?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@colombod&lt;/a> and our entire team&lt;a class="link" href="https://t.co/WqNWQWR3Bo" target="_blank" rel="noopener"
>https://t.co/WqNWQWR3Bo&lt;/a>&lt;a class="link" href="https://twitter.com/dotnet?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@dotnet&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/jupyter?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#jupyter&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/PowerShell?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#PowerShell&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/interactiveprogramming?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#interactiveprogramming&lt;/a>.&lt;/p>
&lt;p>— Maria Naggaga (@LadyNaggaga) &lt;a class="link" href="https://twitter.com/LadyNaggaga/status/1225464258823163906?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="powershell-7-notebooks-">PowerShell 7 Notebooks 🙂&lt;/h2>
&lt;p>A notebook experience for PowerShell 7 that sounds amazing. This will enable a true cross-platform PowerShell Notebook experience which is lacking from the Python version as it uses Windows PowerShell on Windows and PowerShell Core on other OS’s&lt;/p>
&lt;p>The first thing I asked was – Will this come to Azure Data Studio. I got an immediate response from Sydney Smith PowerShell Program Manager saying it is on the roadmap&lt;/p>
&lt;blockquote>
&lt;p>Moving this kernel into ADS is on our roadmap! Right now our kernel uses hosted pwsh 7 but we would love to know if you have scenarios that don&amp;rsquo;t work with 7&lt;/p>
&lt;p>— Sydney Smith (@sydneysmithreal) &lt;a class="link" href="https://twitter.com/sydneysmithreal/status/1225488719567818752?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 6, 2020&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;h2 id="install-dependencies">Install dependencies&lt;/h2>
&lt;p>To be able to run the notebook, you need to install some dependencies. First install the .NET CORE SDK which you can download from &lt;a class="link" href="https://dotnet.microsoft.com/download?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://dotnet.microsoft.com/download&lt;/a> This needs admin permissions to install.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image.png?resize=620%2C418&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You also need a Python installation – You can use Anaconda, which you can download from here &lt;a class="link" href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener"
>https://www.anaconda.com/distribution/&lt;/a> This does not need admin to install&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-1.png?resize=531%2C232&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-2.png?fit=630%2C490&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-anaconda-to-windows-terminal">Add Anaconda to Windows Terminal&lt;/h2>
&lt;p>I have added the Anaconda prompt to Windows Terminal so that I have one entry point for all my CLIs. Open the settings file and add the code below. (It will also give you an icon and background.&lt;/p>
&lt;pre>&lt;code> {
// Make changes here to the Anaconda.exe profile
&amp;quot;guid&amp;quot;: &amp;quot;{0caa0dad-35be-5f56-a7ff-afceeeaa6101}&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;Anaconda&amp;quot;,
&amp;quot;commandline&amp;quot;: &amp;quot;cmd.exe /K C:\\Users\\mrrob\\Anaconda3\\Scripts\\activate.bat&amp;quot;,
&amp;quot;hidden&amp;quot;: false,
&amp;quot;backgroundImage&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;icon&amp;quot;: &amp;quot;C:\\Users\\mrrob\\Anaconda3\\Menu\\anaconda-navigator.ico&amp;quot;,
&amp;quot;backgroundImageAlignment&amp;quot;: &amp;quot;topRight&amp;quot;,
&amp;quot;backgroundImageStretchMode&amp;quot;: &amp;quot;uniform&amp;quot;,
&amp;quot;backgroundImageOpacity&amp;quot;: 0.1
}
&lt;/code>&lt;/pre>
&lt;p>and it appears in the drop down&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-3.png?resize=509%2C409&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>With Anaconda installed, check that that the kernel is available on your path. If like me you have Azure Data Studio installed, you will have additional kernels but the important one line here is&lt;/p>
&lt;p>&lt;code>python3 C:\Users\USERNAME\Anaconda3\share\jupyter\kernels\python3&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-4.png?resize=630%2C210&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>In Windows Terminal move to a PowerShell 7 prompt and install the dotnet interactive tool&lt;/p>
&lt;pre>&lt;code>dotnet tool install --global Microsoft.dotnet-interactive
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-5.png?resize=630%2C259&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can install the .NET kernel in your Anaconda prompt using this command&lt;/p>
&lt;pre>&lt;code>dotnet interactive jupyter install
&lt;/code>&lt;/pre>
&lt;h2 id="sometimes-new-things-have-errors">Sometimes new things have errors&lt;/h2>
&lt;p>I had an error when I tried this first time&lt;/p>
&lt;blockquote>
&lt;p>Could not execute because the specified command or file was not found.&lt;br>
Possible reasons for this include:&lt;br>
* You misspelled a built-in dotnet command.&lt;br>
* You intended to execute a .NET Core program, but dotnet-interactive does not exist.&lt;br>
* You intended to run a global tool, but a dotnet-prefixed executable with this name could not be found on the PATH.&lt;/p>
&lt;/blockquote>
&lt;p>This is easily fixed by adding &lt;code>%USERPROFILE%\.dotnet\tools&lt;/code> to my path with &lt;code>set PATH=%PATH%;%USERPROFILE%\.dotnet\tools&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-6.png?fit=630%2C369&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Running &lt;code>jupyter kernelspec list&lt;/code> shows that the .NET kernel is installed for C Sharp, F Sharp and .NET PowerShell&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-7.png?resize=630%2C197&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="lets-open-a-notebook">Lets open a Notebook&lt;/h2>
&lt;p>Now you want to play with it!&lt;br>
You can run the lab environment using `jupyter lab`&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-8.png?fit=630%2C194&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>This opens a browser&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-9.png?fit=630%2C272&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can open existing Azure Data Studio PowerShell notebooks (but not SQL ones)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-10.png?fit=630%2C492&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="sometimes-new-things-have-errors-part-2">Sometimes new things have errors Part 2&lt;/h2>
&lt;p>Unfortunately, I get errors when trying to import Pester which means I can not use my dbachecks notebooks in this blog post. &lt;a class="link" href="https://github.com/dotnet/interactive/issues/136" target="_blank" rel="noopener"
>I have raised an issue on the repo here&lt;/a>.&lt;/p>
&lt;h2 id="create-a-new-notebook">Create a New Notebook&lt;/h2>
&lt;p>But it is easy to create a new Notebook&lt;/p>
&lt;p>In the launcher page click the .NET PowerShell button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-12.png?resize=567%2C171&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Which will open a new Notebook in the directory that you launched the lab from. You can then add Code or Markdown as I have &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>described before here&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-11.png?resize=316%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Then you can add code, markdown and images to create your notebook.&lt;/p>
&lt;p>Once you have finished using the notebook lab, you can shut it down in the Anaconda prompt with &lt;code>CTRL + C&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-15.png?fit=630%2C103&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Here is a video of running a notebook which anyone can use to create a couple of Docker containers running SQL 2019 and query them with dbatools. You can find the notebook further down this post.&lt;/p>
&lt;h2 id="sharing-notebooks">Sharing Notebooks&lt;/h2>
&lt;p>You can create notebooks to run common tasks. Even better, from the lab you can convert the notebook including the results to a variety of formats to share with other none-technical people. I used this functionality this week to export Azure Data Studio Notebooks to HTML and PDF for a Project manager 🙂&lt;/p>
&lt;p>You can find the Export Notebook command in the File menu&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-13.png?resize=610%2C542&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Exporting to HTML did not export the images but it does include the results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2020/02/image-14.png?fit=630%2C476&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can share notebooks via GitHub – Either in a gist like this&lt;/p>
&lt;p>or by providing a straight link to the notebook in GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks/blob/master/notebooks/Exploring%20dbatools.ipynb&lt;/a>&lt;/p>
&lt;p>You can also use Binder &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a>&lt;/p>
&lt;p>This uses Docker to create an interactive Notebook. Create a GitHub repo like &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Notebooks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Notebooks&lt;/a> (or just clone it) Copy your notebooks into the notebooks folder and push the changes to GitHub and then go to &lt;a class="link" href="https://mybinder.org/" target="_blank" rel="noopener"
>https://mybinder.org/&lt;/a> and add your URL to the repository.&lt;/p>
&lt;p>You can see what it looks like by clicking the button below which Binder creates for you&lt;/p>
&lt;p>&lt;a class="link" href="https://mybinder.org/v2/gh/SQLDBAWithABeard/Notebooks/master" target="_blank" rel="noopener"
>&lt;img src="https://mybinder.org/badge_logo.svg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Unfortunately the kernel only supports Python for the moment but you can see the possibilities 🙂&lt;/p></description></item><item><title>How to fork a GitHub repository and contribute to an open source project</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-fork-a-github-repository-and-contribute-to-an-open-source-project/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/CreatePR.png" alt="Featured image of post How to fork a GitHub repository and contribute to an open source project" />&lt;p>I enjoy maintaining open source GitHub repositories such as &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> and &lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>. I absolutely love it when people add more functionality to them.&lt;/p>
&lt;p>To collaborate with a repository in GitHub you need to follow these steps&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/GitHub.png"
loading="lazy"
>&lt;/p>
&lt;ul>
&lt;li>Fork the repository into your own GitHub&lt;/li>
&lt;li>Clone the repository to your local machine&lt;/li>
&lt;li>Create a new branch for your changes&lt;/li>
&lt;li>Make some changes and commit them with useful messages&lt;/li>
&lt;li>Push the changes to your repository&lt;/li>
&lt;li>Create a Pull Request from your repository back to the original one&lt;/li>
&lt;/ul>
&lt;p>You will need to have &lt;code>git.exe&lt;/code> available which you can download and install from &lt;a class="link" href="https://git-scm.com/downloads" target="_blank" rel="noopener"
>https://git-scm.com/downloads&lt;/a> if required&lt;/p>
&lt;h2 id="fork-the-repository-into-your-own-github">Fork the repository into your own GitHub&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/ForkRepo.png"
loading="lazy"
>&lt;/p>
&lt;p>A fork is a copy of the original repository. This allows you to make changes without affecting the original project. It does not get updated when the original project gets updated (We will talk about that in the next post) This enables you to code a new feature or a bug fix, test it locally and make sure it is working.&lt;/p>
&lt;p>Let’s take dbachecks as our example. Start by going to the project in GiHub. In this case the URL is &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks&lt;/a> You will see a Fork button at the top right of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-41.png?fit=630%2C74&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When you click the button the repository is copied into your own GitHub account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-42.png?resize=630%2C304&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The page will open at &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> in this case &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/dbachecks&lt;/a> You will be able to see that it is a fork of the original repository at the top of the page&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-43.png?resize=474%2C119&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;h2 id="clone-the-repository-to-your-local-machine">Clone the repository to your local machine&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CloneRepo-2.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Forking the repository has created a &lt;em>remote&lt;/em> repository stored on the GitHub servers. Now that the repository has been forked you need to clone it to your local machine to create a &lt;em>local&lt;/em> repository so that you can start coding your amazing fix. When you have finished you can then sync it back to your &lt;em>remote&lt;/em> repository ready for a Pull Request back to the original repository.&lt;/p>
&lt;p>In your browser, at your &lt;em>remote&lt;/em> repository that you just created (&lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks" target="_blank" rel="noopener"
>https://github.com/YOURGITHUBUSERNAME/NameOfRepository&lt;/a> if you have closed the page) click on &lt;code>Clone or Download&lt;/code> and then the icon to the right to copy the url&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-46.png?fit=630%2C316&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone your repository in &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>VS Code&lt;/a> or &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> by clicking F1 or CTRL + SHIFT + P in Windows or Linux and ⇧⌘P or F1 on a Mac&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-44.png?fit=630%2C206&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>then start typing clone until you see &lt;code>Git:Clone&lt;/code> and press enter or click&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-45.png?fit=630%2C100&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Paste in the URL that you just copied and click enter. A dialog will open asking you to select a folder. This is the parent directory where your &lt;em>local&lt;/em> repository will be created. The clone will create a directory for your repository so you do not need to. I suggest that you use a folder called GitHub or something similar to place all of the repositories that you are going to clone and create.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-47.png?fit=630%2C345&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>When it has finished it will ask you if you wish to open the repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-49.png?fit=630%2C215&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>if you click &lt;code>Open&lt;/code> it will close anything that you have already got opened and open the folder. If you click &lt;code>Add to Workspace&lt;/code> it will add the folder to the workspace and leave everything you already had open as it was and surprisingly clicking &lt;code>Open in New Window&lt;/code> will open the folder in a new instance of Visual Studio Code or Azure Data Studio!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-51.png?fit=630%2C997&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and you will also be able to see the local repository files on your computer&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-50.png?resize=442%2C244&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can clone the repository at the command line if you wish by navigating to your local GitHub directory and running &lt;code>git clone TheURLYouCopied&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-48.png?fit=630%2C165&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now your &lt;em>local&lt;/em> repository has been created, it’s time to do your magic coding.&lt;/p>
&lt;h2 id="create-a-new-branch-for-your-changes">Create a new branch for your changes&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/NewBranch.png?resize=630%2C218&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>It is a good idea to create a branch for your &lt;code>amazing new feature&lt;/code> This enables you to work on coding for that feature in isolation. It has the added advantage that if you mess it right royally up, you can just delete that branch and start again with a new one!&lt;/p>
&lt;p>To create a branch in VS Code or Azure Data Studio you can click on the branch name at the bottom left.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-52.png?resize=630%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Or open the Command Palette and type Branch until you see &lt;code>Git: Create Branch&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-53.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will be prompted for a branch name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-54.png?fit=630%2C96&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I like to choose a name that relates to the code that I am writing like &lt;code>configurable_engine&lt;/code> or &lt;code>removeerroringexample&lt;/code> You can see the name of the branch in the bottom left so that you always know which branch you are working on.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?fit=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>The icon shows that the branch is only &lt;em>local&lt;/em> and hasn’t been pushed (published) to the &lt;em>remote&lt;/em> repository yet&lt;/p>
&lt;h2 id="make-some-changes-and-commit-them-with-useful-messages">Make some changes and commit them with useful messages&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/awesomenewfeature.png?resize=630%2C246&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now you can start writing your code for your awesome new feature, bug fix or maybe just documentation improvement. Keep your commits small and give them useful commit messages that explain &lt;em>why&lt;/em> you have made the change as the diff tooling will be able to show &lt;em>what&lt;/em> change you have made&lt;/p>
&lt;p>Write your code or change the documentation, save the file and in Visual Studio Code or Azure Data Studio you will see that the source control icon has a number on it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-56.png?fit=630%2C143&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Clicking on the icon will show the files that have changes ready&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-57.png?fit=630%2C290&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can write your commit message in the box and click CTRL + ENTER to commit your changes with a message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-58.png?fit=630%2C296&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you want to do this at the command line, you can use &lt;code>git status&lt;/code> to see which files have changes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-59.png?fit=630%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will need to &lt;code>git add .&lt;/code>or &lt;code>git add .\pathtofile&lt;/code> to stage your changes ready for committing and then &lt;code>git commit -m 'Commit Message'&lt;/code> to commit them&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-60.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Notice that I did exactly what I just said not to do! A better commit message would have been &lt;em>So that people can find the guide to forking and creating a PR&lt;/em>&lt;/p>
&lt;h2 id="push-the-changes-to-your-repository">Push the changes to your repository&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/publishbranch.png?resize=630%2C219&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You only have the changes that you have made in your &lt;em>local&lt;/em> repository on your computer. Now you need to push those changes to GitHub your &lt;em>remote&lt;/em> repository. You can click on the publish icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-55.png?resize=630%2C312&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You will get a pop-up asking you if you wish to stage your changes. I click &lt;code>Yes&lt;/code> and never &lt;code>Always&lt;/code> so that I can use this prompt as a sanity check that I am doing the right thing&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-75.png?fit=630%2C150&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>At the command line you can push the branch, if you do that, you will have to tell git where the branch needs to go. If you just type &lt;code>git push&lt;/code> it will helpfully tell you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-61.png?fit=630%2C121&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;pre>&lt;code>fatal: The current branch AwesomeNewFeature has no upstream branch.
To push the current branch and set the remote as upstream, use
git push --set-upstream origin AwesomeNewFeature
&lt;/code>&lt;/pre>
&lt;p>So you will need to use that command&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-62.png?fit=630%2C282&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can see in the bottom left that the icon has changed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-63.png?fit=630%2C186&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and if you read the output of the &lt;code>git push&lt;/code> command you will see what the next step is also.&lt;/p>
&lt;h2 id="create-a-pull-request-from-your-repository-back-to-the-original-one">Create a Pull Request from your repository back to the original one&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/CreatePR.png?resize=630%2C238&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You can CTRL click the link in the &lt;code>git push&lt;/code> output if you have pushed from the command line or if you visit either you repository or the original repository in your browser you will see that there is a &lt;code>Compare and Pull Request&lt;/code> button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-64.png?fit=630%2C334&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>You click that and let GitHub do its magic&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-65.png?fit=630%2C459&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will create a Pull Request for you ready for you to fill in the required information, ask for reviewers and other options. Once you have done that you can click &lt;code>Create pull request&lt;/code> and wait for the project maintainer to review it and (hopefully) accept it into their project&lt;/p>
&lt;p>You can find the Pull Request that I created here &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/720" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative/dbachecks/pull/720&lt;/a> and see how the rest of this blog post was created.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-66.png?fit=630%2C489&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>If you make more changes to the code in the same branch in your &lt;em>local&lt;/em> repository and push them, they will automatically be added to this Pull Request whilst it is open. You can do this if the maintainer or reviewer asks for changes.&lt;/p>
&lt;p>Shane has asked for a change&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-67.png?resize=630%2C110&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can go to my &lt;em>local&lt;/em> repository in Azure Data Studio and make the requested change and save the file. If I look in the source control in Azure Data Studio I can again see there is a change waiting to be committed and if I click on the name of the file I can open the diff tool to see what the change was&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-68.png?fit=630%2C128&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Once I am happy with my change I can commit it again in the same way as before either in the editor or at the command line. The icon at the bottom will change to show that I have one commit in my &lt;em>local&lt;/em> repository waiting to be pushed&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-69.png?fit=630%2C160&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>To do the same thing at the command line I can type &lt;code>git status&lt;/code> and see the same thing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-70.png?fit=630%2C138&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can then push my change to my remote repository either in the GUI or by using &lt;code>git push&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-72.png?fit=630%2C213&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>and it will automatically be added to the Pull Request as you can see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-73.png?fit=630%2C480&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Now that the required changes for the review have been made, the review has been approved by Shane and the pull request is now ready to be merged. (You can also see that dbachecks runs some checks against the code when a Pull Request is made)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-74.png?resize=630%2C359&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Many, many thanks to Shane &lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>t&lt;/a> who helped with the writing of this post even whilst on a “no tech” holiday.&lt;/p>
&lt;h2 id="go-ahead--contribute-to-an-open-source-project">Go Ahead – Contribute to an Open Source Project&lt;/h2>
&lt;p>Hopefully you can now see how easy it is to create a fork of a GitHub repository, clone it to your own machine and contribute. There are many open source projects that you can contribute to.&lt;/p>
&lt;p>You can use this process to contribute to the Microsoft Docs for example by clicking on the edit button on any page.&lt;/p>
&lt;p>You can contribute other open source projects like&lt;/p>
&lt;ul>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/PowerShell/PowerShell" target="_blank" rel="noopener"
>PowerShell&lt;/a>&lt;/strong> by Microsoft&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/tigertoolbox" target="_blank" rel="noopener"
>tigertoolbox&lt;/a>&lt;/strong> by Microsoft Tiger Team&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/sqlcollaborative/PSDatabaseClone" target="_blank" rel="noopener"
>PSDatabaseClone&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/OpenQueryStore/OpenQueryStore" target="_blank" rel="noopener"
>OpenQueryStore&lt;/a>&lt;/strong> by William Durkin and Enrico van de Laar&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/marcingminski/sqlwatch" target="_blank" rel="noopener"
>sqlwatch&lt;/a>&lt;/strong> by Marcin Gminski&lt;/li>
&lt;li>&lt;a class="link" href="https://github.com/red-gate/SQLCop" target="_blank" rel="noopener"
>SQLCop&lt;/a> by Redgate&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/amachanic/sp_whoisactive" target="_blank" rel="noopener"
>sp_whoisactive&lt;/a>&lt;/strong> by Adam Machanic&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/olahallengren/sql-server-maintenance-solution" target="_blank" rel="noopener"
>sql-server-maintenance-solution&lt;/a>&lt;/strong> by Ola Hallengren&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit" target="_blank" rel="noopener"
>SQL-Server-First-Responder-Kit&lt;/a>&lt;/strong> by Brent Ozar Unlimited&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a>&lt;/strong>&lt;/li>
&lt;li>&lt;strong>&lt;a class="link" href="https://github.com/microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>ReportingServicesTools&lt;/a>&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>or go and find the the ones that you use and can help with.&lt;/p></description></item><item><title>Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</link><pubDate>Tue, 26 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/fixing-the-failed-to-generate-the-compressed-file-for-module-dotnet.exe-error-when-deploying-to-the-powershell-gallery-using-azure-devops/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-40.png" alt="Featured image of post Fixing the Failed to generate the compressed file for module dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps" />&lt;h1 id="fixing-the-failed-to-generate-the-compressed-file-for-module-cprogram-filesdotnetdotnetexe-error-when-deploying-to-the-powershell-gallery-using-azure-devops">Fixing the Failed to generate the compressed file for module C:\Program Files\dotnet\dotnet.exe error when deploying to the PowerShell Gallery using Azure DevOps&lt;/h1>
&lt;p>The PowerShell module for validating your SQL Server estate &lt;a class="link" href="http://beard.media/dbachecks" target="_blank" rel="noopener"
>dbachecks&lt;/a> is deployed via &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_release?_a=releases&amp;amp;view=mine&amp;amp;definitionId=2" target="_blank" rel="noopener"
>Azure DevOps, you can see how it is working (or not) via this link&lt;/a>&lt;/p>
&lt;h2 id="grrr-automation-for-the-lose">Grrr Automation for the Lose!&lt;/h2>
&lt;p>Until recently, this had worked successfully. In the last few weeks I have been receiving errors&lt;/p>
&lt;pre>&lt;code>Exception : Microsoft.PowerShell.Commands.WriteErrorException: Failed to generate the compressed file for module 'C:\Program Files\dotnet\dotnet.exe failed to pack: error
C:\Program Files\dotnet\sdk\3.0.100\Sdks\NuGet.Build.Tasks.Pack\build\NuGet.Build.Tasks.Pack.targets(198,5): error :
2 Index was outside the bounds of the array.
[C:\Users\VssAdministrator\AppData\Local\Temp\cbc14ba6-5832-46fd-be89-04bb552a83ac\Temp.csproj]
'.
At C:\Program Files\WindowsPowerShell\Modules\PowerShellGet\2.2.1\PSModule.psm1:10944 char:17
20 Publish-PSArtifactUtility @PublishPSArtifactUtility_Param ...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+ CategoryInfo : InvalidOperation: (:) [Write-Error], WriteErrorException
2019-11-25T22:44:46.8459493Z + FullyQualifiedErrorId : FailedToCreateCompressedModule,Publish-PSArtifactUtility
&lt;/code>&lt;/pre>
&lt;p>You can see these errors in the &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_apps/hub/ms.vss-releaseManagement-web.cd-release-progress?_a=release-environment-logs&amp;amp;releaseId=127&amp;amp;environmentId=127" target="_blank" rel="noopener"
>release pipeline logs here&lt;/a>&lt;/p>
&lt;h2 id="confusion">Confusion&lt;/h2>
&lt;p>This was very frustrating as it was stopping the continuous delivery to the PowerShell Gallery. It was even more confusing as I was successfully deploying the &lt;a class="link" href="http://beard.media/ADSNotebook" target="_blank" rel="noopener"
>ADSNotebook module&lt;/a> to the gallery using the same method as &lt;a class="link" href="https://dev.azure.com/sqlcollaborative/ADSSQLNotebook/_build/results?buildId=541" target="_blank" rel="noopener"
>you can see here&lt;/a>.&lt;/p>
&lt;h2 id="raise-an-issue-on-github">Raise an Issue on GitHub&lt;/h2>
&lt;p>I went and looked at the &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/" target="_blank" rel="noopener"
>PowerShellGet GitHub repository&lt;/a> and opened an &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/554" target="_blank" rel="noopener"
>issue&lt;/a> I also found &lt;a class="link" href="https://github.com/PowerShell/PowerShellGet/issues/551" target="_blank" rel="noopener"
>another issue regarding Required Modules&lt;/a>&lt;/p>
&lt;p>But this doesn&amp;rsquo;t help to get dbachecks released.&lt;/p>
&lt;h2 id="just-try-to-make-it-work">Just Try to Make it Work&lt;/h2>
&lt;p>I asked the wonderful folk in the &lt;a class="link" href="http://powershell.slack.com" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a> – Through the magic of automation, you can also interact with them via the powershellhelp channel in the &lt;a class="link" href="http://beard.media/sqlslack" target="_blank" rel="noopener"
>SQL Server Slack&lt;/a> as well but there were no answers that could assist.&lt;/p>
&lt;p>So I had to go searching for an answer. PowerShellGet uses &lt;a class="link" href="https://www.nuget.org/" target="_blank" rel="noopener"
>nuget&lt;/a> for package management. I found that if I downloaded an earlier version and placed it in my user profile (in the right location) I could publish the module.&lt;/p>
&lt;p>I found this out by removing the nuget.exe from anywhere useful on the machine and trying to publish the module. The error message says&lt;/p>
&lt;pre>&lt;code>NuGet.exe upgrade is required to continue
This version of PowerShellGet requires minimum version '4.1.0' of NuGet.exe to publish an item to the NuGet-based repositories. NuGet.exe must be available in
'C:\ProgramData\Microsoft\Windows\PowerShell\PowerShellGet\' or 'C:\Users\BeardyMcBeardFace\AppData\Local\Microsoft\Windows\PowerShell\PowerShellGet\', or under
one of the paths specified in PATH environment variable value. NuGet.exe can be downloaded from https://aka.ms/psget-nugetexe. For more information, see
https://aka.ms/installing-powershellget . Do you want PowerShellGet to upgrade to the latest version of NuGet.exe now?
&lt;/code>&lt;/pre>
&lt;p>If I said yes then I got the latest version and the error continued.&lt;/p>
&lt;p>However, on my laptop I can go to the &lt;a class="link" href="https://www.nuget.org/downloads" target="_blank" rel="noopener"
>nuget downloads page&lt;/a> and download an earlier version and place it in one of those paths then I could publish the module.&lt;/p>
&lt;h2 id="can-i-automate-it">Can I Automate it?&lt;/h2>
&lt;p>I would rather not have to deploy manually though, and as I use hosted agents my access to the operating system is limited so I wondered if I could place the nuget.exe in the user profile and it would get used or if it would look for the the latest one. Turns out it uses the one in the user profile 🙂&lt;/p>
&lt;p>So now I have this code as a step in my Azure DevOps Release pipeline before calling &lt;code>Publish-Module&lt;/code> and we have automated the releases again.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>and now deployments to the PowerShell Gallery are just triggered by the build and the pipeline is green again 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://dev.azure.com/sqlcollaborative/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=129&amp;amp;environmentId=129" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-40.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>test&lt;/p></description></item><item><title>Dynamically Creating Azure Data Studio Notebooks with PowerShell for an Incident Response Index Notebook</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/</link><pubDate>Thu, 21 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dynamically-creating-azure-data-studio-notebooks-with-powershell-for-an-incident-response-index-notebook/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-39.png" alt="Featured image of post Dynamically Creating Azure Data Studio Notebooks with PowerShell for an Incident Response Index Notebook" />&lt;p>Now that &lt;a class="link" href="https://aka.ms/azuredatastudio" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> has &lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/release-notes-azure-data-studio?view=sql-server-ver15?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>PowerShell Notebooks&lt;/a> and there is a &lt;a class="link" href="https://blog.robsewell.com/create-a-powershell-notebook-for-azure-data-studio-with-powershell/" target="_blank" rel="noopener"
>PowerShell Module for creating notebooks&lt;/a>. I have been asked, more than once, what is the point? What is the use case? How does this help. I hope that this post will spark some ideas of one particular use-case.&lt;/p>
&lt;p>I showed my silly example PowerShell code to create a PowerShell Notebook that created a PowerShell Notebook to my good friend Nick.&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Thanks Nick.&lt;/p>
&lt;h2 id="the-use-case">The Use Case&lt;/h2>
&lt;p>The use case that Nick has is that he is converting some troubleshooting runbooks from their original locations (you know the sort of places – Sharepoint Docs, OneNote Notebooks, Shared Folders, the desktop of the Bastion Host) into a single repository of Azure Data Studio SQL or PowerShell Notebooks.&lt;/p>
&lt;p>The idea is to have a single entry point into the troubleshooting steps and for the on-call DBA to create a Notebook from a template for the issue at hand which could be attached to an incident in the incident management solution. I suppose you could call it an Index Notebook.&lt;/p>
&lt;h2 id="work-flow">Work Flow&lt;/h2>
&lt;p>When the DBA (or another team) opens this Notebook, they can choose the task that they are going to perform and click the link which will&lt;/p>
&lt;ul>
&lt;li>copy the Notebook to the local machine&lt;/li>
&lt;li>Rename the Notebook with the username and date&lt;/li>
&lt;li>Open it ready for the work.&lt;/li>
&lt;/ul>
&lt;p>Once the work has been completed, the DBA can then attach the Notebook to the task or incident that has been created or use it in the Wash-Up/ Post Incident meeting.&lt;/p>
&lt;p>This ensures that the original template notebook stays intact and unchanged and it is easy (which is always good when you are called out at 3am!) to create a uniquely named notebook .&lt;/p>
&lt;h2 id="azure-devops">Azure DevOps&lt;/h2>
&lt;p>Nick has placed this code into the deploy step in Azure DevOps which will deploy the template Notebooks from source control into the common folder and then this code will dynamically create the index Notebook each time there is a release.&lt;/p>
&lt;p>Whilst the initial use case is incident response, this could easily be adapted for Notebooks used for Common Tasks or Run Books.&lt;/p>
&lt;h2 id="notebooks">Notebooks&lt;/h2>
&lt;p>There are a number of Notebooks for different issue stored in directories. For this post, I have used the Notebooks from Microsoft that explain SQL 2019 features and troubleshooting which you can find in their GitHub repositories by &lt;a class="link" href="https://github.com/microsoft/sql-server-samples/tree/master/samples/features/sql2019notebooks" target="_blank" rel="noopener"
>following this link&lt;/a>&lt;/p>
&lt;p>The Azure DevOps deploys the Notebooks to a directory which then looks something like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-38.png?resize=494%2C195&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Some directories of Notebooks in a directory&lt;/p>
&lt;h2 id="create-an-index-notebook">Create an Index Notebook&lt;/h2>
&lt;p>Here is the code to create an index Notebook&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>This creates a Notebook in the root of the folder. It also uses the new &lt;code>-Collapse&lt;/code> parameter in &lt;code>New-AdsNoteBookCell&lt;/code> that creates the code blocks with the code collapsed so that it looks neater. The index Notebook looks like this in the root of the folder&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-39.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-39.png?resize=630%2C680&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="three-oclock-in-the-morning">Three O’Clock in the Morning&lt;/h2>
&lt;p>It’s 3am and I have been called out. I can open up the Index Notebook, find the set of queries I want to run and click the run button.&lt;/p>
&lt;p>A new workbook opens up, named with my name and the time and I can get to work 🙂 I think it’s neat.&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Maybe you can find him at SQL Bits next year. Did you know that SQL Bits 2020 was announced?&lt;/p>
&lt;p>Check out &lt;a class="link" href="https://sqlbits.com" target="_blank" rel="noopener"
>https://sqlbits.com&lt;/a> for more details&lt;/p></description></item><item><title>Create a PowerShell Notebook for Azure Data Studio with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</link><pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-a-powershell-notebook-for-azure-data-studio-with-powershell/</guid><description>&lt;p>The latest update to the ADSNotebook PowerShell module &lt;a class="link" href="https://blog.robsewell.com/create-azure-data-studio-sql-notebooks-with-powershell/" target="_blank" rel="noopener"
>I blogged about here&lt;/a> now enables the creation of PowerShell notebooks with PowerShell.&lt;/p>
&lt;p>You can install the module with&lt;/p>
&lt;pre>&lt;code>Install-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>or if you have already installed it you can use&lt;/p>
&lt;pre>&lt;code>Update-Module ADSNotebook
&lt;/code>&lt;/pre>
&lt;p>In the latest release, there is an extra parameter for &lt;code>New-AdsWorkBook&lt;/code> of &lt;code>-Type&lt;/code> which will accept either SQL or PowerShell&lt;/p>
&lt;h2 id="create-a-powershell-notebook-with-powershell-rob">Create a PowerShell Notebook with PowerShell Rob&lt;/h2>
&lt;p>OK!&lt;/p>
&lt;p>Here is some code to create a PowerShell Notebook. First we will create some cells using &lt;code>New-AdsWorkBookCell&lt;/code> including all the markdown to add images and links. You can find my notebooks which explain how to write the markdown for your notebooks in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/2019/PASS%20Summit/SQL%20Notebooks%20in%20Azure%20Data%20Studio%20for%20the%20DBA" target="_blank" rel="noopener"
>GitHub Presentations Repository&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then we will create a new workbook using those cells&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>Then, when that code is run we can open the Notebook and ta-da&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-33.png?fit=630%2C505&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>And it is super quick to run as well&lt;/p>
&lt;p>UPDATE – Tyler Leonhardt &lt;a class="link" href="https://twitter.com/TylerLeonhardt" target="_blank" rel="noopener"
>t&lt;/a> from the PowerShell team asked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-36.png?resize=597%2C284&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>Challenge accepted, with extra meta, here is the PowerShell to create a PowerShell Notebook which will create a PowerShell Notebook!!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item><item><title>Create Azure Data Studio SQL Notebooks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-azure-data-studio-sql-notebooks-with-powershell/</link><pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/create-azure-data-studio-sql-notebooks-with-powershell/</guid><description>&lt;p>At PASS Summit today I gave a presentation about SQL Notebooks in Azure Data Studio for the DBA. I demo’d the &lt;a class="link" href="https://www.powershellgallery.com/packages/ADSNotebook" target="_blank" rel="noopener"
>PowerShell module ADSNotebook&lt;/a>.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-32.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/sqlcollaborative/ADSNotebook" target="_blank" rel="noopener"
>which you can also find on GitHub&lt;/a> (where I will be glad to take PR’s to improve it 🙂 )&lt;/p>
&lt;p>This module has 3 functions&lt;/p>
&lt;p>This module contains only 3 commands at present&lt;/p>
&lt;ul>
&lt;li>Convert-ADSPowerShellForMarkdown&lt;/li>
&lt;/ul>
&lt;p>This will create the markdown link for embedding PowerShell code in a Text Cell for a SQL Notebook as described &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>in this blog post&lt;/a>&lt;/p>
&lt;ul>
&lt;li>New-ADSWorkBookCell&lt;/li>
&lt;/ul>
&lt;p>This command will create a workbook text cell or a code cell for adding to the New-ADSWorkBook command&lt;/p>
&lt;ul>
&lt;li>New-ADSWorkBook&lt;/li>
&lt;/ul>
&lt;p>This will create a new SQL Notebook using the cell objects created by New-ADSWorkBookCell&lt;/p>
&lt;h2 id="usage">Usage&lt;/h2>
&lt;p>Convert-ADSPowerShellForMarkdown&lt;/p>
&lt;pre>&lt;code>Convert-ADSPowerShellForMarkdown -InputText &amp;quot;Get-ChildItem&amp;quot; -LinkText 'This will list the files' -ToClipBoard
Converts the PowerShell so that it works with MarkDown and sets it to the clipboard for pasting into a workbook cell
&lt;/code>&lt;/pre>
&lt;p>New-ADSWorkBookCell&lt;/p>
&lt;pre>&lt;code>$introCelltext = &amp;quot;# Welcome to my Auto Generated Notebook
## Automation
Using this we can automate the creation of notebooks for our use
&amp;quot;
$Intro = New-ADSWorkBookCell -Type Text -Text $introCelltext
Creates an Azure Data Studio Text cell and sets it to a variable for passing to New-AdsWorkBook
&lt;/code>&lt;/pre>
&lt;p>New-ADSWorkBook&lt;/p>
&lt;pre>&lt;code>$introCelltext = &amp;quot;# Welcome to my Auto Generated Notebook
## Automation
Using this we can automate the creation of notebooks for our use
&amp;quot;
$SecondCelltext = &amp;quot;## Running code
The next cell will have some code in it for running
## Server Principals
Below is the code to run against your instance to find the server principals that are enabled&amp;quot;
$thirdcelltext = &amp;quot;SELECT Name
FROM sys.server_principals
WHERE is_disabled = 0&amp;quot;
$Intro = New-ADSWorkBookCell -Type Text -Text $introCelltext
$second = New-ADSWorkBookCell -Type Text -Text $SecondCelltext
$third = New-ADSWorkBookCell -Type Code -Text $thirdcelltext
$path = 'C:\temp\AutoGenerated.ipynb'
New-ADSWorkBook -Path $path -cells $Intro,$second,$third
Creates 3 cells with New-AdsWorkBookCells to add to the workbook,
two text ones and a code one, then creates a SQL Notebook with
those cells and saves it as C:\temp\AutoGenerated.ipynb
&lt;/code>&lt;/pre>
&lt;h1 id="installation">Installation&lt;/h1>
&lt;p>You can install this Module from the PowerShell Gallery using&lt;/p>
&lt;p>&lt;code>Install-Module ADSNotebook&lt;/code>&lt;/p>
&lt;h1 id="compatability">Compatability&lt;/h1>
&lt;p>This module has been tested on Windows PowerShell 5.1, PowerShell Core 6 and PowerShell 7 on Windows 10 and Ubuntu&lt;/p>
&lt;h2 id="demo">Demo&lt;/h2>
&lt;!-- raw HTML omitted --></description></item><item><title>My current VS Code Extensions and using a workspace file</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/my-current-vs-code-extensions-and-using-a-workspace-file/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/11/image-26.png" alt="Featured image of post My current VS Code Extensions and using a workspace file" />&lt;p>I have been asked a couple of times recently what my Visual Studio Code extensions are at the moment so I thought I would write a quick post and also look at workspaces and how you can enable and disable extensions within them&lt;/p>
&lt;h2 id="listing-extensions">Listing Extensions&lt;/h2>
&lt;p>From the command line you can list your extensions using&lt;/p>
&lt;pre>&lt;code>code --list-extensions
code-insiders --list-extensions
&lt;/code>&lt;/pre>
&lt;p>My list looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/11/image.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can also see them in the view on the left of default Visual Studio Code and open them with CTRL + SHIFT + X (unless like me you have Snagit installed and it has taken that shortcut&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-31.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-extensions">Installing Extensions&lt;/h2>
&lt;p>You can install extensions by opening the Extensions view in Visual Studio Code and searching for the extension. The list I have below has the precise names for each extension which you can use to search&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-24.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also install extensions from the command-line with&lt;/p>
&lt;pre>&lt;code>code --install-extension &amp;lt;extensionid&amp;gt;
code-insiders --install-extension &amp;lt;extensionid&amp;gt;
&lt;/code>&lt;/pre>
&lt;h2 id="my-extensions">My Extensions&lt;/h2>
&lt;p>I am going to list these in alphabetical order by display name for ease (my ease that is!)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Because Chrissy LeMaire and I are writing &lt;a class="link" href="https://beard.media/book" target="_blank" rel="noopener"
>dbatools in a Month of Lunches&lt;/a> using AsciiDoc, it makes sense to have an extension enabling previewing and syntax, you can find it &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=stayfool.vscode-asciidoc" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure I use the Azure Account Extension – ms-vscode.azure-account&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>I use Azure CLI so I make use of the functionality of the Azure CLI Tools extension ms-vscode.azurecli&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>For interacting with Azure Repos I use the ms-vsts.team extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>When creating ARM templates, this extension is very useful msazurermtools.azurerm-vscode-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I have a few theme extensions, this one is for fun in demos 😉 beardedbear.beardedtheme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>The blackboard theme is my default one gerane.theme-blackboard&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Chasing closing brackets is much easier with the Bracket Pair Colorizer, I use the beta version coenraads.bracket-pair-colorizer-2&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>I am rubbish at spelling and typing so I use this to help point out the issues! streetsidesoftware.code-spell-checker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>Using the Docker extension adds another view to Visual Studio Code to ease working with containers ms-azuretools.vscode-docker&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>As an open-source project maintainer it is good to be able to work with GitHub pull requests without leaving Visual Studio Code github.vscode-pull-request-github_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>GitLens is absolutely invaluable when working with source control. It has so many features. This is an absolute must eamodio.gitlens&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>Working with Kubernetes? This extension adds another view for interacting with your cluster ms-kubernetes-tools.vscode-kubernetes-tools&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>Visual Studio Live Share enables you to collaborate in real-time in Visual Studio Code with your colleagues or friends. I blogged about this &lt;a class="link" href="https://blog.robsewell.com/visual-studio-code-live-sharing-set-up/" target="_blank" rel="noopener"
>here&lt;/a> ms-vsliveshare.vsliveshare&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I love writing markdown and this linter assists me to ensure that my markdown is correct davidanson.vscode-markdownlint&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>The Material Icon Theme ensures that there are pretty icons in my editor! pkief.material-icon-theme&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I have both the PowerShell extension ms-vscode.powershell and the PowerShell preview extension ms-vscode.powershell-preview installed but only one can be enabled at a time&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>This suite of extensions enables easy remote development so that you can develop your PowerShell scripts, for example, inside a ubuntu container running PowerShell 7 or inside Windows Subsystem for LInux ms-vscode-remote.vscode-remote-extensionpack_Preview_&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-20.png"
loading="lazy"
>&lt;/p>
&lt;p>Writing for cross-platform means looking out for line endings and this extension will display them and any whitespace in your editor medo64.render-crlf&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-21.png"
loading="lazy"
>&lt;/p>
&lt;p>An absolutely essential extension which enables me to backup all of my Visual Studio Code settings, shortcuts, extensions into a GitHub gist and keep all of my machines feeling the same. shan.code-settings-sync&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-22.png"
loading="lazy"
>&lt;/p>
&lt;p>For working with SQL Server within Visual Studio Code and having a view for my instances as well as a linter and intellisense I use ms-mssql.mssql&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-23.png"
loading="lazy"
>&lt;/p>
&lt;p>Yaml files and spaces! I no longer get so confused with this extension to help me 🙂 redhat.vscode-yaml&lt;/p>
&lt;h2 id="workspaces">Workspaces&lt;/h2>
&lt;p>Now that is a lot of extensions and I dont need all of them everytime. I use workspaces to help with this. I will create a workspace file for the project I am working on.&lt;/p>
&lt;p>I open or create the folders I will be working on and then click File and Save Workspace As and save the file in the root of the folder.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-25.png"
loading="lazy"
>&lt;/p>
&lt;p>Now, the next time I want to open the workspace, I can open the workspace file or if I open the folder Visual Studio Code will helpfully prompt me&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-26.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can have all of my settings retained for that workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-27.png"
loading="lazy"
>&lt;/p>
&lt;p>For this folder, I am ensuring that the PowerShell extension uses the PSScriptAnalyzer Settings file that I have created so that it will show if the code is compatible with the versions of PowerShell I have chosen. I can define settings for a workspace in the settings file, which you can open using CTRL and ,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-28.png"
loading="lazy"
>&lt;/p>
&lt;p>But I can also enable or disable extensions for a workspace&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-29.png"
loading="lazy"
>&lt;/p>
&lt;p>So everytime I open this workspace I am only loading the extensions I want&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/11/image-30.png"
loading="lazy"
>&lt;/p></description></item><item><title>PowerShell Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</link><pubDate>Thu, 17 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-8.png" alt="Featured image of post PowerShell Notebooks in Azure Data Studio" />&lt;p>The latest release of the &lt;a class="link" href="https://github.com/microsoft/azuredatastudio#try-out-the-latest-insiders-build-from-master" target="_blank" rel="noopener"
>insiders edition of Azure Data Studio&lt;/a> brings the first edition of PowerShell Notebooks!&lt;/p>
&lt;p>You can download the latest insiders edition from the link above, it can be installed alongside the stable release.&lt;/p>
&lt;p>To access many of the commands available use F1 to open the command palette (like many of my tips this also works in Visual Studio Code). You can then start typing to get the command that you want.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>You can then hit enter with the command that you want highlighted, use the mouse or use the shortcut which is displayed to the right.&lt;/p>
&lt;p>In a new notebook, you can click the drop down next to kernel and now you can see that PowerShell is available&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-9.png"
loading="lazy"
>&lt;/p>
&lt;p>When you choose the PowerShell kernel, you will get a prompt asking you to configure the Python installation&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>If you have Python already installed you can browse to the location that it is installed or you can install Python. In the bottom pane you will be able to see the progress of the installation.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>When it has completed, you will see&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>You may also get a prompt asking if you would like to upgrade some packages&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>Again this will be displayed in the tasks pane&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-14.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="addingpowershell">&lt;strong>Adding PowerShell&lt;/strong>&lt;/h2>
&lt;p>To add PowerShell Code to the notebook click the Code button at the top of the file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>or the one you can find by highlighting above or below a block&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>I did not have intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block.&lt;/p>
&lt;p>Interestingly Shawn Melton ( &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>t&lt;/a> ) did&lt;/p>
&lt;blockquote>
&lt;p>Curious, you state &amp;ldquo;There is not any intellisense, but you can easily write your code in Azure Data Studio or Visual Studio Code and paste it in the block&amp;rdquo;…&lt;/p>
&lt;p>It works flawlessly for me on Windows. &lt;a class="link" href="https://t.co/Lx6fGH9F5L" target="_blank" rel="noopener"
>pic.twitter.com/Lx6fGH9F5L&lt;/a>&lt;/p>
&lt;p>— Shawn Melton (@wsmelton) &lt;a class="link" href="https://twitter.com/wsmelton/status/1184819132598013952?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>October 17, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This was because he had the PowerShell extension installed and I did not (I know !!)&lt;br>
If you find you dont have intellisense then install the PowerShell extension!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the play button (which is only visible when you hover the mouse over it) will run the code&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can clear the results from every code block using the clear results button at the top&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>Otherwise, you can save the results with the Notebook by saving it. This is the part that is missing from running PowerShell in the Markdown blocks in a &lt;a class="link" href="https://blog.robsewell.com/powershell-in-sql-notebooks-in-azure-data-studio/" target="_blank" rel="noopener"
>SQL Notebook as I described here&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>I am looking forward to how this develops. You can find my sample PowerShell notebook (with the code results) &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Notebooks/powershell.ipynb" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p></description></item><item><title>Getting SQL Server installation date with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-installation-date-with-powershell-using-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/10/image-7.png" alt="Featured image of post Getting SQL Server installation date with PowerShell using dbatools" />&lt;p>Most of my writing time at the moment is devoted to  &lt;em>&lt;a class="link" href="https://dbatools.io/book" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> which is now available but here is a short post following a question someone asked me.&lt;/p>
&lt;h2 id="how-can-i-get-the-installation-date-for-sql-server-on-my-estate-into-a-database-with-dbatools-">How can I get the Installation Date for SQL Server on my estate into a database with dbatools ?&lt;/h2>
&lt;p>You can get the date that SQL Server was installed using the creation date of the NT Authority\System login using T-SQL&lt;/p>
&lt;pre>&lt;code>SELECT create_date
FROM sys.server_principals
WHERE sid = 0x010100000000000512000000
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="with-dbatools">With dbatools&lt;/h2>
&lt;p>To do this with dbatools you can use the command &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaInstanceInstallDate" target="_blank" rel="noopener"
>Get-DbaInstanceInstallDate&lt;/a> command&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-1.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="more-than-one-instance">More than one instance&lt;/h2>
&lt;p>If we want to get the installation date for more than one instance we can simply create an array of instances for the SqlInstance parameter&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE
&lt;/code>&lt;/pre>
&lt;h2 id="get-the-windows-installation-date-too">Get the Windows installation date too&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>You can also get the windows installation date with the IncludeWindows switch&lt;/p>
&lt;pre>&lt;code>Get-DbaInstanceInstallDate -SqlInstance localhost, localhost\DAVE -IncludeWindows
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-3.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="gather-your-instances">Gather your instances&lt;/h2>
&lt;p>How you get the instances in your estate is going to be different per reader but here is an example using Registered Servers from my local registered servers list, you can also use a Central Management Server&lt;/p>
&lt;pre>&lt;code>Get-DbaRegisteredServer -Group local
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-4.png"
loading="lazy"
>&lt;/p>
&lt;p>So we can gather those instances into a variable and pass that to Get-DbaInstanceInstallDate&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-5.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="add-to-database">Add to database&lt;/h2>
&lt;p>To add the results of any PowerShell command to a database, you can pipe the results to &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDbTableData" target="_blank" rel="noopener"
>Write-DbaDbTableData&lt;/a>&lt;/p>
&lt;pre>&lt;code>$SqlInstances = Get-DbaRegisteredServer -Group local
$writeDbaDataTableSplat = @{
SqlInstance = 'localhost'
Table = 'InstallDate'
Database = 'tempdb'
Schema = 'dbo'
AutoCreateTable = $true
}
Get-DbaInstanceInstallDate -SqlInstance $SqlInstances | Write-DbaDataTable @writeDbaDataTableSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>This will create a table called InstallDate and put the results of the Get-DbaInstanceInstallDate command. Note – If you want to try this code, I would advise using a different database than tempdb!!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/10/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>It is important to note that the table created may not have the most optimal data types and that you may want to pre-create the table.&lt;/p>
&lt;p>So there you go, all the installation dates for your estate in a database table. Hope that helps you Jonny.&lt;/p></description></item><item><title>MEAP MEAP – #dbatoolsMoL – Live Book edition</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</link><pubDate>Wed, 04 Sep 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/meap-meap-#dbatoolsmol-live-book-edition/</guid><description>&lt;p>It’s been a busy time!&lt;/p>
&lt;p>As well as many other things, the fantastical &lt;a class="link" href="https://en.wikipedia.org/wiki/Benevolent_dictator_for_life" target="_blank" rel="noopener"
>BDFL&lt;/a> of &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a> and myself have written enough of a chunk of &lt;em>&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Learn dbatools in a Month of Lunches&lt;/a>&lt;/em> that our publisher &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>Manning Publications&lt;/a> have agreed to release it as a MEAP. Not a text book, this book is written in a fun conversational style and split up into chapters that you can read in a lunch-time.&lt;/p>
&lt;p>It is impossible for me to hear MEAP and not think of this 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://tenor.com/view/hungry-coyote-looney-tunes-gif-5063446" target="_blank" rel="noopener"
>Roadrunner Speeding GIF&lt;/a> from &lt;a class="link" href="https://tenor.com/search/hungry-gifs" target="_blank" rel="noopener"
>Hungry GIFs&lt;/a>&lt;/p>
&lt;p>but I expect you are wondering what a MEAP is?&lt;/p>
&lt;blockquote>
&lt;p>What is MEAP?&lt;br>
A book can take a year or more to write, so how do you learn that hot new technology today? The answer is MEAP, the Manning Early Access Program. In MEAP, you read a book chapter-by-chapter while it’s being written and get the final eBook as soon as it’s finished. If you pre-order the pBook, you’ll get it long before it’s available in stores.&lt;/p>
&lt;p>&lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>https://www.manning.com/meap-program&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Basically, to make it easy to get and for those that like to get in early, you can order the book and get the first 4 chapters (three in reality) RIGHT NOW!! (It also means that Chrissy and I have to write the rest of book – dang still going to be busy!)&lt;/p>
&lt;p>Simply head over to &lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a> and use the code mlsewell and you can get access to the book too.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/08/meap.png"
loading="lazy"
>](&lt;a class="link" href="https://beard.media/bookblog" target="_blank" rel="noopener"
>https://beard.media/bookblog&lt;/a>)&lt;/p>
&lt;p>This will also give you access to the live book.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/livebook.png"
loading="lazy"
>&lt;/p>
&lt;p>live book&lt;/p>
&lt;p>The live book is fantastic, you can read the whole book from within your browser. See the three icons that appear to the right of the book?&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/stuffage.png"
loading="lazy"
>&lt;/p>
&lt;p>3 little icons (no porridge)&lt;/p>
&lt;p>The left hand one enables you to bookmark an important part so that you can come back to it easily using the bookmarks link in the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/bookmark.png"
loading="lazy"
>&lt;/p>
&lt;p>bookmarks&lt;/p>
&lt;p>The middle icon enables you to write notes for yourself, maybe ways that you can use the information or maybe comments about an awesome Italian.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/satori.png"
loading="lazy"
>&lt;/p>
&lt;p>Shoes&lt;/p>
&lt;p>The last one is the way that you can make comments and engage us , the authors in conversation, ask questions, request clarification or wonder about Dutch data manglers&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/sander.png"
loading="lazy"
>&lt;/p>
&lt;p>I think its down to PII&lt;/p>
&lt;p>If you select a piece of text, another menu opens up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlight.png"
loading="lazy"
>&lt;/p>
&lt;p>The first icon lets you highlight the text, to make it easier to find later&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/highlightyellow.png"
loading="lazy"
>&lt;/p>
&lt;p>Hover over the highlight and you can choose different colours for different things.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/image.png"
loading="lazy"
>&lt;/p>
&lt;p>or even create pretty pictures for Mathias&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/pretty.png"
loading="lazy"
>&lt;/p>
&lt;p>Mathias – Why isn’t he an MVP?&lt;/p>
&lt;p>You can choose to annotate, which is sort of like highlighting and writing a note with the next icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/other-users.png"
loading="lazy"
>&lt;/p>
&lt;p>When you want to share a link to a particular part of the book with someone else, you can highlight part of it and click the link icon&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/linkylinky.png"
loading="lazy"
>&lt;/p>
&lt;p>It’s easy to start PowerShell as another user as long as you remember when to press SHIFT&lt;/p>
&lt;p>Which will highlight the paragraph and open a dialogue at the bottom where you can create and copy the link.&lt;/p>
&lt;p>By far the most important part for Chrissy and I is the last link. When you find something wrong you can mark it for our attention. Yes, even with Chrissy and I proof reading each others words, the fabulous proof reader Cláudio Silva (&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>t&lt;/a>) and awesome tech editor Mike Shepard (&lt;a class="link" href="https://powershellstation.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/MikeShepard70" target="_blank" rel="noopener"
>t&lt;/a>)  as well as many community reviewers there are still, and will continue to be, issues. So when you find them, highlight them and click the right hand most link&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/09/withwith.png"
loading="lazy"
>&lt;/p>
&lt;p>with with more more than than one one&lt;/p>
&lt;p>This will open up as shown so that you can fill in what was wrong (Please don’t report this error again Shane &lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>t&lt;/a> has beaten you to it!)&lt;/p>
&lt;p>You will have noticed on social media and elsewhere that we have left some easter eggs in the book&lt;/p>
&lt;blockquote>
&lt;p>Yup, we have some easter eggs in &lt;a class="link" href="https://twitter.com/hashtag/dbatoolsMol?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatoolsMol&lt;/a>&lt;/p>
&lt;p>We hope you enjoy them &lt;a class="link" href="https://t.co/iZa3u8iLPC" target="_blank" rel="noopener"
>https://t.co/iZa3u8iLPC&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1167116661503266819?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>August 29, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Whenever you find them or whenever you want to talk about the book on social media, please use the hashtag #dbatoolsMoL – you never know what goodies may end up in your inbox.&lt;/p>
&lt;p>Oh and if you have got this far and don’t know what dbatools in a Month of Lunches is, listen to the hair and read more &lt;a class="link" href="https://dbatools.io/meap/" target="_blank" rel="noopener"
>https://dbatools.io/meap/&lt;/a>&lt;/p></description></item><item><title>PowerShell in SQL Notebooks in Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</link><pubDate>Wed, 17 Jul 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-in-sql-notebooks-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/07/image-4.png" alt="Featured image of post PowerShell in SQL Notebooks in Azure Data Studio" />&lt;p>I have done a lot of writing in the last few months but you see no blog posts! My wonderful friend Chrissy and I are writing “dbatools in a Month of Lunches” to be published by Manning. That has taken up a lot of my writing mojo. We have hit a little break whilst we have some reviews done ready for the &lt;a class="link" href="https://www.manning.com/meap-program" target="_blank" rel="noopener"
>MEAP&lt;/a> (For everyone who asks, the answer is the unfulfilling ‘soon’) so it’s time for a blog post!&lt;/p>
&lt;h2 id="sql-notebooks-are-cool">SQL Notebooks are cool&lt;/h2>
&lt;p>I have had a lot of fun with SQL Notebooks recently. I have presented a session about them at a couple of events this month &lt;a class="link" href="http://datagrillen.com" target="_blank" rel="noopener"
>DataGrillen&lt;/a> and SQL Saturday Cork. Here is a little snippet&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://twitter.com/hashtag/dbatools?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbatools&lt;/a> in PowerShell in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> SQL Notebooks for creating the containers and restoring the &lt;a class="link" href="https://twitter.com/hashtag/dbachecks?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#dbachecks&lt;/a> historical database for running queries in 🙂&lt;br>
Getting ready for presentation for &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/wiQ41bblQV" target="_blank" rel="noopener"
>pic.twitter.com/wiQ41bblQV&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1130871277449875456?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 21, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Yes, you can run PowerShell in a SQL Notebook in Azure Data Studio just by clicking a link in the markdown cell. This opens up a lot of excellent possibilities.&lt;/p>
&lt;p>I have had several discussions about how SQL Notebooks can be used by SQL DBAs within their normal everyday roles. (Mainly because I don’t really understand what the sorcerers of data science do with notebooks!). I have helped clients to look at some of their processes and use SQL Notebooks to help with them. Creating Disaster Recovery or Change Run-books or Incident Response Templates or using them for product demonstrations. Of course, I needed to use PowerShell in that 🙂&lt;/p>
&lt;p>I have really enjoyed working out how to run PowerShell in the markdown in a SQL Notebook in Azure Data Studio and I think &lt;a class="link" href="http://www.centinosystems.com/blog/author/aencentinosystems-com/" target="_blank" rel="noopener"
>Anthony the kubernetes magician&lt;/a> did too!&lt;/p>
&lt;blockquote>
&lt;p>I think &lt;a class="link" href="https://twitter.com/sqldbawithbeard?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@sqldbawithbeard&lt;/a> is an actual wizard! You should see the things he can do with &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> &lt;a class="link" href="https://twitter.com/hashtag/DataGrillen?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#DataGrillen&lt;/a> &lt;a class="link" href="https://t.co/KMeZR3CrPK" target="_blank" rel="noopener"
>pic.twitter.com/KMeZR3CrPK&lt;/a>&lt;/p>
&lt;p>— Anthony E. Nocentino (@nocentino) &lt;a class="link" href="https://twitter.com/nocentino/status/1141709511700467712?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>June 20, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>OK enough magic puns lets talk about PowerShell in SQL Notebooks. You can read about &lt;a class="link" href="https://blog.robsewell.com/whats-a-sql-notebook-in-azure-data-studio/" target="_blank" rel="noopener"
>how to create a SQL Notebook and run T-SQL queries here&lt;/a>, (you no longer need the Insider Edition by the way)&lt;/p>
&lt;h2 id="powershell-in-markdown">PowerShell in Markdown!&lt;/h2>
&lt;p>First, before I go any further, I must say this. I was at the European PowerShell Conference when I was working this out and creating my sessions and I said the words&lt;/p>
&lt;blockquote>
&lt;p>“Cool, I can click a link and run PowerShell, this is neat”&lt;/p>
&lt;p>A Beardy fellow in Hannover&lt;/p>
&lt;/blockquote>
&lt;p>This stopped some red team friends of mine in their tracks and they said “Show me”. One of them was rubbing their hands with glee! You can imagine the sort of wicked, devious things that they were immediately considering doing.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>Yes, it’s funny but also it carries a serious warning. Without understanding what it is doing, please don’t enable PowerShell to be run in a SQL Notebook that someone sent you in an email or you find on a GitHub. In the same way as you don’t open the word document attachment which will get a thousand million trillion europounddollars into your bank account or run code you copy from the internet on production without understanding what it does, this could be a very dangerous thing to do.&lt;/p>
&lt;p>With that warning out of the way, there are loads of really useful and fantastic use cases for this. SQL Notebooks make great run-books or incident response recorders and PowerShell is an obvious tool for this. (If only we could save the PowerShell output in a SQL Notebook, this would be even better)&lt;/p>
&lt;h2 id="how-on-earth-did-you-work-this-out">How on earth did you work this out?&lt;/h2>
&lt;p>Someone asked me how I worked it out. I didn’t! It began with Vicky Harp PM lead for the SQL Tools team at Microsoft&lt;/p>
&lt;blockquote>
&lt;p>Did you know you can add markdown links to open a terminal and paste in a command in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a> notebooks? &lt;a class="link" href="https://t.co/YHX9pIVQco" target="_blank" rel="noopener"
>pic.twitter.com/YHX9pIVQco&lt;/a>&lt;/p>
&lt;p>— Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1128359827128950784?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>May 14, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I then went and looked at &lt;a class="link" href="https://twitter.com/kevcunnane" target="_blank" rel="noopener"
>Kevin Cunnane&lt;/a>‘s notebook. Kevin is a member of the tools team working on Azure Data Studio. With SQL Notebooks, you can double click the markdown cell and see the code that is behind it. To understand how it is working, lets deviate a little.&lt;/p>
&lt;h2 id="keyboard-shortcuts">Keyboard Shortcuts&lt;/h2>
&lt;p>IF you click the cog at the bottom left of Azure Data Studio and choose Keyboard Shortcuts&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image.png"
loading="lazy"
>&lt;/p>
&lt;p>you can make Azure Data Studio (and Visual Studio Code) work exactly how you want it to. Typing in the top box will find a command and you can then set the shortcuts that you want to use to save yourself time.&lt;/p>
&lt;p>&lt;img src="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1" target="_blank" rel="noopener"
>https://i1.wp.com/user-images.githubusercontent.com/6729780/59566321-84233d80-9056-11e9-9643-e9e15e85a2f0.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This also enables you to see the command that is called when you use a keyboard shortcut. For example, you can see that for the focus terminal command it says &lt;code>workbench.action.terminal.focus&lt;/code>.&lt;/p>
&lt;p>It turns out that you can call this as a link in a Markdown document using HTML with &lt;code>&amp;lt;a href=&amp;quot;&amp;quot;&amp;gt;&lt;/code> and adding &lt;code>command:&lt;/code> prior to the command text. When the link is clicked the command will run. Cool 🙂&lt;/p>
&lt;p>For this to be able to work (you read the warning above?) you need to set the Notebook to be trusted by clicking this button.&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?w=630&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1" target="_blank" rel="noopener"
>https://i0.wp.com/user-images.githubusercontent.com/6729780/59566360-365b0500-9057-11e9-87fb-1f8cbbb6e9e2.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>This will allow any command to be run. Of course, people with beards will helpfully advise when this is required for a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/05%20-Working%20with%20dbachecks%20Validation%20Results.ipynb" target="_blank" rel="noopener"
>SQL Notebook&lt;/a>. (Safe to say people attempting nefarious actions will try the same with your users)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Now that we know how to run an Azure Data Studio command using a link in a markdown cell the next step is to run a PowerShell command. I headed to the &lt;a class="link" href="https://code.visualstudio.com/docs/editor/integrated-terminal" target="_blank" rel="noopener"
>Visual Studio Code documentation&lt;/a> and found&lt;/p>
&lt;blockquote>
&lt;p>Send text from a keybinding&lt;br>
The &lt;code>workbench.action.terminal.sendSequence&lt;/code> command can be used to send a specific sequence of text to the terminal, including escape sequence&lt;/p>
&lt;/blockquote>
&lt;p>That’s the command we need, however, we still need to craft the command so that it will work as a link. It needs to be converted into a URL.&lt;/p>
&lt;p>I started by using this website &lt;a class="link" href="https://www.url-encode-decode.com/" target="_blank" rel="noopener"
>https://www.url-encode-decode.com/&lt;/a> to do this. This is &lt;strong>how you can check the code in other peoples notebook, use the decode capability.&lt;/strong>&lt;/p>
&lt;p>Encoding &lt;code>Set-Location C:\dbachecks&lt;/code> gives `Set-Location+C%3A%5Cdbacheck``&lt;/p>
&lt;p>&lt;img src="https://i0.wp.com/user-images.githubusercontent.com/6729780/59567164-e5044300-9061-11e9-802b-7b28c3aee345.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>So I can just put that code into the href link and bingo!&lt;/p>
&lt;p>If only it was that easy!!&lt;/p>
&lt;h2 id="some-replacing-is-required">Some Replacing is required&lt;/h2>
&lt;p>The + needs to be replaced with a space or &lt;code>%20&lt;/code>&lt;/p>
&lt;p>You also need to double the &lt;code>\&lt;/code> and replace the &lt;code>%3A&lt;/code> with a &lt;code>:&lt;/code>&lt;br>
The &lt;code>&amp;quot;&lt;/code> needs to be replaced with &lt;code>\u022&lt;/code>, the &lt;code>'&lt;/code> with &lt;code>\u027&lt;/code>, the curly braces won’t work unless you remove the &lt;code>%0D%0A&lt;/code>. Got all that? Good!&lt;/p>
&lt;p>Once you have written your PowerShell, encoded it, performed the replacements, you add &lt;code>\u000D&lt;/code> at the end of the code to pass an enter to run the code and then place all of that into a link like this&lt;/p>
&lt;p>&lt;code>&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 PLACE THE ENCODED CODE HERE %22%7D&amp;quot;&amp;gt;Link Text&amp;lt;/a&amp;gt;&lt;/code>&lt;/p>
&lt;p>This means that if you want to add the PowerShell code to set a location and then list the files and folders in that location to a Markdown cell using PowerShell like this&lt;/p>
&lt;pre>&lt;code>Set-Location C:\dbachecks
Get-ChildItem
&lt;/code>&lt;/pre>
&lt;p>You would end up with a link like this&lt;/p>
&lt;p>&lt;code>`&amp;lt;a href=&amp;quot;command:workbench.action.terminal.sendSequence?%7B%22text%22%3A%22 Set-Location C:%5C%5Cdbachecks \u000D Get-ChildItem \u000D %22%7D&amp;quot;&amp;gt;Set Location and list files&amp;lt;/a`&lt;/code>&amp;gt;&lt;/p>
&lt;h2 id="doing-something-more-than-once">Doing something more than once?&lt;/h2>
&lt;p>I don’t want to remember that all of the time so I wrote a PowerShell function. You can find it on GitHub &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Functions/blob/master/Convert-ADSPowerShellForMarkdown.ps1&lt;/a>&lt;/p>
&lt;p>This will take a PowerShell command and turn it into a link that will work in an Azure Data Studio markdown. It’s not magic, it’s PowerShell. There is a –&lt;code>ToClipboard&lt;/code> parameter which will copy the code to the clipboard ready for you to paste into the cell (On Windows machines only)&lt;/p>
&lt;h2 id="giants">Giants&lt;/h2>
&lt;p>There are many uses for this but here’s one I think is cool.&lt;/p>
&lt;p>The link below will go to a notebook, which will show how you the giants upon whose shoulders I stand&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/GlennAlanBerry" target="_blank" rel="noopener"
>Glenn Berry&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André&lt;/a> &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>Kamman&lt;/a>,&lt;br>
&lt;a class="link" href="https://twitter.com/spaghettidba" target="_blank" rel="noopener"
>Gianluca Sartori&lt;/a>&lt;/p>
&lt;p>have enabled me to create a SQL Notebook with a link which will run some PowerShell to create a SQL Notebook which will have all of the Diagnostic Queries in it.&lt;/p>
&lt;p>You could possibly use something like it for your incident response SQL Notebook.&lt;/p>
&lt;p>It’s also cool that GitHub renders the notebook in a browser (You can’t run PowerShell or T-SQL from there though, you need Azure Data Studio!)&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/2019/Berlin%20SQL%20User%20Group/04%20-%20Glenn%20Berry%20Notebook.ipynb&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/07/image-4.png"
loading="lazy"
>&lt;/p></description></item><item><title>Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</link><pubDate>Thu, 25 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/azure-sql-linux-vm-configuring-sql-installing-pwsh-and-connecting-and-interacting-with-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-125.png" alt="Featured image of post Azure SQL Linux VM – configuring SQL, installing pwsh and connecting and interacting with dbatools" />&lt;p>In my posts about using Azure Devops to build Azure resources with Terraform, &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>I built a Linux SQL VM.&lt;/a> I used the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>Terraform in this GitHub&lt;/a> repository and created this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-mobaxterm">Connecting with MobaXterm&lt;/h2>
&lt;p>I had set the Network security rules to accept connections only from my static IP using variables in the Build Pipeline. I use &lt;a class="link" href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener"
>MobaXterm&lt;/a> as my SSH client. Its a free download. I click on sessions&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-120.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose a SSH session and fill in the remote host address from the portal&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-121.png"
loading="lazy"
>&lt;/p>
&lt;p>fill in the password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-122.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="configuring-sql">Configuring SQL&lt;/h2>
&lt;p>The next task is to configure the SQL installation. Following the instructions on the &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sql/provision-sql-server-linux-virtual-machine?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Microsoft docs site&lt;/a> I run&lt;/p>
&lt;pre>&lt;code>sudo systemctl stop mssql-server
sudo /opt/mssql/bin/mssql-conf set-sa-password
&lt;/code>&lt;/pre>
&lt;p>enter the sa password and&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-123.png"
loading="lazy"
>&lt;/p>
&lt;p>Now to start SQL&lt;/p>
&lt;pre>&lt;code>sudo systemctl start mssql-server
&lt;/code>&lt;/pre>
&lt;h2 id="installing-pwsh">Installing pwsh&lt;/h2>
&lt;p>Installing PowerShell Core (pwsh) is easy with snap&lt;/p>
&lt;p>sudo snap install powershell &amp;ndash;classic&lt;/p>
&lt;p>A couple of minutes of downloads and install&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-124.png"
loading="lazy"
>&lt;/p>
&lt;p>and pwsh is ready for use&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-125.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="installing-dbatools">Installing dbatools&lt;/h2>
&lt;p>To install &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbatools" target="_blank" rel="noopener"
>Powershell Gallery&lt;/a> simply run&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser&lt;/p>
&lt;p>This will prompt you to allow installing from an untrusted repository&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-126.png"
loading="lazy"
>&lt;/p>
&lt;p>and dbatools is ready to go&lt;/p>
&lt;pre>&lt;code>#Set a credential
$cred = Get-Credential
# Show the databases on the local instance
Get-DbaDatabase -SqlInstance localhost -SqlCredential $cred
&lt;/code>&lt;/pre>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-127.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="connecting-with-azure-data-studio">Connecting with Azure Data Studio&lt;/h2>
&lt;p>I can also connect with Azure Data Studio&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-128.png"
loading="lazy"
>&lt;/p>
&lt;p>and connect&lt;/p>
&lt;p>[&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/p>
&lt;p>Just a quick little post explaining what I did 🙂&lt;/p>
&lt;p>Happy Linuxing!&lt;/p></description></item><item><title>Using Azure DevOps Build Pipeline Templates with Terraform to build an AKS cluster</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/</link><pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-151.png" alt="Featured image of post Using Azure DevOps Build Pipeline Templates with Terraform to build an AKS cluster" />&lt;p>In the last few posts I have moved from &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>building an Azure SQL DB with Terraform using VS Code&lt;/a> to &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>automating the build process for the Azure SQL DB using Azure DevOps Build Pipelines&lt;/a> to &lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>using Task Groups in Azure DevOps to reuse the same Build Process and build an Azure Linux SQL VM and Network Security Group&lt;/a>. This evolution is fantastic but Task Groups can only be used in the same Azure DevOps repository. It would be brilliant if I could use Configuration as Code for the Azure Build Pipeline and store that in a separate source control repository which can be used from any Azure DevOps Project.&lt;/p>
&lt;p>Luckily, you can 😉 You can use &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure DevOps Job Templates&lt;/a> to achieve this. There is a limitation at present, you can only use them for Build Pipelines and not Release Pipelines.&lt;/p>
&lt;p>The aim of this little blog series was to have a single Build Pipeline stored as code which I can use to build any infrastructure that I want with Terraform in Azure and be able to use it anywhere&lt;/p>
&lt;h2 id="creating-a-build-pipeline-template">Creating a Build Pipeline Template&lt;/h2>
&lt;p>I created a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-BuildTemplates" target="_blank" rel="noopener"
>GitHub repository&lt;/a> to hold my Build Templates, feel free to use them as a base for your own but please don’t try and use the repo for your own builds.&lt;/p>
&lt;p>The easiest way to create a Build Template is to already have a Build Pipeline. This cannot be done from a Task Group but I still have the Build Pipeline from my &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>automating the build process for the Azure SQL DB using Azure DevOps Build Pipelines&lt;/a> blog post.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-132.png"
loading="lazy"
>&lt;/p>
&lt;p>There is a View YAML button. I can click this to view the YAML definition of the Build Pipeline&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-133.png"
loading="lazy"
>&lt;/p>
&lt;p>I copy that and paste it into a new file in my BuildTemplates repository. (I have replaced my Azure Subscription information in the public repository)&lt;/p>
&lt;pre>&lt;code> jobs:
- job: Build
pool:
name: Hosted VS2017
demands: azureps
steps:
- task: AzureCLI@1
displayName: 'Azure CLI to deploy azure storage for backend'
inputs:
azureSubscription: 'PUTYOURAZURESUBNAMEHERE'
scriptLocation: inlineScript
inlineScript: |
# the following script will create Azure resource group, Storage account and a Storage container which will be used to store terraform state
call az group create --location $(location) --name $(TerraformStorageRG)
call az storage account create --name $(TerraformStorageAccount) --resource-group $(TerraformStorageRG) --location $(location) --sku Standard_LRS
call az storage container create --name terraform --account-name $(TerraformStorageAccount)
- task: AzurePowerShell@3
displayName: 'Azure PowerShell script to get the storage key'
inputs:
azureSubscription: 'PUTYOURAZURESUBNAMEHERE'
ScriptType: InlineScript
Inline: |
# Using this script we will fetch storage key which is required in terraform file to authenticate backend stoarge account
$key=(Get-AzureRmStorageAccountKey -ResourceGroupName $(TerraformStorageRG) -AccountName $(TerraformStorageAccount)).Value[0]
Write-Host &amp;quot;##vso[task.setvariable variable=TerraformStorageKey]$key&amp;quot;
azurePowerShellVersion: LatestVersion
- task: qetza.replacetokens.replacetokens-task.replacetokens@3
displayName: 'Replace tokens in terraform file'
inputs:
rootDirectory: Build
targetFiles: |
**/*.tf
**/*.tfvars
tokenPrefix: '__'
tokenSuffix: '__'
- powershell: |
Get-ChildItem .\Build -Recurse
Get-Content .\Build\*.tf
Get-Content .\Build\*.tfvars
Get-ChildItem Env: | select Name
displayName: 'Check values in files'
enabled: false
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Initialise Terraform'
inputs:
TemplatePath: Build
Arguments: 'init -backend-config=&amp;quot;0-backend-config.tfvars&amp;quot;'
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Plan Terraform execution'
inputs:
TemplatePath: Build
Arguments: plan
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
- task: petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform.Xpirit-Vsts-Release-Terraform.Terraform@2
displayName: 'Apply Terraform'
inputs:
TemplatePath: Build
Arguments: 'apply -auto-approve'
InstallTerraform: true
UseAzureSub: true
ConnectedServiceNameARM: 'PUTYOURAZURESUBNAMEHERE'
&lt;/code>&lt;/pre>
&lt;p>Now I can use this yaml as configuration as code for my Build Pipeline 🙂 It can be used from any Azure DevOps project. Once you start looking at the code and the &lt;a class="link" href="https://docs.microsoft.com/en-gb/azure/devops/pipelines/yaml-schema?view=azure-devops&amp;amp;tabs=schema?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>documentation for the yaml&lt;/a> schema you can begin to write your pipelines as YAML, but sometimes it is easier to just create build pipeline or even just a job step in the browser and click the view yaml button!&lt;/p>
&lt;h2 id="create-an-aks-cluster-with-a-sql-2019-container-using-terraform-and-build-templates">Create an AKS Cluster with a SQL 2019 container using Terraform and Build templates&lt;/h2>
&lt;p>I have a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AKS" target="_blank" rel="noopener"
>GitHub Repository with the Terraform code to build a simple AKS cluster&lt;/a>. This could not have been achieved without &lt;a class="link" href="https://azurecitadel.com/automation/terraform/lab8/" target="_blank" rel="noopener"
>Richard Cheney’s article&lt;/a> I am not going to explain how it all works for this blog post or some of the negatives of doing it this way. Instead lets build an Azure DevOps Build Pipeline to build it with Terraform using Configuration as Code (the yaml file)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-134.png"
loading="lazy"
>&lt;/p>
&lt;p>I am going to create a new Azure DevOps Build Pipeline and as in the previous posts connect it to the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AKS" target="_blank" rel="noopener"
>GitHub Repository holding the Terraform code&lt;/a>.&lt;/p>
&lt;p>This time I am going to choose the Configuration as code template&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-135.png"
loading="lazy"
>&lt;/p>
&lt;p>I am going to give it a name and it will show me that it needs the path to the yaml file containing the build definition in the current repository.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-136.png"
loading="lazy"
>&lt;/p>
&lt;p>Clicking the 3 ellipses will pop-up a file chooser and I pick the build.yaml file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-137.png"
loading="lazy"
>&lt;/p>
&lt;p>The build.yaml file looks like this. The name is the USER/Repository Name and the endpoint is the name of the endpoint for the GitHub service connection in Azure DevOps. The template value is the name of the build yaml file @ the name given for the repository value.&lt;/p>
&lt;pre>&lt;code> resources:
repositories:
- repository: templates
type: GitHub
name: SQLDBAWithABeard/Presentations-BuildTemplates-Private
endpoint: SQLDBAWithABeardGitHub
jobs:
- template: AzureTerraform.yaml@templates # Template reference
&lt;/code>&lt;/pre>
&lt;p>You can find (and change) your GitHub service connection name by clicking on the cog bottom left in Azure DevOps and clicking service connections&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-140.png"
loading="lazy"
>&lt;/p>
&lt;p>I still need to create my variables for my Terraform template (perhaps I can now just leave those in my code?) For the AKS Cluster build right now I have to add presentation, location, ResourceGroupName, AgentPoolName, ServiceName, VMSize, agent_count&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-139.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I click save and queue and the job starts running&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-141.png"
loading="lazy"
>&lt;/p>
&lt;p>If I want to edit the pipeline it looks a little different&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-152.png"
loading="lazy"
>&lt;/p>
&lt;p>The variables and triggers can be found under the 3 ellipses on the top right&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-153.png"
loading="lazy"
>&lt;/p>
&lt;p>It also defaults the trigger to automatic deployment.&lt;/p>
&lt;p>It takes a bit longer to build&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-142.png"
loading="lazy"
>&lt;/p>
&lt;p>and when I get the Terraform code wrong and the build fails, I can just alter the code, commit it, push and a new build will start and the Terraform will work out what is built and what needs to be built!&lt;/p>
&lt;p>but eventually the job finishes successfully&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-143.png"
loading="lazy"
>&lt;/p>
&lt;p>and the resources are built&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-144.png"
loading="lazy"
>&lt;/p>
&lt;p>and in Visual Studio Code with the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-kubernetes-tools.vscode-kubernetes-tools" target="_blank" rel="noopener"
>Kubernetes extension&lt;/a> installed I can connect to the cluster by clicking the 3 ellipses and Add Existing Cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-145.png"
loading="lazy"
>&lt;/p>
&lt;p>I choose Azure Kubernetes Services and click next&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-146.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose my subscription and then add the cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-147.png"
loading="lazy"
>&lt;/p>
&lt;p>and then I can explore my cluster&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-148.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see the dashboard by right clicking on the cluster name and Open Dashboard&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-150.png"
loading="lazy"
>&lt;/p>
&lt;p>Right clicking on the service name and choosing describe&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-149.png"
loading="lazy"
>&lt;/p>
&lt;p>shows the external IP address, which I can put into Azure Data Studio and connect to my container&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-151.png"
loading="lazy"
>&lt;/p>
&lt;p>So I now I can source control my Build Job Steps and hold them in a central repository. I can make use of them in any project. This gives me much more control and saves me from repeating myself repeating myself. The disadvantage is that there is no handy warning when I change the underlying Build Repository that I will be affecting other Build Pipelines and there is no easy method to see which Build Pipelines are dependent on the build yaml file&lt;/p>
&lt;p>Happy Automating&lt;/p></description></item><item><title>Using the same Azure DevOps build steps for Terraform with different Pipelines with Task Groups to build an Azure Linux SQL VM</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups-to-build-an-azure-linux-sql-vm/</link><pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups-to-build-an-azure-linux-sql-vm/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-107.png" alt="Featured image of post Using the same Azure DevOps build steps for Terraform with different Pipelines with Task Groups to build an Azure Linux SQL VM" />&lt;p>In my &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>last post&lt;/a> I showed how to build an Azure DevOps Pipeline for a Terraform build of an Azure SQLDB. This will take the terraform code and build the required infrastructure.&lt;/p>
&lt;p>The plan all along has been to enable me to build &lt;em>different&lt;/em> environments depending on the requirement. Obviously I can repeat the steps from the last post for a new repository containing a Terraform code for a different environment but&lt;/p>
&lt;blockquote>
&lt;p>If you are going to do something more than once Automate It&lt;/p>
&lt;p>who first said this? Anyone know?&lt;/p>
&lt;/blockquote>
&lt;p>The build steps for building the Terraform are the same each time (if I keep a standard folder and naming structure) so it would be much more beneficial if I could keep them in a single place and any alterations to the process only need to be made in the one place 🙂&lt;/p>
&lt;h2 id="task-groups">Task Groups&lt;/h2>
&lt;p>Azure DevOps has task groups. On &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/task-groups?view=azure-devops?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>the Microsoft Docs web-page&lt;/a> they are described as&lt;/p>
&lt;blockquote>
&lt;p>A &lt;em>task group&lt;/em> allows you to encapsulate a sequence of tasks, already defined in a build or a release pipeline, into a single reusable task that can be added to a build or release pipeline, just like any other tas&lt;/p>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/task-groups?view=azure-devops?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://docs.microsoft.com/en-us/azure/devops/pipelines/library/task-groups?view=azure-devops&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>If you are doing this with a more complicated existing build pipeline it is important that &lt;a class="link" href="https://docs.microsoft.com/en-us/azure/devops/pipelines/library/task-groups?view=azure-devops?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>you read the Before You Create A Task Group on the docs pag&lt;/a>e. This will save you time when trying to understand why variables are not available (Another grey hair on my beard!)&lt;/p>
&lt;h2 id="creating-a-task-group">Creating A Task Group&lt;/h2>
&lt;p>Here’s the thing, creating a task group is so easy it should be the default way you create Azure DevOps Pipelines. Let me walk you through it&lt;/p>
&lt;p>I will use the Build Pipeline from the previous post. Click edit from the build page&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-92.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-92.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then CTRL and click to select all of the steps&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-93.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-93.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Right Click and theres a Create Task Group button to click !&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-94.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-94.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see that it has helpfully added the values for the parameters it requires for the location, Storage Account and the Resource Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-95.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-95.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Remember the grey beard hair above? We need to change those values to use the variables that we will add to the Build Pipeline using&lt;/p>
&lt;pre>&lt;code>$(VariableName)
&lt;/code>&lt;/pre>
&lt;p>Once you have done that click Create&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-96.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-96.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This will also alter the current Build Pipeline to use the Task Group. Now we have a Task Group that we can use in any build pipeline in this project.&lt;/p>
&lt;h2 id="using-the-task-group-with-a-new-build-pipeline-to-build-an-azure-linux-sql-vm">Using the Task Group with a new Build Pipeline to build an Azure Linux SQL VM&lt;/h2>
&lt;p>Lets re-use the build steps to create an Azure SQL Linux VM. First I created a &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLVM" target="_blank" rel="noopener"
>new GitHub Repository&lt;/a> for my Terraform code. Using the docs I created the Terraform to create a resource group, a Linux SQL VM, a virtual network, a subnet, a NIC for the VM, a public IP for the VM, a network security group with two rules, one for SQL and one for SSH. It will look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-114.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The next step is to choose the repository&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-98.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-98.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>again we are going to select Empty job (although the next post will be about the Configuration as Code 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-99.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-99.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>As before&lt;/a> we will name the Build Pipeline and the Agent Job Step and click the + to add a new task. This time we will search for the Task Group name that we created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-100.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-100.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I need to add in the variables from the variable.tf in the code and also for the Task Group&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-117.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-117.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and when I click save and queue&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-102.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-102.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>It runs for less than 7 minutes&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-118.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-118.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and when I look in the Azure portal&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-119.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-119.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and I can connect in Azure Data Studio&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-129.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="altering-the-task-group">Altering The Task Group&lt;/h2>
&lt;p>You can find the Task Groups under Pipelines in your Azure DevOps project&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-97.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-97.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click on the Task Group that you have created and then you can alter, edit it if required and click save&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-107.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-107.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This will warn you that any changes will affect all pipelines and task groups that are using this task group. To find out what will be affected click on references&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-108.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-108.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>which will show you what will be affected.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-109.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-109.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now I can run the same build steps for any Build Pipeline and alter them all in a single place using Task Groups simplifying the administration of the Build Pipelines.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/" target="_blank" rel="noopener"
>The next post will show how to use Azure DevOps templates to use the same build steps across many projects and build pipelines and will build a simple AKS cluster&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>The first post showed how to build an Azure SQLDB with Terraform using VS Code&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>The second post showed how to use Azure DevOps Task Groups to use the same build steps in multiple pipelines and build an Azure Linux SQL Server VM&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Building Azure SQL Db with Terraform using Azure DevOps</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-using-azure-devops/</link><pubDate>Sat, 20 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-using-azure-devops/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-49.png" alt="Featured image of post Building Azure SQL Db with Terraform using Azure DevOps" />&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>my last post&lt;/a> I showed how to create a Resource Group and an Azure SQL Database with Terraform using Visual Studio Code to deploy.&lt;/p>
&lt;p>Of course, I haven&amp;rsquo;t stopped there, who wants to manually run code to create things. There was a lot of install this and set up that. I would rather give the code to a build system and get it to run it. I can then even set it to automatically deploy new infrastructure when I commit some code to alter the configuration.&lt;/p>
&lt;p>This scenario though is to build environments for presentations. Last time I created an Azure SQL DB and tagged it with DataInDevon (By the way you can get tickets for &lt;a class="link" href="http://dataindevon.co.uk" target="_blank" rel="noopener"
>Data In Devon here&lt;/a> – It is in Exeter on April 26th and 27th)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If I want to create the same environment but give it tags for a different event (This way I know when I can delete resources in Azure!) or name it differently, I can use Azure DevOps and alter the variables. I could just alter the code and commit the change and trigger a build or I could create variables and enable them to be set at the time the job is run. I use the former in “work” situations and the second for my presentations environment.&lt;/p>
&lt;p>I have created a project in &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/devops/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure DevOps&lt;/a> for my Presentation Builds. I will be using GitHub to share the code that I have used. Once I clicked on pipelines, this is the page I saw&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-51.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-51.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Clicking new pipeline, Azure DevOps asked me where my code was&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-52.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-52.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I chose GitHub, authorised and chose the repository.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-53.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-53.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I then chose Empty Job on the next page. See the Configuration as code choice? We will come back to that later and our infrastructure as code will be deployed with a configuration as code 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-54.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-54.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The next page allows us to give the build a good name and choose the Agent Pool that we want to use. Azure DevOps gives 7 different hosted agents running Linux, Mac, Windows or you can download an agent and run it on your own cpus. We will use the default agent for this process.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-55.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-55.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Clicking on Agent Job 1 enables me to change the name of the Agent Job. I could also choose a different type of Agent for different jobs within the same pipeline. This would be useful for testing different OS’s for example but for right now I shall just name it properly.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-65.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-65.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="state">State&lt;/h2>
&lt;p>First we need somewhere to store the state of our build so that if we re-run it the Terraform plan step will be able to work out what it needs to do. (This is not absolutely required just for building my presentation environments and this might not be the best way to achieve this but for right now this is what I do and it works.)&lt;/p>
&lt;p>I click on the + and search for Azure CLI.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-58.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-58.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and click on the Add button which gives me some boxes to fill in.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-59.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-59.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I choose my Azure subscription from the first drop down and choose Inline Script from the second&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-60.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-60.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Inside the script block I put the following code&lt;/p>
&lt;pre>&lt;code># the following script will create Azure resource group, Storage account and a Storage container which will be used to store terraform state
call az group create --location $(location) --name $(TerraformStorageRG)
call az storage account create --name $(TerraformStorageAccount) --resource-group $(TerraformStorageRG) --location $(location) --sku Standard_LRS
call az storage container create --name terraform --account-name $(TerraformStorageAccount)
&lt;/code>&lt;/pre>
&lt;p>This will create a Resource Group, a storage account and a container and use some variables to provide the values, we will come back to the variables later.&lt;/p>
&lt;h2 id="access-key">Access Key&lt;/h2>
&lt;p>The next thing that we need to do is to to enable the job to be able to access the storage account. We don’t want to store that key anywhere but we can use our Azure DevOps variables and some PowerShell to gather the access key and write it to the variable when the job is running . To create the variables I clicked on the variables tab&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-66.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-66.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and then added the variables with the following names TerraformStorageRG, TerraformStorageAccount and location from the previous task and TerraformStorageKey for the next task.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-62.png"
loading="lazy"
>&lt;/p>
&lt;p>With those created, I go back to Tasks and add an Azure PowerShell task&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-63.png"
loading="lazy"
>&lt;/p>
&lt;p>I then add this code to get the access key and overwrite the variable.&lt;/p>
&lt;pre>&lt;code># Using this script we will fetch storage key which is required in terraform file to authenticate backend storage account
$key=(Get-AzureRmStorageAccountKey -ResourceGroupName $(TerraformStorageRG) -AccountName $(TerraformStorageAccount)).Value[0]
Write-Host &amp;quot;##vso[task.setvariable variable=TerraformStorageKey]$key&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-67.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-67.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="infrastructure-as-code">Infrastructure as Code&lt;/h2>
&lt;p>In &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLDB" target="_blank" rel="noopener"
>my GitHub repository&lt;/a> I now have the following folders&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-64.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-64.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The manual folders hold the code &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>from the last blog post&lt;/a>. In the Build folder, the main.tf file is identical and looks like this.&lt;/p>
&lt;pre>&lt;code>provider &amp;quot;azurerm&amp;quot; {
version = &amp;quot;=1.24.0&amp;quot;
}
terraform {
backend &amp;quot;azurerm&amp;quot; {
key = &amp;quot;terraform.tfstate&amp;quot;
}
}
resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.ResourceGroupName}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_server&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlServerName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group.presentation.name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
version = &amp;quot;12.0&amp;quot;
administrator_login = &amp;quot;__SQLServerAdminUser__&amp;quot;
administrator_login_password = &amp;quot;__SQLServerAdminPassword__&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_database&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlDatabaseName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_sql_server.presentation.resource_group_name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
server_name = &amp;quot;${azurerm_sql_server.presentation.name}&amp;quot;
edition = &amp;quot;${var.Edition}&amp;quot;
requested_service_objective_name = &amp;quot;${var.ServiceObjective}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>The variables.tf folder looks like this.&lt;/p>
&lt;pre>&lt;code>variable &amp;quot;presentation&amp;quot; {
description = &amp;quot;The name of the presentation - used for tagging Azure resources so I know what they belong to&amp;quot;
default = &amp;quot;__Presentation__&amp;quot;
}
variable &amp;quot;ResourceGroupName&amp;quot; {
description = &amp;quot;The Prefix used for all resources in this example&amp;quot;
default = &amp;quot;__ResourceGroupName__&amp;quot;
}
variable &amp;quot;location&amp;quot; {
description = &amp;quot;The Azure Region in which the resources in this example should exist&amp;quot;
default = &amp;quot;__location__&amp;quot;
}
variable &amp;quot;SqlServerName&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server to be created or to have the database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;__SqlServerName__&amp;quot;
}
variable &amp;quot;SQLServerAdminUser&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server Admin user for the Azure SQL Database&amp;quot;
default = &amp;quot;__SQLServerAdminUser__&amp;quot;
}
variable &amp;quot;SQLServerAdminPassword&amp;quot; {
description = &amp;quot;The Azure SQL Database users password&amp;quot;
default = &amp;quot;__SQLServerAdminPassword__&amp;quot;
}
variable &amp;quot;SqlDatabaseName&amp;quot; {
description = &amp;quot;The name of the Azure SQL database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;__SqlDatabaseName__&amp;quot;
}
variable &amp;quot;Edition&amp;quot; {
description = &amp;quot;The Edition of the Database - Basic, Standard, Premium, or DataWarehouse&amp;quot;
default = &amp;quot;__Edition__&amp;quot;
}
variable &amp;quot;ServiceObjective&amp;quot; {
description = &amp;quot;The Service Tier S0, S1, S2, S3, P1, P2, P4, P6, P11 and ElasticPool&amp;quot;
default = &amp;quot;__ServiceObjective__&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>It is exactly the same except that the values have been replaced by the value name prefixed and suffixed with __. This will enable me to replace the values with the variables in my Azure DevOps Build job.&lt;/p>
&lt;p>The backend-config.tf file will store the details of the state that will be created by the first step and use the access key that has been retrieved in the second step.&lt;/p>
&lt;pre>&lt;code>resource_group_name = &amp;quot;__TerraformStorageRG__&amp;quot;
storage_account_name = &amp;quot;__TerraformStorageAccount__&amp;quot;
container_name = &amp;quot;terraform&amp;quot;
access_key = &amp;quot;__TerraformStorageKey__&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>I need to add the following variables to my Azure DevOps Build – Presentation, ResourceGroupName, SqlServerName, SQLServerAdminUser, SQLServerAdminPassword, SqlDatabaseName, Edition, ServiceObjective . Personally I would advise setting the password or any other sensitive values to sensitive by clicking the padlock for that variable. This will stop the value being written to the log as well as hiding it behind *’s&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-69.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-69.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Because I have tagged the variables with Settable at queue time , I can set the values whenever I run a build, so if I am at a different event I can change the name.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-70.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-70.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>But the build job hasn’t been set up yet. First we need to replace the values in the variables file.&lt;/p>
&lt;h2 id="replace-the-tokens">Replace the Tokens&lt;/h2>
&lt;p>I installed the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=qetza.replacetokens" target="_blank" rel="noopener"
>Replace Tokens Task&lt;/a> from the marketplace and added that to the build.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-72.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-72.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I am going to use a standard naming convention for my infrastructure code files so I add Build to the Root Directory. You can also click the ellipses and navigate to a folder in your repo. In the Target Files I add &lt;em>”&lt;/em>&lt;em>/*&lt;/em>.tf” and “&lt;strong>&lt;em>/*&lt;/em>.tfvars” which will search all of the folders (&lt;/strong>) and only work on files with a .tf or .tfvars extension (/*.tfvars) The next step is to make sure that the replacement prefix and suffix are correct. It is hidden under Advanced&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-74.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-74.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Because I often forget this step and to aid in troubleshooting I add another step to read the contents of the files and place them in the logs. I do this by adding a PowerShell step which uses&lt;/p>
&lt;pre>&lt;code>Get-ChildItem .\Build -Recurse
Get-Content .\Build\*.tf
Get-Content .\Build\*.tfvars
&lt;/code>&lt;/pre>
&lt;p>Under control options there is a check box to enable or disable the steps so once I know that everything is ok with the build I will disable this step. The output in the log of a build will look like this showing the actual values in the files. This is really useful for finding spaces :-).&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-76.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-76.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-terraform-in-azure-devops">Running the Terraform in Azure DevOps&lt;/h2>
&lt;p>With everything set up we can now run the Terraform. I installed the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=petergroenewegen.PeterGroenewegen-Xpirit-Vsts-Release-Terraform" target="_blank" rel="noopener"
>Terraform task&lt;/a> from the marketplace and added a task. We are going to follow the same process as the last blog post, init, plan, apply but this time we are going to automate it 🙂&lt;/p>
&lt;p>First we will initialise&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-130.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-130.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I put Build in the Terraform Template path. The Terraform arguments are&lt;/p>
&lt;pre>&lt;code>init -backend-config=&amp;quot;0-backend-config.tfvars&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>which will tell the Terraform to use the backend-config.tfvars file for the state. It is important to tick the Install terraform checkbox to ensure that terraform is available on the agent and to add the Azure Subscription (or Service Endpoint in a corporate environment&lt;/p>
&lt;p>After the Initialise, I add the Terraform task again add Build to the target path and this time the argument is plan&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-78.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-78.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Again, tick the install terraform checkbox and also the Use Azure Service Endpoint and choose the Azure Subscription.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-131.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-131.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>We also need to tell the Terraform where to find the tfstate file by specifying the variables for the resource group and storage account and the container&lt;/p>
&lt;p>Finally, add another Terraform task for the apply remembering to tick the install Terraform and Use Azure checkboxes&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-79.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-79.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The arguments are&lt;/p>
&lt;pre>&lt;code>apply -auto-approve
&lt;/code>&lt;/pre>
&lt;p>This will negate the requirement for the “Only “yes” will be accepted to approve” &lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>from the manual steps post&lt;/a>!&lt;/p>
&lt;h2 id="build-a-thing">Build a Thing&lt;/h2>
&lt;p>Now we can build the environment – Clicking Save and Queue&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-80.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-80.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>opens this dialogue&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-81.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-81.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>where the variables can be filled in.&lt;/p>
&lt;p>The build will be queued and clicking on the build number will open the logs&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-82.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-82.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-83.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-83.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>6 minutes later the job has finished&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-84.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-84.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and the resources have been created.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-85.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-85.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If I want to look in the logs of the job I can click on one of the steps and take a look. This is the apply step&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-87.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-87.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="do-it-again-for-another-presentation">Do it Again For Another Presentation&lt;/h2>
&lt;p>So that is good, I can create my environment as I want it. Once my presentation has finished I can delete the Resource Groups. When I need to do the presentation again, I can queue another build and change the variables&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-88.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-88.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-89.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-89.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The job will run&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-90.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-90.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and the new resource group will be created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-91.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-91.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>all ready for my next presentation 🙂&lt;/p>
&lt;p>This is brilliant, I can set up the same solution for different repositories for different presentations (infrastructure) and recreate the above steps.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>The next post will show how to use Azure DevOps Task Groups to use the same build steps in multiple pipelines and build an Azure Linux SQL Server VM&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/" target="_blank" rel="noopener"
>The post after that will show how to use Azure DevOps templates to use the same build steps across many projects and build pipelines and will build a simple AKS cluster&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-with-visual-studio-code/" target="_blank" rel="noopener"
>The first post showed how to build an Azure SQL Database with Terraform using VS Code&lt;/a>&lt;/p></description></item><item><title>Building Azure SQL Db with Terraform with Visual Studio Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-with-visual-studio-code/</link><pubDate>Wed, 17 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/building-azure-sql-db-with-terraform-with-visual-studio-code/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-42.png" alt="Featured image of post Building Azure SQL Db with Terraform with Visual Studio Code" />&lt;p>I have been using &lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>Terraform&lt;/a> for the last week or so to create some infrastructure and decided to bring that knowledge back to a problem that I and others suffer from – building environments for presentations, all for the sake of doing some learning.&lt;/p>
&lt;h2 id="what-is-terraform">What is Terraform?&lt;/h2>
&lt;p>According to the website&lt;/p>
&lt;blockquote>
&lt;p>HashiCorp Terraform enables you to safely and predictably create, change, and improve infrastructure. It is an open source tool that codifies APIs into declarative configuration files that can be shared amongst team members, treated as code, edited, reviewed, and versioned&lt;/p>
&lt;p>&lt;a class="link" href="https://www.terraform.io/" target="_blank" rel="noopener"
>https://www.terraform.io/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>This means that I can define my infrastructure as code. If I can do that then I can reliably do the same thing again and again, at work to create environments that have the same configuration or outside of work to repeatedly build the environment I need.&lt;/p>
&lt;h2 id="building-an-azure-sql-database-with-terraform">Building an Azure SQL Database with Terraform&lt;/h2>
&lt;p>To understand how to build a thing the best place to start is the documentation &lt;a class="link" href="https://www.terraform.io/docs" target="_blank" rel="noopener"
>https://www.terraform.io/docs&lt;/a> . For an &lt;a class="link" href="https://www.terraform.io/docs/providers/azurerm/r/sql_database.html" target="_blank" rel="noopener"
>Azure SQL Db in the docs&lt;/a> you will find a block of code that looks like this&lt;/p>
&lt;pre>&lt;code> resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;acceptanceTestResourceGroup1&amp;quot;
location = &amp;quot;West US&amp;quot;
}
resource &amp;quot;azurerm_sql_server&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;mysqlserver&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group.test.name}&amp;quot;
location = &amp;quot;West US&amp;quot;
version = &amp;quot;12.0&amp;quot;
administrator_login = &amp;quot;4dm1n157r470r&amp;quot;
administrator_login_password = &amp;quot;4-v3ry-53cr37-p455w0rd&amp;quot;
}
resource &amp;quot;azurerm_sql_database&amp;quot; &amp;quot;test&amp;quot; {
name = &amp;quot;mysqldatabase&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group.test.name}&amp;quot;
location = &amp;quot;West US&amp;quot;
server_name = &amp;quot;${azurerm_sql_server.test.name}&amp;quot;
tags = {
environment = &amp;quot;production&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>If you read the code, you can see that there are key value pairs defining information about the resource that is being created. Anything inside a ${} is a dynamic reference. So&lt;/p>
&lt;p>resource_group_name = &amp;ldquo;${azurerm_resource_group.test.name}&amp;rdquo;
refers to the name property in the azure_resource_group block called test (or the name of the resource group 🙂 )&lt;/p>
&lt;h2 id="infrastructure-as-code">Infrastructure As Code&lt;/h2>
&lt;p>So I can put that code into a file (name it main.tf) and alter it with the values and “run Terraform” and what I want will be created. Lets take it a step further though because I want to be able to reuse this code. Instead of hard-coding all of the values I am going to use variables. I can do this by creating another file called variables.tf which looks like&lt;/p>
&lt;pre>&lt;code> variable &amp;quot;presentation&amp;quot; {
description = &amp;quot;The name of the presentation - used for tagging Azure resources so I know what they belong to&amp;quot;
default = &amp;quot;dataindevon&amp;quot;
}
variable &amp;quot;ResourceGroupName&amp;quot; {
description = &amp;quot;The Resource Group Name&amp;quot;
default = &amp;quot;beardrules&amp;quot;
}
variable &amp;quot;location&amp;quot; {
description = &amp;quot;The Azure Region in which the resources in this example should exist&amp;quot;
default = &amp;quot;uksouth&amp;quot;
}
variable &amp;quot;SqlServerName&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server to be created or to have the database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;jeremy&amp;quot;
}
variable &amp;quot;SQLServerAdminUser&amp;quot; {
description = &amp;quot;The name of the Azure SQL Server Admin user for the Azure SQL Database&amp;quot;
default = &amp;quot;Beard&amp;quot;
}
variable &amp;quot;SQLServerAdminPassword&amp;quot; {
description = &amp;quot;The Azure SQL Database users password&amp;quot;
default = &amp;quot;JonathanlovesR3ge%&amp;quot;
}
variable &amp;quot;SqlDatabaseName&amp;quot; {
description = &amp;quot;The name of the Azure SQL database on - needs to be unique, lowercase between 3 and 24 characters including the prefix&amp;quot;
default = &amp;quot;jsdb&amp;quot;
}
variable &amp;quot;Edition&amp;quot; {
description = &amp;quot;The Edition of the Database - Basic, Standard, Premium, or DataWarehouse&amp;quot;
default = &amp;quot;Standard&amp;quot;
}
variable &amp;quot;ServiceObjective&amp;quot; {
description = &amp;quot;The Service Tier S0, S1, S2, S3, P1, P2, P4, P6, P11 and ElasticPool&amp;quot;
default = &amp;quot;S0&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>and my main.tf then looks like this.&lt;/p>
&lt;pre>&lt;code>provider &amp;quot;azurerm&amp;quot; {
version = &amp;quot;=1.24.0&amp;quot;
}
resource &amp;quot;azurerm_resource_group&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.ResourceGroupName}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_server&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlServerName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_resource_group. presentation.name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
version = &amp;quot;12.0&amp;quot;
administrator_login = &amp;quot;${var.SQLServerAdminUser}&amp;quot;
administrator_login_password = &amp;quot;${var.SQLServerAdminPassword} &amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
resource &amp;quot;azurerm_sql_database&amp;quot; &amp;quot;presentation&amp;quot; {
name = &amp;quot;${var.SqlDatabaseName}&amp;quot;
resource_group_name = &amp;quot;${azurerm_sql_server.presentation. resource_group_name}&amp;quot;
location = &amp;quot;${var.location}&amp;quot;
server_name = &amp;quot;${azurerm_sql_server.presentation. name}&amp;quot;
edition = &amp;quot;${var.Edition}&amp;quot;
requested_service_objective_name = &amp;quot;${var.ServiceObjective}&amp;quot;
tags = {
environment = &amp;quot;${var.presentation}&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>You can find these files in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations-AzureSQLDB/tree/master/Manual" target="_blank" rel="noopener"
>GitHub Repository&lt;/a> here.&lt;/p>
&lt;h2 id="alright--deploy-something">Alright – deploy something&lt;/h2>
&lt;p>To deploy the code that I have written I need to download Terraform from &lt;a class="link" href="https://www.terraform.io/downloads.html" target="_blank" rel="noopener"
>https://www.terraform.io/downloads.html&lt;/a> and then extract the exe to a folder in my PATH. (I chose C:\Windows). Then in Visual Studio Code I installed two extensions The &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=mauve.terraform" target="_blank" rel="noopener"
>Terraform Extension by Mikael Olenfalk&lt;/a> which enables syntax highlighting and auto-completion for the tf files and the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azureterraform" target="_blank" rel="noopener"
>Azure Terraform&lt;/a> extension. You will need also need &lt;a class="link" href="https://nodejs.org/en/" target="_blank" rel="noopener"
>Node.js from here&lt;/a>.&lt;/p>
&lt;p>With those in place I navigated to the directory holding my files in Visual Studio Code and pressed F1 and started typing azure terraform and chose Azure Terraform Init&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-39.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-39.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I was then prompted to use Cloud Shell and a browser opened to login. Once I had logged in I waited until I saw this&lt;/p>
&lt;p>&lt;a class="link" href="blob:https://blog.robsewell.com/787b935b-930a-45c4-ac43-18a18193e01f" >&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-40.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I press F1 again and this time choose Azure Terraform plan. This is going to show me what Terraform is going to do if it applies this configuration.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-41.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-41.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see the what is going to be created. It is going to create 3 things&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-42.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-42.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Once you have checked that the plan is what you want, press F1 again and choose Azure Terraform Apply&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-43.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-43.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You are then asked to confirm that this is what you want. Only “yes” will be accepted. Then you will see the infrastructure being created&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-44.png"
loading="lazy"
>&lt;/p>
&lt;p>and a minute later&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-45.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-45.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and Jeremy exists in the beardrules resource group&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-49.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then once I have finished with using the sqlinstance. I can press F1 again and choose Azure Terraform Destroy. Again there is a confirmation required.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/04/image-47.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-47.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and you will see the progress for 46 seconds&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-50.png"
loading="lazy"
>&lt;/p>
&lt;p>and all of the resources have gone.&lt;/p>
&lt;p>Thats a good start. This enables me to create resources quickly and easily and keep the configuration for them safely in source control and easy to use.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/building-azure-sql-db-with-terraform-using-azure-devops/" target="_blank" rel="noopener"
>In my next post I will create an Azure DevOps pipeline to deploy an AZure SQL Db withTerraform&lt;/a>.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-the-same-azure-devops-build-steps-for-terraform-with-different-pipelines-with-task-groups/" target="_blank" rel="noopener"
>The post after will show how to use Azure DevOps Task Groups to use the same build steps in multiple pipelines and build an Azure Linux SQL Server VM&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/using-azure-devops-build-pipeline-templates-with-terraform-to-build-an-aks-cluster/" target="_blank" rel="noopener"
>The post after that will show how to use Azure DevOps templates to use the same build steps across many projects and build pipelines and will build a simple AKS cluster&lt;/a>&lt;/p></description></item><item><title>Adding a Folder of Scripts to GitHub with Azure Data Studio</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github-with-azure-data-studio/</link><pubDate>Sun, 07 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github-with-azure-data-studio/</guid><description>&lt;p>In my last post I showed how to &lt;a class="link" href="https://blog.robsewell.com/10501/" target="_blank" rel="noopener"
>add a folder of scripts to GitHub&lt;/a> using Visual Studio Code.&lt;/p>
&lt;p>You can do it with Azure Data Studio as well. It’s exactly the same steps!&lt;/p>
&lt;p>The blog post could end here but read on for some screen shots 😉&lt;/p>
&lt;p>Follow the previous post for details of setting up a new GitHub account&lt;/p>
&lt;p>Create a repository in GitHub&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-27.png"
loading="lazy"
>&lt;/p>
&lt;p>Open the folder in Azure Data Studio with CTRL K CTRL O (Or File –&amp;gt; Open Folder)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-28.png"
loading="lazy"
>&lt;/p>
&lt;p>Click on the Source Control icon or CTRL + SHIFT + G and then Initialize Repository&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-29.png"
loading="lazy"
>&lt;/p>
&lt;p>Choose the folder&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-30.png"
loading="lazy"
>&lt;/p>
&lt;p>Write a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-31.png"
loading="lazy"
>&lt;/p>
&lt;p>Say yes to the prompt. Press CTRL + ‘ to open the terminal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-32.png"
loading="lazy"
>&lt;/p>
&lt;p>Navigate to the scripts folder. (I have a PSDrive set up to my Git folder)&lt;/p>
&lt;pre>&lt;code>Set-Location GIT:\\ADS-Scripts\
&lt;/code>&lt;/pre>
&lt;p>and copy the code from the GitHub page after “…or push an existing repository from the command line”&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-33.png"
loading="lazy"
>&lt;/p>
&lt;p>and run it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-34.png"
loading="lazy"
>&lt;/p>
&lt;p>and there are your scripts in GitHub&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-35.png"
loading="lazy"
>&lt;/p>
&lt;p>Make some changes to a script and it will go muddy brown&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-36.png"
loading="lazy"
>&lt;/p>
&lt;p>and then write a commit message. If you click on the file name in the source control tab then you can see the changes that have been made, that are not currently tracked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-37.png"
loading="lazy"
>&lt;/p>
&lt;p>Commit the change with CTRL + ENTER and then click the roundy-roundy icon (seriously anyone know its name ?) click yes on the prompt and your changes are in GitHub as well 🙂&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/04/image-38.png"
loading="lazy"
>&lt;/p>
&lt;p>Realistically, you can use the previous post to do this with Azure Data Studio as it is built on top of Visual Studio Code but I thought it was worth showing the steps in Azure Data Studio.&lt;/p>
&lt;p>Happy Source Controlling&lt;/p></description></item><item><title>Adding a Folder of Scripts to GitHub</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</link><pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-folder-of-scripts-to-github/</guid><description>&lt;p>Yesterday there was a tweet from Allen White.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/SQLRunr/status/1113862196201758720" target="_blank" rel="noopener"
>https://twitter.com/SQLRunr/status/1113862196201758720&lt;/a>&lt;/p>
&lt;p>Allen wanted to add his scripts folder to source control but didn&amp;rsquo;t have a how to do it handy. So I thought I would write one. Hopefully this will enable someone new to GitHub and to source control get a folder of scripts under source control&lt;/p>
&lt;h2 id="github-account">GitHub account&lt;/h2>
&lt;p>If you do not have a GitHub account go to &lt;a class="link" href="https://github.com" target="_blank" rel="noopener"
>https://github.com&lt;/a> and create a new account&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>There is a funky are you a human challenge&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-1.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then you can choose your subscription&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-2.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then answer some questions (Note - you probably want to choose different answers to the what are you interested in question! I&amp;rsquo;d suggest something technical)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-3.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You need to do the email verification&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-4.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Next is a very important step - Please do not skip this. You should set up 2 factor authentication. Yes even if &amp;ldquo;It&amp;rsquo;s just for me there is nothing special here&amp;rdquo;&lt;/p>
&lt;p>Click your user icon top right and then settings&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-5.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then click set up two factor authentication&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-6.png?fit=630%2C365&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and either set up with an app or via SMS (I suggest the app is better)&lt;/p>
&lt;p>OK - Now you have your GitHub account set up. It should have taken you less time than reading this far.&lt;/p>
&lt;h2 id="add-a-scripts-folder-to-github">Add a Scripts Folder to GitHub&lt;/h2>
&lt;p>OK, Now to add a folder of scripts to a repository. Here is my folder of scripts. They can be any type of files. I would recommend copy the folder to a specific Git folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-7.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Open VS Code - If you don&amp;rsquo;t have VS Code, download it from
&lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>https://code.visualstudio.com/&lt;/a> From the welcome window choose open folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-8.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and open your scripts folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-9.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>In VS Code click the Source Control button&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-10.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and up at the top you will see a little icon - initialise repository&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-11.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click that and choose your folder&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-12.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Which will then show all of the changes to the repository (adding all the new files)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-13.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now we need to add a commit message for our changes. I generally try to write commit messages that are the reason why the change has been made as the what has been changed is made easy to see in VS Code (as well as other source control GUI tools)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-14.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Click the tick or press CTRL + ENTER and this box will pop up&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-15.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I never click Always, I click yes, so that I can check if I am committing the correct files. Now we have created a local repository for our scripts folder. Our next step is to publish it to GitHub&lt;/p>
&lt;h2 id="create-a-new-repository-in-github">Create a New Repository in GitHub&lt;/h2>
&lt;p>In GitHub we need to create a remote repository. Click on the New Button. Give your repository a name and decide if you want it to be Public (available for anyone to search and find) or Private (only available to people you explicitly provide access to).&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-18.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This will give you a page that looks like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-19.png?fit=630%2C499&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Copy the code after …or push an existing repository from the command line&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># make sure prompt is at right place
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-Location C:\Git\MyScriptsFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Then paste the code
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git remote add origin https://github.com/SQLDBAWithABeard-Test/TheBeardsFunkyScriptFolder.git
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">git push -u origin master
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and paste it into PowerShell in VS Code. Make sure that your prompt is at the root of your scripts folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-20.png?fit=630%2C340&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Fill in your username and password and your 2FA&lt;/p>
&lt;p>Then you will see a page like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-21.png?fit=630%2C180&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and if you refresh your GitHub page you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/image-22.png?fit=630%2C504&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Congratulations, your code is source controlled :-)&lt;/p>
&lt;h2 id="making-changes">Making Changes&lt;/h2>
&lt;p>Now you can make a change to a file&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-23.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-23.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Commit your change&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-24.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-24.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Hit the roundy-roundy icon (anyone know its proper name ?)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-25.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-25.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Press OK and your commit will be pushed to GitHub :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/image-26.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-26.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Yay - Source Control all the things&lt;/p></description></item><item><title>How to break a SQL 2019 container on my laptop</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-break-a-sql-2019-container-on-my-laptop/</link><pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-break-a-sql-2019-container-on-my-laptop/</guid><description>&lt;p>Just a very quick post today. At the weekend I blogged about &lt;a class="link" href="https://sqldbawithabeard.com/2019/03/26/persisting-databases-with-named-volumes-on-windows-with-docker-compose/" target="_blank" rel="noopener"
>creating SQL 2019 containers with named volumes enabling&lt;/a> you to persist your data and yesterday about &lt;a class="link" href="https://sqldbawithabeard.com/2019/04/02/generating-a-workload-against-adventureworks-with-PowerShell/" target="_blank" rel="noopener"
>creating a random workload using PowerShell&lt;/a> and a big T-SQL script.&lt;/p>
&lt;p>The interesting thing about creating workload is that you can break things :-)&lt;/p>
&lt;p>When I created a SQL 2019 container with the data files mapped to a directory on my laptops C Drive with a docker-compose like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">version: &amp;#39;3.7&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">services:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2019-CTP23:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> image: mcr.microsoft.com/mssql/server:2019-CTP2.3-ubuntu
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ports:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#34;15591:1433&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - &amp;#34;5022:5022&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> environment:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SA_PASSWORD: &amp;#34;Password0!&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ACCEPT_EULA: &amp;#34;Y&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> volumes:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - C:\MSSQL\BACKUP\KEEP:/var/opt/mssql/backups
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - C:\MSSQL\DockerFiles\datafiles:/var/opt/sqlserver
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> - C:\MSSQL\DockerFiles\system:/var/opt/mssql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>restore the AdventureWorks database to use the /var/opt/sqlserver directory and run a workload after a while the container stops and when you examine the logs you find&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2019/04/D26g3dPXgAAso28.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2019/04/D26g3dPXgAAso28.png?fit=630%2C214&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I had a whole load of these errors&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:24.73 spid58 Error: 17053, Severity: 16, State: 1.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:24.73 spid58 FCB::MakePreviousWritesDurable: Operating system error (null) encountered.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:24.74 spid58 Error: 9001, Severity: 21, State: 1.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:24.74 spid58 The log for database &amp;#39;AdventureWorks2014&amp;#39; is not available. Check the operating system error log for related error messages. Resolve any errors and restart the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:25.05 spid58 Error: 9001, Severity: 21, State: 16.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:25.05 spid58 The log for database &amp;#39;AdventureWorks2014&amp;#39; is not available. Check the operating system error log for related error messages. Resolve any errors and restart the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:25.06 spid52 Error: 9001, Severity: 21, State: 16.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:48:25.06 spid52 The log for database &amp;#39;AdventureWorks2014&amp;#39; is not available. Check the operating system error log for related error messages. Resolve any errors and restart the database.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then some of these&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">019-04-02 20:55:16.26 spid53 Error: 17053, Severity: 16, State: 1.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.26 spid53 /var/opt/sqlserver/AdventureWorks2014_Data.mdf: Operating system error 31(A device attached to the system is not functioning.) encountered.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then it went really bad&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.35 spid53 Error: 3314, Severity: 21, State: 3.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.35 spid53 During undoing of a logged operation in database &amp;#39;AdventureWorks2014&amp;#39; (page (0:0) if any), an error occurred at log record ID (65:6696:25). Typically, the specific failure is logged previously as an error in the operating system error log. Restore the database or file from
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">a backup, or repair the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.37 spid53 Database AdventureWorks2014 was shutdown due to error 3314 in routine &amp;#39;XdesRMReadWrite::RollbackToLsn&amp;#39;. Restart for non-snapshot databases will be attempted after all connections to the database are aborted.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Restart packet created for dbid 5.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.41 spid53 Error during rollback. shutting down database (location: 1).
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">after that it tried to restart the database
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.44 spid53 Error: 3314, Severity: 21, State: 3.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.44 spid53 During undoing of a logged operation in database &amp;#39;AdventureWorks2014&amp;#39; (page (0:0) if any), an error occurred at log record ID (65:6696:25). Typically, the specific failure is logged previously as an error in the operating system error log. Restore the database or file from
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">a backup, or repair the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.49 spid53 Error: 3314, Severity: 21, State: 5.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:16.49 spid53 During undoing of a logged operation in database &amp;#39;AdventureWorks2014&amp;#39; (page (0:0) if any), an error occurred at log record ID (65:6696:1). Typically, the specific failure
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">is logged previously as an error in the operating system error log. Restore the database or file from a backup, or repair the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Restart packet processing for dbid 5.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:17.04 spid52 [5]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 0.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:17.06 spid52 Starting up database &amp;#39;AdventureWorks2014&amp;#39;.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>But that caused&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:17.90 spid76 Error: 9001, Severity: 21, State: 16.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:17.90 spid76 The log for database &amp;#39;master&amp;#39; is not available. Check the operating
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">system error log for related error messages. Resolve any errors and restart the database.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Master eh? Now what will you do?&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:25.55 spid52 29 transactions rolled forward in database &amp;#39;AdventureWorks2014&amp;#39; (5:0). This is an informational message only. No user action is required.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:25.90 spid52 1 transactions rolled back in database &amp;#39;AdventureWorks2014&amp;#39; (5:0). This is an informational message only. No user action is required.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:25.90 spid52 Recovery is writing a checkpoint in database &amp;#39;AdventureWorks2014&amp;#39; (5). This is an informational message only. No user action is required.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:26.16 spid52 Recovery completed for database AdventureWorks2014 (database ID 5) in 7 second(s) (analysis 424 ms, redo 5305 ms, undo 284 ms.) This is an informational message only. No user action is required.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:26.21 spid52 Parallel redo is shutdown for database &amp;#39;AdventureWorks2014&amp;#39; with worker pool size [1].
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 20:55:26.27 spid52 CHECKDB for database &amp;#39;AdventureWorks2014&amp;#39; finished without errors on 2018-03-24 00:38:39.313 (local time). This is an informational message only; no user action is required.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Interesting, then back to this.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">2019-04-02 21:00:00.57 spid51 Error: 17053, Severity: 16, State: 1.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 21:00:00.57 spid51 FCB::MakePreviousWritesDurable: Operating system error (null) encountered.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 21:00:00.62 spid51 Error: 9001, Severity: 21, State: 1.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 21:00:00.62 spid51 The log for database &amp;#39;AdventureWorks2014&amp;#39; is not available. Check the operating system error log for related error messages. Resolve any errors and restart the database.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">2019-04-02 21:00:00.64 spid51 Error: 9001, Severity: 21, State: 16.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It did all that again before&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">This program has encountered a fatal error and cannot continue running at Tue Apr 2 21:04:08 2019
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The following diagnostic information is available:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Reason: 0x00000004
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Message: RETAIL ASSERT: Expression=(false) File=Thread.cpp Line=4643 Description=Timed out waiting for thread terminate/suspend/resume.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Stacktrace: 000000006af30187 000000006af2836a 000000006ae4a4d1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 000000006ae48c55 000000006af6ab5e 000000006af6ac04
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 00000002809528df
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Process: 7 - sqlservr
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Thread: 129 (application thread 0x1e8)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Instance Id: 215cfcc9-8f69-4869-9a52-5aa44a415a83
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Crash Id: 53e98400-33f1-4786-98fd-484f0c8d9a7e
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Build stamp: 0e53295d0e1704ae5b221538dd6e2322cd46134e0cc32be49c887ca84cdb8c10
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Distribution: Ubuntu 16.04.6 LTS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Processors: 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Total Memory: 4906205184 bytes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Timestamp: Tue Apr 2 21:04:08 2019
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Ubuntu 16.04.6 LTS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Capturing core dump and information to /var/opt/mssql/log...
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">/usr/bin/find: &amp;#39;/proc/7/task/516&amp;#39;: No such file or directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">dmesg: read kernel buffer failed: Operation not permitted
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">No journal files were found.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">No journal files were found.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Attempting to capture a dump with paldumper
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WARNING: Capture attempt failure detected
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Attempting to capture a filtered dump with paldumper
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WARNING: Attempt to capture dump failed. Reference /var/opt/mssql/log/core.sqlservr.7.temp/log/paldumper-debug.log for details
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Attempting to capture a dump with gdb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WARNING: Unable to capture crash dump with GDB. You may need to
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">allow ptrace debugging, enable the CAP_SYS_PTRACE capability, or
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">run as root.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>failing to capture it&amp;rsquo;s dump!! Oops :-)&lt;/p>
&lt;p>I had to recreate the containers without using the named volumes and then I could run my workload :-)&lt;/p>
&lt;p>Nothing particularly useful about this blog post other than an interesting look at the error log when things go wrong :-)&lt;/p></description></item><item><title>Generating a Workload against AdventureWorks with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</link><pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-a-workload-against-adventureworks-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/04/image-51.png" alt="Featured image of post Generating a Workload against AdventureWorks with PowerShell" />&lt;p>For a later blog post I have been trying to generate some workload against an AdventureWorks database.&lt;/p>
&lt;p>I found this excellent blog post by Pieter Vanhove &lt;a class="link" href="https://twitter.com/Pieter_Vanhove" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/&lt;/a> which references this 2011 post by Jonathan Kehayias &lt;a class="link" href="https://twitter.com/SQLPoolBoy" target="_blank" rel="noopener"
>t&lt;/a>&lt;br>
&lt;a class="link" href="https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/" target="_blank" rel="noopener"
>https://www.sqlskills.com/blogs/jonathan/the-adventureworks2008r2-books-online-random-workload-generator/&lt;/a>&lt;/p>
&lt;p>Both of these run a random query in a single thread so I thought I would use &lt;a class="link" href="https://www.powershellgallery.com/packages/PoshRSJob/1.7.4.4" target="_blank" rel="noopener"
>PoshRSJob&lt;/a> by Boe Prox &lt;a class="link" href="https://learn-powershell.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>t&lt;/a> to run multiple queries at the same time 🙂&lt;/p>
&lt;p>To install PoshRSJob, like with any PowerShell module, you run&lt;/p>
&lt;pre>&lt;code>Install-Module -Name PoshRSJob
&lt;/code>&lt;/pre>
&lt;p>I downloaded AdventureWorksBOLWorkload zip from Pieters blog post and extracted to my &lt;code>C:\temp folder&lt;/code>. I created a &lt;code>Invoke-RandomWorkload&lt;/code> function which you can get from my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions" target="_blank" rel="noopener"
>functions repository in GitHub&lt;/a>. The guts of the function are&lt;/p>
&lt;pre>&lt;code> 1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
&lt;/code>&lt;/pre>
&lt;p>which will created $NumberOfJobs jobs and then run $Throttle number of jobs in the background until they have all completed. Each job will run a random query from the query file using Invoke-SqlCmd. Why did I use Invoke-SqlCmd and not Invoke-DbaQuery from dbatools? dbatools creates runspaces in the background to help with logging and creating runspaces inside background jobs causes errors&lt;/p>
&lt;p>Then I can run the function with&lt;/p>
&lt;pre>&lt;code>Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-51.png?resize=630%2C256&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and create a random workload. Creating lots of background jobs takes resources so when I wanted to run a longer workload I created a loop.&lt;/p>
&lt;pre>&lt;code>$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
&lt;/code>&lt;/pre>
&lt;p>You can get the function here. The full code is below&lt;/p>
&lt;pre>&lt;code># With thanks to Jonathan Kehayias and Pieter Vanhove
&amp;lt;#
.SYNOPSIS
Runs a random workload against a database using a sql file
.DESCRIPTION
Runs a random workload against a database using PoshRSJobs to create parallel jobs to run random
queries from a T-SQL file by default it uses the AdventureWorksBOLWorkload.sql from Pieter Vanhove
.PARAMETER SqlInstance
The SQL instance to run the queries against
.PARAMETER SqlCredential
The SQL Credential for the Instance if required
.PARAMETER Database
The name of the database to run the queries against
.PARAMETER NumberOfJobs
The number of jobs to create - default 10
.PARAMETER Delay
The delay in seconds for the output for the running jobs - default 10
.PARAMETER Throttle
The number of parallel jobs to run at a time - default 5
.PARAMETER PathToScript
The path to the T-SQL script holding the queries - default 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql'
.PARAMETER Delimiter
The delimiter in the T-SQL Script between the queries - default ------
.PARAMETER ShowOutput
Shows the output from the jobs
.EXAMPLE
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 100 -Delay 10 -Throttle 10
Runs 100 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23
.EXAMPLE
$x = 10
while($X -gt 0){
Invoke-RandomWorkload -SqlInstance $SQL2019CTP23 -SqlCredential $cred -Database AdventureWorks2014 -NumberOfJobs 1000 -Delay 10 -Throttle 10
$x --
}
Runs 1000 queries with a maximum of 10 at a time against the AdventureWorks2014 database on $SQL2019CTP23 10 times in a loop
.NOTES
With thanks to Pieter Vanhove
https://blogs.technet.microsoft.com/msftpietervanhove/2016/01/08/generate-workload-on-your-azure-sql-database/
and
Jonathan Kehayias
https://www.sqlskills.com/blogs/jonathan/ the-adventureworks2008r2-books-online-random-workload-generator /
&amp;gt;
function Invoke-RandomWorkload {
#Requires -Module PoshRsJob
#Requires -Module SQLServer
Param(
[string]$SqlInstance,
[pscredential]$SqlCredential,
[string]$Database,
[int]$NumberOfJobs = 10,
[int]$Delay = 10,
[int]$Throttle = 5,
[string]$PathToScript = 'C:\temp\AdventureWorksBOLWorkload\AdventureWorksBOLWorkload. sql',
[string]$Delimiter = &amp;quot;------&amp;quot;,
[switch]$ShowOutput
)
#Check if there are old Workload Jobs
$WorkloadJobs = Get-RSJob -Name Workload
if ($WorkloadJobs) {
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
$WorkloadJobs |Stop-RSJob
$WorkloadJobs | Remove-RSJob
}
Write-Output &amp;quot;Creating Background Jobs&amp;quot;
1.. $NumberOfJobs | Start-RSJob -Name &amp;quot;WorkLoad&amp;quot; -Throttle $Throttle -ScriptBlock {
# Get the queries
$Queries = Get-Content -Delimiter $Using:Delimiter -Path $Using:PathToScript
# Pick a Random Query from the input object
$Query = Get-Random -InputObject $Queries
# Run the Query
Invoke-SqlCmd -ServerInstance $Using:SqlInstance -Credential $Using:SqlCredential -Database $Using:Database -Query $Query
# Choose a random number of milliseconds to wait
$a = Get-Random -Maximum 2000 -Minimum 100;
Start-Sleep -Milliseconds $a;
}
$runningJobs = (Get-RSJob -Name WorkLoad -State Running). Count
While ($runningJobs -ne 0) {
$jobs = Get-RSJob -Name WorkLoad
$runningJobs = $Jobs.Where{$PSItem.State -eq 'Running'} .Count
$WaitingJobs = $Jobs.Where{$PSItem.State -eq 'NotStarted'}.Count
$CompletedJobs = $Jobs.Where{$PSItem.State -eq 'Completed'}.Count
Write-Output &amp;quot;$runningJobs jobs running - $WaitingJobs jobs waiting - $CompletedJobs -jobs finished&amp;quot;
Start-Sleep -Seconds $Delay
}
Write-Output &amp;quot;Jobs have finished&amp;quot;
if ($ShowOutput) {
Write-Output &amp;quot;WorkLoad Jobs Output below -&amp;quot;
Get-RSJob -Name WorkLoad | Receive-RSJob
}
Write-Output &amp;quot;Removing Old WorkLoad Jobs&amp;quot;
Get-RSJob -Name WorkLoad | Remove-RSJob
Write-Output &amp;quot;Finished&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Persisting databases with named volumes on Windows with docker compose</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/persisting-databases-with-named-volumes-on-windows-with-docker-compose/</link><pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/persisting-databases-with-named-volumes-on-windows-with-docker-compose/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-27.png" alt="Featured image of post Persisting databases with named volumes on Windows with docker compose" />&lt;p>With all things containers I refer to my good friend Andrew Pruski. Known as &lt;a class="link" href="https://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>dbafromthecold on twitter&lt;/a> he blogs at &lt;a class="link" href="https://dbafromthecold.com/" target="_blank" rel="noopener"
>https://dbafromthecold.com&lt;/a>&lt;/p>
&lt;p>I was reading his latest blog post &lt;a class="link" href="https://dbafromthecold.com/2019/03/21/using-docker-named-volumes-to-persist-databases-in-sql-server" target="_blank" rel="noopener"
>Using docker named volumes to persist databases in SQL Server&lt;/a> and decided to give it a try.&lt;/p>
&lt;p>His instructions worked perfectly and I thought I would try them using a docker-compose file as I like the ease of spinning up containers with them.&lt;/p>
&lt;p>I created a docker-compose file like this which will map my backup folder on my Windows 10 laptop to a directory on the container and two more folders to the system folders on the container in the same way as Andrew has in his blog.&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
2019-CTP23:
image: mcr.microsoft.com/mssql/server:2019-CTP2. 3-ubuntu
ports:
- &amp;quot;15591:1433&amp;quot;
- &amp;quot;5022:5022&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
volumes:
- C:\MSSQL\BACKUP\KEEP:/var/opt/mssql/backups
- C:\MSSQL\DockerFiles\datafiles:/var/opt/sqlserver
- C:\MSSQL\DockerFiles\system:/var/opt/mssql
&lt;/code>&lt;/pre>
&lt;p>and then from the directory I ran&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>This will build the containers as defined in the docker-compose file. The -d runs the container in the background. This was the result.&lt;/p>
&lt;p>UPDATE – 2019-03-27&lt;/p>
&lt;p>I have no idea why, but today it has worked as expected using the above docker-compose file. I had tried this a couple of times, restarted docker and restarted my laptop and was consistently getting the results below – however today it has worked&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-28.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>So feel free to carry on reading, it’s a fun story and it shows how you can persist the databases in a new container but the above docker-compose has worked!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-20.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>The command completed successfully but as you can see on the left the container is red because it is not running. (I am using the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=formulahendry.docker-explorer" target="_blank" rel="noopener"
>Docker Explorer extension for Visual Studio C&lt;/a>&lt;/p>
&lt;p>I inspected the logs from the container using&lt;/p>
&lt;pre>&lt;code> docker logs ctp23_2019-CTP23_1
&lt;/code>&lt;/pre>
&lt;p>which returned&lt;/p>
&lt;blockquote>
&lt;p>This is an evaluation version. There are [153] days left in the evaluation period.&lt;br>
This program has encountered a fatal error and cannot continue running at Tue Mar 26 19:40:35 20&lt;br>
19&lt;br>
The following diagnostic information is available:&lt;br>
&lt;code>Reason: 0x00000006 Status: 0x40000015 Message: Kernel bug check Address: 0x6b643120&lt;/code>&lt;br>
Parameters: 0x10861f680&lt;br>
Stacktrace: 000000006b72d63f 000000006b64317b 000000006b6305ca&lt;br>
000000006b63ee02 000000006b72b83a 000000006b72a29d&lt;br>
000000006b769c02 000000006b881000 000000006b894000&lt;br>
000000006b89c000 0000000000000001&lt;br>
Process: 7 – sqlservr&lt;br>
Thread: 11 (application thread 0x4)&lt;br>
Instance Id: e01b154f-7986-42c6-ae13-c7d34b8b257d&lt;br>
Crash Id: 8cbb1c22-a8d6-4fad-bf8f-01c6aa5389b7&lt;br>
Build stamp: 0e53295d0e1704ae5b221538dd6e2322cd46134e0cc32be49c887ca84cdb8c10&lt;br>
Distribution: Ubuntu 16.04.6 LTS&lt;br>
Processors: 2&lt;br>
Total Memory: 4906205184 bytes&lt;br>
Timestamp: Tue Mar 26 19:40:35 2019&lt;br>
Ubuntu 16.04.6 LTS&lt;br>
Capturing core dump and information to /var/opt/mssql/log…&lt;br>
dmesg: read kernel buffer failed: Operation not permitted&lt;br>
No journal files were found.&lt;br>
No journal files were found.&lt;br>
Attempting to capture a dump with paldumper&lt;br>
WARNING: Capture attempt failure detected&lt;br>
Attempting to capture a filtered dump with paldumper&lt;br>
WARNING: Attempt to capture dump failed. Reference /var/opt/mssql/log/core.sqlservr.7.temp/log/&lt;br>
paldumper-debug.log for details&lt;br>
Attempting to capture a dump with gdb&lt;br>
WARNING: Unable to capture crash dump with GDB. You may need to&lt;br>
allow ptrace debugging, enable the CAP_SYS_PTRACE capability, or&lt;br>
run as root.&lt;/p>
&lt;/blockquote>
&lt;p>which told me that …………. it hadn’t worked. So I removed the containers with&lt;/p>
&lt;pre>&lt;code>docker-compose down
&lt;/code>&lt;/pre>
&lt;p>I thought I would create the volumes ahead of time like Andrew’s blog had mentioned with&lt;/p>
&lt;pre>&lt;code>docker volume create mssqlsystem
docker volume create mssqluser
&lt;/code>&lt;/pre>
&lt;p>and then use the volume names in the docker-compose file mapped to the system folders in the container, this time the result was&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-21.png%3e"
loading="lazy"
>&lt;/p>
&lt;blockquote>
&lt;p>ERROR: Named volume “mssqlsystem:/var/opt/sqlserver:rw” is used in service “2019-CTP23” but no declaration was found in the volumes section.&lt;/p>
&lt;/blockquote>
&lt;p>So that didn&amp;rsquo;t work either 🙂&lt;/p>
&lt;p>I decided to inspect the volume definition using&lt;/p>
&lt;pre>&lt;code> docker volume inspect mssqlsystem
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-22.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>I can see the mountpoint is /var/lib/docker/volumes/mssqlsystem/_data so I decided to try a docker-compose like this&lt;/p>
&lt;p>version: &amp;lsquo;3.7&amp;rsquo;&lt;/p>
&lt;p>services:
2019-CTP23:
image: mcr.microsoft.com/mssql/server:2019-CTP2.3-ubuntu
ports:&lt;br>
- &amp;ldquo;15591:1433&amp;rdquo;
- &amp;ldquo;5022:5022&amp;rdquo;
environment:
SA_PASSWORD: &amp;ldquo;Password0!&amp;rdquo;
ACCEPT_EULA: &amp;ldquo;Y&amp;rdquo;
volumes:
- C:\MSSQL\BACKUP\KEEP:/var/opt/mssql/backups
- /var/lib/docker/volumes/mssqluser/_data:/var/opt/sqlserver
- /var/lib/docker/volumes/mssqlsystem/_data:/var/opt/mssql&lt;/p>
&lt;p>and then ran docker-compose up without the -d flag so that I could see all of the output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-23.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>You can see in the output that the system database files are being moved. That looks like it is working so I used CTRL + C to stop the container and return the terminal. I then ran docker-compose up -d and&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-24.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>I created a special database for Andrew.&lt;/p>
&lt;blockquote>
&lt;p>This made me laugh out loud…as there&amp;rsquo;s a strong possibility that could happen &lt;a class="link" href="https://t.co/sh0pnhtPQy" target="_blank" rel="noopener"
>https://t.co/sh0pnhtPQy&lt;/a>&lt;/p>
&lt;p>— Andrew Pruski 🏴󠁧󠁢󠁷󠁬󠁳󠁿 (@dbafromthecold) &lt;a class="link" href="https://twitter.com/dbafromthecold/status/1109253907304206336?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 23, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-25.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>I could then remove the container with&lt;/p>
&lt;pre>&lt;code>docker-compose down
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-26.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>To make sure there is nothing up my sleeve I altered the docker-compose file to use a different name and port but kept the volume definitions the same.&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
2019-CTP23-Mk1:
image: mcr.microsoft.com/mssql/server:2019-CTP2. 3-ubuntu
ports:
- &amp;quot;15592:1433&amp;quot;
- &amp;quot;5022:5022&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
volumes:
- C:\MSSQL\BACKUP\KEEP:/var/opt/mssql/backups
- /var/lib/docker/volumes/mssqluser/_data:/var/opt/sqlserver
- /var/lib/docker/volumes/mssqlsystem/_data:/var/opt/mssql
&lt;/code>&lt;/pre>
&lt;p>I ran &lt;code>docker-compose up -d&lt;/code> again and connected to the new container and lo and behold the container is still there&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-27.png%3e"
loading="lazy"
>&lt;/p>
&lt;p>So after doing this, I have learned that to persist the databases and to use docker-compose files I had to map the volume to the mountpoint of the docker volume. Except I haven’t, I have learned that sometimes weird things happen with Docker on my laptop!!&lt;/p></description></item><item><title>Whats a SQL Notebook in Azure Data Studio?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/whats-a-sql-notebook-in-azure-data-studio/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/image-7.png" alt="Featured image of post Whats a SQL Notebook in Azure Data Studio?" />&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-2017?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Azure Data Studio&lt;/a> is a cross-platform database tool for data professionals using the Microsoft family of on-premises and cloud data platforms on Windows, MacOS, and Linux.&lt;/p>
&lt;p>Recently Vicky Harp tweeted&lt;/p>
&lt;blockquote>
&lt;p>We&amp;rsquo;re getting very close to release of SQL Notebooks in &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>! You can give the feature an early spin today with the insider build. &lt;a class="link" href="https://t.co/SEZp7ZdxCp" target="_blank" rel="noopener"
>pic.twitter.com/SEZp7ZdxCp&lt;/a>&lt;/p>
&lt;p>— Vicky Harp (@vickyharp) &lt;a class="link" href="https://twitter.com/vickyharp/status/1104127412944551936?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 8, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>By the way, you can watch a recording from SQLBits of Vicky’s session&lt;/p>
&lt;blockquote>
&lt;p>If you missed &lt;a class="link" href="https://twitter.com/hashtag/sqlbits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#sqlbits&lt;/a>, you will definitely want to watch this demo by &lt;a class="link" href="https://twitter.com/vickyharp?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@vickyharp&lt;/a> and &lt;a class="link" href="https://twitter.com/MGoCODE?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@MGoCODE&lt;/a> about &lt;a class="link" href="https://twitter.com/AzureDataStudio?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@AzureDataStudio&lt;/a>. Learn the latest about our cross-platform tool, including a new feature, SQL Notebooks &lt;a class="link" href="https://twitter.com/hashtag/SQLServer?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLServer&lt;/a> &lt;a class="link" href="https://t.co/diubYwQckn" target="_blank" rel="noopener"
>https://t.co/diubYwQckn&lt;/a>&lt;/p>
&lt;p>— Azure Data Studio (@AzureDataStudio) &lt;a class="link" href="https://twitter.com/AzureDataStudio/status/1103806327065722880?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>March 7, 2019&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>So in the interest of learning about something new I decided to give it a try.&lt;/p>
&lt;h2 id="install-the-insiders-edition">Install The Insiders Edition&lt;/h2>
&lt;p>Unlike &lt;a class="link" href="https://code.visualstudio.com/" target="_blank" rel="noopener"
>Visual Studio Code&lt;/a> which has a link to the insiders download on the front page, you will have to &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio#azure-data-studio" target="_blank" rel="noopener"
>visit the GitHub repository for the links to download the insiders release of Azure Data Studio&lt;/a>. Scroll down and you will see&lt;/p>
&lt;p>Try out the latest insiders build from &lt;code>master&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider" target="_blank" rel="noopener"
>Windows User Installer – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider" target="_blank" rel="noopener"
>Windows System Installer – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider" target="_blank" rel="noopener"
>Windows ZIP – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider" target="_blank" rel="noopener"
>macOS ZIP – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider" target="_blank" rel="noopener"
>Linux TAR.GZ – &lt;strong>Insiders build&lt;/strong>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See the &lt;a class="link" href="https://github.com/Microsoft/azuredatastudio/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>change log&lt;/a> for additional details of what’s in this release.
Once you have installed you can connect to an instance, right click and choose New Notebook or you can use File – New Notebook
&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image.png"
loading="lazy"
>&lt;/p>
&lt;p>Incidentally, I use the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> to create the containers and I map &lt;code>C:\MSSQL\BACKUP\KEEP&lt;/code> on my local machine (where my backups are) to &lt;code>/var/opt/mssql/backups&lt;/code> on the containers on lines 10 and 17 of the docker-compose so change as required . If you want to follow along then put the ValidationResults.bak in the folder on your local machine.
The &lt;code>Create-Ag.ps1&lt;/code> shows the code and creates an AG with &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools.&lt;/a> But I digress!&lt;/p>
&lt;h2 id="install-notebook-dependencies">Install Notebook Dependencies&lt;/h2>
&lt;p>Once you click New Notebook you will get a prompt to install the dependencies.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-1.png"
loading="lazy"
>&lt;/p>
&lt;p>It will show its output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-2.png"
loading="lazy"
>&lt;/p>
&lt;p>and take a few minutes to run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-3.png"
loading="lazy"
>&lt;/p>
&lt;p>It took all but 11 minutes on my machine&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-4.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="create-a-notebook">Create a Notebook&lt;/h2>
&lt;p>OK, so now that we have the dependencies installed we can create a notebook. I decided to use the ValidationResults database that &lt;a class="link" href="https://blog.robsewell.com/dbachecks-save-the-results-to-a-database-for-historical-reporting/" target="_blank" rel="noopener"
>I use for my dbachecks demos and describe here&lt;/a>. I need to restore it from my local folder that I have mapped as a volume to my container. Of course, I use dbatools for this 🙂&lt;/p>
&lt;pre>&lt;code># U: sqladmin P: dbatools.IO
$cred = Get-Credential
$restoreDbaDatabaseSplat = @{
SqlInstance = $sqlinstance1
SqlCredential = $cred
UseDestinationDefaultDirectories = $true
Path = '/var/opt/mssql/backups/ValidationResults.bak'
}
Restore-DbaDatabase @restoreDbaDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>I had already got a connection saved to the instance in Azure Data Studio, you may need to create a new one using the new connection icon at the top left and filling in the details. The password is in the code above.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-5.png"
loading="lazy"
>&lt;/p>
&lt;p>Now I can start with my notebook. I am faced with this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-6.png"
loading="lazy"
>&lt;/p>
&lt;p>I click on text and provide an intro&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-7.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I had written that and clicked out, I couldn’t see what to do straight away!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-8.png"
loading="lazy"
>&lt;/p>
&lt;p>Then I saw the code and text buttons at the top 🙂 Right, lets get on with it 🙂 I hit the code button and paste in the T-SQL to reset the dates in the database to simulate dbachecks having been run this morning.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-9.png"
loading="lazy"
>
There’s a run cell button on the right and when I press it&amp;gt;&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->
Cool 🙂&lt;/p>
&lt;p>If the SQL query has results then they are shown as well&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-10.png"
loading="lazy"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-11.png"
loading="lazy"
>&lt;/p>
&lt;p>This is fun and I can see plenty of uses for it. Go and have a play with SQL notebooks 🙂&lt;/p>
&lt;h2 id="source-control">Source Control&lt;/h2>
&lt;p>I used CTRL K, CTRL O to open a folder and saved my notebook in my local Presentations folder which is source controlled. When I opened the explorer CTRL + SHIFT + E I can see that the folder and the file are colour coded green and have a U next to them marking them as Untracked. I can also see that the source control icon has a 1 for the number of files with changes and in the bottom left that I am in the master branch.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-12.png"
loading="lazy"
>&lt;/p>
&lt;p>If I click on the source control icon (or CTRL + SHIFT + G) I can see the files with the changes and can enter a commit message&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-13.png"
loading="lazy"
>&lt;/p>
&lt;p>I then press CTRL + ENTER to commit my change and get this pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-14.png"
loading="lazy"
>&lt;/p>
&lt;p>As I only have one file and it has all the changes for this commit I click yes. If I had changed more than one file and only wanted to commit a single one at a time I would hover my mouse over the file and click the + to stage my change.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-15.png"
loading="lazy"
>&lt;/p>
&lt;p>If I make a further change to the notebook and save it, I can see that the source control provider recognises the change but this time the folder the file is in and the file are colour coded brown with an M to show that they have been modified.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-16.png"
loading="lazy"
>&lt;/p>
&lt;p>Unlike Visual Studio Code, when you then click on the source control icon and click on the change it does not show the differences in the notebook although this works with SQL files.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-17.png"
loading="lazy"
>&lt;/p>
&lt;p>When I have made all my changes and committed them with good commit messages&lt;/p>
&lt;p>&lt;img src="https://i2.wp.com/imgs.xkcd.com/comics/git_commit.png?w=630&amp;amp;ssl=1"
loading="lazy"
>&lt;/p>
&lt;p>I can see that there are 3 local changes ready to be pushed to by remote repository (GitHub in this case) and 0 remote commits in this branch by looking at the bottom left&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-18.png"
loading="lazy"
>&lt;/p>
&lt;p>I can click on the “roundy roundy” icon (I don&amp;rsquo;t know its proper name 😊) and synchronise my changes. This comes with a pop-up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/image-19.png"
loading="lazy"
>&lt;/p>
&lt;p>Personally I never press OK, Don’t Show Again because I like the double check and to think “Is this really what I want to do right now”. Once I press OK my changes will be synched with the remote repository. Explaining this means that you can find the notebook I have used in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/tree/master/Notebooks" target="_blank" rel="noopener"
>Presentations GitHub Repository&lt;/a> which means that you can run the Notebook too using the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DockerStuff/tree/master/dbatools-2-instances-AG" target="_blank" rel="noopener"
>docker-compose file here&lt;/a> and the instructions further up in the post.&lt;/p></description></item><item><title>#TSQL2sDay – NomNomNomNomNom</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-nomnomnomnomnom/</link><pubDate>Tue, 12 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-nomnomnomnomnom/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2019/03/pille-riin-priske-1238490-unsplash.jpg" alt="Featured image of post #TSQL2sDay – NomNomNomNomNom" />&lt;p>&lt;a class="link" href="https://nocolumnname.blog/2019/03/05/t-sql-tuesday-112-dipping-into-your-cookie-jar/" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/images/TSQL2sDay150x150.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The topic for this months&lt;a class="link" href="https://nocolumnname.blog/2019/03/05/t-sql-tuesday-112-dipping-into-your-cookie-jar/" target="_blank" rel="noopener"
> T-SQL Tuesday #112&lt;/a> hosted by Shane O’Neill (&lt;a class="link" href="https://nocolumnname.blog/" target="_blank" rel="noopener"
>Blog&lt;/a> / &lt;a class="link" href="https://twitter.com/sozdba" target="_blank" rel="noopener"
>Twitter&lt;/a>) is about “dipping into your cookie jar”. This reference means “when times get tough how do you dip into your reserves to keep going”. Shane asks the following:&lt;/p>
&lt;blockquote>
&lt;p>That is what I want from the contributors of this T-SQL Tuesday, those memories that they can think back on for sustenance. Like the humble cookie, I want a humble brag.&lt;/p>
&lt;/blockquote>
&lt;h2 id="mmmm-cookies">Mmmm Cookies&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/pille-riin-priske-1238490-unsplash.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/photos/DM-KD1_fZrg?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Pille-Riin Priske&lt;/a> on &lt;a class="link" href="https://unsplash.com/search/photos/cookie?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>I’m not good at bragging, &lt;a class="link" href="https://en.wikipedia.org/wiki/Impostor_syndrome" target="_blank" rel="noopener"
>I’m generally convinced that all of you are better than me&lt;/a>. Yes, I am aware that it is irrational. This has made writing this post really hard. Sure, I get immense pleasure and satisfaction from solving a problem, that’s a form of instant fulfillment. Certainly, I enjoy teaching people and passing over my knowledge for them to use.&lt;br>
I am not going to write about technical things that I have done because they don’t give me sustenance in that way.&lt;/p>
&lt;p>So what does give me sustenance when times are hard?&lt;/p>
&lt;p>People.&lt;/p>
&lt;p>The things I am most proud of are the things other people do where I have played a small part. These are the things I look back at and help to energise me. Things like&lt;/p>
&lt;ul>
&lt;li>A couple of people who I suggested started writing blogs and then speaking who are now seen as experts in their niche.&lt;/li>
&lt;li>The people I mentored as new speakers who are now speaking all over the continent.&lt;/li>
&lt;/ul>
&lt;p>The most recent story was a DBA who sat in a full day pre-con at a SQL Saturday, took loads of notes and waited at the end to ask questions. We were looking at some code and she was telling me it wasn’t very good and apologising for it. It was good, it performed the required actions over a large estate and I told her so. I asked about her job and with a big sigh, she told a story of being stuck in a rut, dealing with a lot of legacy systems, not enjoying it and not being able to move on. We had a long talk.&lt;/p>
&lt;p>Cut to this years SQL Bits and she came running up to me all energised. She has a new job, doing something “Cool in the cloud”, she said the things she had learned had helped her to land this role.&lt;/p>
&lt;p>In all of these cases, it is the person involved who has done all of the hard work but it is these things that keep me going. The thank yous and the smiles I see on those peoples faces as they do the thing that they love and enjoy their success and progression 🙂&lt;/p>
&lt;h2 id="cake-">Cake !!!!!&lt;/h2>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/03/prince-abid-653931-unsplash.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Photo by &lt;a class="link" href="https://unsplash.com/photos/pEvPkPmuHzo?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Prince Abid&lt;/a> on &lt;a class="link" href="https://unsplash.com/search/photos/cake?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>Hey, thats cake and not cookies Rob.&lt;/p>
&lt;p>I know. The biggest thing that keeps me going when times are tough though is the security I am able to provide. Nearly 20 years ago my life was very different. Without a job, I’d had to give up a career, struggling dealing with my wife’s serious illnesses, suddenly responsible for the entire household without the means to provide, I was in a very bleak place and saw no way out.&lt;/p>
&lt;p>So to have found a career that is my hobby, to be able to work and also to have fun, to have a social world that provides me with friends and entertainment in many countries and the opportunity to experience different cultures and still be able to live comfortably. Thats a blessing and what keeps me going.&lt;/p>
&lt;p>Also being able to pay my dad back for turning up with sacks of potatoes by taking him to football matches and comedy shows 🙂&lt;/p>
&lt;p>Acknowledge what you have got, tell your loved ones that you love them, enjoy life and use your cookies when you need them but don’t forget the cake 🙂&lt;/p></description></item><item><title>#DataInDevon – Getting up to speed with PowerShell or spend a day with one of four other MVPs :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#dataindevon-getting-up-to-speed-with-powershell-or-spend-a-day-with-one-of-four-other-mvps-/</link><pubDate>Wed, 06 Mar 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#dataindevon-getting-up-to-speed-with-powershell-or-spend-a-day-with-one-of-four-other-mvps-/</guid><description>&lt;p>Saturday 27th April is Global Azure Bootcamp day&lt;/p>
&lt;p>What’s Global Azure Bootcamp?&lt;/p>
&lt;p>The &lt;a class="link" href="https://global.azurebootcamp.net/" target="_blank" rel="noopener"
>website&lt;/a> says it best&lt;/p>
&lt;blockquote>
&lt;p>…. communities will come together once again in the sixth great Global Azure Bootcamp event! Each user group will organize their own one day deep dive class on Azure the way they see fit and how it works for their members. The result is that thousands of people get to learn about Azure and join together online under the social hashtag &lt;a class="link" href="https://twitter.com/search?q=%23GlobalAzure" target="_blank" rel="noopener"
>#GlobalAzure&lt;/a>!&lt;/p>
&lt;/blockquote>
&lt;h2 id="saturday-is-free-learning">Saturday Is Free Learning&lt;/h2>
&lt;p>I am a part of the team organising the event in Exeter. Now there is a little story here. We had chosen this date by chance to hold an event we call Data In Devon giving people in the South West (of UK) the chance to access a whole day of high quality data and technical sessions for free on a Saturday.&lt;/p>
&lt;p>When the Global Azure Bootcamp was announced, we had a conversation with the organisers and they agreed that we could add Exeter as a venue as we had already decided to have a whole track dedicated to Azure. You can find our schedule here &lt;a class="link" href="https://sqlsouthwest.co.uk/data-in-devon-saturday-schedule/" target="_blank" rel="noopener"
>https://sqlsouthwest.co.uk/data-in-devon-saturday-schedule/&lt;/a> and you can register to attend &lt;a class="link" href="https://www.eventbrite.com/e/data-in-devon-registration-50262066193v" target="_blank" rel="noopener"
>via this form&lt;/a> &lt;/p>
&lt;p>Now, we have some costs obviously, not a lot but venues are not free and neither is food 😉. We have a couple of sponsors (feel free to contact me if your company is interested in sponsoring the event) but we also have some paid training days on Friday 25th April.&lt;/p>
&lt;h2 id="friday-is-training-day">Friday Is Training Day&lt;/h2>
&lt;p>It’s a great opportunity to get cheap high-quality training from some of the best in their areas of expertise. There are still some tickets for £175 and the price will rise only to £200. I think that £200 is fantastic value to be able to spend a day learning from&lt;/p>
&lt;p>Alex Whittles – Data Platform MVP – &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#BiinAzure" target="_blank" rel="noopener"
>Bi in Azure&lt;/a>&lt;br>
John Martin – Data Platform MVP – &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#InfrastructureAsCode" target="_blank" rel="noopener"
>Infrastructure as Code with Terraform&lt;/a>&lt;br>
Terry McCann – Data Platform MVP – &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#MachineLearning" target="_blank" rel="noopener"
>Machine Learning: From model to production using the cloud, containers and Dev Ops &lt;/a>&lt;br>
William Durkin – Data Platform MVP – &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Performance" target="_blank" rel="noopener"
>Performance Pain Reduction for Data Platform Projects&lt;/a>&lt;/p>
&lt;p>and myself – &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Powershell" target="_blank" rel="noopener"
>Getting up to speed with PowerShell&lt;/a>&lt;/p>
&lt;p>You can sign up for any of these sessions by following the instructions here &lt;a class="link" href="https://sqlsouthwest.co.uk/training-day-schedule/#Pricing" target="_blank" rel="noopener"
>https://sqlsouthwest.co.uk/training-day-schedule/#Pricing&lt;/a> We don’t have a fancy website or booking system as we wanted to keep costs down.&lt;/p>
&lt;p>The details of my training day are below&lt;/p>
&lt;h1 id="getting-up-to-speed-with-powershells">Getting up to speed with PowerShell&lt;strong>S&lt;/strong>&lt;/h1>
&lt;p>PowerShell is cross-platform, it works exactly the same on Windows, on Linux and Mac. It is awesome for automation and amazing for administration.&lt;/p>
&lt;p>We will cover&lt;/p>
&lt;ul>
&lt;li>the basics about PowerShell, PowerShell security&lt;/li>
&lt;li>how to open PowerShell , how to install PowerShell .&lt;/li>
&lt;li>4 vital commands to enable you to be able to help yourself&lt;/li>
&lt;li>The PowerShell Gallery and how to find, install and use additional modules&lt;/li>
&lt;li>Reading the language&lt;/li>
&lt;li>Working with output&lt;/li>
&lt;li>Why Red text is a good thing and how to learn from the errors&lt;/li>
&lt;li>We will even delve into scripting with PowerShell and how to validate your environment&lt;/li>
&lt;/ul>
&lt;p>There will also be the opportunity to learn about any areas of PowerShell, Automation, CI/CD that you have questions about. This is a beginner level session in which I will teach you to be comfortable with PowerShell and confident in being able to use it in the future&lt;/p>
&lt;p>Attendees wanting to follow along should bring a laptop.&lt;/p></description></item><item><title>Using Docker to run Integration Tests for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</link><pubDate>Sat, 19 Jan 2019 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-docker-to-run-integration-tests-for-dbachecks/</guid><description>&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> wrote a fantastic blog post this week &lt;a class="link" href="https://andrekamman.com/sql-server-container-instances-via-cloudshell/" target="_blank" rel="noopener"
>SQL Server Container Instances via Cloudshell&lt;/a> about how he uses containers in Azure to test code against different versions of SQL Server.&lt;/p>
&lt;p>It reminded me that I do something very similar to test &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> code changes. I thought this might make a good blog post. I will talk through how I do this locally as I merge a PR from another great friend &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>Cláudio Silva&lt;/a> who has added &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pull/582" target="_blank" rel="noopener"
>agent job history checks.&lt;/a>&lt;/p>
&lt;h2 id="github-pr-vs-code-extension">GitHub PR VS Code Extension&lt;/h2>
&lt;p>I use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-pull-request-github" target="_blank" rel="noopener"
>GitHub Pull Requests extension for VS Code&lt;/a> to work with pull requests for &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/pulls" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This enables me to see all of the information about the Pull Request, merge it, review it, comment on it all from VS Code&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/GitHub-Pull-Request-VsCode-Extension.png"
loading="lazy"
>&lt;/p>
&lt;p>I can also see which files have been changed and which changes have been made&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/viewing-a-change.png"
loading="lazy"
>&lt;/p>
&lt;p>Once I am ready to test the pull request I perform a checkout using the extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/checkout-pull-request-checkout.png"
loading="lazy"
>&lt;/p>
&lt;p>This will update all of the files in my local repository with all of the changes in this pull request&lt;/p>
&lt;p>&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>You can see at the bottom left that the branch changes from development to the name of the PR.&lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>&lt;/a>&lt;/p>
&lt;h2 id="running-the-unit-tests">Running The Unit Tests&lt;/h2>
&lt;p>The first thing that I do is to run the Unit Tests for the module. These will test that the code is following all of the guidelines that we require and that the tests are formatted in the correct way for the Power Bi to parse. I have blogged about this &lt;a class="link" href="https://blog.robsewell.com/using-the-ast-in-pester-for-dbachecks/" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/using-the-powershell-ast-to-find-a-foreach-method/" target="_blank" rel="noopener"
>here&lt;/a> and we use this Pester in our CI process in Azure DevOps which I described &lt;a class="link" href="https://blog.robsewell.com/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" target="_blank" rel="noopener"
>here.&lt;/a>&lt;/p>
&lt;p>I navigate to the root of the dbachecks repository on my local machine and run&lt;/p>
&lt;pre>&lt;code> $testresults = Invoke-Pester .\tests -ExcludeTag Integration -Show Fails -PassThru
&lt;/code>&lt;/pre>
&lt;p>and after about a minute&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/pester-tests.png"
loading="lazy"
>&lt;/p>
&lt;p>Thank you Cláudio, the code has passed the tests 😉&lt;/p>
&lt;h2 id="running-some-integration-tests">Running Some Integration Tests&lt;/h2>
&lt;p>The difference between Unit tests and Integration tests in a nutshell is that the Unit tests are testing that the code is doing what is expected without any other external influences whilst the Integration tests are checking that the code is doing what is expected when running on an actual environment. In this scenario we know that the code is doing what is expected but we want to check what it does when it runs against a SQL Server and even when it runs against multiple SQL Servers of different versions.&lt;/p>
&lt;h2 id="multiple-versions-of-sql-server">Multiple Versions of SQL Server&lt;/h2>
&lt;p>As I have described &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>before&lt;/a> my friend and former colleague Andrew Pruski &lt;a class="link" href="http://dbafromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="http://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has many resources for running SQL in containers. This means that I can quickly and easily create fresh uncontaminated instances of SQL 2012, 2014, 2016 and 2017 really quickly.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/creating-contatiners.png"
loading="lazy"
>&lt;/p>
&lt;p>I can create 4 instances of different versions of SQL in (a tad over) 1 minute. How about you?&lt;/p>
&lt;p>Imagine how long it would take to run the installers for 4 versions of SQL and the pain you would have trying to uninstall them and make sure everything is ‘clean’. Even images that have been sysprep’d won’t be done in 1 minute.&lt;/p>
&lt;h2 id="docker-compose-up-">Docker Compose Up ?&lt;/h2>
&lt;p>So what is this magic command that has enabled me to do this? docker compose uses a YAML file to define multi-container applications. This means that with a file called docker-compose.yml like &lt;a class="link" href="https://gist.github.com/SQLDBAWithABeard/b589d499484af4ebfb7d637cb6b4efa3" target="_blank" rel="noopener"
>this&lt;/a>&lt;/p>
&lt;pre>&lt;code>version: '3.7'
services:
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/ mssql-server-windows-developer:2017-latest
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and in that directory just run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>and 4 SQL containers are available to you. You can interact with them via SSMS if you wish with localhost comma PORTNUMBER. The port numbers in the above file are 15586, 15587,15588 and 15589&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?resize=630%2C188&amp;amp;ssl=1"
loading="lazy"
>](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2019/01/containers.png?ssl=1&lt;/a>)&lt;/p>
&lt;p>Now it must be noted, as I &lt;a class="link" href="https://blog.robsewell.com/creating-sql-server-containers-for-versions-2012-2017/" target="_blank" rel="noopener"
>describe here&lt;/a> that first I pulled the images to my laptop. The first time you run docker compose will take significantly longer if you haven’t pulled the images already (pulling the images will take quite a while depending on your broadband speed)&lt;/p>
&lt;h2 id="credential">Credential&lt;/h2>
&lt;p>The next thing is to save a credential to make it easier to automate.&lt;del>I use the method described by my PowerShell friend Jaap Brasser &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>here&lt;/a>.&lt;/del>&lt;/p>
&lt;p>EDIT (September or is it March? 2020) - Nowadays I use the Secret Management Module&lt;/p>
&lt;p>I run this code&lt;/p>
&lt;pre>&lt;code> $CredentialPath = 'C:\MSSQL\BACKUP\KEEP\sacred.xml'
Get-Credential | Export-Clixml -Path $CredentialPath
&lt;/code>&lt;/pre>
&lt;p>and then I can create a credential object using&lt;/p>
&lt;pre>&lt;code>$cred = Import-Clixml $CredentialPath
&lt;/code>&lt;/pre>
&lt;h2 id="check-the-connections">Check The Connections&lt;/h2>
&lt;p>I ensure a clean session by removing the dbatools and dbachecks modules and then import the local version of dbachecks and set some variables&lt;/p>
&lt;pre>&lt;code>$dbacheckslocalpath = 'GIT:\dbachecks\'
Remove-Module dbatools, dbachecks -ErrorAction SilentlyContinue
Import-Module $dbacheckslocalpath\dbachecks.psd1
$cred = Import-Clixml $CredentialPath
$containers = 'localhost,15589', 'localhost,15588', 'localhost, 15587', 'localhost,15586'
&lt;/code>&lt;/pre>
&lt;p>Now I can start to run my Integration tests. First reset the dbachecks configuration and set some configuration values&lt;/p>
&lt;pre>&lt;code># run the checks against these instances
$null = Set-DbcConfig -Name app.sqlinstance $containers
# We are using SQL authentication
$null = Set-DbcConfig -Name policy.connection.authscheme -Value SQL
# sometimes its a bit slower than the default value
$null = Set-DbcConfig -Name policy.network.latencymaxms -Value 100 # because the containers run a bit slow!
&lt;/code>&lt;/pre>
&lt;p>Then I will run the dbachecks connectivity checks and save the results to a variable without showing any output&lt;/p>
&lt;pre>&lt;code>$ConnectivityTests = Invoke-DbcCheck -SqlCredential $cred -Check Connectivity -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>I can then use Pester to check that dbachecks has worked as expected by testing if the failedcount property returned is 0.&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;Testing the checks are running as expected&amp;quot; -Tag Integration {
Context &amp;quot;Connectivity Checks&amp;quot; {
It &amp;quot;All Tests should pass&amp;quot; {
$ConnectivityTests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default settings&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/check-connectivity.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="what-is-the-unit-test-for-this-pr">What is the Unit Test for this PR?&lt;/h2>
&lt;p>Next I think about what we need to be testing for the this PR. The Unit tests will help us.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/what-are-the-unit-tests.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="choose-some-integration-tests">Choose some Integration Tests&lt;/h2>
&lt;p>This check is checking the Agent job history settings and the unit tests are&lt;/p>
&lt;ul>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows disabled (-1)”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows disabled (-1) but configured value is 1000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows being 10000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows being less than 10000”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Passes Check Correctly with Maximum History Rows per job being 100”&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It “Fails Check Correctly with Maximum History Rows per job being less than 100”&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>So we will check the same things on real actual SQL Servers. First though we need to start the SQL Server Agent as it is not started by default. We can do this as follows&lt;/p>
&lt;pre>&lt;code>docker exec -ti integration_sql2012_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2014_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2016_1 powershell start-service SQLSERVERAGENT
docker exec -ti integration_sql2017_1 powershell start-service SQLSERVERAGENT
&lt;/code>&lt;/pre>
&lt;p>Unfortunately, the agent service wont start in the SQL 2014 container so I cant run agent integration tests for that container but it’s better than no integration tests.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/agent-wont-start.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="this-is-what-we-will-test">This is What We Will Test&lt;/h2>
&lt;p>So we want to test if the check will pass with default settings. In general, dbachecks will pass for default instance, agent or database settings values by default.&lt;/p>
&lt;p>We also want the check to fail if the configured value for dbachecks is set to default but the value has been set on the instance.&lt;/p>
&lt;p>We want the check to pass if the configured value for the dbachecks configuration is set and the instance (agent, database) setting matches it.&lt;/p>
&lt;h2 id="if-you-are-doing-something-more-than-once-">If You Are Doing Something More Than Once ……&lt;/h2>
&lt;p>Let’s automate that. We are going to be repeatedly running those three tests for each setting that we are running integration tests for. I have created 3 functions for this again checking that FailedCount or Passed Count is 0 depending on the test.&lt;/p>
&lt;pre>&lt;code>function Invoke-DefaultCheck {
It &amp;quot;All Checks should pass with default for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)default&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass with default setting (Yes we may set some values before but you get my drift)&amp;quot;
}
}
function Invoke-ConfigCheck {
It &amp;quot;All Checks should fail when config changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check)configchanged&amp;quot; -ValueOnly
$Tests.PassedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and fail when we have changed the config values&amp;quot;
}
}
function Invoke-ValueCheck {
It &amp;quot;All Checks should pass when setting changed for $Check&amp;quot; {
$Tests = get-variable &amp;quot;$($Check) value changed&amp;quot; -ValueOnly
$Tests.FailedCount | Should -Be 0 -Because &amp;quot;We expect all of the checks to run and pass when we have changed the settings to match the config values&amp;quot;
}
}
&lt;/code>&lt;/pre>
&lt;p>Now I can use those functions inside a loop in my Integration Pester Test&lt;/p>
&lt;pre>&lt;code>$TestingTheChecks = @('errorlogscount','jobhistory')
Foreach ($Check in $TestingTheChecks) {
Context &amp;quot;$Check Checks&amp;quot; {
Invoke-DefaultCheck
Invoke-ConfigCheck
Invoke-ValueCheck
}
}
&lt;/code>&lt;/pre>
&lt;h2 id="write-some-integration-tests">Write Some Integration Tests&lt;/h2>
&lt;p>So for this new test I have added a value to the TestingTheChecks array then I can test my checks. The default check I can check like this&lt;/p>
&lt;pre>&lt;code># run the checks against these instances (SQL2014 agent wont start :-( ))
$null = Set-DbcConfig -Name app.sqlinstance $containers.Where {$_ -ne 'localhost,15588'}
# by default all tests should pass on default instance settings
$jobhistorydefault = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Now I need to change the configurations so that they do not match the defaults and run the checks again&lt;/p>
&lt;pre>&lt;code>#Change the configuration to test that the checks fail
$null = Set-DbcConfig -Name agent.history. maximumjobhistoryrows -value 1000
$null = Set-DbcConfig -Name agent.history.maximumhistoryrows -value 10000
$jobhistoryconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;p>Next we have to change the instance settings so that they match the dbachecks configuration and run the checks and test that they all pass.&lt;/p>
&lt;p>We will (of course) use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> for this. First we need to find the command that we need&lt;/p>
&lt;pre>&lt;code>Find-DbaCommand jobserver
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/find-dbacommand.png"
loading="lazy"
>&lt;/p>
&lt;p>and then work out how to use it&lt;/p>
&lt;pre>&lt;code>Get-Help Set-DbaAgentServer -Detailed
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/set-the-values.png"
loading="lazy"
>&lt;/p>
&lt;p>There is an example that does exactly what we want 🙂 So we can run this.&lt;/p>
&lt;pre>&lt;code>$setDbaAgentServerSplat = @{
MaximumJobHistoryRows = 1000
MaximumHistoryRows = 10000
SqlInstance = $containers.Where{$_ -ne 'localhost,15588'}
SqlCredential = $cred
}
Set-DbaAgentServer @setDbaAgentServerSplat
$jobhistoryvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check JobHistory -Show None -PassThru
&lt;/code>&lt;/pre>
&lt;h2 id="run-the-integration-tests">Run the Integration Tests&lt;/h2>
&lt;p>And then we will check that all of the checks are passing and failing as expected&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\DockerTests.ps1
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/testing-the-checks.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="integration-test-for-error-log-counts">Integration Test For Error Log Counts&lt;/h2>
&lt;p>There is another integration test there for the error logs count. This works in the same way. Here is the code&lt;/p>
&lt;pre>&lt;code>#region error Log Count - PR 583
# default test
$errorlogscountdefault = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set a value and then it will fail
$null = Set-DbcConfig -Name policy.errorlog.logcount -Value 10
$errorlogscountconfigchanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
# set the value and then it will pass
$null = Set-DbaErrorLogConfig -SqlInstance $containers -SqlCredential $cred -LogCount 10
$errorlogscountvaluechanged = Invoke-DbcCheck -SqlCredential $cred -Check ErrorLogCount -Show None -PassThru
#endregion
&lt;/code>&lt;/pre>
&lt;h2 id="merge-the-changes">Merge the Changes&lt;/h2>
&lt;p>So with all the tests passing I can merge the PR into the development branch and Azure DevOps will start a build. Ultimately, I would like to add the integration to the build as well following &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André&lt;/a>‘s blog post but for now I used the GitHub Pull Request extension to merge the pull request into development which started a &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_build/results?buildId=365&amp;amp;view=results" target="_blank" rel="noopener"
>build&lt;/a> and then merged that into master which signed the code and deployed it to the PowerShell gallery as you can see &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/_releaseProgress?_a=release-environment-logs&amp;amp;releaseId=81&amp;amp;environmentId=81" target="_blank" rel="noopener"
>here&lt;/a> and the result is&lt;/p>
&lt;p>&lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.164" target="_blank" rel="noopener"
>https://www.powershellgallery.com/packages/dbachecks/1.1.164&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2019/01/powershell-gallery.png"
loading="lazy"
>&lt;/p></description></item><item><title>Running Windows and Linux SQL Containers together</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-windows-and-linux-sql-containers-together/</link><pubDate>Mon, 24 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-windows-and-linux-sql-containers-together/</guid><description>&lt;p>Just for fun I decided to spend Christmas Eve getting Windows and Linux SQL containers running together.&lt;/p>
&lt;h2 id="warning">WARNING&lt;/h2>
&lt;p>This is NOT a production ready solution, in fact I would not even recommend that you try it.&lt;br>
I definitely wouldn’t recommend it on any machine with anything useful on it that you want to use again.&lt;br>
We will be using a re-compiled dockerd.exe created by someone else and you know the rules about downloading things from the internet don’t you? and trusting unknown unverified people?&lt;/p>
&lt;p>Maybe you can try this in an Azure VM or somewhere else safe.&lt;/p>
&lt;p>Anyway, with that in mind, lets go.&lt;/p>
&lt;h2 id="linux-containers-on-windows">Linux Containers On Windows&lt;/h2>
&lt;p>You can run Linux containers on Windows in Docker as follows. You need to be running the latest Docker for Windows.&lt;/p>
&lt;p>Right click on the whale in the task bar and select Settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-settings.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Notice that I am running Windows Containers as there is a switch to Linux containers option. If you see Switch to Windows containers then click that first.&lt;/p>
&lt;p>Click on Daemon and then tick the experimental features tick box and press apply.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-daemon-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-daemon-settings.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Docker will restart and you can now run Linux containers alongside windows containers.&lt;/p>
&lt;p>So you you can pull the Ubuntu container with&lt;/p>
&lt;pre>&lt;code>docker pull ubuntu:18.04
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-image-pull.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-image-pull.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and then you can run it with&lt;/p>
&lt;pre>&lt;code>docker run -it --name ubuntu ubuntu:18.04
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-coontainer-interactively.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/ubuntu-coontainer-interactively.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>There you go one Linux container running 🙂&lt;br>
A good resource for learning bash for SQL Server DBAs is Kellyn Pot’Vin-Gorman &lt;a class="link" href="https://dbakevlar.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/DBAKevlar" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://www.red-gate.com/simple-talk/sql/sql-linux/how-to-linux-for-sql-server-dbas-part-1/" target="_blank" rel="noopener"
>series on Simple Talk&lt;/a>&lt;/p>
&lt;p>Type Exit to get out of the container and to remove it&lt;/p>
&lt;pre>&lt;code>docker rm ubuntu
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/exit-remove-ubuntu.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/exit-remove-ubuntu.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h3 id="heading">&lt;/h3>
&lt;p>Running SQL Linux Containers On Windows&lt;/p>
&lt;p>So can we run SQL Containers ?&lt;/p>
&lt;p>Well, we can pull the image successfully.&lt;/p>
&lt;pre>&lt;code>docker pull mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
&lt;/code>&lt;/pre>
&lt;p>If you try that without the experimental features enabled you will get this error.&lt;/p>
&lt;blockquote>
&lt;p>image operating system “linux” cannot be used on this platform&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/wrong-platform.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/wrong-platform.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>So you would think that what you can do is to use the code from Andrew ‘dbafromthecold’ Pruski’s &lt;a class="link" href="http://DBAfromthecold.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/DBAfromthecold" target="_blank" rel="noopener"
>t&lt;/a> excellent &lt;a class="link" href="https://dbafromthecold.com/2017/03/15/summary-of-my-container-series/" target="_blank" rel="noopener"
>container series&lt;/a>&lt;/p>
&lt;pre>&lt;code>docker run -d -p 15789:1433 --env ACCEPT_EULA=Y --env SA_PASSWORD=Testing1122 --name testcontainer mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
&lt;/code>&lt;/pre>
&lt;p>When you do, the command will finish successfully but the container won’t be started (as can been seen by the red dot in the docker explorer).&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/container-wont-run.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/container-wont-run.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>If you look at the logs for the container. (I am lazy, I right click on the container and choose show logs in VS Code 🙂 ) you will see&lt;/p>
&lt;blockquote>
&lt;p>sqlservr: This program requires a machine with at least 2000 megabytes of memory.&lt;br>
/opt/mssql/bin/sqlservr: This program requires a machine with at least 2000 megabytes of memory.&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/needs-more-memory.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/needs-more-memory.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now, if you are running Linux containers, this is an easy fix. All you have to do is to right click on the whale in the taskbar, choose Settings, Advanced and move the slider for the Memory and click apply.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/linux-containers-memory-increase.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/linux-containers-memory-increase.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>But in Windows containers that option is not available.&lt;/p>
&lt;p>If you go a-googling you will find that &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>Shawn Melton&lt;/a> created an &lt;a class="link" href="https://github.com/Microsoft/mssql-docker/issues/293" target="_blank" rel="noopener"
>issue for thi&lt;/a>s many months ago, which gets referenced by &lt;a class="link" href="https://github.com/Microsoft/opengcs/issues/145" target="_blank" rel="noopener"
>this issue&lt;/a> for the guest compute service, which references t&lt;a class="link" href="https://github.com/moby/moby/pull/37296" target="_blank" rel="noopener"
>his PR&lt;/a> in moby. But as this hasn’t been merged into master yet it is not available. I got bored of waiting for this and decided to look a bit deeper today.&lt;/p>
&lt;h3 id="get-it-working-just-for-fun">Get It Working Just For Fun&lt;/h3>
&lt;p>So, you read the warning at the top?&lt;/p>
&lt;p>Now let’s get it working. I take zero credit here. All of the work was done by Brian Weeteling &lt;a class="link" href="https://www.brianweet.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://github.com/brianweet" target="_blank" rel="noopener"
>G&lt;/a> in &lt;a class="link" href="https://www.brianweet.com/2018/04/26/running-mssql-server-linux-using-lcow.html" target="_blank" rel="noopener"
>this post&lt;/a>&lt;/p>
&lt;p>So you can follow Brians examples and check out the source code and compile it as he says or you can &lt;a class="link" href="https://www.brianweet.com/assets/mssql-linux/dockerd.rar" target="_blank" rel="noopener"
>download the exe&lt;/a> that he has made available (remember the warning?)&lt;/p>
&lt;p>Stop Docker for Windows, and with the file downloaded and unzipped, open an admin PowerShell and navigate to the directory the dockerd.exe file is and run&lt;/p>
&lt;pre>&lt;code>.\dockerd.exe
&lt;/code>&lt;/pre>
&lt;p>You will get an output like this and it will keep going for a while.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/running-dockerd.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/running-dockerd.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Leave this window open whilst you are using Docker like this. Once you see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/logs.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/logs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then open a new PowerShell window or VS Code. You will need to run it as admin. I ran&lt;/p>
&lt;pre>&lt;code>docker ps-a
&lt;/code>&lt;/pre>
&lt;p>to see if it was up and available.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/docker-ps.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/docker-ps.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>I also had to create a bootx64.efi file at C:\Program Files\Linux Containers which I did by copying and renaming the kernel file in that folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/bootx64-file.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/bootx64-file.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Now I can use a docker-compose file to create 5 containers. Four will be Windows containers from &lt;a class="link" href="https://hub.docker.com/u/dbafromthecold" target="_blank" rel="noopener"
>Andrews Docker hub repositories&lt;/a> or &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server/" target="_blank" rel="noopener"
>Microsoft’s Docker Hub&lt;/a> for SQL 2012, SQL 2014, SQL 2016, and SQL 2017 and one will be the latest &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server" target="_blank" rel="noopener"
>Ubuntu SQL 2019 CTP 2.2 image&lt;/a>. Note that you have to use version 2.4 of docker compose as the platform tag is not available yet in any later version, although it is coming to 3.7 soon.&lt;/p>
&lt;pre>&lt;code>version: '2.4'
services:
sql2019:
image: mcr.microsoft.com/mssql/server:2019-CTP2.2-ubuntu
platform: linux
ports:
- &amp;quot;15585:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2012:
image: dbafromthecold/sqlserver2012dev:sp4
platform: windows
ports:
- &amp;quot;15589:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2014:
image: dbafromthecold/sqlserver2014dev:sp2
platform: windows
ports:
- &amp;quot;15588:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2016:
image: dbafromthecold/sqlserver2016dev:sp2
platform: windows
ports:
- &amp;quot;15587:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
sql2017:
image: microsoft/mssql-server-windows-developer:2017-latest
platform: windows
ports:
- &amp;quot;15586:1433&amp;quot;
environment:
SA_PASSWORD: &amp;quot;Password0!&amp;quot;
ACCEPT_EULA: &amp;quot;Y&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Save this code as docker-compose.yml and navigate to the directory in an admin PowerShell or VS Code and run&lt;/p>
&lt;pre>&lt;code>docker-compose up -d
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and now I have Windows and Linux SQL containers running together. This means that I can test some code against all versions of SQL from 2012 to 2019 easily in containers 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/containers-in-SSMS.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/containers-in-SSMS.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers-dbatools.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-the-containers-dbatools.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>So that is just a bit of fun.&lt;/p>
&lt;p>To return to the normal Docker, simply CTRL and C the admin PowerShell you ran .\dockerd.exe in and you will see the logs showing it shutting down.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/shutdown-docker.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/shutdown-docker.png?fit=630%2C142"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You will then be able to start Docker For Windows as usual.&lt;/p>
&lt;p>I look forward to the time, hopefully early next year when all of the relevant PR’s have been merged and this is available in Docker for Windows.&lt;/p>
&lt;p>Happy Automating 🙂&lt;/p></description></item><item><title>Getting SQL Services, Starting, Stopping and Restarting them with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-services-starting-stopping-and-restarting-them-with-dbatools/</link><pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-services-starting-stopping-and-restarting-them-with-dbatools/</guid><description>&lt;p>There was a question in the &lt;a class="link" href="https://sqlcommunity.slack.com/#dbatools" target="_blank" rel="noopener"
>#dbatools slack channel &lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/dbatools-question.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/dbatools-question.png"
loading="lazy"
alt="dbatools question"
>&lt;/a>&lt;/p>
&lt;h3 id="getting-dbatools">Getting dbatools&lt;/h3>
&lt;p>dbatools enables you to administer SQL Server with PowerShell. To get it simply open PowerShell run&lt;/p>
&lt;p>Install-Module dbatools&lt;/p>
&lt;p>You can find more details on &lt;a class="link" href="http://dbatools.io/install" target="_blank" rel="noopener"
>the web-site&lt;/a>&lt;/p>
&lt;h3 id="finding-the-command">Finding the Command&lt;/h3>
&lt;p>To find a command you can use the dbatools command &lt;a class="link" href="https://docs.dbatools.io/#Find-DbaCommand" target="_blank" rel="noopener"
>Find-DbaCommand&lt;/a>&lt;br>
For commands for service run&lt;/p>
&lt;p>Find-DbaCommand Service&lt;/p>
&lt;p>There are a whole bundle returned&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/find-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/find-services.png"
loading="lazy"
alt="find services.png"
>&lt;/a>&lt;/p>
&lt;p>This is how you can find any dbatools command. There is also a -Tag parameter on Find-DbaCommand.&lt;/p>
&lt;p>Find-DbaCommand -Tag Service&lt;/p>
&lt;p>This returns&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/find-services-tag.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/find-services-tag.png"
loading="lazy"
alt="find services tag.png"
>&lt;/a>&lt;/p>
&lt;h3 id="how-to-use-any-powershell-command">How to use any PowerShell command&lt;/h3>
&lt;p>Always always start with Get-Help&lt;/p>
&lt;p>Get-Help Get-DbaService -Detailed&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/get-help.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/get-help.png"
loading="lazy"
alt="get help.png"
>&lt;/a>&lt;/p>
&lt;p>This will show you all the information about the command including examples 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/help-examples.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/help-examples.png"
loading="lazy"
alt="help examples.png"
>&lt;/a>&lt;/p>
&lt;p>All of these commands below require that the account running the PowerShell is a Local Admin on the host.&lt;/p>
&lt;h3 id="one-host-many-hosts">One Host Many Hosts&lt;/h3>
&lt;p>Now I have used just one host for all of the examples on this page. Do not be fooled, you can always use an array of hosts wherever I have $ComputerName you can set it to as many hosts as you like&lt;/p>
&lt;p>$ComputerName = &amp;lsquo;SQL0&amp;rsquo;,&amp;lsquo;SQL1&amp;rsquo;&lt;/p>
&lt;p>You can even get those names form a database, Excel sheet, CMS.&lt;/p>
&lt;h3 id="getting-the-services">Getting the Services&lt;/h3>
&lt;p>So to get the services on a machine run&lt;/p>
&lt;p>$ComputerName = &amp;lsquo;Name of Computer&amp;rsquo;
Get-DbaService -ComputerName $ComputerName&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/getting-servies-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/getting-servies-1.png"
loading="lazy"
alt="getting servies 1.png"
>&lt;/a>&lt;/p>
&lt;p>You can output into a table format.&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>I will use the alias ft for this in some of the examples, that is fine for the command line but use the full command name in any code that you write that other people use&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/services-table.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/services-table.png"
loading="lazy"
alt="services table.png"
>&lt;/a>&lt;/p>
&lt;p>You have an object returned so you can output to anything if you want – CSV, JSON, text file, email, azure storage, database, the world is your oyster.&lt;/p>
&lt;h3 id="getting-the-services-for-one-instance">Getting the Services for one instance&lt;/h3>
&lt;p>The &lt;a class="link" href="https://docs.dbatools.io/#Get-DbaService" target="_blank" rel="noopener"
>Get-DbaService&lt;/a> command has a number of parameters. There is an InstanceName parameter enabling you to get only the services for one instance. If we just want the default instance services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MSSQLSERVER| Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/default-instances.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/default-instances.png"
loading="lazy"
alt="default instances.png"
>&lt;/a>&lt;/p>
&lt;p>Just the MIRROR instance services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MIRROR| Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/mirror-instances.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/mirror-instances.png"
loading="lazy"
alt="mirror instances.png"
>&lt;/a>&lt;/p>
&lt;h3 id="getting-just-the-engine-or-agent-services">Getting just the Engine or Agent services&lt;/h3>
&lt;p>You can also use the -Type parameter to get only services of a particular type. You can get one of the following: “Agent”,”Browser”,”Engine”,”FullText”,”SSAS”,”SSIS”,”SSRS”, “PolyBase”&lt;/p>
&lt;p>So to get only the Agent Services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/agent-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/agent-services.png"
loading="lazy"
alt="agent services.png"
>&lt;/a>&lt;/p>
&lt;p>You can combine the InstanceName and the Type parameters to get say only the default instance engine service&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -InstanceName MSSQLSERVER -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/default-engine-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/default-engine-service.png"
loading="lazy"
alt="default engine service.png"
>&lt;/a>&lt;/p>
&lt;h3 id="starting-and-stopping-and-restarting-services">Starting and stopping and restarting services&lt;/h3>
&lt;p>You can use &lt;a class="link" href="https://docs.dbatools.io/#Start-DbaService" target="_blank" rel="noopener"
>Start-DbaService&lt;/a> and &lt;a class="link" href="https://docs.dbatools.io/#Stop-DbaService" target="_blank" rel="noopener"
>Stop-DbaService&lt;/a> to start and stop the services. They each have ComputerName, InstanceName and Type parameters like Get-DbaService.&lt;/p>
&lt;p>So if after running&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>you find that all services are stopped&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped.png"
loading="lazy"
alt="all stopped.png"
>&lt;/a>&lt;/p>
&lt;h3 id="start-all-the-services">Start All the Services&lt;/h3>
&lt;p>You can run&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>and start them all&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-them-all.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-them-all.png"
loading="lazy"
alt="start them all.png"
>&lt;/a>&lt;/p>
&lt;p>The full text service was started with the engine service which is why it gave a warning. You can see this if you have all of the services stopped and just want to start the engine services with the type parameter.&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName | Format-Table
Start-DbaService -ComputerName $ComputerName -Type Engine
Get-DbaService -ComputerName $ComputerName | Format-Table&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped-start-engine.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/all-stopped-start-engine.png"
loading="lazy"
alt="all stopped - start engine.png"
>&lt;/a>&lt;/p>
&lt;p>If you just want to start the Agent services, you can use&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-agent.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-agent.png"
loading="lazy"
alt="start agent.png"
>&lt;/a>&lt;/p>
&lt;p>You can start just the services for one instance&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -InstanceName MIRROR&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-instance-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-instance-services.png"
loading="lazy"
alt="start instance services.png"
>&lt;/a>&lt;/p>
&lt;h3 id="stopping-the-services">Stopping the services&lt;/h3>
&lt;p>Stopping the services works in the same way. Lets stop the MIRROR instance services we have just started. This will stop the services for an instance&lt;/p>
&lt;p>Stop-DbaService -ComputerName $ComputerName -InstanceName MIRROR&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stopping-instance-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stopping-instance-services.png"
loading="lazy"
alt="stopping instance services.png"
>&lt;/a>&lt;/p>
&lt;p>We can stop them by type as well, although this will show an extra requirement. If we start our MIRROR instance services again and then try to stop just the engine type.&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName -InstanceName MIRROR | ft
Stop-DbaService -ComputerName $ComputerName -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/cant-stop.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/cant-stop.png"
loading="lazy"
alt="cant stop.png"
>&lt;/a>&lt;/p>
&lt;p>You will get a warning due to the dependant services&lt;/p>
&lt;blockquote>
&lt;p>WARNING: [10:31:02][Update-ServiceStatus] (MSSQL$MIRROR on SQL0) The attempt to stop the service returned the following error: The service cannot be stopped because other services that are running are dependent on it.&lt;br>
WARNING: [10:31:02][Update-ServiceStatus] (MSSQL$MIRROR on SQL0) Run the command with ‘-Force’ switch to force the restart of a dependent SQL Agent&lt;/p>
&lt;/blockquote>
&lt;p>So all you have to do is use the force Luke (or whatever your name is!)&lt;/p>
&lt;p>Stop-DbaService -ComputerName $ComputerName -Type Engine -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/Use-the-force.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/Use-the-force.png"
loading="lazy"
alt="Use the force.png"
>&lt;/a>&lt;/p>
&lt;p>You can also stop the services for an entire host, again you will need the Force parameter.&lt;/p>
&lt;p>Start-DbaService -ComputerName $ComputerName |ft
Stop-DbaService -ComputerName $ComputerName -Force | ft&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stop-all-of-them.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stop-all-of-them.png"
loading="lazy"
alt="stop all of them.png"
>&lt;/a>&lt;/p>
&lt;h3 id="restarting-services">Restarting Services&lt;/h3>
&lt;p>It will come as no surprise by now to learn that &lt;a class="link" href="https://docs.dbatools.io/#Restart-DbaService" target="_blank" rel="noopener"
>Restart-DbaService&lt;/a> follows the same pattern. It also has ComputerName, InstanceName and Type parameters like Get-DbaService, Start-DbaService and Stop-DbaService (Consistency is great, It’s one of the things that is being worked on towards 1.0 as you can see in the &lt;a class="link" href="https://sqlcollaborative.github.io/boh.html" target="_blank" rel="noopener"
>Bill of Health&lt;/a>)&lt;/p>
&lt;p>Again you will need the -Force for dependant services, you can restart all of the services on a host with&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-tehm-all.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-tehm-all.png"
loading="lazy"
alt="restart tehm all.png"
>&lt;/a>&lt;/p>
&lt;p>or just the services for an instance&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -InstanceName MIRROR -Force&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-instance.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-instance.png"
loading="lazy"
alt="restart instance.png"
>&lt;/a>&lt;/p>
&lt;p>or just the Agent Services&lt;/p>
&lt;p>Restart-DbaService -ComputerName $ComputerName -Type Agent&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restart-agent.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restart-agent.png"
loading="lazy"
alt="restart agent.png"
>&lt;/a>&lt;/p>
&lt;h3 id="doing-a-bit-of-coding">Doing a bit of coding&lt;/h3>
&lt;p>Now none of that answers @g-kannan’s question. Restarting only services with a certain service account.&lt;/p>
&lt;p>With PowerShell you can pipe commands together so that the results of the first command are piped into the second. So we can get all of the engine services on a host for an instance with Get-DbaService and start them with Start-DbaService like this&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Start-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start.png"
loading="lazy"
alt="start.png"
>&lt;/a>&lt;/p>
&lt;p>or get all of the engine services for an instance on a host and stop them&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine  -InstanceName Mirror| Stop-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stop-one-isntance.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stop-one-isntance.png"
loading="lazy"
alt="stop one isntance.png"
>&lt;/a>&lt;/p>
&lt;p>or maybe you want to get all of the service that have stopped&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine).Where{$_.State -eq &amp;lsquo;Stopped&amp;rsquo;}&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/stopped-services.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/stopped-services.png"
loading="lazy"
alt="stopped services.png"
>&lt;/a>&lt;/p>
&lt;p>You can do the same thing with syntax that may make more sense to you if you are used to T-SQL as follows&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine) | Where State -eq &amp;lsquo;Stopped&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/T-SQL-syntax-powershell.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/T-SQL-syntax-powershell.png"
loading="lazy"
alt="T SQL syntax powershell.png"
>&lt;/a>&lt;/p>
&lt;p>and then start only those services you could do&lt;/p>
&lt;p>(Get-DbaService -ComputerName $ComputerName -Type Engine) | Where State -eq &amp;lsquo;Stopped&amp;rsquo; | Start-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/start-the-stopped-ones.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/start-the-stopped-ones.png"
loading="lazy"
alt="start the stopped ones.png"
>&lt;/a>&lt;/p>
&lt;p>(note – you would just use Start-DbaService in this case as it wont start services that are already started!)&lt;/p>
&lt;p># Stop just one of the engine services
Stop-DbaService -ComputerName $ComputerName -InstanceName MIRROR -Type Engine
# Get the engine services
Get-DbaService -ComputerName $ComputerName -Type Engine
# This will only start the one engine service that is stopped
Start-DbaService -ComputerName $ComputerName -Type Engine&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/only-one-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/only-one-service.png"
loading="lazy"
alt="only one service.png"
>&lt;/a>&lt;/p>
&lt;h3 id="come-on-rob-answer-the-question">Come On Rob! Answer the question!&lt;/h3>
&lt;p>So now that you know a lot more about these commands, you can restart only the services using a particular service account by using Get-DbaService to get the services&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Where StartName -eq &amp;rsquo;thebeard\sqlsvc&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/services-by-start-name.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/services-by-start-name.png"
loading="lazy"
alt="services by start name.png"
>&lt;/a>&lt;/p>
&lt;p>and then once you know that you have the right ‘query’ you can pipe that to Restart-DbaService (Like making sure your SELECT query returns the correct rows for your WHERE clause before running the DELETE or UPDATE)&lt;/p>
&lt;p>Get-DbaService -ComputerName $ComputerName -Type Engine | Where StartName -eq &amp;rsquo;thebeard\sqlsvc&amp;rsquo; | Restart-DbaService&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/12/restarting-only-one.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/12/restarting-only-one.png"
loading="lazy"
alt="restarting only one.png"
>&lt;/a>&lt;/p>
&lt;p>Happy Automating !&lt;/p></description></item><item><title>SQL Server Availability Group FailoverDetection Utility PowerShell Function Improvements – Named Instances, Archiving Data, Speed</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</link><pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-availability-group-failoverdetection-utility-powershell-function-improvements-named-instances-archiving-data-speed/</guid><description>&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>my last post I wrote about a new function&lt;/a> for gathering the data and running the &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy/" target="_blank" rel="noopener"
>FailoverDetection utility&lt;/a> by the &lt;a class="link" href="https://twitter.com/mssqltiger" target="_blank" rel="noopener"
>Tiger Team&lt;/a> to analyse availability group failovers. I have updated it following some comments and using it for a day.&lt;/p>
&lt;h3 id="dont-forget-the-named-instances-rob">Don’t forget the named instances Rob!&lt;/h3>
&lt;p>Michael Karpenko wrote a comment pointing out that I had not supported named instances, which was correct as it had not been written for that. Thank you Michael 🙂 I have updated the code to deal with named instances.&lt;/p>
&lt;h3 id="confusing-results">Confusing results&lt;/h3>
&lt;p>I also realised as we started testing the code that if you had run the code once and then ran it again against a different availability group the tool does not clear out the data folder that it uses so you can get confusing results.&lt;/p>
&lt;p>In the image below I had looked at the default instance and then a MIRROR named instance. As you can see the results json on the left shows the default instance SQLClusterAG while the one on the right shows both the SQLClusterAG and the MirrrAG instance results.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results.png"
loading="lazy"
alt="duplicate results.png"
>&lt;/a>&lt;/p>
&lt;p>This is not so useful if you don’t notice this at first with the expanded json!! Now you may in this situation want to see the combined results from all of the availability groups on one cluster. You could gather all of the data from each instance and then add it to the data folder easily enough.&lt;/p>
&lt;p>By cleaning out the data folder before running the utility the results are as expected.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/duplicate-results-fixed.png"
loading="lazy"
alt="duplicate results fixed.png"
>&lt;/p>
&lt;h3 id="archive-the-data-for-historical-analysis">Archive the data for historical analysis&lt;/h3>
&lt;p>One of the production DBAs pointed out that having gathered the information, it would be useful to hold it for better analysis of repeated issues. I have added an archiving step so that when the tools runs, if there is already data in the data gathering folder, it will copy that to an archive folder and name it with the date and time that the cluster log was created as this is a good estimation of when the analysis was performed. If an archive folder location is not provided it will create an archive folder in the data folder. This is not an ideal solution though, as the utility will copy all of the files and folders from there to its own location so it is better to define an archive folder in the parameters.&lt;/p>
&lt;h3 id="get-eventlog-is-sloooooooooooow">Get-Eventlog is sloooooooooooow&lt;/h3>
&lt;p>I was running the tools and noticed it sat running the system event log task for a long long time. I ran some tests using a variation of the &lt;a class="link" href="http://dbatools.io/prompt" target="_blank" rel="noopener"
>dbatools prompt.&lt;/a>&lt;/p>
&lt;p>This will show in the prompt how long it took to run the previous statement .&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/speed.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/speed.png"
loading="lazy"
alt="speed.png"
>&lt;/a>&lt;/p>
&lt;p>In the image above (which you can click to get a larger version as with all images on this blog) you can see that it took 18ms to set the date variable, FOUR MINUTES and FORTY THREE seconds to get the system log in the last 2 days using Get-EventLog and 29.1 seconds using Get-WinEvent and a FilterHashtable.&lt;/p>
&lt;h3 id="getting-the-function">Getting the function&lt;/h3>
&lt;p>This function requires PowerShell version 5 and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment – will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>. .\Invoke-SqlFailOverDetection.ps1&lt;/p>
&lt;p>There are two .’s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters and more info &lt;a class="link" href="https://blog.robsewell.com/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/" target="_blank" rel="noopener"
>on my previous post.&lt;/a>&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Gathering all the Logs and Running the Availability Group Failover Detection Utility with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</link><pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/gathering-all-the-logs-and-running-the-availability-group-failover-detection-utility-with-powershell/</guid><description>&lt;p>30/11/2018 – Function has been updated to deal with named instances.&lt;/p>
&lt;p>Last week the Tiger Team released their Availability Group Failover Detection Utility which will provide root cause analysis on Cluster Logs, SQL Error Logs, and the Availability groups extended events logs. There is a &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_server_team/failover-detection-utility-availability-group-failover-analysis-made-easy" target="_blank" rel="noopener"
>blog post here&lt;/a> and the tool can be downloaded from the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/tree/master/Always-On/FailoverDetection" target="_blank" rel="noopener"
>Tiger Team GitHub Repository&lt;/a>&lt;/p>
&lt;h3 id="a-bit-of-faffing">A Bit of Faffing*&lt;/h3>
&lt;p>It states on the &lt;a class="link" href="https://github.com/Microsoft/tigertoolbox/blob/master/README.md" target="_blank" rel="noopener"
>readme&lt;/a> for the Tiger Team GitHub Repository.&lt;/p>
&lt;blockquote>
&lt;p>Repository for Tiger team for “as-is” solutions and tools/scripts that the team publishes.&lt;/p>
&lt;/blockquote>
&lt;p>The important words are “as-is” sometimes these tools need a bit of faffing some looking after!&lt;/p>
&lt;p>There is a pre-requisite and sometimes a little “fixing” that you need to do to get it to run correctly.&lt;/p>
&lt;p>First, install the “Microsoft Visual C++ Redistributable for Visual Studio 2017” &lt;a class="link" href="https://visualstudio.microsoft.com/downloads/" target="_blank" rel="noopener"
>from here.&lt;/a> On the download page, scroll down to the “Other Tools and Frameworks” section to download the redistributable (x64 version).&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/cdistributable.png"
loading="lazy"
alt="cdistributable.PNG"
>&lt;/p>
&lt;p>Then when you run &lt;code>FailoverDetection.exe&lt;/code> you may get strong name validation errors like.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/strong-name.png"
loading="lazy"
alt="strong name.png"
>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Unhandled Exception: System.IO.FileLoadException: Could not load file or assembly ‘Microsoft.Sq1Server.XEvent.Linq, Version=15.0.0.0, Culture=neutral, PublicKeyToken=89845dcd808cc91’ or one of it s dependencies. Strong name validation failed. (Exception from HRESULT; 0x8013141A) – – – &amp;gt;.Security.SecurityException: Strong name validation failed. (Exception from HRESULT: 0x8e13141A)&lt;br>
—End of inner exception stack trace  —&lt;br>
at FailoverDetector. XeventParser.LoadXevent(String xelFi1eName, String serverName)&lt;/p>
&lt;/blockquote>
&lt;p>Then you will need to run the sn.exe tool which is in the zip file. Use this syntax.&lt;/p>
&lt;p>&lt;code>.\sn.exe -Vr PATHTODLLFile&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/stroingname-fix.png"
loading="lazy"
alt="stroingname fix.png"
>&lt;/a>&lt;/p>
&lt;p>I had to do it for two DLLs.&lt;/p>
&lt;p>NOTE – If you get an error like this when running sn.exe (or any executable) from PowerShell it means that you have missed the &lt;code>.\&lt;/code> (dot whack) in front of the executable name.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.pnghttps://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/striong-name-fail.png"
loading="lazy"
alt="striong name fail.png"
>&lt;/a>&lt;/p>
&lt;p>* &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>Faffing&lt;/a> – Doing something that is a bit awkward &lt;a class="link" href="https://www.thefreedictionary.com/faffing" target="_blank" rel="noopener"
>See Link&lt;/a> .&lt;/p>
&lt;h3 id="logs-required-for-the-tool">Logs required for the Tool&lt;/h3>
&lt;p>To run the Failover Detection Utility you need to gather the following information from each replica and place it in the specified data folder.&lt;/p>
&lt;ul>
&lt;li>SQL error logs&lt;/li>
&lt;li>Always On Availability Groups Extended Event Logs&lt;/li>
&lt;li>System Health Extended Event Logs&lt;/li>
&lt;li>System log&lt;/li>
&lt;li>Windows cluster log&lt;/li>
&lt;/ul>
&lt;p>Once you have gathered all of that data then you need to alter the configuration file for the executable.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Data Source Path&amp;#34;: &amp;#34;Path to Data File&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Health Level&amp;#34;: 3,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Instances&amp;#34;: \[
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica1&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Replica3&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h3 id="running-the-tool">Running The Tool&lt;/h3>
&lt;p>Once you have done that you can then run the Failover Detection Utility. You can double click the exe,&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe.png"
loading="lazy"
alt="run the exe.PNG"
>&lt;/a>&lt;/p>
&lt;p>or you can run it from the command line.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.pnghttps://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run-the-exe-with-powershell.png"
loading="lazy"
alt="run the exe with powershell.PNG"
>&lt;/a>&lt;/p>
&lt;p>In both cases it won’t exit so when you see the Saving Results to JSON file, you can press enter (sometimes twice!).&lt;/p>
&lt;p>The results can be seen in the JSON file which will be stored in a Results directory in the directory that the the FailoverDetection.exe exists.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results.png"
loading="lazy"
alt="results.PNG"
>&lt;/a>&lt;/p>
&lt;p>You can also use some switches with the FailoverDetection utility.&lt;/p>
&lt;p>**–Analyze – **When “–Analyze” is specified as a parameter, the utility will load configuration file without copying log data. It assumes the log files have already been copied over. It does everything as default mode except copying log data. This option is useful if you already have the data in the local tool execution subdirectories and want to rerun the analysis.&lt;/p>
&lt;p>–&lt;strong>-Show&lt;/strong> -The utility after analyzing log data will display the results in the command console. Additionally, the results will be persisted to a JSON file in the results folder.&lt;/p>
&lt;p>They look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/results-show.pnghttps://blog.robsewell.com/assets/uploads/2018/11/results-show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/results-show.png"
loading="lazy"
alt="results - show.PNG"
>&lt;/a>&lt;/p>
&lt;p>Again, you need to press enter for the details to come through. The results are still saved to the Results folder as json as well so you won’t lose them.&lt;/p>
&lt;h3 id="when-you-are-doing-something-more-than-once-">When You Are Doing Something More Than Once ….&lt;/h3>
&lt;p>Automate it 🙂&lt;/p>
&lt;p>When I saw the data that needed to be gathered for this tool, I quickly turned to PowerShell to enable me to easily gather the information. That has turned into a function which will&lt;/p>
&lt;ul>
&lt;li>Download and extract the zip file from the Tiger Team GitHub repository&lt;/li>
&lt;li>Identify all of the replicas for an Availability Group and dynamically create the configuration JSON file&lt;/li>
&lt;li>Gather all of the required log files and place them in a specified data folder&lt;/li>
&lt;li>Run the FailoverDetection.exe with any of the switches&lt;/li>
&lt;li>Includes -Verbose, -Confirm, -Whatif switches so that you can easily see what is happening, be prompted to confirm before actions or see what would happen if you ran the function&lt;/li>
&lt;li>You still need to press enter at the end though 🙁&lt;/li>
&lt;li>and you will still need to install the “Microsoft Visual C++ Redistributable for Visual Studio 2017” and runt he strong names tool if needed&lt;/li>
&lt;/ul>
&lt;p>This function requires PowerShell version 5, the failovercluster module and and the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module.&lt;/p>
&lt;p>You can get the function from &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Invoke-SqlFailOverDetection.ps1" target="_blank" rel="noopener"
>my GitHub Functions Repository here (at the moment – will be adding to dbatools see below)&lt;/a>&lt;/p>
&lt;p>Load the function by either running the code or if you have it saved as a file dot-sourcing it.&lt;/p>
&lt;p>&lt;code>. .\Invoke-SqlFailOverDetection.ps1&lt;/code>&lt;/p>
&lt;p>There are two .’s with a space in between and then a \ without a space. so Dot Space Dot Whack path to file.&lt;/p>
&lt;p>The next thing you should do is what you should always do with a new PowerShell function, look at the help.&lt;/p>
&lt;p>&lt;code>Get-Help Invoke-SqlFailOverDetection -Detailed&lt;/code>&lt;/p>
&lt;p>You will find plenty of examples to get you going and explanations of all of the parameters.&lt;/p>
&lt;p>Let’s see it in action.&lt;/p>
&lt;p>First lets run with a -WhatIf switch which will show us what will happen without performing any state changing actions.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat -WhatIf
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/whatif-2.png"
loading="lazy"
alt="whatif.PNG"
>&lt;/a>&lt;/p>
&lt;p>So you can see that if we run it without the -WhatIf switch it will&lt;/p>
&lt;ul>
&lt;li>Create some directories&lt;/li>
&lt;li>Download the zip file from the repo&lt;/li>
&lt;li>Extract the zip file&lt;/li>
&lt;li>Copy the required logs from each of the replicas to the data folder&lt;/li>
&lt;li>Create the JSON configuration file&lt;/li>
&lt;li>Run the executable&lt;/li>
&lt;/ul>
&lt;p>NOTE : – I have limited the gathering of the system event log to the last 2 days to limit the amount of time spent dealing with a large system log. I gather all of the SQL Error logs in the Error log path as that works for the first scenario I wrote this for, your mileage may vary.&lt;/p>
&lt;p>So if we want to run the command we can remove the -WhatIf switch.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\new\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\new\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\new\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It can take a little while to run depending on the number of replicas, size of logs etc but once it has started running you can do other things.&lt;/p>
&lt;p>It will require being run as an account with permissions to all of the folders specified and Windows and SQL permissions on all of the replicas in the Availability Group.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/run1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/run1.png"
loading="lazy"
alt="run1.PNG"
>&lt;/a>&lt;/p>
&lt;p>As you can see below it has gathered all of the results and placed them in the data folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/datagathered.png"
loading="lazy"
alt="datagathered.PNG"
>&lt;/a>&lt;/p>
&lt;p>The results can be found in the results folder.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/resultsjson.png"
loading="lazy"
alt="resultsjson.PNG"
>&lt;/a>&lt;/p>
&lt;p>If I have already run the tool, I can use the Analyze switch to save gathering the data again. I also use the AlreadyDownloaded switch as I do not need to download the zip file again.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/analyze.png"
loading="lazy"
alt="analyze.PNG"
>&lt;/a>&lt;/p>
&lt;p>and the results are again saved in the results folder.&lt;/p>
&lt;p>I can show the results on the screen as well as saving them as JSON with the Show parameter.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$InstallationFolder = &amp;#39;C:\temp\failoverdetection\Install&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DownloadFolder = &amp;#39;C:\temp\failoverdetection\Download&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DataFolder = &amp;#39;C:\temp\failoverdetection\Data&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLInstance = &amp;#39;SQL0&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$invokeSqlFailOverDetectionSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DownloadFolder = $DownloadFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLInstance = $SQLInstance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataFolder = $DataFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">InstallationFolder = $InstallationFolder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AlreadyDownloaded = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Analyze = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Show = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-SqlFailOverDetection @invokeSqlFailOverDetectionSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/11/show.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/show.png"
loading="lazy"
alt="show.PNG"
>&lt;/a>&lt;/p>
&lt;p>You will then need to press enter to get the next lot of results.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/more-show-results.png"
loading="lazy"
alt="more show results.PNG"
>&lt;/p>
&lt;h3 id="why-not-add-this-to-dbatools">Why Not Add This To dbatools?&lt;/h3>
&lt;p>I haven’t added this to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> (yet) because I wrote it in this way for a particular need and &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> requires support for PowerShell V3 . I have, however created an issue a&lt;a class="link" href="https://github.com/sqlcollaborative/dbatools/issues/4601" target="_blank" rel="noopener"
>dded to this issue in the dbatools GitHub Repository&lt;/a> (as this is how you to start the process of adding things to &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>) so hopefully we can get it in there soon as well – in which case I will come back and update this post.&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Getting the SQL Version from a backup using dbatools ………. on PowerShell Core</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-the-sql-version-from-a-backup-using-dbatools-.-on-powershell-core/</link><pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-the-sql-version-from-a-backup-using-dbatools-.-on-powershell-core/</guid><description>&lt;p>Following an upgrade to SQL Server the backup share had a number of backups, some from the old version and some from the newer version. I was asked if I had a script to be able to get the SQL Version from the backup file from all of the files in the backup share.&lt;/p>
&lt;p>With &lt;a class="link" href="http://dbatools,io" target="_blank" rel="noopener"
>dbatools&lt;/a> this was easy to accomplish with &lt;a class="link" href="https://docs.dbatools.io/#Read-DbaBackupHeader" target="_blank" rel="noopener"
>Read-DbaBackuoHeader&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$backupshare = &amp;#34;$share\\keep&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instance = &amp;#34;SQL0\\Mirror&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$information = foreach ($BackupFile in (Get-ChildItem $backupshare)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $FileName = @{Name = &amp;#39;FileName&amp;#39;; Expression = {$BackupFile.Name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Read-DbaBackupHeader -SqlInstance $Instance -Path $BackupFile.FullName | Select-Object $FileName, DatabaseName , CompatibilityLevel, SqlVersion
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$information | Format-Table
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/read-dbabackupheader.png"
loading="lazy"
alt="read-dbabackupheader.PNG"
>&lt;/p>
&lt;p>You can get more information about the backup using &lt;code>Read-DbaBackupHeader&lt;/code> and as it is PowerShell it is easy to put this information into any format that you wish, maybe into a database with &lt;a class="link" href="https://docs.dbatools.io/#Write-DbaDataTable" target="_blank" rel="noopener"
>&lt;code>Write-DbaDataTable&lt;/code>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>So I looked at &lt;a class="link" href="https://t.co/MUw7Dw7CRv" target="_blank" rel="noopener"
>https://t.co/MUw7Dw7CRv&lt;/a>&lt;/p>
&lt;p>I saw the words &amp;quot; Support for PS Core on Windows 🎉&amp;quot;&lt;/p>
&lt;p>I updated the module to 0.9.522 and ran a command and&lt;/p>
&lt;p>BOOOOOOOOOOOOOOOOOOM&lt;/p>
&lt;p>Good work fine &lt;a class="link" href="https://twitter.com/psdbatools?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@psdbatools&lt;/a> contirbutors and &lt;a class="link" href="https://twitter.com/cl?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@cl&lt;/a> &lt;a class="link" href="https://t.co/fzpSIju1Gx" target="_blank" rel="noopener"
>pic.twitter.com/fzpSIju1Gx&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/1065955800823332864?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>November 23, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Support for PowerShell Core in dbatools is coming along very nicely. Following some hard work by the dbatools team and some PowerShell Community members like &lt;a class="link" href="https://twitter.com/IISResetMe" target="_blank" rel="noopener"
>Mathias Jessen&lt;/a> it is now possible to run a large number of dbatools commands in PowerShell Core running on Windows. There is still a little bit of work to do to get it working on Linux and Mac but I hear the team are working hard on that.&lt;/p>
&lt;p>So the code example you see above was running on Windows 10 using PowerShell 6.1.1 the current latest stable release. This is excellent news and congratulations to all those working hard to make this work&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/11/dbatoolscore.png"
loading="lazy"
alt="dbatoolscore.PNG"
>&lt;/p>
&lt;p>If you want to try PowerShell Core, you can follow the instructions&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-windows?view=powershell-6" target="_blank" rel="noopener"
>Here for Windows&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-linux?view=powershell-6" target="_blank" rel="noopener"
>Here for Linux&lt;/a>&lt;/li>
&lt;li>&lt;a class="link" href="https://docs.microsoft.com/en-gb/powershell/scripting/setup/installing-powershell-core-on-macos?view=powershell-6" target="_blank" rel="noopener"
>Or here for MacOs&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>PASS Summit, SQLTrain and My First US SQL Saturday</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</link><pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</guid><description>&lt;p>Next week is the week when I used to dread looking at Twitter and especially the &lt;a class="link" href="https://twitter.com/search?q=%23passsummit&amp;amp;src=typd" target="_blank" rel="noopener"
>#PASSsummit&lt;/a> hashtag, watching all of those folk having a great time in great sessions and doing all of the networking. Last year I was lucky enough to attend for the first time and take part in &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and CKs pre-con, this year I decided to add a US SQL Saturday to the list.&lt;/p>
&lt;p>I shall be attending &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Oregon in Portland&lt;/a> and presenting about &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>dbatools&lt;/a>. I am really lucky, my amazing Dad, now that he is retired, happily plays Dad’s taxi (still!) and frequently drives me to the airport when I go away on trips. This is the first time he has really gone Wow! When I asked why, it is because Portland is where &lt;a class="link" href="https://www.imdb.com/title/tt1830617/" target="_blank" rel="noopener"
>Grimm is filmed&lt;/a> and he has watched the whole series and loved it!&lt;/p>
&lt;p>I am looking forward to ticking off another thing on my list of things to do and presenting at a US SQL Saturday to add to 12 SQL Saturday cities in Europe and multiple other events around the world. If you are there come up and say hi.&lt;/p>
&lt;p>I shall also be room monitoring for the &lt;a class="link" href="https://www.sqlsaturday.com/808/Speakers/Details.aspx?name=amy-herold&amp;amp;spid=1767" target="_blank" rel="noopener"
>PowerShell for the DBA session&lt;/a> by Amy Herold &lt;a class="link" href="https://twitter.com/texasamy" target="_blank" rel="noopener"
>t&lt;/a> | &lt;a class="link" href="http://www.sqlkitten.com/" target="_blank" rel="noopener"
>b&lt;/a> There are still volunteer slots available to help, &lt;a class="link" href="https://www.sqlsaturday.com/808/Volunteers.aspx" target="_blank" rel="noopener"
>sign up here&lt;/a> if you are going. It is a lot of fun and an excellent way to give something back. SQL Saturdays take a lot of work to organise and organisers are always willing for some help. You will meet new people and have a lot of fun as well.&lt;/p>
&lt;p>To get to Seattle I am going on the SQL Train. A whole bunch of data platform folk travelling on a train together up to Seattle for PASS Summit. It looks like it will be a lot of fun 🙂&lt;/p>
&lt;p>Once in Seattle it is time for the week where others will not want to look at my twitter feed 🙂 A whole week at PASS Summit watching the sessions and networking (there may be beer involved) with our peers.&lt;/p>
&lt;p>My one piece of advice is please don’t hide away in your hotel room for all of the time that sessions are not on. I know that dealing with a large amount of people can be tough and you might need some me time ( I will ) but there are a lot of activities both loud and quieter where you will have the opportunity to meet up and make new friends and contacts which may really pay back further down the line and you will have fun too.&lt;/p>
&lt;p>On the Tuesday I am doing a pre-conference session Professional and Proficient PowerShell: From Writing Scripts to Developing Solutions. A whole day where I will be showing how to write PowerShell modules and all of the tips and tricks that I have learnt over the years.&lt;/p>
&lt;p>Wednesday sees me embracing my inner &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> – unfortunately he is unable to make PASS Summit this year, so I will be delivering the session dbatools Powershell Library – The Complete Introduction in his place in room 2AB. I shall try to do it in as cool and relaxed a way as he does (It probably wont work I will get too excited 🙂 )&lt;/p>
&lt;p>On Thursday I will be talking about &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> in room 6C which will also be streamed on PASSTv.&lt;/p>
&lt;p>In between all of that, I shall be attending some networking events, visiting sessions, hanging out with people new and old and walking down the corridors, so if you see me, stop me and say hi, I’d love to meet you 🙂&lt;br>
(note – just before my sessions I may be too nervous to properly have a conversation)&lt;/p>
&lt;p>Hopefully, I will meet you there and for the twitter folk stuck back in Europe I empathise 🙂&lt;/p></description></item><item><title>PASS Summit, SQLTrain and My First US SQL Saturday</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</link><pubDate>Wed, 31 Oct 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pass-summit-sqltrain-and-my-first-us-sql-saturday/</guid><description>&lt;p>Next week is the week when I used to dread looking at Twitter and especially the &lt;a class="link" href="https://twitter.com/search?q=%23passsummit&amp;amp;src=typd" target="_blank" rel="noopener"
>#PASSsummit&lt;/a> hashtag, watching all of those folk having a great time in great sessions and doing all of the networking. Last year I was lucky enough to attend for the first time and take part in &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and CKs pre-con, this year I decided to add a US SQL Saturday to the list.&lt;/p>
&lt;p>I shall be attending &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Oregon in Portland&lt;/a> and presenting about &lt;a class="link" href="https://www.sqlsaturday.com/808/eventhome.aspx" target="_blank" rel="noopener"
>dbatools&lt;/a>. I am really lucky, my amazing Dad, now that he is retired, happily plays Dad’s taxi (still!) and frequently drives me to the airport when I go away on trips. This is the first time he has really gone Wow! When I asked why, it is because Portland is where &lt;a class="link" href="https://www.imdb.com/title/tt1830617/" target="_blank" rel="noopener"
>Grimm is filmed&lt;/a> and he has watched the whole series and loved it!&lt;/p>
&lt;p>I am looking forward to ticking off another thing on my list of things to do and presenting at a US SQL Saturday to add to 12 SQL Saturday cities in Europe and multiple other events around the world. If you are there come up and say hi.&lt;/p>
&lt;p>I shall also be room monitoring for the &lt;a class="link" href="https://www.sqlsaturday.com/808/Speakers/Details.aspx?name=amy-herold&amp;amp;spid=1767" target="_blank" rel="noopener"
>PowerShell for the DBA session&lt;/a> by Amy Herold &lt;a class="link" href="https://twitter.com/texasamy" target="_blank" rel="noopener"
>t&lt;/a> | &lt;a class="link" href="http://www.sqlkitten.com/" target="_blank" rel="noopener"
>b&lt;/a> There are still volunteer slots available to help, &lt;a class="link" href="https://www.sqlsaturday.com/808/Volunteers.aspx" target="_blank" rel="noopener"
>sign up here&lt;/a> if you are going. It is a lot of fun and an excellent way to give something back. SQL Saturdays take a lot of work to organise and organisers are always willing for some help. You will meet new people and have a lot of fun as well.&lt;/p>
&lt;p>To get to Seattle I am going on the SQL Train. A whole bunch of data platform folk travelling on a train together up to Seattle for PASS Summit. It looks like it will be a lot of fun 🙂&lt;/p>
&lt;p>Once in Seattle it is time for the week where others will not want to look at my twitter feed 🙂 A whole week at PASS Summit watching the sessions and networking (there may be beer involved) with our peers.&lt;/p>
&lt;p>My one piece of advice is please don’t hide away in your hotel room for all of the time that sessions are not on. I know that dealing with a large amount of people can be tough and you might need some me time ( I will ) but there are a lot of activities both loud and quieter where you will have the opportunity to meet up and make new friends and contacts which may really pay back further down the line and you will have fun too.&lt;/p>
&lt;p>On the Tuesday I am doing a pre-conference session Professional and Proficient PowerShell: From Writing Scripts to Developing Solutions. A whole day where I will be showing how to write PowerShell modules and all of the tips and tricks that I have learnt over the years.&lt;/p>
&lt;p>Wednesday sees me embracing my inner &lt;a class="link" href="https://twitter.com/AndreKamman" target="_blank" rel="noopener"
>André Kamman&lt;/a> – unfortunately he is unable to make PASS Summit this year, so I will be delivering the session dbatools Powershell Library – The Complete Introduction in his place in room 2AB. I shall try to do it in as cool and relaxed a way as he does (It probably wont work I will get too excited 🙂 )&lt;/p>
&lt;p>On Thursday I will be talking about &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> in room 6C which will also be streamed on PASSTv.&lt;/p>
&lt;p>In between all of that, I shall be attending some networking events, visiting sessions, hanging out with people new and old and walking down the corridors, so if you see me, stop me and say hi, I’d love to meet you 🙂&lt;br>
(note – just before my sessions I may be too nervous to properly have a conversation)&lt;/p>
&lt;p>Hopefully, I will meet you there and for the twitter folk stuck back in Europe I empathise 🙂&lt;/p></description></item><item><title>Checking Trace Flags with dbachecks, online docs and PSPowerHour</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-trace-flags-with-dbachecks-online-docs-and-pspowerhour/</link><pubDate>Sat, 29 Sep 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-trace-flags-with-dbachecks-online-docs-and-pspowerhour/</guid><description>&lt;p>It’s been a few weeks since i have blogged as I have been busy with a lot of other things. One of which is preparing for &lt;a class="link" href="https://www.pass.org/summit/2018/Sessions/Details.aspxsid=80306" target="_blank" rel="noopener"
>my SQL Pass Summit pre-con&lt;/a> which has lead to me improving the CI/CD for &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> by adding auto-creation of online documentation, which you can find at &lt;a class="link" href="https://dbachecks.readthedocs.io" target="_blank" rel="noopener"
>https://dbachecks.readthedocs.io&lt;/a> or by running Get-Help with the -Online switch for any dbachecks command.&lt;/p>
&lt;p>Get-Help Invoke-DbcCheck -Online&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/01-online-help.png"
loading="lazy"
alt="01 - online help.png"
>&lt;/p>
&lt;p>I will blog about how dbachecks uses &lt;a class="link" href="https://azure.microsoft.com/en-us/services/devops/" target="_blank" rel="noopener"
>Azure DevOps&lt;/a> to do this another time&lt;/p>
&lt;h2 id="pspowerhour">PSPowerHour&lt;/h2>
&lt;p>The PowerShell community members &lt;a class="link" href="https://twitter.com/barbariankb" target="_blank" rel="noopener"
>Michael T Lombardi&lt;/a> and &lt;a class="link" href="http://twitter.com/psCookieMonster" target="_blank" rel="noopener"
>Warren Frame&lt;/a> have created &lt;a class="link" href="https://github.com/PSPowerHour/PSPowerHour" target="_blank" rel="noopener"
>PSPowerHour&lt;/a>. PSPowerHour is “like a virtual User Group, with a lightning-demo format, and room for non-PowerShell-specific content. Eight community members will give a demo each PowerHour.”&lt;/p>
&lt;p>&lt;a class="link" href="http://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy&lt;/a> blogged about the first one &lt;a class="link" href="https://dbatools.io/pspowerhour/" target="_blank" rel="noopener"
>on the dbatools blog&lt;/a>&lt;/p>
&lt;p>You can watch the videos on the &lt;a class="link" href="https://www.youtube.com/channel/UCtHKcGei3EjxBNYQCFZ3WNQ" target="_blank" rel="noopener"
>Youtube channel&lt;/a> and keep an eye out for more online &lt;a class="link" href="https://twitter.com/hashtag/PSPowerHoursrc=hash" target="_blank" rel="noopener"
>PSPowerHours via twitter&lt;/a> or &lt;a class="link" href="https://github.com/PSPowerHour/PSPowerHour" target="_blank" rel="noopener"
>the GitHub page&lt;/a>.&lt;/p>
&lt;p>While watching the first group of sessions &lt;a class="link" href="https://twitter.com/awickham" target="_blank" rel="noopener"
>Andrew Wickham&lt;/a> demonstrated using dbatools with trace flags and I thought that needs to be added to dbachecks so I created &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/issues/529" target="_blank" rel="noopener"
>an issue.&lt;/a> Anyone can do this to file improvements as well as bugs for members of the team to code.&lt;/p>
&lt;h2 id="trace-flags">Trace Flags&lt;/h2>
&lt;p>The previous release of dbachecks brought 2 new checks for traceflags. One for traceflags expected to be running and one for traceflags not expected to be running.&lt;/p>
&lt;p>You will need to have installed &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks" target="_blank" rel="noopener"
>dbachecks from the PowerShell Gallery&lt;/a> to do this. This can be done using&lt;/p>
&lt;p>Install-Module -Name dbachecks&lt;/p>
&lt;p>Once dbachecks is installed you can find the checks using&lt;/p>
&lt;p>Get-DBcCheck&lt;/p>
&lt;p>you can filter using the pattern parameter&lt;/p>
&lt;p>Get-DBcCheck -Pattern traceflag&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/02-get0dbcconfig.png"
loading="lazy"
alt="02 - get0dbcconfig.png"
>&lt;/p>
&lt;p>This will show you&lt;/p>
&lt;ul>
&lt;li>the UniqueTag which will enable you to run only that check if you wish&lt;/li>
&lt;li>AllTags which shows which tags will include that check&lt;/li>
&lt;li>Config will show you which configuration items can be set for this check&lt;/li>
&lt;/ul>
&lt;p>The trace flag checks require the app.sqlinstance configuration which is the list of SQL instances that the checks will run against. You can also specify the instances as a parameter for &lt;a class="link" href="https://dbachecks.readthedocs.io/en/latest/functions/Invoke-DbcCheck/" target="_blank" rel="noopener"
>Invoke-DbCheck&lt;/a> as well.&lt;/p>
&lt;p>The configuration for the expected traceflags is policy.traceflags.expected By default it is set to null. You can see what configuration it has using&lt;/p>
&lt;p>Get-DBcConfig policy.traceflags.expected&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/get-dbcconfig.png"
loading="lazy"
alt="get-dbcconfig.png"
>&lt;/p>
&lt;p>So if you want to check that there are no trace flags running, then you can run&lt;/p>
&lt;p>$instance = &amp;lsquo;sql0&amp;rsquo;
Set-DbcConfig -Name app.sqlinstance -Value $instance
Invoke-DbcCheck -Check TraceFlagsExpected&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/check-1.png"
loading="lazy"
alt="check 1.png"
>&lt;/p>
&lt;p>Maybe this instance is required to have &lt;a class="link" href="https://blogs.msdn.microsoft.com/sql_pfe_blog/2017/07/18/trace-flag-1117-growth-and-contention/" target="_blank" rel="noopener"
>trace flag 1117 enabled&lt;/a> so that &lt;a class="link" href="https://www.brentozar.com/archive/2014/06/trace-flags-1117-1118-tempdb-configuration/" target="_blank" rel="noopener"
>all files in a file group grow equally&lt;/a>, you can set the trace flag you expect to be running using&lt;/p>
&lt;p>Set-DbcConfig -Name policy.traceflags.expected -Value 1117&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-config.png"
loading="lazy"
alt="set config.png"
>&lt;/p>
&lt;p>Now you when you run the check it fails&lt;/p>
&lt;p>Invoke-DbcCheck -Check TraceFlagsExpecte&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/not-found.png"
loading="lazy"
alt="not found.png"
>&lt;/p>
&lt;p>and gives you the error message&lt;/p>
&lt;blockquote>
&lt;p> [-] Expected Trace Flags 1117 exist on sql0 593ms&lt;br>
Expected 1117 to be found in collection @(), because We expect that Trace Flag 1117 will be set on sql0, but it was not found.&lt;/p>
&lt;/blockquote>
&lt;p>So we have a failing test. We need to fix that. We can use &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>&lt;/p>
&lt;p>Enable-DbaTraceFlag -SqlInstance $instance -TraceFlag 1117&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-traceflag.png"
loading="lazy"
alt="set traceflag.png"
>&lt;/p>
&lt;p>This time when we run the check&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsExpected&lt;/code>&lt;/p>
&lt;p>it passes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/passed-test.png"
loading="lazy"
alt="passed test"
>&lt;/p>
&lt;p>If you just need to see what trace flags are enabled you can use&lt;/p>
&lt;p>&lt;code>Get-DbaTraceFlag -SqlInstance $instance&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/get-trace-flag.png"
loading="lazy"
alt="get trace flag.png"
>&lt;/p>
&lt;p>Reset the configuration for the expected trace flag to an empty array and then set the configuration for traceflags we do not expect to be running to 1117&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.traceflags.expected -Value @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.traceflags.notexpected -Value 1117
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/set-config-2.png"
loading="lazy"
alt="set config 2.png"
>&lt;/p>
&lt;p>and then run the trace flags not expected to be running check with&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsNotExpected&lt;/code>&lt;/p>
&lt;p>It will fail as 1117 is still running&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/not-expected-fail.png"
loading="lazy"
alt="not expected fail.png"
>&lt;/p>
&lt;p>and give the message&lt;/p>
&lt;blockquote>
&lt;p>[-] Expected Trace Flags 1117 to not exist on sql0 321ms&lt;br>
Expected 1117 to not be found in collection 1117, because We expect that Trace Flag 1117 will not be set on sql0, but it was found.&lt;/p>
&lt;/blockquote>
&lt;p>So to resolve this failing check we need to disable the trace flag and we can do that with dbatools using&lt;/p>
&lt;p>&lt;code>Disable-DbaTraceFlag -SqlInstance $instance -TraceFlag 1117&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/disable-trace-flag-1.png"
loading="lazy"
alt="disable trace flag"
>&lt;/p>
&lt;p>and now when we run the check&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlagsNotExpected&lt;/code>&lt;/p>
&lt;p>it passes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/passed-bnot-expected.png"
loading="lazy"
alt="passed bnot expected.png"
>&lt;/p>
&lt;p>The checks also work with multiple traceflags so you can set multiple values for trace flags that are not expexted to be running&lt;/p>
&lt;p>&lt;code>Set-DbcConfig -Name policy.traceflags.notexpected -Value 1117, 1118&lt;/code>&lt;/p>
&lt;p>and as we saw earlier, you can run both trace flag checks using&lt;/p>
&lt;p>&lt;code>Invoke-DbcCheck -Check TraceFlag&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/09/multi-checks.png"
loading="lazy"
alt="multi checks.png"
>&lt;/p>
&lt;p>You can use this or any of the 95 available checks to validate that your SQL instances, singular or your whole estate are as you expect them to be.&lt;/p></description></item><item><title>Deploying To a Power Bi Report Server with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-to-a-power-bi-report-server-with-powershell/</link><pubDate>Tue, 21 Aug 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-to-a-power-bi-report-server-with-powershell/</guid><description>&lt;p>Just a quick post to share some code that I used to solve a problem I had recently.&lt;/p>
&lt;p>I needed to automate the deployment of some Power Bi reports to a Power Bi Report Server PBRS using TFS. I had some modified &lt;a class="link" href="https://blog.robsewell.com/dbachecks-dark-mode-historical-validation-powerbi/" target="_blank" rel="noopener"
>historical validation dbachecks&lt;/a> pbix files that I wanted to automate the deployment of and enable the client to be able to quickly and simply deploy the reports as needed.&lt;/p>
&lt;h2 id="the-manual-way">The manual way&lt;/h2>
&lt;p>It is always a good idea to understand how to do a task manually before automating it. To deploy to PBRS you need to use the Power Bi Desktop optimised for Power Bi Report Server. &lt;a class="link" href="https://docs.microsoft.com/en-us/power-bi/report-server/quickstart-create-powerbi-report" target="_blank" rel="noopener"
>There are instructions here&lt;/a>. Then it is easy to deploy to the PBRS by clicking file and save as and choosing Power Bi Report Server&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/manual-deploy.png"
loading="lazy"
alt="manual deploy"
>&lt;/p>
&lt;p>If I then want to set the datasource to use a different set of credentials I navigate to the folder that holds the report in PBRS and click the hamburger menu and Manage&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/manage.png"
loading="lazy"
alt="manage"
>&lt;/p>
&lt;p>and I can alter the User Name and Password or the type of connection by clicking on DataSources&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/testconn.png"
loading="lazy"
alt="testconn.PNG"
>&lt;/p>
&lt;p>and change it to use the reporting user for example.&lt;/p>
&lt;h2 id="automation">Automation&lt;/h2>
&lt;p>But I dont want to have to do this each time and there will be multiple pbix files, so I wanted to automate the solution. The end result was a VSTS or TFS release process so that I could simply drop the pbix into a git repository, commit my changes, sync them and have the system deploy them automatically.&lt;/p>
&lt;p>As with all good ideas, I started with a google and found &lt;a class="link" href="http://byobi.com/2018/04/programmatically-deploy-power-bi-reports-to-power-bi-report-server/" target="_blank" rel="noopener"
>this post&lt;/a> by &lt;a class="link" href="https://twitter.com/SQLbyoBI" target="_blank" rel="noopener"
>Bill Anton&lt;/a> which gave me a good start ( I could not get the connection string change to work in my test environment but this was not required so I didnt really examine why)&lt;/p>
&lt;p>I wrote a function that I can use via TFS or VSTS by embedding it in a PowerShell script. The function requires the &lt;a class="link" href="https://github.com/Microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>ReportingServicesTools&lt;/a> module which you can get by&lt;/p>
&lt;p>Install-Module -Name ReportingServicesTools&lt;/p>
&lt;p>The function below is available via the &lt;a class="link" href="https://www.powershellgallery.com/packages/PublishPBIXFile/1.0.0.2/DisplayScript" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> also and you can get it with&lt;/p>
&lt;p>Install-Script -Name PublishPBIXFile&lt;/p>
&lt;p>The source code is on &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/PublishPBIXFile.ps1" target="_blank" rel="noopener"
>Github&lt;/a>&lt;/p>
&lt;p>and the code to call it looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$folderName = &amp;#39;TestFolder&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ReportServerURI = &amp;#39;http://localhost/Reports&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$folderLocation = &amp;#39;/&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$pbixfile = &amp;#39;C:\Temp\test.pbix&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$description = &amp;#34;Descriptions&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$publishPBIXFileSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ReportServerURI = $ReportServerURI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderLocation = $folderLocation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> description = $description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pbixfile = $pbixfile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderName = $folderName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AuthenticationType = &amp;#39;Windows&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ConnectionUserName = $UserName1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Secret = $Password1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Verbose = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Publish-PBIXFile @publishPBIXFileSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/code1.png"
loading="lazy"
alt="code1.PNG"
>&lt;/p>
&lt;p>which uploads the report to a folder which it will create if it does not exist. It will then upload pbix file, overwriting the existing one if it already exists&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/numbe3r1.png"
loading="lazy"
alt="numbe3r1.PNG"
>&lt;/p>
&lt;p>and uses the username and password specified&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/code2.png"
loading="lazy"
alt="code2.PNG"
>&lt;/p>
&lt;p>If I wanted to use a Domain reporting user instead I can do&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$UserName1 = &amp;#39;TheBeard\ReportingUser&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$publishPBIXFileSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ReportServerURI = $ReportServerURI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderLocation = $folderLocation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> description = $description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pbixfile = $pbixfile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderName = $folderName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AuthenticationType = &amp;#39;Windows&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ConnectionUserName = $UserName1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Secret = $Password1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Verbose = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Publish-PBIXFile @publishPBIXFileSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and it changes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/code4-reporting.png"
loading="lazy"
alt="code4 reporting"
>&lt;/p>
&lt;p>If we want to use a SQL Authenticated user then&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$UserName1 = &amp;#39;TheReportingUserOfBeard&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$publishPBIXFileSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ReportServerURI = $ReportServerURI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderLocation = $folderLocation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> description = $description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pbixfile = $pbixfile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderName = $folderName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AuthenticationType = &amp;#39;SQL&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # credential = $cred
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ConnectionUserName = $UserName1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Secret = $Password1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Publish-PBIXFile @publishPBIXFileSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/sql-auth.png"
loading="lazy"
alt="sql auth.PNG"
>&lt;/p>
&lt;p>Excellent, it all works form the command line. You can pass in a credential object as well as username and password. The reason I enabled username and password? So that I can use TFS or VSTS and store my password as a secret variable.&lt;/p>
&lt;p>Now I simply create a repository which has my pbix files and a PowerShell script and build a quick release process to deploy them whenever there is a change 🙂&lt;/p>
&lt;p>The deploy script looks like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">[CmdletBinding()]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Param (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $PBIXFolder,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ConnectionStringPassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$VerbosePreference = &amp;#39;continue&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ReportServerURI = &amp;#39;http://TheBeardsAmazingReports/Reports&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;Starting Deployment&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">function Publish-PBIXFile {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CmdletBinding(DefaultParameterSetName = &amp;#39;ByUserName&amp;#39;, SupportsShouldProcess)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(Mandatory = $true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$FolderName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(Mandatory = $true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$ReportServerURI,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(Mandatory = $true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$FolderLocation,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(Mandatory = $true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$PBIXFile,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter()]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$Description = &amp;#34;Description of Your report Should go here&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter()]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ValidateSet(&amp;#39;Windows&amp;#39;, &amp;#39;SQL&amp;#39;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$AuthenticationType,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(ParameterSetName = &amp;#39;ByUserName&amp;#39;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$ConnectionUserName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(ParameterSetName = &amp;#39;ByUserName&amp;#39;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$Secret,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameter(Mandatory = $true, ParameterSetName = &amp;#39;ByCred&amp;#39;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [pscredential]$Credential
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $FolderPath = $FolderLocation + $FolderName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $PBIXName = $PBIXFile.Split(&amp;#39;\&amp;#39;)[-1].Replace(&amp;#39;.pbix&amp;#39;, &amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Creating a session to the Report Server $ReportServerURI&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # establish session w/ Report Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $session = New-RsRestSession-ReportPortalUri $ReportServerURI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Created a session to the Report Server $ReportServerURI&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;Failed to create a session to the report server $reportserveruri&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # create folder (optional)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($PSCmdlet.ShouldProcess(&amp;#34;$ReportServerURI&amp;#34;, &amp;#34;Creating a folder called $FolderName at $FolderLocation&amp;#34;)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Null = New-RsRestFolder-WebSession $session-RsFolder $FolderLocation-FolderName $FolderName-ErrorAction Stop
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch [System.Exception] {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If ($_.Exception.InnerException.Message -eq &amp;#39;The remote server returned an error: (409) Conflict.&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;The folder already exists - moving on&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;Failed to create a folder called $FolderName at $FolderLocation report server $ReportServerURI but not because it already exists&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($PSCmdlet.ShouldProcess(&amp;#34;$ReportServerURI&amp;#34;, &amp;#34;Uploading the pbix from $PBIXFile to the report server &amp;#34;)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # upload copy of PBIX to new folder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-RsRestCatalogItem-WebSession $session-Path $PBIXFile-RsFolder $folderPath-Description $Description-Overwrite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;Failed to upload the file $PBIXFile to report server $ReportServerURI&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Getting the datasources from the pbix file for updating&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # get data source object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $datasources = Get-RsRestItemDataSource-WebSession $session-RsItem &amp;#34;$FolderPath/$PBIXName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Got the datasources for updating&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;Failed to get the datasources&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Updating Datasource&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($dataSourcein$datasources) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($AuthenticationType -eq &amp;#39;SQL&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dataSource.DataModelDataSource.AuthType = &amp;#39;UsernamePassword&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dataSource.DataModelDataSource.AuthType = &amp;#39;Windows&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Credential -or $UserName) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Credential) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $UserName = $Credential.UserName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Password = $Credential.GetNetworkCredential().Password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $UserName = $ConnectionUserName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Password = $Secret
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dataSource.CredentialRetrieval = &amp;#39;Store&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dataSource.DataModelDataSource.Username = $UserName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dataSource.DataModelDataSource.Secret = $Password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($PSCmdlet.ShouldProcess(&amp;#34;$ReportServerURI&amp;#34;, &amp;#34;Updating the data source for the report $PBIXName&amp;#34;)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # update data source object on server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-RsRestItemDataSource-WebSession $session-RsItem &amp;#34;$folderPath/$PBIXName&amp;#34;-RsItemType PowerBIReport -DataSources $datasource
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning&amp;#34;Failed to set the datasource&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose&amp;#34;Completed Successfully&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($File in (Get-ChildItem $PBIXFolder\*.pbix)) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output&amp;#34;Processing $($File.FullName)&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## to enable further filtering later
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($File.FullName -like &amp;#39;*&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $folderName = &amp;#39;ThePlaceForReports&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $folderLocation = &amp;#39;/&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $UserName = &amp;#39;TheBeard\ReportingUser&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Password = $ConnectionStringPassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $pbixfile = $File.FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($File.FullName -like &amp;#39;\*dbachecks\*&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $description = &amp;#34;This is the morning daily checks file that....... more info&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($File.FullName -like &amp;#39;\*TheOtherReport\*&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $description = &amp;#34;This is hte other report, it reports others&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $publishPBIXFileSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ReportServerURI = $ReportServerURI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderLocation = $folderLocation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> description = $description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AuthenticationType = &amp;#39;Windows&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> pbixfile = $pbixfile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> folderName = $folderName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ConnectionUserName = $UserName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Secret = $Password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Verbose = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Results = Publish-PBIXFile@publishPBIXFileSplat
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output$Results
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Although the function does not need to be embedded in the script and can be deployed in a module, I have included it in here to make it easier for people to use quickly. I&lt;/p>
&lt;p>&lt;a class="link" href="https://docs.microsoft.com/en-us/vsts/pipelines/release/variables?view=vsts&amp;amp;tabs=batch&amp;amp;WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Store the password for the user as a variable in TFS or VSTS&lt;/a>&lt;/p>
&lt;p>Then create a PowerShell step in VSTS or TFS and call the script with the parameters as shown below and PowerBi files auto deploy to Power Bi Report Server&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/08/vsts.png"
loading="lazy"
alt="vsts.PNG"
>&lt;/p>
&lt;p>and I have my process complete 🙂&lt;/p>
&lt;p>Happy Automating 🙂&lt;/p></description></item><item><title>Using the PowerShell AST to find a ForEach Method</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-powershell-ast-to-find-a-foreach-method/</link><pubDate>Thu, 16 Aug 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-powershell-ast-to-find-a-foreach-method/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/08/server.png" alt="Featured image of post Using the PowerShell AST to find a ForEach Method" />&lt;p>In &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> we enable people to see what checks are available by running Get-DbcCheck. This gives a number of properties including the ‘type’ of check. This refers to the configuration item or parameter that is required to have a value for this check to run.&lt;/p>
&lt;p>For example – Any check to do with SQL Agent is of type Sqlinstance because it requires an instance to be specified but a check for SPN is of type ComputerName because it requires a computer name to run.&lt;/p>
&lt;h2 id="automation-for-the-win">Automation for the win&lt;/h2>
&lt;p>Because I believe in automation I do not want to have to hard code these values anywhere but create them when the module is imported so we use a json file to feed Get-DbcCheck and populate the Json file when we import the module. This is done using the &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/using-the-ast-in-pester-for-dbachecks/" >method that I described here&lt;/a> and means that whenever a new check is added it is automatically available in Get-DbcCheck without any extra work.&lt;/p>
&lt;p>We use code like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## Parse the file with AST
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CheckFileAST = [Management.Automation.Language.Parser]::ParseInput($check, [ref]$null, [ref]$null)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Old code we can use the describes
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Describes = $CheckFileAST.FindAll([Func[Management.Automation.Language.Ast, bool]] {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ($ast)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ast.CommandElements -and
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ast.CommandElements[0].Value -eq &amp;#39;describe&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }, $true)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">@($describes).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $groups += $filename
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Describe = $_.CommandElements.Where{$PSItem.StaticType.name -eq &amp;#39;string&amp;#39;}[1]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $title = $Describe.Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Tags = $PSItem.CommandElements.Where{$PSItem.StaticType.name -eq &amp;#39;Object[]&amp;#39; -and $psitem.Value -eq $null}.Extent.Text.ToString().Replace(&amp;#39;, $filename&amp;#39;, &amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # CHoose the type
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Describe.Parent -match &amp;#34;Get-Instance&amp;#34;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $type = &amp;#34;Sqlinstance&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($Describe.Parent -match &amp;#34;Get-ComputerName&amp;#34; -or $Describe.Parent -match &amp;#34;AllServerInfo&amp;#34;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $type = &amp;#34;ComputerName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($Describe.Parent -match &amp;#34;Get-ClusterObject&amp;#34;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Type = &amp;#34;ClusteNode&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>First we parse the code with the AST and store that in the CheckFileAST variable, then we use the FindAll method to find any command elements that match “Describe” which conveniently gets our describes and then we can simply match the Parent object which holds some code to each function that we use to get our values to be passed to the tests &lt;code>Get-ComputerName&lt;/code>, &lt;code>Get-Instance&lt;/code>, &lt;code>Get-ClusterObject&lt;/code> and set the type appropriately.&lt;/p>
&lt;p>which when run against a check like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Backup Path Access&amp;#34; -Tags BackupPathAccess, Storage, DISA, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-Instance).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($NotContactable -contains $psitem) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing Backup Path Access on $psitem&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Can&amp;#39;t Connect to $Psitem&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $false| Should -BeTrue -Because &amp;#34;The instance should be available to be connected to!&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing Backup Path Access on $psitem&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $backuppath = Get-DbcConfigValue policy.storage.backuppath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (-not$backuppath) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $backuppath = (Get-DbaDefaultPath-SqlInstance $psitem).Backup
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;can access backup path ($backuppath) on $psitem&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Test-DbaSqlPath-SqlInstance $psitem -Path $backuppath| Should -BeTrue -Because &amp;#39;The SQL Service account needs to have access to the backup path to backup your databases&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>will find the describe block and get the title “Backup Path Access”  and the tags BackupPathAccess, Storage, DISA, $filename and then find the Get-Instance and set the type to SqlInstance&lt;/p>
&lt;h2 id="until-rob-breaks-it">Until Rob breaks it!&lt;/h2>
&lt;p>This has worked wonderfully well for 6 months or so of the life of dbachecks but this week I broke it!&lt;/p>
&lt;p>The problem was the performance of the code. It is taking a long time to run the tests and I am looking at ways to improve this. I was looking at the Server.Tests file because I thought why not start with one of the smaller files.&lt;/p>
&lt;p>It runs the following checks&lt;/p>
&lt;ul>
&lt;li>Server Power Plan Configuration&lt;/li>
&lt;li>SPNs&lt;/li>
&lt;li>Disk Space&lt;/li>
&lt;li>Ping Computer&lt;/li>
&lt;li>CPUPrioritisation&lt;/li>
&lt;li>Disk Allocation Unit&lt;/li>
&lt;li>Instance Connection&lt;/li>
&lt;/ul>
&lt;p>and it was looping through the computer names for each check like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Server Power Plan Configuration&amp;#34; -Tags PowerPlan, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Instance Connection&amp;#34; -Tags InstanceConnection, Connectivity, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-Instance).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;SPNs&amp;#34; -Tags SPN, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Disk Space&amp;#34; -Tags DiskCapacity, Storage, DISA, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Ping Computer&amp;#34; -Tags PingComputer, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;CPUPrioritisation&amp;#34; -Tags CPUPrioritisation, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Disk Allocation Unit&amp;#34; -Tags DiskAllocationUnit, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I altered it to have only one loop for the computer names like so&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">@(Get-ComputerName).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Server Power Plan Configuration&amp;#34; -Tags PowerPlan, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;SPNs&amp;#34; -Tags SPN, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Disk Space&amp;#34; -Tags DiskCapacity, Storage, DISA, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Ping Computer&amp;#34; -Tags PingComputer, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;CPUPrioritisation&amp;#34; -Tags CPUPrioritisation, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Disk Allocation Unit&amp;#34; -Tags DiskAllocationUnit, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Instance Connection&amp;#34; -Tags InstanceConnection, Connectivity, $filename {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @(Get-Instance).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and immediately in testing my checks for the Server Tag decreased in time by about 60% 🙂&lt;/p>
&lt;p>I was very happy.&lt;/p>
&lt;p>Then I added it to the dbachecks module on my machine, loaded the module and realised that my Json file for &lt;code>Get-DbcCheck &lt;/code>was no longer being populated for the type because this line&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">elseif ($Describe.Parent-match&amp;#34;Get-ComputerName&amp;#34;-or$Describe.Parent-match&amp;#34;AllServerInfo&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>was no longer true.&lt;/p>
&lt;h2 id="ast-for-other-things">AST for other things&lt;/h2>
&lt;p>So I googled &lt;a class="link" href="http://Management.Automation.Language.Ast" target="_blank" rel="noopener"
>Management.Automation.Language.Ast&lt;/a> the first result lead me to &lt;a class="link" href="https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.language.invokememberexpressionast?view=powershellsdk-1.1.0" target="_blank" rel="noopener"
>docs.microsoft&lt;/a> There are a number of different language elements available there and I found &lt;a class="link" href="https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.language.invokememberexpressionast?view=powershellsdk-1.1.0" target="_blank" rel="noopener"
>InvokeMemberExpressionAst&lt;/a> which will let me find any methods that have been invoked, so now I can find the loops with&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ComputerNameForEach = $CheckFileAST.FindAll([Func[Management.Automation.Language.Ast, bool]] {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ($ast)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ast -is [System.Management.Automation.Language.InvokeMemberExpressionAst]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }, $true)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>When I examined the object returned I could see that I could further limit the result to get only the method for Get-ComputerName and then if I choose the Extent I can get the code of that loop&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## New code uses a Computer Name loop to speed up execution so need to find that as well
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ComputerNameForEach=$CheckFileAST.FindAll([Func[Management.Automation.Language.Ast,bool]] {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ($ast)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ast-is [System.Management.Automation.Language.InvokeMemberExpressionAst] -and$ast.expression.Subexpression.Extent.Text-eq&amp;#39;Get-ComputerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}, $true).Extent
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and now I can match the Tags to the type again :-)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($ComputerNameForEach-match$title) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$type=&amp;#34;ComputerName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and now &lt;code>Get-DbcCheck&lt;/code> is returning the right results and the checks are a little faster&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/08/server.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/08/server.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can find &lt;a class="link" href="http://powershellgallery.com/packages/dbachecks" target="_blank" rel="noopener"
>dbachecks on the PowerShell Gallery&lt;/a> or install it using&lt;/p>
&lt;p>Install-Module dbachecks -Scope CurrentUser&lt;/p></description></item><item><title>Hitting the Wall – #TSQL2sDay</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/hitting-the-wall-#tsql2sday/</link><pubDate>Tue, 14 Aug 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/hitting-the-wall-#tsql2sday/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/08/farrel-nobel-97504-unsplash.jpg" alt="Featured image of post Hitting the Wall – #TSQL2sDay" />&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/08/farrel-nobel-97504-unsplash.jpg"
loading="lazy"
alt="farrel-nobel-97504-unsplash"
>
Photo by &lt;a class="link" href="https://unsplash.com/photos/G9neENK1Z5I?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Farrel Nobel&lt;/a> on &lt;a class="link" href="https://unsplash.com/search/photos/walk-around-wall?utm_source=unsplash&amp;amp;utm_medium=referral&amp;amp;utm_content=creditCopyText" target="_blank" rel="noopener"
>Unsplash&lt;/a>&lt;/p>
&lt;p>Welcome to another edition of T-SQL Tuesday!&lt;/p>
&lt;p>This T-SQL Tuesday is hosted by Wayne Sheffield ( &lt;a class="link" href="https://blog.waynesheffield.com/wayne/" target="_blank" rel="noopener"
>blog&lt;/a> | &lt;a class="link" href="https://twitter.com/DBAWayne" target="_blank" rel="noopener"
>twitter&lt;/a> ) and &lt;a class="link" href="https://blog.waynesheffield.com/wayne/archive/2018/08/t-sql-tuesday-105-invitation-brick-wall/" target="_blank" rel="noopener"
>he has asked us to talk about&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>[…]&lt;/em> a time when you ran up against your own brick wall, and how you worked it out or dealt with it.&lt;/p>
&lt;/blockquote>
&lt;h2 id="hitting-the-wall">Hitting The Wall&lt;/h2>
&lt;p>When stuck in a problem in the past, I could often be found glued to a keyboard and screen for many hours. I would try this way and that way, I would Google and read Stack Overflow looking for ways around the particular issue I was seeing trying different things and finally I would get frustrated and fed up and stop.&lt;/p>
&lt;p>Maybe I would go and walk the dog, maybe just sit somewhere else but I would often find that I had an idea how to solve my problem and quickly go back to the keyboard frustrated that I hadnt thought about this earlier and frequently rinse and repeat.&lt;/p>
&lt;h2 id="a-different-way">A Different Way&lt;/h2>
&lt;p>It took me many years to realise this and I wish I had done so sooner but once I made the connection that leaving the problem to one side for a little while meant that I often found a way to a solution for a problem I started setting a time limit.&lt;/p>
&lt;p>30 minutes&lt;/p>
&lt;p>If I have been stuck on a problem for 30 minutes, I (mostly, I still sometimes fail at this) stop, take a break, go for a walk or do something different and the number of times that I arrive if not at a solution then at a path to a solution is remarkable.&lt;/p>
&lt;h2 id="ask">Ask&lt;/h2>
&lt;p>The other thing to do at this point in the troublesome problem solving is to ask. Twitter, Google, Slack, Stack Overflow. These are all excellent resources where you can quickly find people who are willing and capable of helping.&lt;/p>
&lt;p>Don’t be like me and take years to work this out 🙂&lt;/p></description></item><item><title>A PowerShell Conference In A Book</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-conference-in-a-book/</link><pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-conference-in-a-book/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/08/book.jpeg" alt="Featured image of post A PowerShell Conference In A Book" />&lt;h2 id="a-question">A Question&lt;/h2>
&lt;p>Shortly after the &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>European PowerShell Conference&lt;/a> and the &lt;a class="link" href="https://powershell.org/summit/" target="_blank" rel="noopener"
>PowerShell and Devops 2018&lt;/a> summit in the USA Mike Robbins &lt;a class="link" href="https://mikefrobbins.com" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/mikefrobbins" target="_blank" rel="noopener"
>t&lt;/a> contacted me with a question.&lt;/p>
&lt;blockquote>
&lt;p>Interested in writing a chapter in a PowerShell book?&lt;/p>
&lt;/blockquote>
&lt;p>I was intrigued and read on.&lt;/p>
&lt;h2 id="a-conference-in-a-book">A Conference in a Book&lt;/h2>
&lt;p>There was more to this book than just writing about PowerShell though. Mike was suggesting that a group of wonderful PowerShell experts (&lt;a class="link" href="https://twitter.com/mikefrobbins/lists/psh-conference-book/members" target="_blank" rel="noopener"
>Here’s a Twitter list&lt;/a>) got together and created a conference in a book.&lt;/p>
&lt;blockquote>
&lt;p>The book is designed as a conference in a book where each chapter is written independently with content similar to what you would present in a 45 minute presentation.&lt;/p>
&lt;/blockquote>
&lt;p>That’s a neat idea, people who couldn’t come to one of the conferences would be able to get an experience a little bit like attending a conference but in book form.&lt;/p>
&lt;p>OK there would be no networking, evening entertainment or instance responses to questions but a bundle of useful information that you can take with you and read anywhere.&lt;/p>
&lt;h2 id="its-all-for-charity">It’s All For Charity&lt;/h2>
&lt;p>(I hope older UK viewers read that &lt;a class="link" href="https://gfycat.com/gifs/detail/JaggedGenuineGavial" target="_blank" rel="noopener"
>in this voice&lt;/a> 🙂 )&lt;/p>
&lt;p>The bit that clinched it for me was this though&lt;/p>
&lt;blockquote>
&lt;p>We’re donating all of the royalties from the book to the DevOps Collective Scholarship program &lt;a class="link" href="https://leanpub.com/causes/devopscollective" target="_blank" rel="noopener"
>https://leanpub.com/causes/devopscollective&lt;/a>.&lt;/p>
&lt;/blockquote>
&lt;p>All the money raised by &lt;a class="link" href="https://leanpub.com/powershell-conference-book" target="_blank" rel="noopener"
>buying this book&lt;/a> will go to the &lt;a class="link" href="https://powershell.org/summit/summit-onramp/onramp-scholarship/" target="_blank" rel="noopener"
>DevOps Collective OnRamp Scholarship program&lt;/a>.&lt;/p>
&lt;p>This scholarship provides&lt;/p>
&lt;ul>
&lt;li>ticket to PowerShell and DevOps Global Summit OnRamp track specifically designed for entry-level professionals&lt;/li>
&lt;li>five nights lodging&lt;/li>
&lt;li>domestic airfare&lt;/li>
&lt;li>buddy programme&lt;/li>
&lt;/ul>
&lt;p>and half of the slots are reserved for under-represented groups.&lt;/p>
&lt;p>I really approve of this idea, without the help and support of the SQL and PowerShell technical communities I would not be where I am today and this will help to bring other people in at an early stage in their career. I am proud that I can give a little back.&lt;/p>
&lt;h2 id="fabulous-editors">Fabulous Editors&lt;/h2>
&lt;p>So I said yes.&lt;/p>
&lt;p>I then had to sit down and write some words. I wrote about how we created &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks,&lt;/a> the challenges we faced and how we overcame them.&lt;/p>
&lt;p>One of my biggest challenges was writing in the wrong English! The book is written in American English and there are zeds where there should be esses and missing u’s in words! My spell checker was covered in red squiggles! The second challenge was getting the code to fit the column limit for the book. I show a lot of the AST code that we use to validate that dbachecks code will work correctly and it doesnt split to 80 characters very easily.&lt;/p>
&lt;p>Luckily I had 3 wonderful, patient editors to help me with all of this. &lt;a class="link" href="https://twitter.com/mikefrobbins" target="_blank" rel="noopener"
>Mike Robbins&lt;/a> , &lt;a class="link" href="https://twitter.com/barbariankb" target="_blank" rel="noopener"
>Michael T Lombardi&lt;/a> and &lt;a class="link" href="https://twitter.com/JeffHicks" target="_blank" rel="noopener"
>Jeff Hicks&lt;/a> each helped me to make the chapter read more fluently, make sense and be spelled correctly!&lt;/p>
&lt;p>Thank you very much you three for all the work you have put into this book.&lt;/p>
&lt;h2 id="help-yourself-and-others">Help Yourself and Others&lt;/h2>
&lt;p>If you want to attend a PowerShell conference in book form, want 30 chapters of fabulous PowerShell material and want to help grow and diversify our industry then look no further &lt;a class="link" href="https://leanpub.com/powershell-conference-book" target="_blank" rel="noopener"
>you can get the book here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://leanpub.com/powershell-conference-book" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/08/book.jpeg"
loading="lazy"
alt="book"
>&lt;/a>&lt;/p>
&lt;p>You can also find all of the authors twitters and websites below, You should go and see what they are sharing there as well.&lt;/p>
&lt;h6 id="_thank-you-to-mike-robbins-mike-kanakos-and-rob-pleau-for-having-all-the-links-below-already-handy-in-their-blog-posts-at-the-time-of-writing-this_">👍 &lt;em>Thank you to Mike Robbins, Mike Kanakos and Rob Pleau for having all the links below already handy in their blog posts at the time of writing this!&lt;/em>&lt;/h6>
&lt;p>Author&lt;/p>
&lt;p>Website&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/mikefrobbins" target="_blank" rel="noopener"
>Mike F Robbins&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://mikefrobbins.com/" target="_blank" rel="noopener"
>https://mikefrobbins.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/JeffHicks" target="_blank" rel="noopener"
>Jeff Hicks&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://jdhitsolutions.com/" target="_blank" rel="noopener"
>https://jdhitsolutions.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/barbariankb" target="_blank" rel="noopener"
>Michael Lombardi&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://appoint.ly/t/michaeltlombardi" target="_blank" rel="noopener"
>https://appoint.ly/t/michaeltlombardi&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/muzzar78" target="_blank" rel="noopener"
>Adam Murry&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://tikabu.com.au/blog/" target="_blank" rel="noopener"
>https://tikabu.com.au/blog/&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/nocentino" target="_blank" rel="noopener"
>Anthony Nocentino&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://www.centinosystems.com/" target="_blank" rel="noopener"
>http://www.centinosystems.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/devblackops" target="_blank" rel="noopener"
>Brandon Olin&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://devblackops.io/" target="_blank" rel="noopener"
>https://devblackops.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/brianbunke" target="_blank" rel="noopener"
>Brian Bunke&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://www.brianbunke.com/" target="_blank" rel="noopener"
>https://www.brianbunke.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/concentrateddon" target="_blank" rel="noopener"
>Don Jones&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://donjones.com/" target="_blank" rel="noopener"
>https://donjones.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/dfinke" target="_blank" rel="noopener"
>Doug Finke&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://dfinke.github.io/" target="_blank" rel="noopener"
>https://dfinke.github.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/p0w3rsh3ll" target="_blank" rel="noopener"
>Emin Atac&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://p0w3rsh3ll.wordpress.com/" target="_blank" rel="noopener"
>https://p0w3rsh3ll.wordpress.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/fredweinmann" target="_blank" rel="noopener"
>Fred Weinmann&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://allthingspowershell.blogspot.com/" target="_blank" rel="noopener"
>https://allthingspowershell.blogspot.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/GKBeer" target="_blank" rel="noopener"
>Graham Beer&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://graham-beer.github.io/" target="_blank" rel="noopener"
>https://graham-beer.github.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/IrwinStrachan" target="_blank" rel="noopener"
>Irwin Strachan&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://pshirwin.wordpress.com/" target="_blank" rel="noopener"
>https://pshirwin.wordpress.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/PSJamesP" target="_blank" rel="noopener"
>James Petty&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://scriptautomaterepeat.com/" target="_blank" rel="noopener"
>https://scriptautomaterepeat.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/JeremyMurrah" target="_blank" rel="noopener"
>Jeremy Murrah&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://murrahjm.github.io/" target="_blank" rel="noopener"
>https://murrahjm.github.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/jpsider" target="_blank" rel="noopener"
>Justin Sider&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://invoke-automation.blog/" target="_blank" rel="noopener"
>https://invoke-automation.blog&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/LucD22" target="_blank" rel="noopener"
>Luc Dekens&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://www.lucd.info/" target="_blank" rel="noopener"
>http://www.lucd.info&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/markekraus" target="_blank" rel="noopener"
>Mark Kraus&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://get-powershellblog.blogspot.com/" target="_blank" rel="noopener"
>https://get-powershellblog.blogspot.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/markwragg" target="_blank" rel="noopener"
>Mark Wragg&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://wragg.io/" target="_blank" rel="noopener"
>https://wragg.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/MikeKanakos" target="_blank" rel="noopener"
>Mike Kanakos&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://www.networkadm.in/" target="_blank" rel="noopener"
>https://www.networkadm.in&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/MikeShepard70" target="_blank" rel="noopener"
>Mike Shepard&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://powershellstation.com/" target="_blank" rel="noopener"
>https://powershellstation.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/pewa2303" target="_blank" rel="noopener"
>Patrick Gruenauer&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sid-500.com/" target="_blank" rel="noopener"
>https://sid-500.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/SinghPrateik" target="_blank" rel="noopener"
>Prateek Singh&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://ridicurious.com/" target="_blank" rel="noopener"
>https://ridicurious.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/rjpleau" target="_blank" rel="noopener"
>Rob Pleau&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://ephos.github.io" target="_blank" rel="noopener"
>https://ephos.github.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/doctordns" target="_blank" rel="noopener"
>Thomas Lee&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://tfl09.blogspot.com/" target="_blank" rel="noopener"
>https://tfl09.blogspot.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/MrThomasRayner" target="_blank" rel="noopener"
>Thomas Rayner&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://workingsysadmin.com/" target="_blank" rel="noopener"
>https://workingsysadmin.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/driberif" target="_blank" rel="noopener"
>Thom Schumacher&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://powershellposse.com/" target="_blank" rel="noopener"
>https://powershellposse.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/MadWPowerShell" target="_blank" rel="noopener"
>Tim Curwick&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://madwithpowershell.com/" target="_blank" rel="noopener"
>https://MadWithPowerShell.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/TechTrainerTim" target="_blank" rel="noopener"
>Tim Warner&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://timwarnertech.com/" target="_blank" rel="noopener"
>https://timwarnertech.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/thetommymaynard" target="_blank" rel="noopener"
>Tommy Maynard&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://tommymaynard.com/" target="_blank" rel="noopener"
>https://tommymaynard.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/ToreGroneng" target="_blank" rel="noopener"
>Tore Groneng&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://asaconsultant.blogspot.com/" target="_blank" rel="noopener"
>https://asaconsultant.blogspot.com&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/unleashthecloud" target="_blank" rel="noopener"
>Wesley Kirkland&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://wesleyk.me/" target="_blank" rel="noopener"
>https://wesleyk.me&lt;/a>&lt;/p></description></item><item><title>A PowerShell Pester Check for parsing SQL scripts</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-pester-check-for-parsing-sql-scripts/</link><pubDate>Wed, 25 Jul 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-powershell-pester-check-for-parsing-sql-scripts/</guid><description>&lt;p>I like &lt;a class="link" href="https://blog.robsewell.com/?s=pester" target="_blank" rel="noopener"
>to write Pester checks&lt;/a> to make sure that all is as expected! This is just a quick post as much to help me remember this script 🙂&lt;/p>
&lt;p>This is a quick Pester test I wrote to ensure that some SQL Scripts in a directory would parse so there was some guarantee that they were valid T-SQL. It uses the SQLParser.dll and because it was using a build server without SQL Server I have to load the required DLLs from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> module (Thank you dbatools 🙂 )&lt;/p>
&lt;p>It simply runs through all of the .sql files and runs the parser against them and checks the errors. In the case of failures it will output where it failed in the error message in the failed Pester result as well.&lt;/p>
&lt;p>You will need &lt;a class="link" href="http://dbatools.io/install" target="_blank" rel="noopener"
>dbatools module installed&lt;/a> on the instance and at least &lt;a class="link" href="https://github.com/pester/Pester/wiki/Installation-and-Updatehttps://github.com/pester/Pester/wiki/Installation-and-Update" target="_blank" rel="noopener"
>version 4 of the Pester module&lt;/a> as well&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Testing SQL&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Running Parser&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Load assembly
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Parserdll = (Get-ChildItem &amp;#39;C:\\Program Files\\WindowsPowerShell\\Modules\\dbatools&amp;#39; -Include Microsoft.SqlServer.Management.SqlParser.dll -Recurse)\[0\].FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \[System.Reflection.Assembly\]::LoadFile($Parserdll) | Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TraceDll = (Get-ChildItem &amp;#39;C:\\Program Files\\WindowsPowerShell\\Modules\\dbatools&amp;#39; -Include Microsoft.SqlServer.Diagnostics.Strace.dll -Recurse)\[0\].FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \[System.Reflection.Assembly\]::LoadFile($TraceDll) | Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ParseOptions = New-Object Microsoft.SqlServer.Management.SqlParser.Parser.ParseOptions
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ParseOptions.BatchSeparator = &amp;#39;GO&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $files = Get-ChildItem -Path $Env:Directory -Include *.sql -Recurse ## This variable is set as a Build Process Variable or put your path here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $files.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;$($Psitem.FullName) Should Parse SQL correctly&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $filename = $Psitem.FullName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $sql = Get-Content -LiteralPath &amp;#34;$fileName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Script = \[Microsoft.SqlServer.Management.SqlParser.Parser.Parser\]::Parse($SQL, $ParseOptions)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Script.Errors | Should -BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>dbachecks – Dark Mode Historical Validation PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-dark-mode-historical-validation-powerbi/</link><pubDate>Mon, 28 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-dark-mode-historical-validation-powerbi/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/dark-mode.png" alt="Featured image of post dbachecks – Dark Mode Historical Validation PowerBi" />&lt;p>in &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/dbachecks-save-the-results-to-a-database-for-historical-reporting/" >my last post&lt;/a> I showed how you can save the results of dbachecks to a database and created a PowerBi report. Inspired by Frank Henninger in the #dbachecks slack channel and &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>Shawn Melton&lt;/a> who explained the difficulties with red/green colour blind I then created this one 🙂&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/dark-mode.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/dark-mode.png"
loading="lazy"
alt="dark mode"
>&lt;/a>&lt;/p>
&lt;p>You can find it in my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks-expanded" target="_blank" rel="noopener"
>GitHub&lt;/a> and have a play with it below&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>dbachecks – Save the results to a database for historical reporting</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-save-the-results-to-a-database-for-historical-reporting/</link><pubDate>Wed, 23 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-save-the-results-to-a-database-for-historical-reporting/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/08-filter-by-instance-and-insance.png" alt="Featured image of post dbachecks – Save the results to a database for historical reporting" />&lt;p>I gave a presentation at &lt;a class="link" href="https://sqlday.pl/en/" target="_blank" rel="noopener"
>SQL Day&lt;/a> in Poland last week on &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> and one of the questions I got asked was will you write a command to put the results of the checks into a database for historical reporting.&lt;/p>
&lt;p>The answer is no and here is the reasoning. The capability is already there. Most good PowerShell commands will only return an object and the beauty of an object is that you can do anything you like with it. Your only limit is your imagination 🙂 I have written about this before &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/taking-dbatools-test-dbalastbackup-a-little-further/" >here. &lt;/a>The other reason is that it would be very difficult to write something that was easily configurable for the different requirements that people will require. But here is one way of doing it.&lt;/p>
&lt;h2 id="create-a-configuration-and-save-it">Create a configuration and save it&lt;/h2>
&lt;p>Let’s define a configuration and call it production. This is something that I do all of the time so that I can easily run a set of checks with the configuration that I want.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># The computername we will be testing
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.computername -Value $sql0,$SQl1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The Instances we want to test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlinstance -Value $sql0,$SQl1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The database owner we expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.validdbowner.name -Value &amp;#39;THEBEARD\\EnterpriseAdmin&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># the database owner we do NOT expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.invaliddbowner.name -Value &amp;#39;sa&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should backups be compressed by default?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.defaultbackupcompression -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Do we allow DAC connections?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.dacallowed -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What recovery model should we have?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.type -value FULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should ourt database growth type be?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthtype -Value kb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What authentication scheme are we expecting?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.connection.authscheme -Value &amp;#39;KERBEROS&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatorname -Value &amp;#39;The DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator email should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatoremail -Value &amp;#39;TheDBATeam@TheBeard.Local&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which failsafe operator shoudl be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.failsafeoperator -Value &amp;#39;The DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Set the database mail profile name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.databasemailprofile -Value &amp;#39;DbaTeam&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is the whoisactive stored procedure?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.whoisactive.database -Value master
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a Full backup?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.fullmaxdays -Value 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a DIFF backup (in hours) ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.diffmaxhours -Value 26
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a log backup (in minutes)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.logmaxminutes -Value 30
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my domain name?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;TheBeard.Local&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is my Ola database?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.ola.database -Value master
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which database should not be checked for recovery model
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.excludedb -Value &amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;tempdb&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files on c?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilesonc -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files count?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilecount -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Checks should be excluded?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value LogShipping,ExtendedEvent, PseudoSimple,SPN, TestLastBackupVerifyOnly,IdentityUsage,SaRenamed
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># How many months before a build is unsupported do I want to fail the test?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.build.warningwindow -Value 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## I need to set the app.cluster configuration to one of the nodes for the HADR check
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## and I need to set the domain.name value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.cluster -Value $SQL0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;TheBeard.Local&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## I also skip the ping check for the listener as we are in Azure
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.hadr.listener.pingcheck -Value $true
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now I can export that configuration to a json file and store on a file share or in source control using the code below. This makes it easy to embed the checks into an automation solution&lt;/p>
&lt;p>&lt;code>Export-DbcConfig -Path Git:\\Production.Json&lt;/code>&lt;/p>
&lt;p>and then I can use it with&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Import-DbcConfig -Path Git:\\Production.Json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-Invoke-DbcCheck.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-Invoke-DbcCheck.png"
loading="lazy"
alt="01 - Invoke-DbcCheck"
>&lt;/a>&lt;/p>
&lt;p>I would use one of the Show parameter values here if I was running it at the command line, probably fails to make reading the information easier&lt;/p>
&lt;h2 id="add-results-to-a-database">Add results to a database&lt;/h2>
&lt;p>This only gets us the test results on the screen, so if we want to save them to a database we have to use the PassThru parameter for Invoke-DbcCheck. I will run the checks again, save them to a variable&lt;/p>
&lt;p>&lt;code>$Testresults = Invoke-DbcCheck -PassThru -Show Fails&lt;/code>&lt;/p>
&lt;p>Then I can use the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> &lt;a class="link" href="https://dbatools.io/functions/write-dbadatatable/" target="_blank" rel="noopener"
>Write-DbaDatatable&lt;/a> command to write the results to a table in a database. I need to do this twice, once for the summary and once for the test results&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Testresults | Write-DbaDataTable -SqlInstance $sql0 -Database tempdb -Table Prod_dbachecks_summary -AutoCreateTable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Testresults.TestResult | Write-DbaDataTable -SqlInstance $sql0 -Database tempdb -Table Prod_dbachecks_detail -AutoCreateTable
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and I get two tables one for the summary&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-summary.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-summary.png"
loading="lazy"
alt="02 - summary"
>&lt;/a>&lt;/p>
&lt;p>and one for the details&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-detail.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-detail.png"
loading="lazy"
alt="03 - detail"
>&lt;/a>&lt;/p>
&lt;p>This works absolutely fine and I could continue to add test results in this fashion but it has no date property so it is not so useful for reporting.&lt;/p>
&lt;h2 id="create-tables-and-triggers">Create tables and triggers&lt;/h2>
&lt;p>This is one way of doing it. I am not sure it is the best way but it works! I always look forward to how people take ideas and move them forward so if you have a better/different solution please blog about it and reference it in the comments below&lt;/p>
&lt;p>First I created a staging table for the summary results&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbachecks].[Prod_dbachecks_summary_stage](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TagFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ExcludeTagFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TestNameFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TotalCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PassedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FailedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SkippedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PendingCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InconclusiveCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Time] [bigint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TestResult] [nvarchar](max) NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and a destination table with a primary key and a date column which defaults to todays date&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbachecks].[Prod_dbachecks_summary](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SummaryID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TestDate] [date] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TagFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ExcludeTagFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TestNameFilter] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TotalCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PassedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FailedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SkippedCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PendingCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InconclusiveCount] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Time] [bigint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TestResult] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK_Prod_dbachecks_summary] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SummaryID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [dbachecks].[Prod_dbachecks_summary] ADD CONSTRAINT [DF_Prod_dbachecks_summary_TestDate] DEFAULT (getdate()) FOR [TestDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and added an INSERT trigger to the staging table&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TRIGGER [dbachecks].[Load_Prod_Summary]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON [dbachecks].[Prod_dbachecks_summary_stage]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AFTER INSERT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BEGIN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \\ SET NOCOUNT ON added to prevent extra result sets from
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \\ interfering with SELECT statements.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SET NOCOUNT ON;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> INSERT INTO [dbachecks].[Prod_dbachecks_summary]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ([TagFilter], [ExcludeTagFilter], [TestNameFilter], [TotalCount], [PassedCount], [FailedCount], [SkippedCount], [PendingCount], [InconclusiveCount], [Time], [TestResult])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [TagFilter], [ExcludeTagFilter], [TestNameFilter], [TotalCount], [PassedCount], [FailedCount], [SkippedCount], [PendingCount], [InconclusiveCount], [Time], [TestResult] FROM [dbachecks].[Prod_dbachecks_summary_stage]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">END
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [dbachecks].[Prod_dbachecks_summary_stage] ENABLE TRIGGER [Load_Prod_Summary]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and for the details I do the same thing. A details table&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbachecks].[Prod_dbachecks_detail](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DetailID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SummaryID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ErrorRecord] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ParameterizedSuiteName] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Describe] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameters] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Passed] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Show] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FailureMessage] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Time] [bigint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Name] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Result] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Context] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [StackTrace] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK_Prod_dbachecks_detail] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DetailID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [dbachecks].[Prod_dbachecks_detail] WITH CHECK ADD CONSTRAINT [FK_Prod_dbachecks_detail_Prod_dbachecks_summary] FOREIGN KEY([SummaryID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">REFERENCES [dbachecks].[Prod_dbachecks_summary] ([SummaryID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [dbachecks].[Prod_dbachecks_detail] CHECK CONSTRAINT [FK_Prod_dbachecks_detail_Prod_dbachecks_summary]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>A stage table&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbachecks].[Prod_dbachecks_detail_stage](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ErrorRecord] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ParameterizedSuiteName] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Describe] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Parameters] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Passed] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Show] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FailureMessage] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Time] [bigint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Name] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Result] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Context] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [StackTrace] [nvarchar](max) NULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>with a trigger&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TRIGGER [dbachecks].[Load_Prod_Detail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON [dbachecks].[Prod_dbachecks_detail_stage]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AFTER INSERT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BEGIN
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \\ SET NOCOUNT ON added to prevent extra result sets from
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> \\ interfering with SELECT statements.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SET NOCOUNT ON;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> INSERT INTO [dbachecks].[Prod_dbachecks_detail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">([SummaryID],[ErrorRecord], [ParameterizedSuiteName], [Describe], [Parameters], [Passed], [Show], [FailureMessage], [Time], [Name], [Result], [Context], [StackTrace])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (SELECT MAX(SummaryID) From [dbachecks].[Prod_dbachecks_summary]),[ErrorRecord], [ParameterizedSuiteName], [Describe], [Parameters], [Passed], [Show], [FailureMessage], [Time], [Name], [Result], [Context], [StackTrace]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [dbachecks].[Prod_dbachecks_detail_stage]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">END
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [dbachecks].[Prod_dbachecks_detail_stage] ENABLE TRIGGER [Load_Prod_Detail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then I can use &lt;code>Write-DbaDatatable&lt;/code> with a couple of extra parameters, &lt;code>FireTriggers&lt;/code> to run the trigger, &lt;code>Truncate&lt;/code> and &lt;code>Confirm:$false&lt;/code> to avoid any confirmation because I want this to run without any interaction and I can get the results into the database.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Testresults | Write-DbaDataTable -SqlInstance $Instance -Database $Database -Schema dbachecks -Table Prod_dbachecks_summary_stage -FireTriggers -Truncate -Confirm:$False
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Testresults.TestResult | Write-DbaDataTable -SqlInstance $Instance -Database $Database -Schema dbachecks -Table Prod_dbachecks_detail_stage -FireTriggers -Truncate -Confirm:$False
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="assets/uploads/2018/05/detail-with-stage.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/detail-with-stage.png"
loading="lazy"
alt="detail with stage"
>&lt;/a>&lt;/p>
&lt;p>Which means that I can now query some of this data and also create PowerBi reports for it.&lt;/p>
&lt;p>To enable me to have results for the groups in dbachecks I have to do a little bit of extra manipulation. I can add all of the checks to the database using&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Get-DbcCheck | Write-DbaDataTable -SqlInstance $sql0 -Database ValidationResults -Schema dbachecks -Table Checks -Truncate -Confirm:$False -AutoCreateTable
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>But because the Ola Hallengren Job names are configuration items I need to update the values for those checks which I can do as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$query = &amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.systemfull) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$SysFullJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.UserFull) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$UserFullJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.UserDiff) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$UserDiffJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.UserLog) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$UserLogJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.CommandLogCleanup) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$CommandLogJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.SystemIntegrity) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$SysIntegrityJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.UserIntegrity) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$UserIntegrityJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.UserIndex) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$UserIndexJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.OutputFileCleanup) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$OutputFileJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.DeleteBackupHistory) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$DeleteBackupJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">UPDATE [dbachecks].[Checks] SET [Describe] = &amp;#39;Ola - &amp;#34; + (Get-DbcConfigValue -Name ola.jobname.PurgeBackupHistory) + &amp;#34;&amp;#39; WHERE [Describe] = &amp;#39;Ola - `$PurgeBackupJobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbaSqlQuery -SqlInstance $SQL0 -Database ValidationResults -Query $query
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can get a sample Power Bi report in &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks-expanded" target="_blank" rel="noopener"
>my Github which also has the code from this blog post&lt;/a>&lt;/p>
&lt;p>Then you just need to open in PowerBi Desktop and&lt;/p>
&lt;p>Click Edit Queries&lt;br>
Click Data Source Settings&lt;br>
Click Change Source&lt;br>
Change the Instance and Database names&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-PowerBi.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-PowerBi.png"
loading="lazy"
alt="09 - PowerBi"
>&lt;/a>&lt;/p>
&lt;p>Then have an interactive report like this. Feel free to click around and see how it works. Use the arrows at the bottom right to go full-screen. NOTE – it filters by “today” so if I haven’t run the check and the import then click on one of the groups under “Today’s Checks by Group”&lt;/p>
&lt;p>This enables me to filter the results and see what has happened in the past so I can filter by one instance&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-filter-by-instance.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-filter-by-instance.png"
loading="lazy"
alt="05 - filter by instance"
>&lt;/a>&lt;/p>
&lt;p>or I can filter by a group of tests&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-filter-by-instance.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-filter-by-instance.png"
loading="lazy"
alt="07 - filter by instance"
>&lt;/a>&lt;/p>
&lt;p>or even by a group of tests for an instance&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-filter-by-instance-and-insance.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-filter-by-instance-and-insance.png"
loading="lazy"
alt="08 - filter by instance and insance"
>&lt;/a>&lt;/p>
&lt;p>Hopefully, this will give you some ideas of what you can do with your dbachecks results. &lt;a class="link" href="https://github.com/SQLDBAWithABeard/dbachecks-expanded" target="_blank" rel="noopener"
>You can find all of the code and the PowerBi in my GitHub&lt;/a>&lt;/p>
&lt;p>Happy Validating!&lt;/p></description></item><item><title>dbachecks – Improved Descriptions</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-improved-descriptions/</link><pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-improved-descriptions/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/04-get-dbacheck-ogv.png" alt="Featured image of post dbachecks – Improved Descriptions" />&lt;p>With the latest release of &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks/1.1.128" target="_blank" rel="noopener"
>dbachecks&lt;/a> we have added a new check for testing that foreign keys and constraints are trusted thanks to Cláudio Silva &lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/ClaudioESSilva" target="_blank" rel="noopener"
>t&lt;/a>&lt;/p>
&lt;p>To get the latest release you will need to run&lt;/p>
&lt;pre>&lt;code>Update-Module dbachecks
&lt;/code>&lt;/pre>
&lt;p>You should do this regularly as we release &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/" >new improvements frequently&lt;/a>.&lt;/p>
&lt;p>We have also added better descriptions for the checks which was suggested by the same person who inspired the previous improvement &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/dbachecks-which-configuration-item-for-which-check/" >I blogged about here&lt;/a>&lt;/p>
&lt;p>Instead of the description just being the name of the check it is now more of a, well, a description really 🙂&lt;/p>
&lt;p>This has the added effect that it means that just running Get-DbcCheck in the command line will not fit all of the information on a normal screen&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-get-dbccheck.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-get-dbccheck.png"
loading="lazy"
alt="01 - get-dbccheck.png"
>&lt;/a>&lt;/p>
&lt;p>You can use the &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/format-table?view=powershell-5.1" target="_blank" rel="noopener"
>Format-Table&lt;/a> command (or its alias ft at the command line) and select the properties to display using&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | ft -Property UniqueTag, Description -Wrap
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-get-dbccheck-format-table.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-get-dbccheck-format-table.png"
loading="lazy"
alt="02 - get-dbccheck format table"
>&lt;/a>&lt;/p>
&lt;p>or you can use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/format-list?view=powershell-5.1" target="_blank" rel="noopener"
>Format-List &lt;/a>(or its alias fl at the command line)&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | fl
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-get-dbccheck-format-list.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-get-dbccheck-format-list.png"
loading="lazy"
alt="03 get-dbccheck format list.png"
>&lt;/a>&lt;/p>
&lt;p>Or you can use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/out-gridview?view=powershell-5.1" target="_blank" rel="noopener"
>Out-GridView&lt;/a> (or its alias ogv at the command line) (Incidentally, could you also thumbs up &lt;a class="link" href="https://github.com/PowerShell/PowerShell/issues/3957" target="_blank" rel="noopener"
>this issue on Github&lt;/a> to get Out-GridView functionality in PowerShell 6)&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | ogv
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-get-dbacheck-ogv.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-get-dbacheck-ogv.png"
loading="lazy"
alt="04 - get-dbacheck ogv"
>&lt;/a>&lt;/p>
&lt;p>Happy Validating !&lt;/p></description></item><item><title>dbachecks – Which Configuration Item For Which Check ?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-which-configuration-item-for-which-check/</link><pubDate>Tue, 15 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-which-configuration-item-for-which-check/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/03-New-dbccheck.png" alt="Featured image of post dbachecks – Which Configuration Item For Which Check ?" />&lt;p>I love showing &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> to people. It’s really cool seeing how people will use it and listening to their experiences. I was showing it to a production DBA a month or so ago and he said&lt;/p>
&lt;h2 id="how-do-i-know-which-checks-there-are">How Do I Know Which Checks There Are?&lt;/h2>
&lt;p>OK you just need to run&lt;/p>
&lt;p>&lt;code>Get-DbcCheck&lt;/code>&lt;/p>
&lt;p>and it will show you&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-get-dbcchecks.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-get-dbcchecks.png"
loading="lazy"
alt="01 - get-dbcchecks.png"
>&lt;/a>&lt;/p>
&lt;p>It will show you the group, the type (does it need a computer name or an instance name), The description, the unique tag for running just that check and all the tags that will run that check&lt;/p>
&lt;p>OK he said, you talked about configurations&lt;/p>
&lt;h2 id="how-do-i-know-which-configurations-there-are">How Do I Know Which Configurations There Are?&lt;/h2>
&lt;p>So to do that you just need to run&lt;/p>
&lt;p>&lt;code>Get-DbcConfig&lt;/code>&lt;/p>
&lt;p>and it will show you&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-dbcconfig.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-dbcconfig.png"
loading="lazy"
alt="02 - dbcconfig.png"
>&lt;/a>&lt;/p>
&lt;p>You can see the name, the current value and the description&lt;/p>
&lt;p>Ah thats cool he said so&lt;/p>
&lt;h2 id="how-do-i-know-which-configuration-is-for-which-check">How Do I Know Which Configuration Is For Which Check?&lt;/h2>
&lt;p>Well, you just…. , you know…… AHHHHHHH&lt;/p>
&lt;p>Ping – light bulb moment!&lt;/p>
&lt;p>It’s always really useful to give something you have built to people who have never seen it before and then listen to what they say. Their new eyes and different experiences or expectations will give you lots of insight&lt;/p>
&lt;p>None of the amazing contributors to dbachecks had thought of this scenario so I decided to fix this. First I asked for an &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/issues" target="_blank" rel="noopener"
>issue to be raised in GitHub&lt;/a> because an issue can be an improvement or a suggestion not just a bug.&lt;/p>
&lt;p>Then I fixed it so that it would do what was required. Thank you Nick for this feedback and for helping to improve dbachecks&lt;/p>
&lt;p>I improved &lt;code>Get-DbcCheck&lt;/code> so that now it shows the configuration item related to each check&lt;/p>
&lt;p>It is easier to see (and sort or search) if you use Out-GridView&lt;/p>
&lt;pre>&lt;code>Get-DbcCheck | Out-GridView
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-New-dbccheck.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-New-dbccheck.png"
loading="lazy"
alt="03 - New dbccheck.png"
>&lt;/a>&lt;/p>
&lt;p>So now you can see which configuration can be set for each check!&lt;/p>
&lt;p>Happy Validating!&lt;/p></description></item><item><title>Creating SQL Server Containers for versions 2012-2017</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-containers-for-versions-2012-2017/</link><pubDate>Thu, 10 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-containers-for-versions-2012-2017/</guid><description>&lt;p>I am working on my &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a> presentations for &lt;a class="link" href="http://www.sqlsaturday.com/735/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday Finland&lt;/a>, &lt;a class="link" href="https://sqlday.pl/" target="_blank" rel="noopener"
>SQLDays&lt;/a>, &lt;a class="link" href="http://www.sqlsaturday.com/742/EventHome.aspx" target="_blank" rel="noopener"
>SQL Saturday Cork&lt;/a> and &lt;a class="link" href="https://sqlgrillen.de/" target="_blank" rel="noopener"
>SQLGrillen&lt;/a> I want to show the two modules running against a number of SQL Versions so I have installed&lt;/p>
&lt;ul>
&lt;li>2 Domain Controllers&lt;/li>
&lt;li>2 SQL 2017 instances on Windows 2016 with an Availability Group and WideWorldImporters database&lt;/li>
&lt;li>1 Windows 2016 jump box with all the programmes I need&lt;/li>
&lt;li>1 Windows 2016 with containers&lt;/li>
&lt;/ul>
&lt;p>using a VSTS build and this set of &lt;a class="link" href="https://github.com/SQLDBAWithABeard/ARMTemplates/tree/master/DeployAlwaysOn" target="_blank" rel="noopener"
>ARM templates and scripts&lt;/a>&lt;/p>
&lt;p>I wanted to create containers running SQL2017, SQL2016, SQL2014 and SQL2012 and restore versions of the AdventureWorks database onto each one.&lt;/p>
&lt;h2 id="move-docker-location">Move Docker Location&lt;/h2>
&lt;p>I redirected my docker location from my &lt;code>C:\&lt;/code> drive to my &lt;code>E:\&lt;/code> drive so I didnt run out of space. I did this by creating a &lt;code>daemon.json&lt;/code> file in &lt;code>C:\ProgramData\docker\config&lt;/code> and adding&lt;/p>
&lt;p>&lt;code>{&amp;quot;data-root&amp;quot;: &amp;quot;E:\containers&amp;quot;}&lt;/code>&lt;/p>
&lt;p>and restarting the docker service which created folders like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/01-folders.png"
loading="lazy"
alt="01 - folders.png"
>&lt;/p>
&lt;p>Then I ran&lt;/p>
&lt;p>&lt;code>docker volume create SQLBackups&lt;/code>&lt;/p>
&lt;p>to create a volume to hold the backups that I could mount on the containers&lt;/p>
&lt;h2 id="adventureworks-backups">AdventureWorks Backups&lt;/h2>
&lt;p>I downloaded &lt;a class="link" href="https://github.com/Microsoft/sql-server-samples/releases/tag/adventureworks" target="_blank" rel="noopener"
>all the AdventureWorks backups from GitHub&lt;/a> and copied them to &lt;code>E:\containers\volumes\sqlbackups\_data&lt;/code>&lt;/p>
&lt;p>&lt;code>Get-ChildItem $Home\Downloads\AdventureWorks* | Copy-Item -Destination E:\containers\volumes\sqlbackups\_data&lt;/code>&lt;/p>
&lt;h2 id="getting-the-images">Getting the Images&lt;/h2>
&lt;p>To download the &lt;a class="link" href="https://hub.docker.com/r/microsoft/mssql-server-windows-developer/" target="_blank" rel="noopener"
>SQL 2017 image from the DockerHub&lt;/a> I ran&lt;/p>
&lt;p>&lt;code>docker pull microsoft/mssql-server-windows-developer:latest&lt;/code>&lt;/p>
&lt;p>and waited for it to download and extract&lt;/p>
&lt;p>I also needed the images for other versions. My good friend Andrew Pruski &lt;a class="link" href="https://dbafromthecold.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>t&lt;/a> has versions available for us to use on &lt;a class="link" href="https://hub.docker.com/u/dbafromthecold/" target="_blank" rel="noopener"
>his Docker Hub &lt;/a> so it is just a case of running&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2016dev:sp1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2014dev:sp2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker pull dbafromthecold/sqlserver2012dev:sp4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and waiting for those to download and extract (This can take a while!)&lt;/p>
&lt;h2 id="create-the-containers">Create the containers&lt;/h2>
&lt;p>Creating the containers is as easy as&lt;/p>
&lt;p>&lt;code>docker run -d -p ExposedPort:InternalPort --name NAME -v VolumeName:LocalFolder -e sa\_password=THEPASSWORD -e ACCEPT\_EULA=Y IMAGENAME&lt;/code>&lt;/p>
&lt;p>so all I needed to run to create 4 SQL containers one of each version was&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">docker run -d -p 15789:1433 --name 2017 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y microsoft/mssql-server-windows-developer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15788:1433 --name 2016 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2016dev:sp1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15787:1433 --name 2014 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2014dev:sp2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">docker run -d -p 15786:1433 --name 2012 -v sqlbackups:C:\SQLBackups -e sa\_password=PruskiIsSQLContainerMan! -e ACCEPT\_EULA=Y dbafromthecold/sqlserver2012dev:sp4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and just a shade over 12 seconds later I have 4 SQL instances ready for me 🙂&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/02-creating-containers.png"
loading="lazy"
alt="02 - creating containers.png"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/03-Containers-at-the-ready.png"
loading="lazy"
alt="03 - Containers at the ready.png"
>&lt;/p>
&lt;h2 id="storing-credentials">Storing Credentials&lt;/h2>
&lt;p>This is not something I would do in a Production environment but I save my credentials using this method that Jaap Brasser &lt;a class="link" href="http://www.jaapbrasser.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/jaap_brasser" target="_blank" rel="noopener"
>t&lt;/a> &lt;a class="link" href="https://www.jaapbrasser.com/quickly-and-securely-storing-your-credentials-powershell/" target="_blank" rel="noopener"
>shared here&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-Credential | Export-Clixml -Path $HOME\Documents\sa.cred&lt;/code>&lt;/p>
&lt;p>which means that I can get the credentials in my PowerShell session (as long as it is the same user that created the file) using&lt;/p>
&lt;p>&lt;code>$cred = Import-Clixml $HOME\Documents\sa.cred&lt;/code>&lt;/p>
&lt;h2 id="restoring-the-databases">Restoring the databases&lt;/h2>
&lt;p>I restored all of the AdventureWorks databases that each instance will support onto each instance, so 2017 has all of them whilst 2012 only has the 2012 versions.&lt;/p>
&lt;p>First I needed to get the filenames of the backup files into a variable&lt;/p>
&lt;p>&lt;code>$filenames = (Get-ChildItem '\bearddockerhost\e$\containers\volumes\sqlbackups\_data').Name&lt;/code>&lt;/p>
&lt;p>and the container connection strings, which are the hostname and the port number&lt;/p>
&lt;p>&lt;code>$containers = 'bearddockerhost,15789', 'bearddockerhost,15788', 'bearddockerhost,15787', 'bearddockerhost,15786'&lt;/code>&lt;/p>
&lt;p>then I can restore the databases using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> using a switch statement on the version which I get with the NameLevel property of &lt;code>Get-DbaSqlBuildReference&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$cred = Import-Clixml $HOME\Documents\sa.cred
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$containers = &amp;#39;bearddockerhost,15789&amp;#39;, &amp;#39;bearddockerhost,15788&amp;#39;, &amp;#39;bearddockerhost,15787&amp;#39;, &amp;#39;bearddockerhost,15786&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$filenames = (Get-ChildItem &amp;#39;\bearddockerhost\e$\containers\volumes\sqlbackups\_data&amp;#39;).Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$containers.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Container = $Psitem
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $NameLevel = (Get-DbaSqlBuildReference-SqlInstance $Container-SqlCredential $cred).NameLevel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> switch ($NameLevel) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2017 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path C:\sqlbackups\ -useDestinationDefaultDirectories -WithReplace |Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2017&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2016 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -notlike &amp;#39;\*2017\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2016&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2014 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -notlike &amp;#39;\*2017\*&amp;#39; -and $Psitem -notlike &amp;#39;\*2016\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2014&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> 2012 {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Files = $Filenames.Where{$PSitem -like &amp;#39;\*2012\*&amp;#39;}.ForEach{&amp;#39;C:\sqlbackups\&amp;#39; + $Psitem}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Restore-DbaDatabase-SqlInstance $Container-SqlCredential $cred-Path $Files-useDestinationDefaultDirectories -WithReplace
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Verbose-Message &amp;#34;Restored Databases on 2012&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Default {}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I need to create the file paths for each backup file by getting the correct backups and appending the names to &lt;code>C:\SQLBackups&lt;/code> which is where the volume is mounted inside the container&lt;/p>
&lt;p>As Get-DbaDatabase gives the container ID as the Computer Name I have highlighted each container below&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/05/04-databases.png"
loading="lazy"
alt="04 - databases.png"
>&lt;/p>
&lt;p>That is how easy it is to create a number of SQL containers of differing versions for your presentations or exploring needs&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>#tsql2sday – Giving Back – Reprise</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-giving-back-reprise/</link><pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-giving-back-reprise/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/08/tsql2sday.jpg" alt="Featured image of post #tsql2sday – Giving Back – Reprise" />&lt;p>&lt;a class="link" href="https://scribnasium.com/2018/05/giving-back-t-sql-tuesday-102-invite/" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2017/08/tsql2sday.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/a>&lt;/p>
&lt;p>It’s TSQL Tuesday again! This month our host is Riley Major (&lt;a class="link" href="https://scribnasium.com/about-me/" target="_blank" rel="noopener"
>b&lt;/a>/&lt;a class="link" href="https://twitter.com/RileyMajor" target="_blank" rel="noopener"
>t&lt;/a>) and the subject is &lt;em>Giving Back&lt;/em>. He’s given us two options here (as well as the side option of &lt;em>your favorite 2017 improvement&lt;/em>). Pick a way that you’d like to give back to the community and talk about it, or if you already give back,  tell us how and why you started.&lt;/p>
&lt;p>There will be a lot of excellent posts on this subject and one of the things that I like is that you can go to &lt;a class="link" href="http://tsqltuesday.com" target="_blank" rel="noopener"
>http://tsqltuesday.com&lt;/a> and look up all of the entries which means that for a particular topic you can find a bunch of blog posts from different angles (I miss-typed that as angels first and yes they are all angels!) whether it is &lt;a class="link" href="http://tsqltuesday.com/tag/career-improvement/" target="_blank" rel="noopener"
>career improvement&lt;/a> or technical like say &lt;a class="link" href="http://tsqltuesday.com/tag/extended-events/" target="_blank" rel="noopener"
>Extended Events&lt;/a> it is all there waiting for you 🙂&lt;/p>
&lt;p>I wrote about &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-giving-back-some-examples-and-encouragement/" target="_blank" rel="noopener"
>giving back in 2014&lt;/a> when I was about to help organise SQL Saturday Exeter for the first time. Last year I blogged about a &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-folks-who-have-made-a-difference/" target="_blank" rel="noopener"
>few of the wonderful people&lt;/a> who made a difference to me. So this post is a little about how I give back and also hopefully some hints that can help you to do the same as well.&lt;/p>
&lt;h2 id="how">How&lt;/h2>
&lt;p>There are so many ways that you can give back to the community as Riley’s post shows.&lt;/p>
&lt;p>Sharing your knowledge is a good way. I share my knowledge in blog posts and in sessions at user groups and at conferences. You can too.&lt;/p>
&lt;p>From beginner, introductory posts and talks to expert level deep dives every single one of us has learned from the blog posts that other people have spent their time and effort creating.&lt;/p>
&lt;p>YOU can share your knowledge, even if you have only been using a technology for a few months, you have knowledge of the things you have learned and the things that would have made it easier. Write a post about those things.&lt;/p>
&lt;p>Answering questions is another way. You can do this on &lt;a class="link" href="https://stackoverflow.com/" target="_blank" rel="noopener"
>Stack Overflow,&lt;/a> &lt;a class="link" href="http://www.sqlservercentral.com/" target="_blank" rel="noopener"
>SQL Server Central&lt;/a>, &lt;a class="link" href="http://PowerShell.Org" target="_blank" rel="noopener"
>PowerShell.Org&lt;/a> , Reddit, Facebook , on &lt;a class="link" href="https://twitter.com/hashtag/SQLHelp" target="_blank" rel="noopener"
>Twitter using the #sqlhelp&lt;/a> or #PowerShellHelp or just in person. I try to answer questions when I see them on twitter or in the &lt;a class="link" href="http://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Community Slack&lt;/a>&lt;/p>
&lt;p>Mentoring or just providing feedback to people. You can offer to proof read blog posts or abstract submissions or you can listen to peoples presentations. I do this and it is a lot of fun&lt;/p>
&lt;p>I also share my knowledge via &lt;a class="link" href="https://github.com/sqldbawithabeard" target="_blank" rel="noopener"
>my GitHub&lt;/a>. All of my &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations" target="_blank" rel="noopener"
>presentations slides and code&lt;/a> are available as well as other code that I use. I also contribute to open-source projects such as &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>.  You can do this too. You could open an issue for an improvement or bug. You can contribute your code, even if you are not confident writing the code you can fix spelling mistakes or add documentation., everything helps&lt;/p>
&lt;p>You can help with organisation of events. I have helped to organise the PowerShell Europe Conference, PSDay.UK, SQL Saturday Exeter, SQL SouthWest user group, PASS PowerShell Virtual Group. I have also helped with session choices for a number of other events like &lt;a class="link" href="http://sqlgrillen.de" target="_blank" rel="noopener"
>SQL Grillen&lt;/a> and &lt;a class="link" href="https://sqlgla.co.uk/" target="_blank" rel="noopener"
>SQLGLA&lt;/a> and I have volunteered at many events from SQL Saturdays to SQL Bits. Everything from setting up and tearing down (IE moving heavy things and cleaning up rubbish) to sitting on the information desk, giving out badges, making sure the speakers are on time in their sessions. You can do this too. Just ask the organisers of the events what they need. It is better to do this prior to the event than on the day but I am sure all help is welcomed. &lt;a class="link" href="https://twitter.com/sql_unicorn" target="_blank" rel="noopener"
>Richard Munn&lt;/a> and &lt;a class="link" href="https://sqlbits.com/Sessions/Event17/Advice_and_guidance_on_becoming_a_speaker_or_volunteer" target="_blank" rel="noopener"
>I talked (waffled?) about this at SQL Bits this year&lt;/a>&lt;/p>
&lt;p>If you would like to be considered as a volunteer for next years SQL Bits please email helpers at sqlbits.com&lt;/p>
&lt;h2 id="why">Why&lt;/h2>
&lt;p>So why did I start giving back?&lt;/p>
&lt;p>I wanted to be useful. I saw the amount of work that Jonathan and Annette were doing organising SQL Saturday Exeter and SQL South West. I hoped that I could help them with that.&lt;/p>
&lt;p>Why do I carry on doing it?&lt;/p>
&lt;p>Because it is fun 🙂 I enjoy speaking, I enjoy sharing my knowledge and talking to people&lt;/p>
&lt;p>That is good but there is more to it as well&lt;/p>
&lt;p>You learn so much by writing a presentation or a blog post because you will do research.&lt;/p>
&lt;p>You will learn even more when people ask you questions in your sessions or leave comments on your blog posts and you have to go and find the answers&lt;/p>
&lt;p>You learn new and useful skills and demonstrate your knowledge to potential employers&lt;/p>
&lt;p>My blog is a scrapbook of knowledge that I go back to and use all the time (and sometimes I forget that I have written something and find my own post in the search results!)&lt;/p>
&lt;p>But the most important reason is that I feel that it pays back some of the benefit that I have gained from all of those people who’s time and effort I made use of for free when I was learning and continue to do so to this day. All of those blog posts and videos and presentations that I consumed have helped to make me the technician I am today. I have skills and abilities that I would not have without them all and by giving back I hope that I am enabling others to develop and see the benefit of sharing so that they will continue to do so in the future and I can learn from them.&lt;/p></description></item><item><title>Visual Studio Code Live Sharing Set-Up</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/visual-studio-code-live-sharing-set-up/</link><pubDate>Tue, 08 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/visual-studio-code-live-sharing-set-up/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/07-sign-in.png" alt="Featured image of post Visual Studio Code Live Sharing Set-Up" />&lt;p>There was an &lt;a class="link" href="https://code.visualstudio.com/blogs/2018/05/07/live-share-public-preview" target="_blank" rel="noopener"
>announcement on the Visual Studio Code blog&lt;/a> about the public preview of Live Share. This enables you to easily collaborate on code by securely sharing your coding session.&lt;/p>
&lt;p>It is remarkably easy to set up 🙂&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Open Visual Studio Code, open the Extensions side bar (CTRL + SHIFT + X)&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-open-extensions.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-open-extensions.png"
loading="lazy"
alt="01 - open extensions"
>&lt;/a>&lt;/p>
&lt;p>Search for Live Share&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-search.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-search.png"
loading="lazy"
alt="02 - search.png"
>&lt;/a>&lt;/p>
&lt;p>Click Install and then reload when it has done&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-reload.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-reload.png"
loading="lazy"
alt="03 - reload.png"
>&lt;/a>&lt;/p>
&lt;p>You will notice in the bottom bar it will say finishing the installation and if you open the terminal (CTRL + ‘) and click on Output and change the drop down on the right to Visual Studio Live Share you can see what it is doing&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-finishing-installation.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-finishing-installation.png"
loading="lazy"
alt="04 - finishing installation.png"
>&lt;/a>&lt;/p>
&lt;p>It is installing the dependancies as shown below&lt;/p>
&lt;blockquote>
&lt;p>[Client I] Installing dependencies for Live Share…&lt;/p>
&lt;p>[Client I] Downloading package ‘.NET Core Runtime 2.0.5 for win7-x86’&lt;/p>
&lt;p>[Client I] Download complete.&lt;/p>
&lt;p>[Client I] Downloading package ‘OmniSharp for Windows (.NET 4.6)’&lt;/p>
&lt;p>[Client I] Download complete.&lt;/p>
&lt;p>[Client I] Installing package ‘.NET Core Runtime 2.0.5 for win7-x86’&lt;/p>
&lt;p>[Client V] Extracted packed files&lt;/p>
&lt;p>[Client I] Validated extracted files.&lt;/p>
&lt;p>[Client I] Moved and validated extracted files.&lt;/p>
&lt;p>[Client I] Finished installing.&lt;/p>
&lt;p>[Client I] Installing package ‘OmniSharp for Windows (.NET 4.6)’&lt;/p>
&lt;p>[Client V] Extracted packed files&lt;/p>
&lt;p>[Client I] Validated extracted files.&lt;/p>
&lt;p>[Client I] Finished installing.&lt;/p>
&lt;p>[Client I] No workspace id found.&lt;/p>
&lt;/blockquote>
&lt;p>Incidentally, this will also show the location of the log file&lt;/p>
&lt;p>You will see in the bottom bar it will now say sign in&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/06-sign-in.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/06-sign-in.png"
loading="lazy"
alt="06 - sign in.png"
>&lt;/a>&lt;/p>
&lt;p>Clicking that will open a browser and give you a choice of accounts to sign in with, your GitHub or your Microsoft ID&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-sign-in.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-sign-in.png"
loading="lazy"
alt="07 - sign in.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the one that you want to use and do your 2FA.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-2FA.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-2FA.png"
loading="lazy"
alt="08 - 2FA.png"
>&lt;/a>&lt;/p>
&lt;p>You do have 2FA on your Microsoft and GitHub (and all the other services)? If not go and set it up now – &lt;a class="link" href="https://account.live.com/proofs/manage/additional?mkt=en-US&amp;amp;refd=account.microsoft.com&amp;amp;refp=security" target="_blank" rel="noopener"
>here for Microsoft&lt;/a> and &lt;a class="link" href="https://github.com/settings/security" target="_blank" rel="noopener"
>here for GitHub &lt;/a>&lt;/p>
&lt;p>Once you have signed in you will get this notification which you can close&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-close-this-notification.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-close-this-notification.png"
loading="lazy"
alt="09 - close this notification.png"
>&lt;/a>&lt;/p>
&lt;p>The icon in the bottom will change and show your account name and if you click it it will open the menu&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-sharing-menu.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-sharing-menu.png"
loading="lazy"
alt="09 - sharing menu.png"
>&lt;/a>&lt;/p>
&lt;h2 id="sharing">Sharing&lt;/h2>
&lt;p>To share your session you click on the Share icon in the bottom bar or the Start collaboration session in the menu above. The first time you do this there will be a pop-up as shown&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-firewall-popup.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-firewall-popup.png"
loading="lazy"
alt="05 - firewall popup.png"
>&lt;/a>&lt;/p>
&lt;p>You can decide which way you (or your organisation) want to share. I chose to accept the firewall exception.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/10-invite-link.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/10-invite-link.png"
loading="lazy"
alt="10 - invite link.png"
>&lt;/a>&lt;/p>
&lt;p>The invite link is in your clipboard ready to share with your friends and colleagues (other open source contributors ??)&lt;/p>
&lt;p>They can either open the link in a browser&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/11-join-via-browser.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/11-join-via-browser.png"
loading="lazy"
alt="11 - join via browser.png"
>&lt;/a>&lt;/p>
&lt;p>or by using the Join Collaboration Session in the menu in VS Code&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/12-Join-via-VS-COde.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/12-Join-via-VS-COde.png"
loading="lazy"
alt="12 - Join via VS COde.png"
>&lt;/a>&lt;/p>
&lt;p>Once they do the sharer will get a notification&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/13-notification-of-sharing.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/13-notification-of-sharing.png"
loading="lazy"
alt="13 - notification of sharing.png"
>&lt;/a>&lt;/p>
&lt;p>and the person who has joined will have the same workspace opened in their Visual Studio Code&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/14-shared-workspace.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/14-shared-workspace.png"
loading="lazy"
alt="14 -shared workspace.png"
>&lt;/a>&lt;/p>
&lt;p>You can then collaborate on your code and share the session. In the video below the left hand side is running in my jump box in Azure and the right hand side on my laptop and you can see that if you highlight code in one side it is shown in the other and if you alter it in one side it is changed in the other. I also saved that file in the joined session rather than from the session that initialised the sharing and it then saved in both sessions 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So that shows how easy it is to install and to use. You can dive deeper &lt;a class="link" href="https://docs.microsoft.com/en-us/visualstudio/liveshare/" target="_blank" rel="noopener"
>using the documentation&lt;/a>.&lt;/p>
&lt;p>Happy Collaborating 🙂&lt;/p></description></item><item><title>Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/version-update-code-signing-and-publishing-to-the-powershell-gallery-with-vsts/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png" alt="Featured image of post Version Update, Code Signing and publishing to the PowerShell Gallery with VSTS" />&lt;p>At the fabulous &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference EU&lt;/a> I presented about Continuous Delivery to the PowerShell Gallery with VSTS and explained how we use VSTS to enable CD for &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>. We even released a new version during the session 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So how do we achieve this?&lt;/p>
&lt;p>We have a few steps&lt;/p>
&lt;ul>
&lt;li>Create a project and link to our GitHub&lt;/li>
&lt;li>Run unit uests with Pester to make sure that our code is doing what we expect.&lt;/li>
&lt;li>Update our module version and commit the change to GitHub&lt;/li>
&lt;li>Sign our code with a code signing certificate&lt;/li>
&lt;li>Publish to the PowerShell Gallery&lt;/li>
&lt;/ul>
&lt;h2 id="create-project-and-link-to-github">Create Project and link to GitHub&lt;/h2>
&lt;p>First you need to create a VSTS project by going to &lt;a class="link" href="https://www.visualstudio.com/" target="_blank" rel="noopener"
>https://www.visualstudio.com/&lt;/a> This is free for up to 5 users with 1 concurrent CI/CD queue limited to a maximum of 60 minutes run time which should be more than enough for your PowerShell module.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/01-sign-up-1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/01-sign-up-1.png"
loading="lazy"
alt="01 - sign up.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Get Started for free under Visual Studio Team Services and fill in the required information. Then on the front page click new project&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/02-New-Project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/02-New-Project.png"
loading="lazy"
alt="02 - New Project.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in the details and click create&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/03-create-project.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/03-create-project.png"
loading="lazy"
alt="03 - create project.png"
>&lt;/a>&lt;/p>
&lt;p>Click on builds and then new definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/04-builds.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/04-builds.png"
loading="lazy"
alt="04- builds.png"
>&lt;/a>&lt;/p>
&lt;p>next you need to link your project to your GitHub (or other source control providers) repository&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/05-github-auth.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/05-github-auth.png"
loading="lazy"
alt="05 - github auth.png"
>&lt;/a>&lt;/p>
&lt;p>You can either authorise with OAuth or you can &lt;a class="link" href="https://help.github.com/articles/creating-a-personal-access-token-for-the-command-line/" target="_blank" rel="noopener"
>provide a PAT token following the instructions here&lt;/a>. Once that is complete choose your repo. Save the PAT as you will need it later in the process!&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/06-choose-repo.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/06-choose-repo.png"
loading="lazy"
alt="06 - choose repo.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the branch that you want this build definition to run against.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/07-branch.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/07-branch.png"
loading="lazy"
alt="07 branch.png"
>&lt;/a>&lt;/p>
&lt;p>I chose to run the Unit Tests when a PR was merged into the development branch. I will then create another build definition for the master branch to sign the code and update module version. This enables us to push several PRs into the development branch and create a single release for the gallery.&lt;/p>
&lt;p>Then I start with an empty process&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/08-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/08-empty-process.png"
loading="lazy"
alt="08 - empty process.png"
>&lt;/a>&lt;/p>
&lt;p>and give it a suitable name&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/09-name-it.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/09-name-it.png"
loading="lazy"
alt="09 - name it.png"
>&lt;/a>&lt;/p>
&lt;p>i chose the hosted queue but you can download an agent to your build server if you need to do more or your integration tests require access to other resources not available on the hosted agent.&lt;/p>
&lt;h2 id="run-unit-tests-with-pester">Run Unit Tests with Pester&lt;/h2>
&lt;p>We have a number of Unit tests in our &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks/tree/development/tests" target="_blank" rel="noopener"
>tests folder in dbachecks&lt;/a> so we want to run them to ensure that everything is as it should be and the new code will not break existing functionality (and for dbachecks the &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/using-the-ast-in-pester-for-dbachecks/" >format of the PowerBi&lt;/a>)&lt;/p>
&lt;p>You can use the &lt;a class="link" href="https://marketplace.visualstudio.com/items?itemName=richardfennellBM.BM-VSTS-PesterRunner-Task" target="_blank" rel="noopener"
>Pester Test Runner Build Task&lt;/a> from the folk at &lt;a class="link" href="http://blackmarble.com/" target="_blank" rel="noopener"
>Black Marble&lt;/a> by clicking on the + sign next to Phase 1 and searching for Pester&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/10-Pester-task-runner.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/10-Pester-task-runner.png"
loading="lazy"
alt="10 - Pester task runner.png"
>&lt;/a>&lt;/p>
&lt;p>You will need to click Get It Free to install it and then click add to add the task to your build definition. You can pretty much leave it as default if you wish and Pester will run all of the *.Tests.ps1 files that it finds in the directory where it downloads the GitHub repo which is referred to using the variable $(Build.SourcesDirectory). It will then output the results to a json file called Test-Pester.XML ready for publishing.&lt;/p>
&lt;p>However, as dbachecks has a number of dependent modules, this task was not suitable. I spoke with Chris Gardner  &lt;a class="link" href="https://chrislgardner.github.io/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/HalbaradKenafin" target="_blank" rel="noopener"
>t&lt;/a>  from Black Marble at the PowerShell Conference and he says that this can be resolved so look out for the update. Chris is a great guy and always willing to help, you can often find him in the &lt;a class="link" href="http://slack.poshcode.org/" target="_blank" rel="noopener"
>PowerShell Slack channel&lt;/a> answering questions and helping people&lt;/p>
&lt;p>But as you can use PowerShell in VSTS tasks, this is not a problem although you need to write your PowerShell using try catch to make sure that your task fails when your PowerShell errors. This is the code I use to install the modules&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;&lt;/p>
&lt;p># Set location to module home path in artifacts directory
try {
Set-Location $(Build.SourcesDirectory)
Get-ChildItem
}
catch {
Write-Error &amp;ldquo;Failed to set location&amp;rdquo;&lt;/p>
&lt;p>}&lt;/p>
&lt;p># Get the Module versions
Install-Module Configuration -Scope CurrentUser -Force
$Modules = Get-ManifestValue -Path .\dbachecks.psd1 -PropertyName RequiredModules&lt;/p>
&lt;p>$PesterVersion = $Modules.Where{$&lt;em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;Pester&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$PSFrameworkVersion = $Modules.Where{$&lt;/em>.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;PSFramework&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)
$dbatoolsVersion = $Modules.Where{$_.Get_Item(&amp;lsquo;ModuleName&amp;rsquo;) -eq &amp;lsquo;dbatools&amp;rsquo;}[0].Get_Item(&amp;lsquo;ModuleVersion&amp;rsquo;)&lt;/p>
&lt;p># Install Pester
try {
Write-Output &amp;ldquo;Installing Pester&amp;rdquo;
Install-Module Pester -RequiredVersion $PesterVersion -Scope CurrentUser -Force -SkipPublisherCheck
Write-Output &amp;ldquo;Installed Pester&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install Pester $($_)&amp;rdquo;
}
# Install dbatools
try {
Write-Output &amp;ldquo;Installing PSFramework&amp;rdquo;
Install-Module PSFramework -RequiredVersion $PsFrameworkVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed PSFramework&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install PSFramework $($_)&amp;rdquo;
}
# Install dbachecks
try {
Write-Output &amp;ldquo;Installing dbatools&amp;rdquo;
Install-Module dbatools -RequiredVersion $dbatoolsVersion -Scope CurrentUser -Force
Write-Output &amp;ldquo;Installed dbatools&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbatools $($_)&amp;rdquo;
}&lt;/p>
&lt;p># Add current folder to PSModulePath
try {
Write-Output &amp;ldquo;Adding local folder to PSModulePath&amp;rdquo;
$ENV:PSModulePath = $ENV:PSModulePath + &amp;ldquo;;$pwd&amp;rdquo;
Write-Output &amp;ldquo;Added local folder to PSModulePath&amp;rdquo; &lt;br>
$ENV:PSModulePath.Split(&amp;rsquo;;&amp;rsquo;)
}
catch {
Write-Error &amp;ldquo;Failed to add $pwd to PSModulePAth - $_&amp;rdquo;
}&lt;/p>
&lt;p>I use the &lt;a class="link" href="https://github.com/PoshCode/Configuration" target="_blank" rel="noopener"
>Configuration module&lt;/a> from &lt;a class="link" href="https://twitter.com/jaykul" target="_blank" rel="noopener"
>Joel Bennett&lt;/a> to get the required module versions for the required modules and then add the path to $ENV:PSModulePath so that the modules will be imported. I think this is because the modules did not import correctly without it.&lt;/p>
&lt;p>Once I have the modules I can then run Pester as follows&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Installing dbachecks&amp;rdquo;
Import-Module .\dbachecks.psd1
Write-Output &amp;ldquo;Installed dbachecks&amp;rdquo;&lt;/p>
&lt;p>}
catch {
Write-Error &amp;ldquo;Failed to Install dbachecks $($_)&amp;rdquo;
}
$TestResults = Invoke-Pester .\tests -ExcludeTag Integration,IntegrationTests -Show None -OutputFile $(Build.SourcesDirectory)\Test-Pester.XML -OutputFormat NUnitXml -PassThru&lt;/p>
&lt;p>if ($TestResults.failedCount -ne 0) {
Write-Error &amp;ldquo;Pester returned errors&amp;rdquo;
}&lt;/p>
&lt;p>As you can see I import the dbachecks module from the local folder, run Invoke-Pester and output the results to an XML file and check that there are no failing tests.&lt;/p>
&lt;p>Whether you use the task or PowerShell the next step is to Publish the test results so that they are displayed in the build results in VSTS.&lt;/p>
&lt;p>Click on the + sign next to Phase 1 and search for Publish&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/12-publish-test-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/12-publish-test-results.png"
loading="lazy"
alt="12 - publish test results.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the Publish Test Results task and leave everything as default unless you have renamed the xml file. This means that on the summary page you will see some test results&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/13-Test-on-sumary-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/13-Test-on-sumary-page.png"
loading="lazy"
alt="13 - Test on sumary page.png"
>&lt;/a>&lt;/p>
&lt;p>and on the tests tab you can see more detailed information and drill down into the tests&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/14-detailed-test-report.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/14-detailed-test-report.png"
loading="lazy"
alt="14 - detailed test report.png"
>&lt;/a>&lt;/p>
&lt;h2 id="trigger">Trigger&lt;/h2>
&lt;p>The next step is to trigger a build when a commit is pushed to the development branch. Click on Triggers and tick enable continuous integration&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/15-Trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/15-Trigger.png"
loading="lazy"
alt="15 Trigger.png"
>&lt;/a>&lt;/p>
&lt;h2 id="saving-the-build-definition">Saving the Build Definition&lt;/h2>
&lt;p>I would normally save the build definition regularly and ensure that there is a good message in the comment. I always tell clients that this is like a commit message for your build process so that you can see the history of the changes for the build definition.&lt;/p>
&lt;p>You can see the history on the edit tab of the build definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/16-build-history.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/16-build-history.png"
loading="lazy"
alt="16 - build history.png"
>&lt;/a>&lt;/p>
&lt;p>If you want to compare or revert the build definition this can be done using the hamburger menu as shown below.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/17-build-history-compare-revert.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/17-build-history-compare-revert.png"
loading="lazy"
alt="17 - build history compare revert.png"
>&lt;/a>&lt;/p>
&lt;h2 id="update-the-module-version">Update the Module Version&lt;/h2>
&lt;p>Now we need to create a build definition for the master branch to update the module version and sign the code ready for publishing to the PowerShell Gallery when we commit or merge to master&lt;/p>
&lt;p>Create a new build definition as above but this time choose the master branch&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/18-master-build.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/18-master-build.png"
loading="lazy"
alt="18 - master build.png"
>&lt;/a>&lt;/p>
&lt;p>Again choose an empty process and name it sensibly, click the + sign next to Phase 1 and search for PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/19-PowerShell-task.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/19-PowerShell-task.png"
loading="lazy"
alt="19 - PowerShell task.png"
>&lt;/a>&lt;/p>
&lt;p>I change the version to 2 and use this code. Note that the commit message has ***NO_CI*** in it. Putting this in a commit message tells VSTS not to trigger a build for this commit.&lt;/p>
&lt;p>$manifest = Import-PowerShellDataFile .\dbachecks.psd1
[version]$version = $Manifest.ModuleVersion
Write-Output &amp;ldquo;Old Version - $Version&amp;rdquo;
# Add one to the build of the version number
[version]$NewVersion = &amp;ldquo;{0}.{1}.{2}&amp;rdquo; -f $Version.Major, $Version.Minor, ($Version.Build + 1)
Write-Output &amp;ldquo;New Version - $NewVersion&amp;rdquo;
# Update the manifest file
try {
Write-Output &amp;ldquo;Updating the Module Version to $NewVersion&amp;rdquo;
$path = &amp;ldquo;$pwd\dbachecks.psd1&amp;rdquo;
(Get-Content .\dbachecks.psd1) -replace $version, $NewVersion | Set-Content .\dbachecks.psd1 -Encoding string
Write-Output &amp;ldquo;Updated the Module Version to $NewVersion&amp;rdquo;
}
catch {
Write-Error &amp;ldquo;Failed to update the Module Version - $_&amp;rdquo;
}&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Updating GitHub&amp;rdquo;
git config user.email &amp;ldquo;&lt;a class="link" href="mailto:mrrobsewell@outlook.com" >mrrobsewell@outlook.com&lt;/a>&amp;rdquo;
git config user.name &amp;ldquo;SQLDBAWithABeard&amp;rdquo;
git add .\dbachecks.psd1
git commit -m &amp;ldquo;Updated Version Number to $NewVersion ***NO_CI***&amp;rdquo;&lt;/p>
&lt;p>git push https://$(RobsGitHubPAT)@github.com/sqlcollaborative/dbachecks.git HEAD:master
Write-Output &amp;ldquo;Updated GitHub &amp;quot;&lt;/p>
&lt;p>}
catch {
$_ | Fl -Force
Write-Output &amp;ldquo;Failed to update GitHub&amp;rdquo;
}&lt;/p>
&lt;p>I use Get-Content Set-Content as I had errors with the Update-ModuleManifest but Adam Murray &lt;a class="link" href="https://github.com/muzzar78" target="_blank" rel="noopener"
>g&lt;/a> | &lt;a class="link" href="https://twitter.com/muzzar78" target="_blank" rel="noopener"
>t&lt;/a> uses this code to update the version using the BuildID from VSTS&lt;/p>
&lt;p>$newVersion = New-Object version -ArgumentList 1, 0, 0, $env:BUILD_BUILDID
$Public = @(Get-ChildItem -Path $ModulePath\Public\*.ps1)
$Functions = $public.basename
Update-ModuleManifest -Path $ModulePath\$ModuleName.psd1 -ModuleVersion $newVersion -FunctionsToExport $Functions&lt;/p>
&lt;p>You can commit your change by adding your PAT token as a variable under the variables tab. Don’t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/20-variables.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/20-variables.png"
loading="lazy"
alt="20 - variables.png"
>&lt;/a>&lt;/p>
&lt;h2 id="sign-the-code-with-a-certificate">Sign the code with a certificate&lt;/h2>
&lt;p>The SQL Collaborative uses a code signing certificate from &lt;a class="link" href="https://digicert.com/" target="_blank" rel="noopener"
>DigiCert&lt;/a> who allow MVPs to use one for free to sign their code for open source projects, Thank You. We had to upload the certificate to the secure files store in the VSTS library. Click on library, secure files and the blue +Secure File button&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/21-secure-file-store.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/21-secure-file-store.png"
loading="lazy"
alt="21 - secure file store.png"
>&lt;/a>&lt;/p>
&lt;p>You also need to add the password as a variable under the variables tab as above. Again don’t forget to tick the padlock to make it a secret so it is not displayed in the logs&lt;/p>
&lt;p>Then you need to add a task to download the secure file. Click on the + sign next to Phase 1 and search for secure&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/22-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/22-download-secure-file.png"
loading="lazy"
alt="22 download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>choose the file from the drop down&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/23-download-secure-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/23-download-secure-file.png"
loading="lazy"
alt="23 - download secure file.png"
>&lt;/a>&lt;/p>
&lt;p>Next we need to import the certificate and sign the code. I use a PowerShell task for this with the following code&lt;/p>
&lt;p>$ErrorActionPreference = &amp;lsquo;Stop&amp;rsquo;
# read in the certificate from a pre-existing PFX file
# I have checked this with @IISResetMe and this does not go in the store only memory
$cert = [System.Security.Cryptography.X509Certificates.X509Certificate2]::new(&amp;quot;$(Agent.WorkFolder)\_temp\dbatools-code-signing-cert.pfx&amp;rdquo;,&amp;quot;$(CertPassword)&amp;quot;)&lt;/p>
&lt;p>try {
Write-Output &amp;ldquo;Signing Files&amp;rdquo;
# find all scripts in your module&amp;hellip;
Get-ChildItem -Filter *.ps1 -Include *.ps1 -Recurse -ErrorAction SilentlyContinue |
# &amp;hellip;that do not have a signature yet&amp;hellip;
Where-Object {
($_ | Get-AuthenticodeSignature).Status -eq &amp;lsquo;NotSigned&amp;rsquo;
} |
# and apply one
# (note that we added -WhatIf so no signing occurs. Remove this only if you
# really want to add digital signatures!)
Set-AuthenticodeSignature -Certificate $cert
Write-Output &amp;ldquo;Signed Files&amp;rdquo;
}
catch {
$_ | Format-List -Force
Write-Error &amp;ldquo;Failed to sign scripts&amp;rdquo;
}&lt;/p>
&lt;p>which will import the certificate into memory and sign all of the scripts in the module folder.&lt;/p>
&lt;h2 id="publish-your-artifact">Publish your artifact&lt;/h2>
&lt;p>The last step of the master branch build publishes the artifact (your signed module) to VSTS ready for the release task. Again, click the + sign next to Phase one and choose the Publish Artifact task not the deprecated copy and publish artifact task and give the artifact a useful name&lt;/p>
&lt;h2 id="24---publish-artifactpngassetsuploads20180524-publish-artifactpngassetsuploads20180524-publish-artifactpng">&lt;a class="link" href="assets/uploads/2018/05/24-publish-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/24-publish-artifact.png"
loading="lazy"
alt="24 - publish artifact.png"
>&lt;/a>&lt;/h2>
&lt;p>Don’t forget to set the trigger for the master build as well following the same steps as the development build above&lt;/p>
&lt;h2 id="publish-to-the-powershell-gallery">Publish to the PowerShell Gallery&lt;/h2>
&lt;p>Next we create a release to trigger when there is an artifact ready and publish to the PowerShell Gallery.&lt;/p>
&lt;p>Click the Releases tab and New Definition&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/25-Reelase-creation.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/25-Reelase-creation.png"
loading="lazy"
alt="25 - Reelase creation"
>&lt;/a>&lt;/p>
&lt;p>Choose an empty process and name the release definition appropriately&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/26-Release-name-empty-process.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/26-Release-name-empty-process.png"
loading="lazy"
alt="26 Release name empty process.png"
>&lt;/a>&lt;/p>
&lt;p>Now click on the artifact and choose the master build definition. If you have not run a build you will get an error like below but dont worry click add.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/27-add-artifact.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/27-add-artifact.png"
loading="lazy"
alt="27 - add artifact.png"
>&lt;/a>&lt;/p>
&lt;p>Click on the lightning bolt next to the artifact to open the continuous deployment trigger&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Choose-lightning-bolt.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Choose-lightning-bolt.png"
loading="lazy"
alt="28 - Choose lightning bolt"
>&lt;/a>&lt;/p>
&lt;p>and turn on Continuous Deployment so that when an artifact has been created with an updated module version and signed code it is published to the gallery&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/28-Continuous-deployment-trigger.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/28-Continuous-deployment-trigger.png"
loading="lazy"
alt="28 - Continuous deployment trigger"
>&lt;/a>&lt;/p>
&lt;p>Next, click on the environment and name it appropriately and then click on the + sign next to Agent Phase and choose a PowerShell step&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/29-PowerShell-Publish-step.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/29-PowerShell-Publish-step.png"
loading="lazy"
alt="29 - PowerShell Publish step"
>&lt;/a>&lt;/p>
&lt;p>You may wonder why I dont choose the PowerShell Gallery Packager task. There are two reasons. First I need to install the required modules for dbachecks (dbatools, PSFramework, Pester) prior to publishing and second it appears that the API Key is stored in plain text&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/30-PowerShell-Gallery-Publisher.png"
loading="lazy"
alt="30 - PowerShell Gallery Publisher"
>&lt;/a>&lt;/p>
&lt;p>I save my API key for the PowerShell Gallery as a variable again making sure to tick the padlock to make it a secret&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/31-API-Key-variable.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/31-API-Key-variable.png"
loading="lazy"
alt="31 - API Key variable.png"
>&lt;/a>&lt;/p>
&lt;p>and then use the following code to install the required modules and publish the module to the gallery&lt;/p>
&lt;p>Install-Module dbatools -Scope CurrentUser -Force
Install-Module Pester -Scope CurrentUser -SkipPublisherCheck -Force
Install-Module PSFramework -Scope CurrentUser -Force&lt;/p>
&lt;p>Publish-Module -Path &amp;ldquo;$(System.DefaultWorkingDirectory)/Master - Version Update, Signing and Publish Artifact/dbachecks&amp;rdquo; -NuGetApiKey &amp;ldquo;$(GalleryApiKey)&amp;rdquo;&lt;/p>
&lt;p>Thats it 🙂&lt;/p>
&lt;p>Now we have a process that will automatically run our Pester tests when we commit or merge to the development branch and then update our module version number and sign our code and publish to the PowerShell Gallery when we commit or merge to the master branch&lt;/p>
&lt;h2 id="added-extra--dashboard">Added Extra – Dashboard&lt;/h2>
&lt;p>I like to create dashboards in VSTS to show the progress of the various definitions. You can do this under the dashboard tab. Click edit and choose or search for widgets and add them to the dashboard&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/32-Dashboard.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/32-Dashboard.png"
loading="lazy"
alt="32 - Dashboard.png"
>&lt;/a>&lt;/p>
&lt;h2 id="added-extra--badges">Added Extra – Badges&lt;/h2>
&lt;p>You can also enable badges for displaying on your readme in GitHub (or VSTS). For the build defintions this is under the options tab.&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/33-Build-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/33-Build-badges.png"
loading="lazy"
alt="33 - Build badges"
>&lt;/a>&lt;/p>
&lt;p>for the release definitions, click the environment and then options and integrations&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/34-Release-Badge.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/34-Release-Badge.png"
loading="lazy"
alt="34 - Release Badge"
>&lt;/a>&lt;/p>
&lt;p>You can then copy the URL and use it in your readme &lt;a class="link" href="https://github.com/sqlcollaborative/dbachecks" target="_blank" rel="noopener"
>like this on dbachecks&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/05/35-dbachecks-readme-badges.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/05/35-dbachecks-readme-badges.png"
loading="lazy"
alt="35 - dbachecks readme badges.png"
>&lt;/a>&lt;/p>
&lt;p>The SQL Collaborative has joined the preview of enabling public access to VSTS projects as &lt;a class="link" href="https://blogs.msdn.microsoft.com/devops/2018/04/27/vsts-public-projects-limited-preview/" target="_blank" rel="noopener"
>detailed in this blog post&lt;/a> So you can &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbachecks/dbachecks%20Team/_build" target="_blank" rel="noopener"
>see the dbachecks build and release without the need to log in&lt;/a> and soon &lt;a class="link" href="https://sqlcollaborative.visualstudio.com/dbatools/_build" target="_blank" rel="noopener"
>the dbatools process as well&lt;/a>&lt;/p>
&lt;p>I hope you found this useful and if you have any questions or comments please feel free to contact me&lt;/p>
&lt;p>Happy Automating!&lt;/p></description></item><item><title>Professional and Proficient PowerShell: From Writing Scripts to Developing Solutions at PASS Summit</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/professional-and-proficient-powershell-from-writing-scripts-to-developing-solutions-at-pass-summit/</link><pubDate>Wed, 11 Apr 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/professional-and-proficient-powershell-from-writing-scripts-to-developing-solutions-at-pass-summit/</guid><description>&lt;p>&lt;a class="link" href="http://www.pass.org/summit/2018/" target="_blank" rel="noopener"
>PASS Summit&lt;/a> is the largest conference for technical professionals who leverage the Microsoft Data Platform. PASS Summit 2018 is happening November 5th – 9th 2018 in Seattle. It is an amazing conference. I attended last year and thoroughly enjoyed every minute. It is a whole week of opportunities to learn from and network with people from all over the world involved in Data Platform.&lt;/p>
&lt;p>The pre-cons have just been announced so go and take a look at the &lt;a class="link" href="http://www.pass.org/summit/2018/Learn/Pre-ConferenceSessions.aspx" target="_blank" rel="noopener"
>Pre-Con Page&lt;/a> to see the wonderful full day learning opportunities you can get this year.&lt;/p>
&lt;p>I am immensely honoured to say that on Tuesday 6th November you can &lt;a class="link" href="http://www.pass.org/summit/2018/Sessions/Details.aspx?sid=80306" target="_blank" rel="noopener"
>join me for a whole day of PowerShell learning &lt;/a>&lt;/p>
&lt;p>I will pass on as much of the skills and knowledge I have learnt using PowerShell with SQL Server (and other technologies) that I can fit in one day. I want you to leave feeling more confident in using PowerShell to automate away all of the mundane. In particular I want to enable you to have the skills to write professional PowerShell solutions.&lt;/p>
&lt;p>You can &lt;a class="link" href="http://www.pass.org/summit/2018/Sessions/Details.aspx?sid=80306" target="_blank" rel="noopener"
>read more and sign up here&lt;/a>&lt;/p>
&lt;p>If you have any questions about this session please feel free to contact me. You can use any of the various social media sites, or via the contact page or in person if you see me.&lt;/p></description></item><item><title>Checking Availability Groups with dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-availability-groups-with-dbachecks/</link><pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-availability-groups-with-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/04/VSTS-results.png" alt="Featured image of post Checking Availability Groups with dbachecks" />&lt;p>It’s been 45 days since we released dbachecks&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>Since then there have been 25 releases to the PowerShell Gallery!! Today release 1.1.119 was released 🙂 There have been over 2000 downloads of the module already.&lt;/p>
&lt;p>In the beginning we had 80 checks and 108 configuration items, today we have 84 checks and 125 configuration items!&lt;/p>
&lt;p>If you have already installed dbachecks it is important to make sure that you update regularly. You can do this by running&lt;/p>
&lt;p>Update-Module dbachecks&lt;/p>
&lt;p>If you want to try dbachecks, you can install it from the &lt;a class="link" href="https://www.powershellgallery.com/packages/dbachecks" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> by running&lt;/p>
&lt;p>Install-Module dbachecks # -Scope CurrentUser # if not running as admin&lt;/p>
&lt;p>You can read more about installation and read a number of blog posts about using different parts of dbachecks at this link &lt;a class="link" href="https://dbatools.io/installing-dbachecks/" target="_blank" rel="noopener"
>https://dbatools.io/installing-dbachecks/&lt;/a>&lt;/p>
&lt;h2 id="hadr-tests">HADR Tests&lt;/h2>
&lt;p>Today we updated the HADR tests to add the capability to test multiple availability groups and fix a couple of bugs&lt;/p>
&lt;p>Once you have installed dbachecks you will need to set some configuration so that you can perform the tests. You can see all of the configuration items and their values using&lt;/p>
&lt;p>Get-DbcConfig | Out-GridView&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/get-config.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/get-config.png"
loading="lazy"
alt="get-config.png"
>&lt;/a>&lt;/p>
&lt;p>You can set the values with the Set-DbcConfig command. It has intellisense to make things easier 🙂 To set the values for the HADR tests&lt;/p>
&lt;p>Set-DbcConfig -Name app.cluster -Value sql1
Set-DbcConfig -Name app.computername -Value sql0,sql1
Set-DbcConfig -Name app.sqlinstance -Value sql0,sql1
Set-DbcConfig -Name domain.name -Value TheBeard.Local
Set-DbcConfig -Name skip.hadr.listener.pingcheck -Value $true&lt;/p>
&lt;ul>
&lt;li>app.cluster requires one of the nodes of the cluster.&lt;/li>
&lt;li>app.computername requires the windows computer names of the machines to run operating system checks against&lt;/li>
&lt;li>app.sqlinstance requires the instance names of the SQL instances that you want to run SQL checks against (These are default instances but it will accept SERVER\INSTANCE)&lt;/li>
&lt;li>domain.name requires the domain name the machines are part of&lt;/li>
&lt;li>skip.hadr.listener.pingcheck is a boolean value which defines whether to skip the listener ping check or not. As this is in Azure I am skipping the check by setting the value to $true&lt;/li>
&lt;li>policy.hadr.tcpport is set to default to 1433 but you can also set this configuration if your SQL is using a different port&lt;/li>
&lt;/ul>
&lt;p>NOTE – You can find all the configuration items that can skip tests by running&lt;/p>
&lt;p>Get-DbcConfig -Name skip*&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/skips.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/skips.png"
loading="lazy"
alt="skips.png"
>&lt;/a>&lt;/p>
&lt;p>Now we have set the configuration (For the HADR checks – There are many more configurations for other checks that you can set) you can run the checks with&lt;/p>
&lt;p>Invoke-DbcCheck -Check HADR&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/check-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/check-results.png"
loading="lazy"
alt="check results.png"
>&lt;/a>&lt;/p>
&lt;p>This runs the following checks&lt;/p>
&lt;ul>
&lt;li>Each node on the cluster should be up&lt;/li>
&lt;li>Each resource on the cluster should be online&lt;/li>
&lt;li>Each SQL instance should be enabled for Always On&lt;/li>
&lt;li>Connection check for the listener and each node
&lt;ul>
&lt;li>Should be pingable (unless skip.hadr.listener.pingcheck is set to true)&lt;/li>
&lt;li>Should be able to run SQL commands&lt;/li>
&lt;li>Should be the correct domain name&lt;/li>
&lt;li>Should be using the correct tcpport&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Each replica should not be in unknown state&lt;/li>
&lt;li>Each synchronous replica should be synchronised&lt;/li>
&lt;li>Each asynchronous replica should be synchonising&lt;/li>
&lt;li>Each database should be synchronised (or synchronising) on each replica&lt;/li>
&lt;li>Each database should be failover ready on each replica&lt;/li>
&lt;li>Each database should be joined to the availability group on each replica&lt;/li>
&lt;li>Each database should not be suspended on each replica&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event running&lt;/li>
&lt;li>Each node should have the AlwaysOn_Health extended event set to auto start&lt;/li>
&lt;/ul>
&lt;p>(Apologies folk over the pond, I use the Queens English 😉 )&lt;/p>
&lt;p>This is good for us to be able to run this check at the command line but we can do more.&lt;/p>
&lt;p>We can export the results and display them with PowerBi. Note we need to add -PassThru so that the results go through the pipeline and that I used -Show Fails so that only the titles of the Describe and Context blocks and any failing tests are displayed to the screen&lt;/p>
&lt;p>Invoke-DbcCheck -Check HADR -Show Fails -PassThru | Update-DbcPowerBiDataSource -Environment HADR-Test
Start-DbcPowerBi&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/results.png"
loading="lazy"
alt="results.png"
>&lt;/a>&lt;/p>
&lt;p>This will create a file at C:\Windows\Temp\dbachecks and open the PowerBi report. You will need to refresh the data in the report and then you will see&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/dbachecks.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/dbachecks.png"
loading="lazy"
alt="dbachecks.png"
>&lt;/a>&lt;/p>
&lt;p>Excellent, everything passed 🙂&lt;/p>
&lt;h2 id="saving-configuration-for-reuse">Saving Configuration for reuse&lt;/h2>
&lt;p>We can save our configuration using Export-DbcConfig which will export the configuration to a json file&lt;/p>
&lt;p>Export-DbcConfig -Path Git:\PesterTests\MyHADRTestsForProd.json&lt;/p>
&lt;p>so that we can run this particular set of tests with this comfiguration by importing the configuration using Import-DbcConfig&lt;/p>
&lt;p>Import-DbcConfig -Path -Path Git:\PesterTests\MyHADRTestsForProd.json
Invoke-DbcCheck -Check HADR&lt;/p>
&lt;p>In this way you can set up different check configurations for different use cases. This also enables you to make use of the checks in your CI/CD process. For example, I have a GitHub repository for creating a domain, a cluster and a SQL 2017 availability group using VSTS. I have saved a dbachecks configuration to my repository and as part of my build I can import that configuration, run the checks and output them to XML for consumption by the publish test results task of VSTS&lt;/p>
&lt;p>After copying the configuration to the machine, I run&lt;/p>
&lt;p>Import-Dbcconfig -Path C:\Windows\Temp\FirstBuild.json
Invoke-DbcCheck-AllChecks -OutputFile PesterTestResultsdbachecks.xml -OutputFormat NUnitXml&lt;/p>
&lt;p>in my build step and then use the publish test results task and VSTS does the rest 🙂&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/04/VSTS-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/04/VSTS-results.png"
loading="lazy"
alt="VSTS results.png"
>&lt;/a>&lt;/p></description></item><item><title>Easily Splatting PowerShell with VS Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/easily-splatting-powershell-with-vs-code/</link><pubDate>Sun, 11 Mar 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/easily-splatting-powershell-with-vs-code/</guid><description>&lt;img src="https://pbs.twimg.com/media/DX8UjepX0AYnDMS?format=jpg&name=large" alt="Featured image of post Easily Splatting PowerShell with VS Code" />&lt;p>So I always like to show splatting PowerShell commands when I am presenting sessions or workshops and realised that I had not really blogged about it. (This blog is for &lt;a class="link" href="https://twitter.com/dbafromthecold" target="_blank" rel="noopener"
>@dbafromthecold&lt;/a> who asked me to 🙂 )&lt;/p>
&lt;h2 id="what-is-splatting">What is Splatting?&lt;/h2>
&lt;p>Well you will know that when you call a PowerShell function you can use intellisense to get the parameters and sometimes the parameter values as well. This can leave you with a command that looks like this on the screen&lt;/p>
&lt;pre>&lt;code>Start-DbaMigration -Source $Source -Destination $Destination -BackupRestore -NetworkShare $Share -WithReplace -ReuseSourceFolderStructure -IncludeSupportDbs -NoAgentServer -NoAudits -NoResourceGovernor -NoSaRename -NoBackupDevices
&lt;/code>&lt;/pre>
&lt;p>It goes on and on and on and while it is easy to type once, it is not so easy to see which values have been chosen. It is also not so easy to change the values.&lt;/p>
&lt;p>By Splatting the parameters it makes it much easier to read and also to alter. So instead of the above you can have&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$startDbaMigrationSplat = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Source = $Source
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NetworkShare = $Share
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoAgentServer = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoResourceGovernor = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WithReplace = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ReuseSourceFolderStructure = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Destination = $Destination
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoAudits = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BackupRestore = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoSaRename = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IncludeSupportDbs = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoBackupDevices = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbaMigration @startDbaMigrationSplat
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is much easier on the eye, but if you dont know what the parameters are (and are too lazy to use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/get-help?view=powershell-6" target="_blank" rel="noopener"
>Get-Help&lt;/a> – Hint You should always use &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.core/get-help?view=powershell-6" target="_blank" rel="noopener"
>Get-Help&lt;/a> ) or like the convenience and efficiency of using the intellisense, this might feel like a backward step that slows your productivity in the cause of easy on the eye code.&lt;/p>
&lt;p>Enter &lt;a class="link" href="https://github.com/SeeminglyScience/EditorServicesCommandSuite" target="_blank" rel="noopener"
>EditorServicesCommandSuite&lt;/a> by SeeminglyScience for VS Code. Amongst the things it makes available to you is easy splatting and people are always impressed when I show it&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>You can install it from the PowerShell Gallery like all good modules using&lt;/p>
&lt;pre>&lt;code>Install-Module EditorServicesCommandSuite -Scope CurrentUser
&lt;/code>&lt;/pre>
&lt;p>and then add it to your VSCode PowerShell profile usually found at &lt;code>C:\Users\USERNAME\Documents\WindowsPowerShell\Microsoft.VSCode_profile.ps1&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\# Place this in your VSCode profile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module EditorServicesCommandSuite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-EditorCommand -Module EditorServicesCommandSuite
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and now creating a splat is as easy as this.&lt;/p>
&lt;p>Write the command, leave the cursor on a parameter, hit F1 – Choose PowerShell : Show Additional Commands (or use a keyboard shortcut) type splat press enter. Done 🙂&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>So very easy 🙂&lt;/p>
&lt;p>Happy Splatting 🙂&lt;/p></description></item><item><title>Announcing dbachecks – Configurable PowerShell Validation For Your SQL Instances</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-dbachecks-configurable-powershell-validation-for-your-sql-instances/</link><pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-dbachecks-configurable-powershell-validation-for-your-sql-instances/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/09-PowerBi.png" alt="Featured image of post Announcing dbachecks – Configurable PowerShell Validation For Your SQL Instances" />&lt;p>For the last couple of months members of the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> team have been working on a new PowerShell module called &lt;a class="link" href="http://dbachecks.io" target="_blank" rel="noopener"
>dbachecks&lt;/a>. This open source PowerShell module will enable you to validate your SQL Instances. Today it is released for you all to start to use 🙂&lt;/p>
&lt;h2 id="validate-your-sql-instances">Validate Your SQL Instances?&lt;/h2>
&lt;p>What do I mean by validate your SQL Instances? You want to know if your SQL Instances are (still) set up in the way that you want them to be or that you have not missed any configurations when setting them up. With dbachecks you can use any or all of the 80 checks to ensure one or many SQL Instances are as you want them to be. Using Pester, dbachecks will validate your SQL Instance(s) against default settings or ones that you configure yourself.&lt;/p>
&lt;h2 id="installation">Installation&lt;/h2>
&lt;p>Installation is via the PowerShell Gallery. You will need to open PowerShell on a machine connected to the internet and run&lt;/p>
&lt;p>Install-Module dbachecks&lt;/p>
&lt;p>If you are not running your process as admin or you only want (or are able) to install for your own user account you will need to&lt;/p>
&lt;p>Install-Module -Scope CurrentUser&lt;/p>
&lt;p>This will also install the PSFramework module used for configuration (and other things beneath the hood) and the latest version (4.2.0 – released on Sunday!) of Pester&lt;/p>
&lt;p>Once you have installed the module you can see the commands available by running&lt;/p>
&lt;p>Get-Command -Module dbachecks&lt;/p>
&lt;p>To be able to use these (and any PowerShell) commands, your first step should always be Get-Help&lt;/p>
&lt;p>Get-Help Send-DbcMailMessage&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/01a-get-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01a-get-help.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="80-checks">80 Checks&lt;/h2>
&lt;p>At the time of release, dbachecks has 80 checks. You can see all of the checks by running&lt;/p>
&lt;p>Get-DbcCheck&lt;/p>
&lt;p>(Note this has nothing to do with DBCC CheckDb!) Here is the output of&lt;/p>
&lt;p>Get-DbcCheck | Select Group, UniqueTag&lt;/p>
&lt;p>so you can see the current checks&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Group&lt;/strong>&lt;/th>
&lt;th>&lt;strong>UniqueTag&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>AgentServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>DbaOperator&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>FailsafeOperator&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>DatabaseMailProfile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Agent&lt;/strong>&lt;/td>
&lt;td>FailedJob&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatabaseCollation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>SuspectPage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>TestLastBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>TestLastBackupVerifyOnly&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>ValidDatabaseOwner&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>InvalidDatabaseOwner&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastGoodCheckDb&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>IdentityUsage&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>RecoveryModel&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DuplicateIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>UnusedIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DisabledIndex&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatabaseGrowthEvent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>PageVerify&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoClose&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoShrink&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastFullBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastDiffBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LastLogBackup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>VirtualLogFile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LogfileCount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>LogfileSize&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>FileGroupBalanced&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoCreateStatistics&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoUpdateStatistics&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AutoUpdateStatisticsAsynchronously&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>DatafileAutoGrowthType&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>Trustworthy&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>OrphanedUser&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>PseudoSimple&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Database&lt;/strong>&lt;/td>
&lt;td>AdHocWorkloads&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Domain&lt;/strong>&lt;/td>
&lt;td>DomainName&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Domain&lt;/strong>&lt;/td>
&lt;td>OrganizationalUnit&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>ClusterHealth&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>ClusterServerHealth&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>HADR&lt;/strong>&lt;/td>
&lt;td>System.Object[]&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SqlEngineServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SqlBrowserServiceAccount&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>TempDbConfiguration&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>AdHocWorkload&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>BackupPathAccess&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>DAC&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>NetworkLatency&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>LinkedServerConnection&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>MaxMemory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>OrphanedFile&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>ServerNameMatch&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>MemoryDump&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SupportedBuild&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>SaRenamed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>DefaultBackupCompression&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionStopped&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionRunning&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>XESessionRunningAllowed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>OLEAutomation&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Instance&lt;/strong>&lt;/td>
&lt;td>WhoIsActiveInstalled&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>LogShipping&lt;/strong>&lt;/td>
&lt;td>LogShippingPrimary&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>LogShipping&lt;/strong>&lt;/td>
&lt;td>LogShippingSecondary&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>PowerPlan&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>InstanceConnection&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>SPN&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>DiskCapacity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>Server&lt;/strong>&lt;/td>
&lt;td>PingComputer&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>SystemFull&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserFull&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserDiff&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserLog&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>CommandLog&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>SystemIntegrityCheck&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserIntegrityCheck&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>UserIndexOptimize&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>OutputFileCleanup&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>DeleteBackupHistory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>MaintenancePlan&lt;/strong>&lt;/td>
&lt;td>PurgeJobHistory&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="108-configurations">108 Configurations&lt;/h2>
&lt;p>One of the things I have been talking about in my presentation “Green is Good Red is Bad” is configuring Pester checks so that you do not have to keep writing new tests for the same thing but with different values.&lt;/p>
&lt;p>For example, a different user for a database owner. The code to write the test for the database owner is the same but the value might be different for different applications, environments, clients, teams, domains etc. I gave a couple of different methods for achieving this.&lt;/p>
&lt;p>With dbachecks we have made this much simpler enabling you to set configuration items at run-time or for your session and enabling you to export and import them so you can create different configs for different use cases&lt;/p>
&lt;p>There are 108 configuration items at present. You can see the current configuration by running&lt;/p>
&lt;p>Get-DbcConfig&lt;/p>
&lt;p>which will show you the name of the config, the value it is currently set and the description&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/01-configs.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-configs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can see all of the configs and their descriptions here&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Name&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>agent.databasemailprofile&lt;/strong>&lt;/td>
&lt;td>Name of the Database Mail Profile in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatoremail&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatorname&lt;/strong>&lt;/td>
&lt;td>Name of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.failsafeoperator&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.checkrepos&lt;/strong>&lt;/td>
&lt;td>Where Pester tests/checks are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.computername&lt;/strong>&lt;/td>
&lt;td>List of Windows Servers that Windows-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.localapp&lt;/strong>&lt;/td>
&lt;td>Persisted files live here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.maildirectory&lt;/strong>&lt;/td>
&lt;td>Files for mail are stored here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlcredential&lt;/strong>&lt;/td>
&lt;td>The universal SQL credential if Trusted/Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlinstance&lt;/strong>&lt;/td>
&lt;td>List of SQL Server instances that SQL-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.wincredential&lt;/strong>&lt;/td>
&lt;td>The universal Windows if default Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>command.invokedbccheck.excludecheck&lt;/strong>&lt;/td>
&lt;td>Invoke-DbcCheck: The checks that should be skipped by default.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.domaincontroller&lt;/strong>&lt;/td>
&lt;td>The domain controller to process your requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.name&lt;/strong>&lt;/td>
&lt;td>The Active Directory domain that your server is a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.organizationalunit&lt;/strong>&lt;/td>
&lt;td>The OU that your server should be a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.failurethreshhold&lt;/strong>&lt;/td>
&lt;td>Number of errors that must be present to generate an email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.from&lt;/strong>&lt;/td>
&lt;td>Email address the email reports should come from&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.smtpserver&lt;/strong>&lt;/td>
&lt;td>Store the name of the smtp server to send email reports&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.subject&lt;/strong>&lt;/td>
&lt;td>Subject line of the email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.to&lt;/strong>&lt;/td>
&lt;td>Email address to send the report to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.datadir&lt;/strong>&lt;/td>
&lt;td>Destination server data directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.defaultbackupcompreesion&lt;/strong>&lt;/td>
&lt;td>Default Backup Compression check should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.diffmaxhours&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of hours before Diff Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.fullmaxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before Full Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logdir&lt;/strong>&lt;/td>
&lt;td>Destination server log directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logmaxminutes&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of minutes before Log Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.newdbgraceperiod&lt;/strong>&lt;/td>
&lt;td>The number of hours a newly created database is allowed to not have backups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.testserver&lt;/strong>&lt;/td>
&lt;td>Destination server for backuptests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.build.warningwindow&lt;/strong>&lt;/td>
&lt;td>The number of months prior to a build being unsupported that you want warning about&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.authscheme&lt;/strong>&lt;/td>
&lt;td>Auth requirement (Kerberos, NTLM, etc)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingcount&lt;/strong>&lt;/td>
&lt;td>Number of times to ping a server to establish average response time&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingmaxms&lt;/strong>&lt;/td>
&lt;td>Maximum response time in ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dacallowed&lt;/strong>&lt;/td>
&lt;td>DAC should be allowed $true or disallowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoclose&lt;/strong>&lt;/td>
&lt;td>Auto Close should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autocreatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Create Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoshrink&lt;/strong>&lt;/td>
&lt;td>Auto Shrink should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatisticsasynchronously&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics Asynchronously should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filebalancetolerance&lt;/strong>&lt;/td>
&lt;td>Percentage for Tolerance for checking for balanced files in a filegroups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthexcludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from the file growth check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthtype&lt;/strong>&lt;/td>
&lt;td>Growth Type should be &amp;lsquo;kb&amp;rsquo; or &amp;lsquo;percent&amp;rsquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthvalue&lt;/strong>&lt;/td>
&lt;td>The auto growth value (in kb) should be equal or higher than this value. Example: A value of 65535 means at least 64MB.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilecount&lt;/strong>&lt;/td>
&lt;td>The number of Log files expected on a database&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizecomparison&lt;/strong>&lt;/td>
&lt;td>How to compare data and log file size, options are maximum or average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizepercentage&lt;/strong>&lt;/td>
&lt;td>Maximum percentage of Data file Size that logfile is allowed to be.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.maxvlf&lt;/strong>&lt;/td>
&lt;td>Max virtual log files&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dbcc.maxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before DBCC CHECKDB is considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.diskspace.percentfree&lt;/strong>&lt;/td>
&lt;td>Percent disk free&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dump.maxcount&lt;/strong>&lt;/td>
&lt;td>Maximum number of expected dumps&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.hadr.tcpport&lt;/strong>&lt;/td>
&lt;td>The TCPPort for the HADR check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.identity.usagepercent&lt;/strong>&lt;/td>
&lt;td>Maxmimum percentage of max of identity column&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from invalid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should not be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.network.latencymaxms&lt;/strong>&lt;/td>
&lt;td>Max network latency average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.database&lt;/strong>&lt;/td>
&lt;td>The database where Ola&amp;rsquo;s maintenance solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.installed&lt;/strong>&lt;/td>
&lt;td>Checks to see if Ola Hallengren solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizeenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizescheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.oleautomation&lt;/strong>&lt;/td>
&lt;td>OLE Automation should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.pageverify&lt;/strong>&lt;/td>
&lt;td>Page verify option should be set to this value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from standard recovery model check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.type&lt;/strong>&lt;/td>
&lt;td>Standard recovery model&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.storage.backuppath&lt;/strong>&lt;/td>
&lt;td>Enables tests to check if servers have access to centralized backup location&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from valid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.whoisactive.database&lt;/strong>&lt;/td>
&lt;td>Which database should contain the sp_WhoIsActive stored procedure&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredstoppedsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should not be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.validrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that can be be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.backup.testing&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run Test-DbaLastBackup by default (it&amp;rsquo;s not read-only)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.ping&lt;/strong>&lt;/td>
&lt;td>Skip the ping check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.remoting&lt;/strong>&lt;/td>
&lt;td>Skip PowerShell remoting check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.filegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.datafilegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.dbcc.datapuritycheck&lt;/strong>&lt;/td>
&lt;td>Skip data purity check in last good dbcc command&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.diffbackuptest&lt;/strong>&lt;/td>
&lt;td>Skip the Differential backup test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logshiptesting&lt;/strong>&lt;/td>
&lt;td>Skip the logshipping test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdb1118&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Trace Flag 1118&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilecount&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Count&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilegrowthpercent&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Growth in Percent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesizemax&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files Max Size&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesonc&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files on C&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="running-a-check">Running A Check&lt;/h2>
&lt;p>You can quickly run a single check by calling Invoke-DbcCheck.&lt;/p>
&lt;p>Invoke-DbcCheck -SqlInstance localhost -Check FailedJob&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/02-failed-jobs.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/02-failed-jobs.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Excellent, my agent jobs have not failed 🙂&lt;/p>
&lt;p>Invoke-DbcCheck -SqlInstance localhost -Check LastGoodCheckDb&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/03-dbcc-check.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/03-dbcc-check.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Thats good, all of my databases have had a successful DBCC CHECKDB within the last 7 days.&lt;/p>
&lt;h2 id="setting-a-configuration">Setting a Configuration&lt;/h2>
&lt;p>To save me from having to specify the instance I want to run my tests against I can set the app.sqlinstance config to the instances I want to check.&lt;/p>
&lt;p>Set-DbcConfig -Name app.sqlinstance -Value localhost, &amp;rsquo;localhost\PROD1&amp;rsquo;&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/04-setting-instances-config.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/04-setting-instances-config.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Then whenever I call Invoke-DbcCheck it will run against those instances for the SQL checks&lt;/p>
&lt;p>So now if I run&lt;/p>
&lt;p>Invoke-DbcCheck -Check LastDiffBackup&lt;/p>
&lt;p>I can see that I dont have a diff backup for the databases on both instances. Better stop writing this and deal with that !!&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/05-last-backup.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/05-last-backup.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>The configurations are stored in the registry but you can export them and then import them for re-use easily. I have written another blog post about that.&lt;/p>
&lt;h2 id="the-show-parameter">The Show Parameter&lt;/h2>
&lt;p>Getting the results of the tests on the screen is cool but if you are running a lot of tests against a lot of instances then you might find that you have 3 failed tests out of 15000! This will mean a lot of scrolling through green text looking for the red text and you may find that your PowerShell buffer doesnt hold all of your test results leaving you very frustrated.&lt;/p>
&lt;p>dbachecks supports the Pester Show parameter enabling you to filter the output of the results to the screen. The available values are Summary, None, Fails, Inconclusive, Passed, Pending and Skipped&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/06-show.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/06-show.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>in my opinion by far the most useful one is Fails as this will show you only the failed tests with the context to enable you to see which tests have failed&lt;/p>
&lt;p>Invoke-DbcCheck -Check Agent -Show Fails&lt;/p>
&lt;p>If we check all of the checks tagged as Agent we can easily see that most passed but The Job That Fails (surprisingly) failed. All of the other tests that were run for the agent service, operators, failsafe operator, database mail and all other agent jobs all passed in the example below&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/07-Jobs-that-filed.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/07-Jobs-that-filed.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;h2 id="test-results-are-for-other-people-as-well">Test Results are for other People as well&lt;/h2>
&lt;p>It is all very well and good being able to run tests and get the results on our screen. It will be very useful for people to be able to validate a new SQL instance for example or run a morning check or the first step of an incident response. But test results are also useful for other people so we need to be able to share them&lt;/p>
&lt;p>We have created a Power Bi Dashboard that comes with the dbachecks module to enable easy sharing of the test results. You can also send the results via email using Send-DbcMailMessage. we have an &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks/issues/270" target="_blank" rel="noopener"
>open issue for putting them into a database&lt;/a> that we would love you to help resolve.&lt;/p>
&lt;p>To get the results into PowerBi you can run&lt;/p>
&lt;p>Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Production&lt;/p>
&lt;p>This will run all of the dbachecks using your configuration for your Production environment, output only the failed tests to the screen and save the results in your windows\temp\dbachecks folder with a suffix of Production&lt;/p>
&lt;p>If you then used a different configuration for your development environment and ran&lt;/p>
&lt;p>Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Development&lt;/p>
&lt;p>it will run all of the dbachecks using your configuration for your Development environment, output only the failed tests to the screen and save the results in your windows\temp\dbachecks folder with a suffix of Development and you would end up with two files in the folder&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/08-test-results.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/08-test-results.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>You can then simply run&lt;/p>
&lt;p>Start-DbcPowerBi&lt;/p>
&lt;p>and as long as you have the (free) Powerbi Desktop then you will see this. You will need to refresh the data to get your test results&lt;/p>
&lt;p>&lt;a class="link" href="assets/uploads/2018/02/09-PowerBi.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/09-PowerBi.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Of course it is Powerbi so you can publish this report. Here it is so that you can click around and see what it looks like&lt;/p>
&lt;h2 id="its-open-source--we-want-your-ideas-issues-new-code">It’s Open Source – We Want Your Ideas, Issues, New Code&lt;/h2>
&lt;p>dbachecks is open-source &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks" target="_blank" rel="noopener"
>available on GitHub for anyone to contribute&lt;/a>&lt;/p>
&lt;p>We would love you to contribute. Please open issues for new tests, enhancements, bugs. Please fork the repository and add code to improve the module. please give feedback to make this module even more useful&lt;/p>
&lt;p>You can also come in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> and join the dbachecks channel and get advice, make comments or just join in the conversation&lt;/p>
&lt;h2 id="further-reading">Further Reading&lt;/h2>
&lt;p>There are many more introduction blog posts covering different areas at&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="https://dbachecks.io/install" target="_blank" rel="noopener"
>dbachecks.io/install&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="thank-you">Thank You&lt;/h2>
&lt;p>I want to say thank you to all of the people who have enabled dbachecks to get this far. These wonderful people have used their own time to ensure that you have a useful tool available to you for free&lt;/p>
&lt;p>Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a>&lt;/p>
&lt;p>Fred Weinmann &lt;a class="link" href="https://twitter.com/FredWeinmann" target="_blank" rel="noopener"
>@FredWeinmann&lt;/a>&lt;/p>
&lt;p>Cláudio Silva &lt;a class="link" href="https://twitter.com/ClaudioESSilva" target="_blank" rel="noopener"
>@ClaudioESSilva&lt;/a>&lt;/p>
&lt;p>Stuart Moore &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a>&lt;/p>
&lt;p>Shawn Melton &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>&lt;/p>
&lt;p>Garry Bargsley &lt;a class="link" href="https://twitter.com/gbargsley" target="_blank" rel="noopener"
>@gbargsley&lt;/a>&lt;/p>
&lt;p>Stephen Bennett &lt;a class="link" href="https://twitter.com/staggerlee011" target="_blank" rel="noopener"
>@staggerlee011&lt;/a>&lt;/p>
&lt;p>Sander Stad &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>@SQLStad&lt;/a>&lt;/p>
&lt;p>Jess Pomfret &lt;a class="link" href="https://twitter.com/jpomfret" target="_blank" rel="noopener"
>@jpomfret&lt;/a>&lt;/p>
&lt;p>Jason Squires &lt;a class="link" href="https://twitter.com/js0505" target="_blank" rel="noopener"
>@js0505&lt;/a>&lt;/p>
&lt;p>Shane O’Neill &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>@SOZDBA&lt;/a>&lt;/p>
&lt;p>Tony Wilhelm &lt;a class="link" href="https://twitter.com/TonyWSQL" target="_blank" rel="noopener"
>@TonyWSQL&lt;/a>&lt;/p>
&lt;p>and all of the other people who have contributed in the dbachecks Slack channel&lt;/p></description></item><item><title>dbachecks – Configuration Deep Dive</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-configuration-deep-dive/</link><pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbachecks-configuration-deep-dive/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/03-autocomplete.png" alt="Featured image of post dbachecks – Configuration Deep Dive" />&lt;p>Today is the day that &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/?p=8997" >we have announced dbachecks&lt;/a>  a PowerShell module enabling you to validate your SQL Instances. You can read more about it &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/?p=8997" >here where you can learn how to install it and see some simple use cases&lt;/a>&lt;/p>
&lt;h2 id="108-configurations">108 Configurations&lt;/h2>
&lt;p>One of the things I have been talking about &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/write-your-first-pester-test-today/" >in my presentation “Green is Good Red is Bad”&lt;/a> is configuring Pester checks so that you do not have to keep writing new tests for the same thing but with different values.&lt;/p>
&lt;p>For example, a different user for a database owner. The code to write the test for the database owner is the same but the value might be different for different applications, environments, clients, teams, domains etc. I gave a couple of different methods for achieving this.&lt;/p>
&lt;p>With dbachecks we have made this much simpler enabling you to set configuration items at run-time or for your session and enabling you to export and import them so you can create different configs for different use cases&lt;/p>
&lt;p>There are 108 configuration items at present. You can see the current configuration by running&lt;/p>
&lt;p>Get-DbcConfig&lt;/p>
&lt;p>which will show you the name of the config, the value it is currently set and the description
&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-configs.png"
loading="lazy"
>&lt;/p>
&lt;p>You can see all of the configs and their descriptions here&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;strong>Name&lt;/strong>&lt;/th>
&lt;th>&lt;strong>Description&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>&lt;strong>agent.databasemailprofile&lt;/strong>&lt;/td>
&lt;td>Name of the Database Mail Profile in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatoremail&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.dbaoperatorname&lt;/strong>&lt;/td>
&lt;td>Name of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>agent.failsafeoperator&lt;/strong>&lt;/td>
&lt;td>Email address of the DBA Operator in SQL Agent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.checkrepos&lt;/strong>&lt;/td>
&lt;td>Where Pester tests/checks are stored&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.computername&lt;/strong>&lt;/td>
&lt;td>List of Windows Servers that Windows-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.localapp&lt;/strong>&lt;/td>
&lt;td>Persisted files live here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.maildirectory&lt;/strong>&lt;/td>
&lt;td>Files for mail are stored here&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlcredential&lt;/strong>&lt;/td>
&lt;td>The universal SQL credential if Trusted/Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.sqlinstance&lt;/strong>&lt;/td>
&lt;td>List of SQL Server instances that SQL-based tests will run against&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>app.wincredential&lt;/strong>&lt;/td>
&lt;td>The universal Windows if default Windows Authentication is not used&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>command.invokedbccheck.excludecheck&lt;/strong>&lt;/td>
&lt;td>Invoke-DbcCheck: The checks that should be skipped by default.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.domaincontroller&lt;/strong>&lt;/td>
&lt;td>The domain controller to process your requests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.name&lt;/strong>&lt;/td>
&lt;td>The Active Directory domain that your server is a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>domain.organizationalunit&lt;/strong>&lt;/td>
&lt;td>The OU that your server should be a part of&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.failurethreshhold&lt;/strong>&lt;/td>
&lt;td>Number of errors that must be present to generate an email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.from&lt;/strong>&lt;/td>
&lt;td>Email address the email reports should come from&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.smtpserver&lt;/strong>&lt;/td>
&lt;td>Store the name of the smtp server to send email reports&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.subject&lt;/strong>&lt;/td>
&lt;td>Subject line of the email report&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>mail.to&lt;/strong>&lt;/td>
&lt;td>Email address to send the report to&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.datadir&lt;/strong>&lt;/td>
&lt;td>Destination server data directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.defaultbackupcompreesion&lt;/strong>&lt;/td>
&lt;td>Default Backup Compression check should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.diffmaxhours&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of hours before Diff Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.fullmaxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before Full Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logdir&lt;/strong>&lt;/td>
&lt;td>Destination server log directory&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.logmaxminutes&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of minutes before Log Backups are considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.newdbgraceperiod&lt;/strong>&lt;/td>
&lt;td>The number of hours a newly created database is allowed to not have backups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.backup.testserver&lt;/strong>&lt;/td>
&lt;td>Destination server for backuptests&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.build.warningwindow&lt;/strong>&lt;/td>
&lt;td>The number of months prior to a build being unsupported that you want warning about&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.authscheme&lt;/strong>&lt;/td>
&lt;td>Auth requirement (Kerberos, NTLM, etc)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingcount&lt;/strong>&lt;/td>
&lt;td>Number of times to ping a server to establish average response time&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.connection.pingmaxms&lt;/strong>&lt;/td>
&lt;td>Maximum response time in ms&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dacallowed&lt;/strong>&lt;/td>
&lt;td>DAC should be allowed $true or disallowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoclose&lt;/strong>&lt;/td>
&lt;td>Auto Close should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autocreatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Create Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoshrink&lt;/strong>&lt;/td>
&lt;td>Auto Shrink should be allowed $true or dissalowed $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatistics&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.autoupdatestatisticsasynchronously&lt;/strong>&lt;/td>
&lt;td>Auto Update Statistics Asynchronously should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filebalancetolerance&lt;/strong>&lt;/td>
&lt;td>Percentage for Tolerance for checking for balanced files in a filegroups&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthexcludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from the file growth check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthtype&lt;/strong>&lt;/td>
&lt;td>Growth Type should be &amp;lsquo;kb&amp;rsquo; or &amp;lsquo;percent&amp;rsquo;&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.filegrowthvalue&lt;/strong>&lt;/td>
&lt;td>The auto growth value (in kb) should be equal or higher than this value. Example: A value of 65535 means at least 64MB.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilecount&lt;/strong>&lt;/td>
&lt;td>The number of Log files expected on a database&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizecomparison&lt;/strong>&lt;/td>
&lt;td>How to compare data and log file size, options are maximum or average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.logfilesizepercentage&lt;/strong>&lt;/td>
&lt;td>Maximum percentage of Data file Size that logfile is allowed to be.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.database.maxvlf&lt;/strong>&lt;/td>
&lt;td>Max virtual log files&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dbcc.maxdays&lt;/strong>&lt;/td>
&lt;td>Maxmimum number of days before DBCC CHECKDB is considered outdated&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.diskspace.percentfree&lt;/strong>&lt;/td>
&lt;td>Percent disk free&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.dump.maxcount&lt;/strong>&lt;/td>
&lt;td>Maximum number of expected dumps&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.hadr.tcpport&lt;/strong>&lt;/td>
&lt;td>The TCPPort for the HADR check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.identity.usagepercent&lt;/strong>&lt;/td>
&lt;td>Maxmimum percentage of max of identity column&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from invalid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.invaliddbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should not be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.network.latencymaxms&lt;/strong>&lt;/td>
&lt;td>Max network latency average&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.commandlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s CommandLog Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.database&lt;/strong>&lt;/td>
&lt;td>The database where Ola&amp;rsquo;s maintenance solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.deletebackuphistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Delete Backup History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.installed&lt;/strong>&lt;/td>
&lt;td>Checks to see if Ola Hallengren solution is installed&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.outputfilecleanupscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Output File Cleanup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.purgejobhistoryscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Purge Job History should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full System Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.systemintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s System Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userdiffscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Diff User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userfullscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Full User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizeenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userindexoptimizescheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Index Optimization should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userintegritycheckscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s User Database Integrity should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogenabled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogretention&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup retention number of hours&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.ola.userlogscheduled&lt;/strong>&lt;/td>
&lt;td>Ola&amp;rsquo;s Log User Database Backup should be scheduled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.oleautomation&lt;/strong>&lt;/td>
&lt;td>OLE Automation should be enabled $true or disabled $false&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.pageverify&lt;/strong>&lt;/td>
&lt;td>Page verify option should be set to this value&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from standard recovery model check&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.recoverymodel.type&lt;/strong>&lt;/td>
&lt;td>Standard recovery model&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.storage.backuppath&lt;/strong>&lt;/td>
&lt;td>Enables tests to check if servers have access to centralized backup location&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.excludedb&lt;/strong>&lt;/td>
&lt;td>Databases to exclude from valid dbowner checks&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.validdbowner.name&lt;/strong>&lt;/td>
&lt;td>The database owner account should be this user&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.whoisactive.database&lt;/strong>&lt;/td>
&lt;td>Which database should contain the sp_WhoIsActive stored procedure&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.requiredstoppedsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that should not be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>policy.xevent.validrunningsession&lt;/strong>&lt;/td>
&lt;td>List of XE Sessions that can be be running.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.backup.testing&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run Test-DbaLastBackup by default (it&amp;rsquo;s not read-only)&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.ping&lt;/strong>&lt;/td>
&lt;td>Skip the ping check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.connection.remoting&lt;/strong>&lt;/td>
&lt;td>Skip PowerShell remoting check for connectivity&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.filegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.database.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.datafilegrowthdisabled&lt;/strong>&lt;/td>
&lt;td>Skip validation of datafiles which have growth value equal to zero.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.dbcc.datapuritycheck&lt;/strong>&lt;/td>
&lt;td>Skip data purity check in last good dbcc command&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.diffbackuptest&lt;/strong>&lt;/td>
&lt;td>Skip the Differential backup test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logfilecounttest&lt;/strong>&lt;/td>
&lt;td>Skip the logfilecount test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.logshiptesting&lt;/strong>&lt;/td>
&lt;td>Skip the logshipping test&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdb1118&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Trace Flag 1118&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilecount&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Count&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilegrowthpercent&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database File Growth in Percent&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesizemax&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files Max Size&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;strong>skip.tempdbfilesonc&lt;/strong>&lt;/td>
&lt;td>Don&amp;rsquo;t run test for Temp Database Files on C&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>So there are a lot of configurations that you can use. A lot are already set by default but all of them you can configure for the values that you need for your own estate.&lt;/p>
&lt;p>The configurations are stored in the registry at HKCU:\Software\Microsoft\WindowsPowerShell\PSFramework\&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/01-registry.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="first-configurations">First Configurations&lt;/h2>
&lt;p>First I would run this so that you can see all of the configs in a seperate window (note this does not work on PowerShell v6)&lt;/p>
&lt;pre>&lt;code>Get-DbcConfig | Out-GridView
&lt;/code>&lt;/pre>
&lt;p>Lets start with the first configurations that you will want to set. This should be the Instances and the Hosts that you want to check&lt;/p>
&lt;p>You can get the value of the configuration item using&lt;/p>
&lt;pre>&lt;code>Get-DbcConfigValue -Name app.sqlinstance
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/02-config.png"
loading="lazy"
>&lt;/p>
&lt;p>as you can see in the image, nothing is returned so we have no instances configured at present. We have added tab completion to the name parameter so that you can easily find the right one&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/03-autocomplete.png"
loading="lazy"
>&lt;/p>
&lt;p>If you want to look at more information about the configuration item you can use&lt;/p>
&lt;pre>&lt;code>Get-DbcConfig -Name app.sqlinstance
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/04-config.png"
loading="lazy"
>&lt;/p>
&lt;p>which shows you the name, current value and the description&lt;/p>
&lt;p>So lets set our first configuration for our SQL instance to localhost. I have included a video so you can see the auto-complete in action as well&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name app.sqlinstance localhost
&lt;/code>&lt;/pre>
&lt;p>This configuration will be used for any SQL based checks but not for any windows based ones like Services, PowerPlan, SPN, DiskSpace, Cluster so lets set the app.computername configuration as well&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/05-windows-config.png"
loading="lazy"
>&lt;/p>
&lt;p>This means that when we run invoke-DbcCheck with AllChecks or by specifying a check, it will run against the local machine and default instance unless we specify a sqlinstance when calling Invoke-DbcCheck. So the code below will not use the configuration for app.sqlinstance.&lt;/p>
&lt;pre>&lt;code>Invoke-DbcCheck -SqlInstance TheBeard
&lt;/code>&lt;/pre>
&lt;h2 id="exclude-a-check">Exclude a Check&lt;/h2>
&lt;p>You can exclude a check using the -ExcludeCheck parameter of Invoke-DbcConfig. In the example below I am running all of the Server checks but excluding the SPN as we are not on a domain&lt;/p>
&lt;pre>&lt;code>Invoke-DbcCheck -Check Server -ExcludeCheck SPN
&lt;/code>&lt;/pre>
&lt;p>There is a configuration setting to exclude checks as well. (Be careful this will exclude them even if you specifically specify a check using Invoke-DbcCheck but we do give you a warning!)&lt;/p>
&lt;p>So now I can run&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value SPN
Invoke-DbcCheck -Check Server
&lt;/code>&lt;/pre>
&lt;p>and all of the server checks except the SPN check will run against the local machine and the default instance that I have set in the config&lt;/p>
&lt;h2 id="creating-an-environment-config-and-exporting-it-to-use-any-time-we-like">Creating an environment config and exporting it to use any time we like&lt;/h2>
&lt;p>So lets make this a lot more useful. Lets create a configuration for our production environment and save it to disk (or even source control it!) so that we can use it again and again. We can also then pass it to other members of our team or even embed it in an automated process or our CI/CD system&lt;/p>
&lt;p>Lets build up a configuration for a number of tests for my “production” environment. I will not explain them all here but let you read through the code and the comments to see what has been set. You will see that some of them are due to me running the test on a single machine with one drive.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># The computername we will be testing
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.computername -Value localhost
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The Instances we want to test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlinstance -Value &amp;#39;localhost&amp;#39; ,&amp;#39;localhost\PROD1&amp;#39;,&amp;#39;localhost\PROD2&amp;#39;, &amp;#39;localhost\PROD3&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The database owner we expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.validdbowner.name -Value &amp;#39;dbachecksdemo\dbachecks&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># the database owner we do NOT expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.invaliddbowner.name -Value &amp;#39;sa&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should backups be compressed by default?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.defaultbackupcompreesion -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Do we allow DAC connections?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.dacallowed -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What recovery model should we have?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.type -value FULL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth type be?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthtype -Value kb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What authentication scheme are we expecting?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.connection.authscheme -Value &amp;#39;NTLM&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatorname -Value &amp;#39;DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Agent Operator email should be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.dbaoperatoremail -Value &amp;#39;DBATeam@TheBeard.Local&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which failsafe operator shoudl be defined?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name agent.failsafeoperator -Value &amp;#39;DBA Team&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is the whoisactive stored procedure?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.whoisactive.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a Full backup?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.fullmaxdays -Value 7
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a DIFF backup (in hours) ?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.diffmaxhours -Value 26
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum time since I took a log backup (in minutes)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.logmaxminutes -Value 30
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my domain name?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;WORKGROUP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is my Ola database?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.ola.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which database should not be checked for recovery model
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.excludedb -Value &amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;tempdb&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my SQL Credential
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlcredential -Value $null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files on c?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilesonc -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files count?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilecount -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Checks should be excluded?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value LogShipping,ExtendedEvent, HADR, PseudoSimple,spn
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># How many months before a build is unsupported do I want to fail the test?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.build.warningwindow -Value 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-Dbcconfig | ogv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>When I run this I get&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/08-configuration.png"
loading="lazy"
>&lt;/p>
&lt;p>I can then export this to disk (to store in source control) using&lt;/p>
&lt;pre>&lt;code>Export-DbcConfig -Path C:\Users\dbachecks\Desktop\production_config.json
&lt;/code>&lt;/pre>
&lt;p>and I have a configuration file&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/09-configuration-json.png"
loading="lazy"
>&lt;/p>
&lt;p>which I can use any time to set the configuration for dbachecks using the Import-DbcConfig command (But this doesn’t work in VS Codes integrated terminal – which occasionally does odd things, this appears to be one of them)&lt;/p>
&lt;pre>&lt;code>Import-DbcConfig -Path C:\Users\dbachecks\Desktop\production_config.json
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/10-import-configuration.png"
loading="lazy"
>&lt;/p>
&lt;p>So I can import this configuration and run my checks with it any time I like. This means that I can create many different test configurations for my many different environment or estate configurations.&lt;/p>
&lt;p>Yes, I know “good/best practice” says we should use the same configuration for all of our instances but we know that isn’t true. We have instances that were set up 15 years ago that are still in production. We have instances from the companies our organisation has bought over the years that were set up by system administrators. We have instances that were set up by shadow IT and now we have to support but cant change.&lt;/p>
&lt;p>As well as those though, we also have different environments. Our development or test environment will have different requirements to our production environments.&lt;/p>
&lt;p>In this hypothetical situation the four instances for four different applications have 4 development containers which are connected to using SQL Authentication. We will need a different configuration.&lt;/p>
&lt;h2 id="sql-authentication">SQL Authentication&lt;/h2>
&lt;p>We can set up SQL Authentication for connecting to our SQL Instances using the app.sqlcredential configuration. this is going to hold a PSCredential object for SQL Authenticated connection to your instance. If this is set the checks will always try to use it. Yes this means that the same username and password is being used for each connection. No there is currently no way to choose which instances use it and which don’t. This may be a limitation but as you will see further down you can still do this with different configurations&lt;/p>
&lt;p>To set the  SQL Authentication run&lt;/p>
&lt;pre>&lt;code>Set-DbcConfig -Name app.sqlcredential -Value (Get-Credential)
&lt;/code>&lt;/pre>
&lt;p>This will give a prompt for you to enter the credential&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/assets/uploads/2018/02/11-prompt-for-credenial.png"
loading="lazy"
>&lt;/p>
&lt;h2 id="development-environment-configuration">Development Environment Configuration&lt;/h2>
&lt;p>So now we know how to set a SQL Authentication configuration we can create our development environment configuration like so. As you can see below the values are different for the checks and more checks have been skipped. I wont explain it all, if it doesn’t make sense ask a question in the comments or in the dbachecks in SQL Server Community Slack&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#region Dev Config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The Instances we want to test
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlinstance -Value &amp;#39;localhost,1401&amp;#39; ,&amp;#39;localhost,1402&amp;#39;,&amp;#39;localhost,1403&amp;#39;, &amp;#39;localhost,1404&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my SQL Credential
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name app.sqlcredential -Value (Get-Credential)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># The database owner we expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.validdbowner.name -Value &amp;#39;sa&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What authentication scheme are we expecting?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.connection.authscheme -Value &amp;#39;SQL&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># the database owner we do NOT expect
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.invaliddbowner.name -Value &amp;#39;dbachecksdemo\dbachecks&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should backups be compressed by default?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.backup.defaultbackupcompreesion -Value $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth type be?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthtype -Value kb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What should our database growth value be higher than (Mb)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.database.filegrowthvalue -Value 64
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Do we allow DAC connections?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.dacallowed -Value $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is the maximum latency (ms)?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.network.latencymaxms -Value 100
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What recovery model should we have?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.type -value Simple
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Where is the whoisactive stored procedure?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.whoisactive.database -Value DBAAdmin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># What is my domain name?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name domain.name -Value &amp;#39;WORKGROUP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which database should not be checked for recovery model
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.recoverymodel.excludedb -Value &amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;tempdb&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files on c?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilesonc -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Should I skip the check for temp files count?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name skip.tempdbfilecount -Value $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># How many months before a build is unsupported do I want to fail the test?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name policy.build.warningwindow -Value 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Which Checks should be excluded?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-DbcConfig -Name command.invokedbccheck.excludecheck -Value LogShipping,ExtendedEvent, HADR, SaReNamed, PseudoSimple,spn, DiskSpace, DatabaseCollation,Agent,Backup,UnusedIndex,LogfileCount,FileGroupBalanced,LogfileSize,MaintenanceSolution,ServerNameMatch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Export-DbcConfig -Path C:\Users\dbachecks\Desktop\development_config.json
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="using-the-different-configurations">Using The Different Configurations&lt;/h2>
&lt;p>Now I have two configurations, one for my Production Environment and one for my development environment. I can run my checks whenever I like (perhaps you will automate this in some way)&lt;/p>
&lt;ul>
&lt;li>Import the production configuration&lt;/li>
&lt;li>Run my tests with that configuration and create a json file for my Power Bi labelled production&lt;/li>
&lt;li>Import the development configuration (and enter the SQL authentication credential)&lt;/li>
&lt;li>Run my tests with that configuration and create a json file for my Power Bi labelled development&lt;/li>
&lt;li>Start Power Bi to show those results&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Import the production config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\production_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the production json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Import the development config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\development_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the development json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment Development
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Open the PowerBi
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbcPowerBi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have published the Power Bi so that you can see what it would like and have a click around (maybe you can see improvements you would like to contribute)&lt;/p>
&lt;p>now we can see how each environment is performing according to our settings for each environment&lt;/p>
&lt;h2 id="combining-configurations-into-one-result-set">Combining Configurations Into One Result Set&lt;/h2>
&lt;p>As you saw above, by using the Environment parameter of Update-DbcPowerBiDataSource you can add different environments to one report. But if I wanted to have a report for my application APP1 showing both production and development environments but they have different configurations how can I do this?&lt;/p>
&lt;p>Here’s how.&lt;/p>
&lt;ul>
&lt;li>Create a configuration for the production environment (I have used the production configuration one from above but only localhost for the instance)&lt;/li>
&lt;li>Export it using to  C:\Users\dbachecks\Desktop\APP1-Prod_config.json&lt;/li>
&lt;li>Create a configuration for the development environment (I have used the development configuration one from above but only localhost,1401 for the instance)&lt;/li>
&lt;li>Export it using to  C:\Users\dbachecks\Desktop\APP1-Dev_config.json&lt;/li>
&lt;/ul>
&lt;p>Then run&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Import the production config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\APP1-Prod_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the production json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment APP1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Import the development config
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-DbcConfig C:\Users\dbachecks\Desktop\APP1-Dev_config.json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run the tests with the production config and create/update the development json
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-DbcCheck -AllChecks -Show Fails -PassThru |Update-DbcPowerBiDataSource -Environment APP1 -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Start-DbcPowerBi
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that this time there is an Append on the last Invoke-DbcCheck this creates a single json file for the PowerBi and the results look like this. Now we have the results for our application and both the production environment localhost and the development container localhost,1401&lt;/p>
&lt;h2 id="its-open-source--we-want-your-ideas-issues-new-code">It’s Open Source – We Want Your Ideas, Issues, New Code&lt;/h2>
&lt;p>dbachecks is open-source &lt;a class="link" href="https://github.com/potatoqualitee/dbachecks" target="_blank" rel="noopener"
>available on GitHub for anyone to contribute&lt;/a>&lt;/p>
&lt;p>We would love you to contribute. Please open issues for new tests, enhancements, bugs. Please fork the repository and add code to improve the module. please give feedback to make this module even more useful&lt;/p>
&lt;p>You can also come in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> and join the dbachecks channel and get advice, make comments or just join in the conversation&lt;/p>
&lt;h2 id="thank-you">Thank You&lt;/h2>
&lt;p>I want to say thank you to all of the people who have enabled dbachecks to get this far. These wonderful people have used their own time to ensure that you have a useful tool available to you for free&lt;/p>
&lt;p>Chrissy Lemaire &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>@cl&lt;/a>&lt;/p>
&lt;p>Fred Weinmann &lt;a class="link" href="https://twitter.com/FredWeinmann" target="_blank" rel="noopener"
>@FredWeinmann&lt;/a>&lt;/p>
&lt;p>Cláudio Silva &lt;a class="link" href="https://github.com/ClaudioESSilva" target="_blank" rel="noopener"
>@ClaudioESSilva&lt;/a>&lt;/p>
&lt;p>Stuart Moore &lt;a class="link" href="https://github.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a>&lt;/p>
&lt;p>Shawn Melton &lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>&lt;/p>
&lt;p>Garry Bargsley &lt;a class="link" href="https://twitter.com/gbargsley" target="_blank" rel="noopener"
>@gbargsley&lt;/a>&lt;/p>
&lt;p>Stephen Bennett &lt;a class="link" href="https://twitter.com/staggerlee011" target="_blank" rel="noopener"
>@staggerlee011&lt;/a>&lt;/p>
&lt;p>Sander Stad &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>@SQLStad&lt;/a>&lt;/p>
&lt;p>Jess Pomfret &lt;a class="link" href="https://twitter.com/jpomfret" target="_blank" rel="noopener"
>@jpomfret&lt;/a>&lt;/p>
&lt;p>Jason Squires &lt;a class="link" href="https://twitter.com/js0505" target="_blank" rel="noopener"
>@js0505&lt;/a>&lt;/p>
&lt;p>Shane O’Neill &lt;a class="link" href="https://twitter.com/SOZDBA" target="_blank" rel="noopener"
>@SOZDBA&lt;/a>&lt;/p>
&lt;p>and all of the other people who have contributed in the dbachecks Slack channel&lt;/p></description></item><item><title>VS Code – Terminal crashes when formatting script</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-terminal-crashes-when-formatting-script/</link><pubDate>Sat, 10 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-terminal-crashes-when-formatting-script/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/02/formatting.gif" alt="Featured image of post VS Code – Terminal crashes when formatting script" />&lt;p>I love VS Code. I love being able to press ALT + SHIFT + F and format my code.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/formatting.gif" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/formatting.gif"
loading="lazy"
alt="formatting.gif"
>&lt;/a>&lt;/p>
&lt;h2 id="the-problem">The Problem&lt;/h2>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/format-error.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/format-error.png"
loading="lazy"
alt="format error.png"
>&lt;/a>&lt;/p>
&lt;p>I could reproduce it will. This was very frustrating.&lt;/p>
&lt;h2 id="turning-on-verbose-logging">Turning on Verbose Logging&lt;/h2>
&lt;p>To turn on verbose logging for the PowerShell Editor Services go the Cog in the bottom left, click it and then click User Settings.&lt;/p>
&lt;p>Search for powershell.developer.editorServicesLogLevel&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/powershell.developer.editorServicesLogLevel.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/powershell.developer.editorServicesLogLevel.png"
loading="lazy"
alt="powershell.developer.editorServicesLogLevel.png"
>&lt;/a>&lt;/p>
&lt;p>If you hover over the left hand channel a pencil will appear, click it and then click replace in settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/edit-settings.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/edit-settings.png"
loading="lazy"
alt="edit settings.png"
>&lt;/a>&lt;/p>
&lt;p>This will put the entry in the right hand side where you can change the value. Set it to Verbose and save&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/user-settigns.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/user-settigns.png"
loading="lazy"
alt="user settigns.png"
>&lt;/a>&lt;/p>
&lt;p>a prompt will come up asking if you want to restart PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/start-a-new-session.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/start-a-new-session.png"
loading="lazy"
alt="start a new session.png"
>&lt;/a>&lt;/p>
&lt;p>When you restart PowerShell, if you click on  Output and choose PowerShell Extension Logs you will see the path to the log file&lt;/p>
&lt;h2 id="logfilepathpnghttpsblogrobsewellcomassetsuploads201802logfilepathpnghttpsblogrobsewellcomassetsuploads201802logfilepathpng">&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/logfilepath.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/logfilepath.png"
loading="lazy"
alt="logfilepath.png"
>&lt;/a>&lt;/h2>
&lt;h2 id="reproduce-the-error">Reproduce the error&lt;/h2>
&lt;p>I then reproduced the error and opened the log file this is what I got&lt;/p>
&lt;blockquote>
&lt;p>10/02/2018 09:11:19 [ERROR] – Method “OnListenTaskCompleted” at line 391 of C:\projects\powershelleditorservices\src\PowerShellEditorServices.Protocol\MessageProtocol\ProtocolEndpoint.cs&lt;/p>
&lt;p>ProtocolEndpoint message loop terminated due to unhandled exception:&lt;/p>
&lt;p>System.AggregateException: One or more errors occurred. —&amp;gt; System.Management.Automation.CommandNotFoundException: The term ‘Invoke-Formatter’ is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.&lt;br>
at System.Management.Automation.Runspaces.PipelineBase.Invoke(IEnumerable input)&lt;br>
at System.Management.Automation.PowerShell.Worker.ConstructPipelineAndDoWork(Runspace rs, Boolean performSyncInvoke)&lt;br>
at System.Management.Automation.PowerShell.Worker.CreateRunspaceIfNeededAndDoWork(Runspace rsToUse, Boolean isSync)&lt;br>
at System.Management.Automation.PowerShell.CoreInvokeHelper[TInput,TOutput](PSDataCollection`1 input, PSDataCollection`1 output, PSInvocationSettings settings)&lt;br>
at System.Management.Automation.PowerShell.CoreInvoke[TInput,TOutput](PSDataCollection`1 input, PSDataCollection`1 output, PSInvocationSettings settings)&lt;br>
at System.Management.Automation.PowerShell.Invoke(IEnumerable input, PSInvocationSettings settings)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.InvokePowerShell(String command, IDictionary&lt;code>2 paramArgMap)
at System.Threading.Tasks.Task&lt;/code>1.InnerInvoke()&lt;br>
at System.Threading.Tasks.Task.Execute()&lt;br>
— End of stack trace from previous location where exception was thrown —&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;br>
at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.&lt;!-- raw HTML omitted -->d__31.MoveNext()&lt;br>
— End of stack trace from previous location where exception was thrown —&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;br>
at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)&lt;br>
at Microsoft.PowerShell.EditorServices.AnalysisService.&lt;!-- raw HTML omitted -->d__22.MoveNext()&lt;br>
— End of stack trace from previous location where exception was thrown —&lt;br>
at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw()&lt;/p>
&lt;/blockquote>
&lt;h2 id="open-an-issue-on-github">Open an issue on GitHub&lt;/h2>
&lt;p>I couldnt quickly see what was happening so &lt;a class="link" href="https://github.com/PowerShell/vscode-powershell/issues/1193" target="_blank" rel="noopener"
>I opened an issue&lt;/a> on the &lt;a class="link" href="https://github.com/PowerShell/vscode-powershell" target="_blank" rel="noopener"
>vscode-powershell repo&lt;/a> by going to issues and clicking new issue and following the instructions&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/new-issue.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/new-issue.png"
loading="lazy"
alt="new issue.png"
>&lt;/a>&lt;/p>
&lt;h2 id="the-resolution">The Resolution&lt;/h2>
&lt;p>Keith Hill &lt;a class="link" href="https://rkeithhill.wordpress.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/r_keith_hill" target="_blank" rel="noopener"
>t&lt;/a> pointed me to the resolution. Thank you Keith.&lt;/p>
&lt;p>Further up in the log file there is a line where the editor services is loading the PSScriptAnalyzer module and it should have the Invoke-Formatter command exported, but mine was not. It loaded the PsScriptAnalyzer module  from my users module directory&lt;/p>
&lt;blockquote>
&lt;p>10/02/2018 09:11:01 [NORMAL] – Method “FindPSScriptAnalyzerModule” at line 354 of C:\projects\powershelleditorservices\src\PowerShellEditorServices\Analysis\AnalysisService.cs&lt;/p>
&lt;p>PSScriptAnalyzer found at C:\Users\XXXX\Documents\WindowsPowerShell\Modules\PSScriptAnalyzer\1.10.0\PSScriptAnalyzer.psd1&lt;/p>
&lt;p>10/02/2018 09:11:01 [VERBOSE] – Method “EnumeratePSScriptAnalyzerCmdlets” at line 389 of C:\projects\powershelleditorservices\src\PowerShellEditorServices\Analysis\AnalysisService.cs&lt;/p>
&lt;p>The following cmdlets are available in the imported PSScriptAnalyzer module:&lt;br>
Get-ScriptAnalyzerRule&lt;br>
Invoke-ScriptAnalyzer&lt;/p>
&lt;/blockquote>
&lt;p>I ran&lt;/p>
&lt;p>$Env:PSModulePath.Split(&amp;rsquo;;')&lt;/p>
&lt;p>to see the module paths&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/module-path.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/module-path.png"
loading="lazy"
alt="module path.png"
>&lt;/a>&lt;/p>
&lt;p>and looked in the .vscode-insiders\extensions\ms-vscode.powershell-1.5.1\modules directory. There was no PsScriptAnalyzer folder&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/no-module.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/no-module.png"
loading="lazy"
alt="no module.png"
>&lt;/a>&lt;/p>
&lt;p>So I copied the PSScriptAnalyzer folder from the normal VS Code PowerShell Extension module folder into that folder and restarted PowerShell and I had my formatting back again 🙂&lt;/p>
&lt;p>I then reset the logging mode in my user settings back to Normal&lt;/p>
&lt;p>Thank you Keith&lt;/p></description></item><item><title>How I created PowerShell.cool using Flow, Azure SQL DB, Cognitive Services &amp; PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</link><pubDate>Sat, 03 Feb 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-created-powershell.cool-using-flow-azure-sql-db-cognitive-services-powerbi/</guid><description>&lt;p>Last weekend I was thinking about how to save the tweets for PowerShell Conference Europe. This annual event occurs in Hanover and this year it is on April 17-20, 2018. The agenda has just been released and you can find it on the website &lt;a class="link" href="http://www.psconf.eu/" target="_blank" rel="noopener"
>http://www.psconf.eu/&lt;/a>&lt;/p>
&lt;p>I ended up creating an interactive PowerBi report to which my good friend and Data Platform MVP Paul Andrew &lt;a class="link" href="https://mrpaulandrew.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/mrpaulandrew" target="_blank" rel="noopener"
>t&lt;/a> added a bit of magic and I published it. The magnificent Tobias Weltner &lt;a class="link" href="http://www.powertheshell.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/TobiasPSP" target="_blank" rel="noopener"
>t&lt;/a> who organises PSConfEU pointed the domain name &lt;a class="link" href="http://powershell.cool" target="_blank" rel="noopener"
>http://powershell.cool&lt;/a> at the link. It looks like this.&lt;/p>
&lt;p>During the monthly &lt;a class="link" href="https://twitter.com/hashtag/PSTweetChat?src=hash" target="_blank" rel="noopener"
>#PSTweetChat&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Reminder that we do this chat the first Friday of every month from 1-2PM Eastern which I think is 6:00PM UTC &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p>— Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959495635182477324?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I mentioned that I need to blog about how I created it and Jeff replied&lt;/p>
&lt;blockquote>
&lt;p>Yes, please. I&amp;rsquo;d love to setup something similiar for the PowerShell+DevOps Summit. &lt;a class="link" href="https://twitter.com/hashtag/pstweetchat?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#pstweetchat&lt;/a>&lt;/p>
&lt;p>— Jeffery Hicks (@JeffHicks) &lt;a class="link" href="https://twitter.com/JeffHicks/status/959494450547511298?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>February 2, 2018&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>so here it is! Looking forward to seeing the comparison between the &lt;a class="link" href="https://powershell.org/summit/" target="_blank" rel="noopener"
>PowerShell and Devops Summi&lt;/a>t and the &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference Europe&lt;/a> 🙂&lt;/p>
&lt;p>This is an overview of how it works&lt;/p>
&lt;ul>
&lt;li>A &lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>Microsoft Flow&lt;/a> looks for tweets with the &lt;a class="link" href="https://twitter.com/search?q=%23PSConfEU&amp;amp;src=typd" target="_blank" rel="noopener"
>#PSConfEU&lt;/a> hashtag and then gets the information about the tweet&lt;/li>
&lt;li>&lt;a class="link" href="https://azure.microsoft.com/en-gb/services/cognitive-services/text-analytics/" target="_blank" rel="noopener"
>Microsoft Cognitive Services Text Analysis API&lt;/a> analyses the sentiment of the tweet and provides a score between 0 (negative) and 1 (positive)&lt;/li>
&lt;li>Details about the tweet and the sentiment are saved in &lt;a class="link" href="https://azure.microsoft.com/en-gb/services/sql-database/" target="_blank" rel="noopener"
>Azure SQL database&lt;/a>&lt;/li>
&lt;li>A &lt;a class="link" href="http://PowerBi.com" target="_blank" rel="noopener"
>PowerBi&lt;/a> report uses that data and provides the report&lt;/li>
&lt;/ul>
&lt;p>You will find all of the resources and the scripts to do all of the below in &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>the GitHub repo.&lt;/a> So clone it and navigate to the filepath&lt;/p>
&lt;h2 id="create-database">Create Database&lt;/h2>
&lt;p>First lets create a database. Connect to your Azure subscription&lt;/p>
&lt;pre>&lt;code>## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YourSubscriptionIDHere
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/01-subscription.png"
loading="lazy"
alt="01 - subscription.png"
>&lt;/a>&lt;/p>
&lt;p>Then set some variables&lt;/p>
&lt;pre>&lt;code># The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
# The logical server name: Use a random value or replace with your own value (do not capitalize)
$servername = &amp;quot;server-$(Get-Random)&amp;quot;
# Set an admin login and password for your database
# The login information for the server You need to set these and uncomment them - Dont use these values
# $adminlogin = &amp;quot;ServerAdmin&amp;quot;
# $password = &amp;quot;ChangeYourAdminPassword1&amp;quot;
# The ip address range that you want to allow to access your server - change as appropriate
# $startip = &amp;quot;0.0.0.0&amp;quot;
# $endip = &amp;quot;0.0.0.0&amp;quot;
# To just add your own IP Address
$startip = $endip = (Invoke-WebRequest 'http:// myexternalip.com/raw').Content -replace &amp;quot;`n&amp;quot;
# The database name
$databasename = &amp;quot;tweets&amp;quot;
$AzureSQLServer = &amp;quot;$servername.database. windows.net,1433&amp;quot;
$Table = &amp;quot;table.sql&amp;quot;
$Proc = &amp;quot;InsertTweets.sql&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>They should all make sense, take note that you need to set and uncomment the login and password and choose which IPs to allow through the firewall&lt;/p>
&lt;p>Create a Resource Group&lt;/p>
&lt;pre>&lt;code>## Create a resource group
New-AzureRmResourceGroup -Name $resourcegroupname -Location $location
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/02-resource-group.png"
loading="lazy"
alt="02 - resource group.png"
>&lt;/a>&lt;/p>
&lt;p>Create a SQL Server&lt;/p>
&lt;pre>&lt;code>## Create a Server
$newAzureRmSqlServerSplat = @{
SqlAdministratorCredentials = $SqlAdministratorCredentials
ResourceGroupName = $resourcegroupname
ServerName = $servername
Location = $location
}
New-AzureRmSqlServer @newAzureRmSqlServerSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03-create-server.png"
loading="lazy"
alt="03 - create server.png"
>&lt;/a>&lt;/p>
&lt;p>Create a firewall rule, I just use my own IP and add the allow azure IPs&lt;/p>
&lt;pre>&lt;code>$newAzureRmSqlServerFirewallRuleSplat = @{
EndIpAddress = $endip
StartIpAddress = $startip
ServerName = $servername
ResourceGroupName = $resourcegroupname
FirewallRuleName = &amp;quot;AllowSome&amp;quot;
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
# Allow Azure IPS
$newAzureRmSqlServerFirewallRuleSplat = @{
AllowAllAzureIPs = $true
ServerName = $servername
ResourceGroupName = $resourcegroupname
}
New-AzureRmSqlServerFirewallRule @newAzureRmSqlServerFirewallRuleSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/03a-firewall-rule.png"
loading="lazy"
alt="03a - firewall rule.png"
>&lt;/a>&lt;/p>
&lt;p>Create a database&lt;/p>
&lt;pre>&lt;code># Create a database
$newAzureRmSqlDatabaseSplat = @{
ServerName = $servername
ResourceGroupName = $resourcegroupname
Edition = 'Basic'
DatabaseName = $databasename
}
New-AzureRmSqlDatabase @newAzureRmSqlDatabaseSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/04-create-database.png"
loading="lazy"
alt="04 - create database.png"
>&lt;/a>&lt;/p>
&lt;p>I have used the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> to run the scripts to create the database. You can get it using&lt;/p>
&lt;pre>&lt;code>Install-Module dbatools # -Scope CurrentUser # if not admin process
Run the scripts
# Create a credential
$newObjectSplat = @{
ArgumentList = $adminlogin, $ (ConvertTo-SecureString -String $password -AsPlainText -Force)
TypeName = 'System.Management.Automation. PSCredential'
}
$SqlAdministratorCredentials = New-Object @newObjectSplat
## Using dbatools module
$invokeDbaSqlCmdSplat = @{
SqlCredential = $SqlAdministratorCredentials
Database = $databasename
File = $Table,$Proc
SqlInstance = $AzureSQLServer
}
Invoke-DbaSqlCmd @invokeDbaSqlCmdSplat
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/05-Create-Table-Sproc.png"
loading="lazy"
alt="05 - Create Table Sproc.png"
>&lt;/a>&lt;/p>
&lt;p>This will have created the following in Azure, you can see it in the portal&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/07-portal.png"
loading="lazy"
alt="07 - portal.png"
>&lt;/p>
&lt;p>You can connect to the database in SSMS and you will see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/06-show-table.png"
loading="lazy"
alt="06 - show table.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-cognitive-services">Create Cognitive Services&lt;/h2>
&lt;p>Now you can create the Text Analysis Cognitive Services API&lt;/p>
&lt;p>First login (if you need to) and set some variables&lt;/p>
&lt;pre>&lt;code>## This creates cognitive services for analysing the tweets
## Log in to your Azure subscription using the Add-AzureRmAccount command and follow the on-screen directions.
Add-AzureRmAccount
## Select the subscription
Set-AzureRmContext -SubscriptionId YOUR SUBSCRIPTION ID HERE
#region variables
# The data center and resource name for your resources
$resourcegroupname = &amp;quot;twitterresource&amp;quot;
$location = &amp;quot;WestEurope&amp;quot;
$APIName = 'TweetAnalysis'
#endregion
Then create the API and get the key
#Create the cognitive services
$newAzureRmCognitiveServicesAccountSplat = @{
ResourceGroupName = $resourcegroupname
Location = $location
SkuName = 'F0'
Name = $APIName
Type = 'TextAnalytics'
}
New-AzureRmCognitiveServicesAccount @newAzureRmCognitiveServicesAccountSplat
# Get the Key
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat
&lt;/code>&lt;/pre>
&lt;p>You will need to accept the prompt&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/08-cognitive-service.png"
loading="lazy"
alt="08 -cognitive service"
>&lt;/a>&lt;/p>
&lt;p>Copy the Endpoint URL as you will need it.Then save one of  the keys for the next step!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/09-cognitiveservice-key.png"
loading="lazy"
alt="09 cognitiveservice key"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow">Create the Flow&lt;/h2>
&lt;p>I have exported the Flow to a zip file and also the json for a PowerApp (no details about that in this post). Both are available in the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a>. I have submitted a template but it is not available yet.&lt;/p>
&lt;p>Navigate to &lt;a class="link" href="https://flow.microsoft.com/" target="_blank" rel="noopener"
>https://flow.microsoft.com/&lt;/a> and sign in&lt;/p>
&lt;h2 id="creating-connections">Creating Connections&lt;/h2>
&lt;p>You will need to set up your connections. Click New Connection and search for Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/16-import-step-3.png"
loading="lazy"
alt="16 - import step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add and fill in the Account Key and the Site URL from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/17-import-step-5.png"
loading="lazy"
alt="17 import step 5.png"
>&lt;/a>&lt;/p>
&lt;p>click new connection and search for SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/18-import-step-6.png"
loading="lazy"
alt="18 - import step 6.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the SQL Server Name (value of &lt;code>$AzureSQLServer&lt;/code>) , Database Name , User Name and Password from the steps above&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/19-import-step-7.png"
loading="lazy"
alt="19 - import step 7.png"
>&lt;/a>&lt;/p>
&lt;p>Click new Connection and search for Twitter and create a connection (the authorisation pop-up may be hidden behind other windows!)&lt;/p>
&lt;h2 id="import-the-flow">Import the Flow&lt;/h2>
&lt;p>If you have a premium account you can import the flow, click Import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/11-import-flow.png"
loading="lazy"
alt="11 - import flow.png"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/12-choose-import.png"
loading="lazy"
alt="12 - choose import.png"
>&lt;/a>&lt;/p>
&lt;p>and choose the import.zip from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub Repo&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/13-import-step-1.png"
loading="lazy"
alt="13 import step 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click on Create as new and choose a name&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/14-import-step-2.png"
loading="lazy"
alt="14 - import step 2.png"
>&lt;/a>&lt;/p>
&lt;p>Click select during import next to Sentiment and choose the Sentiment connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/15-impot-step-3.png"
loading="lazy"
alt="15 impot step 3.png"
>&lt;/a>&lt;/p>
&lt;p>Select during import for the SQL Server Connection and choose the SQL Server Connection and do the same for the Twitter Connection&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/20-import-stpe-8.png"
loading="lazy"
alt="20 - import stpe 8.png"
>&lt;/a>&lt;/p>
&lt;p>Then click import&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/21-imported.png"
loading="lazy"
alt="21 - imported.png"
>&lt;/a>&lt;/p>
&lt;h2 id="create-the-flow-without-import">Create the flow without import&lt;/h2>
&lt;p>If you do not have a premium account you can still create the flow using these steps. I have created a template but it is not available at the moment. Create the connections as above and then click Create from blank.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/22-importblank.png"
loading="lazy"
alt="22 - importblank.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the trigger When a New Tweet is posted and add a search term. You may need to choose the connection to twitter by clicking the three dots&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/23-importblank-1.png"
loading="lazy"
alt="23 - importblank 1.png"
>&lt;/a>&lt;/p>
&lt;p>Click Add an action&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/24-add-action.png"
loading="lazy"
alt="24 - add action.png"
>&lt;/a>&lt;/p>
&lt;p>search for detect and choose the Text Analytics Detect Sentiment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/25-choose-sentuiment.png"
loading="lazy"
alt="25 - choose sentuiment.png"
>&lt;/a>&lt;/p>
&lt;p>Enter the name for the connection, the account key and the URL from the creation of the API above. If you forgot to copy them&lt;/p>
&lt;pre>&lt;code>#region Forgot the details
# Copy the URL if you forget to save it
$getAzureRmCognitiveServicesAccountSplat = @{
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccount @getAzureRmCognitiveServicesAccountSplat). Endpoint | Clip
# Copy the Key if you forgot
$getAzureRmCognitiveServicesAccountKeySplat = @ {
Name = $APIName
ResourceGroupName = $resourcegroupname
}
(Get-AzureRmCognitiveServicesAccountKey @getAzureRmCognitiveServicesAccountKeySplat). Key1 | Clip
#endregion
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/26-enter-details.png"
loading="lazy"
alt="26 - enter details.png"
>&lt;/a>&lt;/p>
&lt;p>Click in the text box and choose Tweet Text&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/27-choose-tweet-text.png"
loading="lazy"
alt="27 - choose tweet text.png"
>&lt;/a>&lt;/p>
&lt;p>Click New Step and add an action. Search for SQL Server and choose SQL Server – Execute Stored Procedure&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/28-choose-sql-server-execute-stored-procedure.png"
loading="lazy"
alt="28 - choose sql server execute stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Choose the stored procedure [dbo].[InsertTweet]&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/29-choose-stored-procedure.png"
loading="lazy"
alt="29 - choose stored procedure.png"
>&lt;/a>&lt;/p>
&lt;p>Fill in as follows&lt;/p>
&lt;ul>
&lt;li>__PowerAppsID__         0&lt;/li>
&lt;li>Date                                 Created At&lt;/li>
&lt;li>Sentiment                      Score&lt;/li>
&lt;li>Tweet                              Tweet Text&lt;/li>
&lt;li>UserLocation                 Location&lt;/li>
&lt;li>UserName                      Tweeted By&lt;/li>
&lt;/ul>
&lt;p>as shown below&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/30-stored-procedure-info.png?resize=630%2C368&amp;amp;ssl=1"
loading="lazy"
alt="30 stored procedure info.png"
>&lt;/a>&lt;/p>
&lt;p>Give the flow a name at the top and click save flow&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/31-flow-created.png"
loading="lazy"
alt="31 flow created.png"
>&lt;/a>&lt;/p>
&lt;h2 id="connect-powerbi">Connect PowerBi&lt;/h2>
&lt;p>Open the PSConfEU Twitter Analysis Direct.pbix from the &lt;a class="link" href="https://github.com/SQLDBAWithABeard/PowerShellCool" target="_blank" rel="noopener"
>GitHub repo&lt;/a> in PowerBi Desktop. Click the arrow next to Edit Queries and then change data source settings&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/32-change-data-source.png"
loading="lazy"
alt="32 change data source.png"
>&lt;/a>&lt;/p>
&lt;p>Click Change source and enter the server (value of &lt;code>$AzureSQLServer&lt;/code>) and the database name. It will alert you to apply changes&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/33-apply-changes.png"
loading="lazy"
alt="33 apply changes.png"
>&lt;/a>&lt;/p>
&lt;p>It will then pop-up with a prompt for the credentials. Choose Database and enter your credentials and click connect&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/02/34-creds.png?resize=630%2C370&amp;amp;ssl=1"
loading="lazy"
alt="34 - creds.png"
>&lt;/a>&lt;/p>
&lt;p>and your PowerBi will be populated from the Azure SQL Database 🙂 This will fail if there are no records in the table because your flow hasn’t run yet. If it does just wait until you see some tweets and then click apply changes again.&lt;/p>
&lt;p>You will probably want to alter the pictures and links etc and then yo can publish the report&lt;/p>
&lt;p>Happy Twitter Analysis&lt;/p>
&lt;p>Dont forget to keep an eye on your flow runs to make sure they have succeeded.&lt;/p></description></item><item><title>How to write a PowerShell function to use Confirm, Verbose and WhatIf</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/</link><pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-write-a-powershell-function-to-use-confirm-verbose-and-whatif/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/03-confirm.png" alt="Featured image of post How to write a PowerShell function to use Confirm, Verbose and WhatIf" />&lt;p>In &lt;a class="link" href="https://blog.robsewell.com/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/" target="_blank" rel="noopener"
>my last blog post&lt;/a> I showed how to run a script with the WhatIf parameter. This assumes that the commands within the script have been written to use the common parameters Confirm, Verbose and WhatIf.&lt;/p>
&lt;p>Someone asked me how to make sure that any functions that they write will be able to do this.&lt;/p>
&lt;p>it is very easy&lt;/p>
&lt;p>When we define our function we are going to add &lt;code>[cmdletbinding(SupportsShouldProcess)]&lt;/code> at the top&lt;/p>
&lt;pre>&lt;code>function Set-FileContent {
[cmdletbinding(SupportsShouldProcess)]
Param()
&lt;/code>&lt;/pre>
&lt;p>and every time we perform an action that will change something we put that code inside a code block like this&lt;/p>
&lt;pre>&lt;code>if ($PSCmdlet.ShouldProcess(&amp;quot;The Item&amp;quot; , &amp;quot;The Change&amp;quot;)) {
# place code here
}
&lt;/code>&lt;/pre>
&lt;p>and alter The Item and The Change as appropriate.&lt;/p>
&lt;p>I have created a snippet for VS Code to make this quicker for me. To add it to your VS Code. Click the settings button bottom right, Click User Snippets, choose the powershell json and add the code below between the last two }’s (Don’t forget the comma)&lt;/p>
&lt;pre>&lt;code>,
&amp;quot;IfShouldProcess&amp;quot;: {
&amp;quot;prefix&amp;quot;: &amp;quot;IfShouldProcess&amp;quot;,
&amp;quot;body&amp;quot;: [
&amp;quot;if ($$PSCmdlet.ShouldProcess(\&amp;quot;The Item\&amp;quot; , \&amp;quot;The Change\&amp;quot;)) {&amp;quot;,
&amp;quot; # Place Code here&amp;quot;,
&amp;quot;}&amp;quot;
],
&amp;quot;description&amp;quot;: &amp;quot;Shows all the colour indexes for the Excel colours&amp;quot;
}
&lt;/code>&lt;/pre>
&lt;p>and save the powershell.json file&lt;/p>
&lt;p>Then when you are writing your code you can simply type “ifs” and tab and the code will be generated for you&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-VS-Code-Snippet.gif"
loading="lazy"
>&lt;/p>
&lt;p>As an example I shall create a function wrapped around Set-Content just so that you can see what happens.&lt;/p>
&lt;pre>&lt;code>function Set-FileContent {
[cmdletbinding(SupportsShouldProcess)]
Param(
[Parameter(Mandatory = $true)]
[ValidateNotNullOrEmpty()]
[string]$Content,
[Parameter(Mandatory = $true)]
[ValidateScript( {Test-Path $_ })]
[string]$File
)
if ($PSCmdlet.ShouldProcess(&amp;quot;$File&amp;quot; , &amp;quot;Adding $Content to &amp;quot;)) {
Set-Content -Path $File -Value $Content
}
}
&lt;/code>&lt;/pre>
&lt;p>I have done this before because if the file does not exist then &lt;code>Set-Content&lt;/code> will create a new file for you, but with this function I can check if the file exists first with the ValidateScript before running the rest of the function.&lt;/p>
&lt;p>As you can see I add variables from my PowerShell code into the “The Item” and “The Change”. If I need to add a property of an object I use &lt;code>$($Item.Property)&lt;/code>.&lt;/p>
&lt;p>So now, if I want to see what my new function would do if I ran it without actually making any changes I have -WhatIf added to my function automagically.&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -WhatIf
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-what-if.png"
loading="lazy"
>&lt;/p>
&lt;p>If I want to confirm any action I take before it happens I have &lt;code>-Confirm&lt;/code>&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -Confirm
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-confirm.png"
loading="lazy"
>&lt;/p>
&lt;p>As you can see it also give the confirm prompts for the &lt;code>Set-Content&lt;/code> command&lt;/p>
&lt;p>You can also see the verbose messages with&lt;/p>
&lt;pre>&lt;code>Set-FileContent -File C:\temp\number1\TextFile.txt -Content &amp;quot;This is the New Content&amp;quot; -Verbose
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/04-verbose.png"
loading="lazy"
>&lt;/p>
&lt;p>So to summarise, it is really very simple to add Confirm, WhatIf and Verbose to your functions by placing  &lt;code>[cmdletbinding(SupportsShouldProcess)]&lt;/code> at the top of the function and placing any code that makes a change inside&lt;/p>
&lt;pre>&lt;code>if ($PSCmdlet.ShouldProcess(&amp;quot;The Item&amp;quot; , &amp;quot;The Change&amp;quot;)) {
&lt;/code>&lt;/pre>
&lt;p>with some values that explain what the code is doing to the The Item and The Change.&lt;/p>
&lt;p>Bonus Number 1 – This has added support for other common parameters as well – Debug, ErrorAction, ErrorVariable, WarningAction, WarningVariable, OutBuffer, PipelineVariable, and OutVariable.&lt;/p>
&lt;p>Bonus Number 2 – This has automatically been added to your Help&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/05-get-help.png"
loading="lazy"
>&lt;/p>
&lt;p>Bonus Number 3 – This has reduced the amount of comments you need to write and improved other peoples understanding of what your code is supposed to do 🙂 People can read your code and read what you have entered for the IfShouldProcess and that will tell them what the code is supposed to do 🙂&lt;/p>
&lt;p>Now you have seen how easy it is to write more professional PowerShell functions&lt;/p></description></item><item><title>How to run a PowerShell script file with Verbose, Confirm or WhatIf</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</link><pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-to-run-a-powershell-script-file-with-verbose-confirm-or-whatif/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Showing-the-results.png" alt="Featured image of post How to run a PowerShell script file with Verbose, Confirm or WhatIf" />&lt;p>Before you run a PowerShell command that makes a change to something you should check that it is going to do what you expect. You can do this by using the WhatIf parameter for commands that support it. For example, if you wanted to create a New SQL Agent Job Category you would use the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>awesome dbatools module&lt;/a> and write some code like this&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup'
&lt;/code>&lt;/pre>
&lt;p>before you run it, you can check what it is going to do using&lt;/p>
&lt;pre>&lt;code>New-DbaAgentJobCategory -SqlInstance ROB-XPS -Category 'Backup' -WhatIf
&lt;/code>&lt;/pre>
&lt;p>which gives a result like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Whatif.png"
loading="lazy"
>&lt;/p>
&lt;p>This makes it easy to do at the command line but when we get confident with PowerShell we will want to write scripts to perform tasks using more than one command. So how can we ensure that we can check that those will do what we are expecting without actually running the script and see what happens? Of course, there are Unit and integration testing that should be performed using &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>Pester&lt;/a> when developing the script but there will still be occasions when we want to see what this script will do this time in this environment.&lt;/p>
&lt;p>Lets take an example. We want to place our SQL Agent jobs into specific custom categories depending on their name. We might write a script like this&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.SYNOPSIS
Adds SQL Agent Jobs to categories and creates the categories if needed
.DESCRIPTION
Adds SQL Agent Jobs to categories and creates the categories if needed. Creates
Backup', 'Index', 'TroubleShooting','General Info Gathering' categories and adds
the agent jobs depending on name to the category
.PARAMETER Instance
The Instance to run the script against
#&amp;gt;
Param(
[string]$Instance
)
$Categories = 'Backup', 'Index','DBCC', 'TroubleShooting', 'General Info Gathering'
$Categories.ForEach{
## Create Category if it doesnot exist
If (-not (Get-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem)) {
New-DbaAgentJobCategory -SqlInstance $instance -Category $PSItem -CategoryType LocalJob
}
}
## Get the agent jobs and iterate through them
(Get-DbaAgentJob -SqlInstance $instance).ForEach{
## Depending on the name of the Job - Put it in a Job Category
switch -Wildcard ($PSItem.Name) {
'*DatabaseBackup*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Backup'
}
'*Index*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'Index'
}
'*DatabaseIntegrity*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'DBCC'
}
'*Log SP_*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'TroubleShooting'
}
'*Collection*' {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category 'General Info Gathering'
}
## Otherwise put it in the uncategorised category
Default {
Set-DbaAgentJob -SqlInstance $instance -Job $PSItem -Category '[Uncategorized (Local)]'
}
}
}
&lt;/code>&lt;/pre>
&lt;p>You can run this script against any SQL instance by calling  it and passing an instance parameter from the command line like this&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>If you wanted to see what would happen, you could edit the script and add the WhatIf parameter to every changing command but that’s not really a viable solution. What you can do is&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $true
&lt;/code>&lt;/pre>
&lt;p>this will set all commands that accept WhatIf to use the WhatIf parameter. This means that if you are using functions that you have written internally you must ensure that you write your functions to use the common parameters&lt;/p>
&lt;p>Once you have set the default value for WhatIf as above, you can simply call your script and see the WhatIf output&lt;/p>
&lt;pre>&lt;code> &amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>which will show the WhatIf output for the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Showing-the-results.png"
loading="lazy"
>&lt;/p>
&lt;p>Once you have checked that everything is as you expected then you can remove the default value for the WhatIf parameter and run the script&lt;/p>
&lt;pre>&lt;code>$PSDefaultParameterValues['*:WhatIf'] = $false
&amp;amp; C:\temp\ChangeJobCategories.ps1 -instance ROB-XPS
&lt;/code>&lt;/pre>
&lt;p>and get the expected output&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-run-the-script-1.png"
loading="lazy"
>&lt;/p>
&lt;p>If you wish to see the verbose output or ask for confirmation before any change you can set those default parameters like this&lt;/p>
&lt;pre>&lt;code>## To Set Verbose output
$PSDefaultParameterValues['*:Verbose'] = $true
## To Set Confirm
$PSDefaultParameterValues['*:Confirm'] = $true
&lt;/code>&lt;/pre>
&lt;p>and set them back by setting to false&lt;/p></description></item><item><title>Pester 4.2.0 has a Because…… because :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</link><pubDate>Thu, 18 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-4.2.0-has-a-because-because-/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/01-Because-1.png" alt="Featured image of post Pester 4.2.0 has a Because…… because :-)" />&lt;p>I was going through my demo for the &lt;a class="link" href="http://meetu.ps/e/DdYV6/gHMdv/g" target="_blank" rel="noopener"
>South Coast User Group meeting&lt;/a> tonight and decided to add some details about the Because parameter available in the Pester pre-release version 4.2.0.&lt;/p>
&lt;p>To install a pre-release version you need to get the latest  &lt;a class="link" href="https://go.microsoft.com/fwlink/?linkid=846259" target="_blank" rel="noopener"
>PowerShellGet&lt;/a> module. This is pre-installed with PowerShell v6 but for earlier versions open PowerShell as administrator and run&lt;/p>
&lt;pre>&lt;code>Install-Module PowerShellGet
&lt;/code>&lt;/pre>
&lt;p>You can try out the Pester pre-release version (once you have the latest PowerShellGet) by installing it from the &lt;a class="link" href="http://powershellgallery.com" target="_blank" rel="noopener"
>PowerShell Gallery&lt;/a> with&lt;/p>
&lt;pre>&lt;code>Install-Module -Name Pester -AllowPrerelease -Force # -Scope CurrentUser # if not admin
&lt;/code>&lt;/pre>
&lt;p>There are a number of improvements as you can see in &lt;a class="link" href="https://github.com/pester/Pester/blob/master/CHANGELOG.md" target="_blank" rel="noopener"
>the change log&lt;/a> I particularly like the&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>Add -BeTrue to test for truthy values&lt;/li>
&lt;li>Add -BeFalse to test for falsy values&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>This release adds the Because parameter to the all assertions. This means that you can add a reason why the test has failed. As &lt;a class="link" href="http://jakubjares.com/2017/12/19/using-because/" target="_blank" rel="noopener"
>JAKUB JAREŠ writes here&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Reasons force you think more&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons document your intent&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Reasons make your TestCases clearer&lt;/p>
&lt;/li>
&lt;li>
&lt;p>So you can do something like this&lt;/p>
&lt;p>Describe &amp;ldquo;This shows the Because&amp;rdquo;{
It &amp;ldquo;Should be true&amp;rdquo; {
$false | Should -BeTrue -Because &amp;ldquo;The Beard said so&amp;rdquo;
}
}&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Which gives an error message like this 🙂&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-Because-1.png"
loading="lazy"
>&lt;/p>
&lt;p>As you can see the Expected gives the expected value and then your Because statement and then the actual result. Which means that you could write validation tests like&lt;/p>
&lt;pre>&lt;code>Describe &amp;quot;My System&amp;quot; {
Context &amp;quot;Server&amp;quot; {
It &amp;quot;Should be using XP SP3&amp;quot; {
(Get-CimInstance -ClassName win32_operatingsystem) .Version | Should -Be '5.1.2600' -Because &amp;quot;We have failed to bother to update the App and it only works on XP&amp;quot;
}
It &amp;quot;Should be running as rob-xps\\mrrob&amp;quot; {
whoami | Should -Be 'rob-xps\\mrrob' -Because &amp;quot;This is the user with the permissions&amp;quot;
}
It &amp;quot;Should have SMB1 enabled&amp;quot; {
(Get-SmbServerConfiguration).EnableSMB1Protocol | Should -BeTrue -Because &amp;quot;We don't care about the risk&amp;quot;
}
}
}
&lt;/code>&lt;/pre>
&lt;p>and get a result like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-example.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Or if you were looking to validate your SQL Server you could write something like this&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_.Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG&amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>or maybe your security policies allow Windows Groups as logins on your SQL instances. You could easily link to the documentation and explain why this is important. This way you could build up a set of tests to validate your SQL Server is just so for your environment&lt;/p>
&lt;pre>&lt;code>It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins). LoginType -contains 'WindowsUser' | Should @Should
}
&lt;/code>&lt;/pre>
&lt;p>Just for fun, these would look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-for-fun.png"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>and the code looks like&lt;/p>
&lt;pre>&lt;code>$Instances = 'Rob-XPS', 'Rob-XPS\\Bolton'
foreach ($instance in $Instances) {
$Server, $InstanceName = $Instance.Split('/')
if ($InstanceName.Length -eq 0) {$InstanceName = 'MSSSQLSERVER'}
Describe &amp;quot;Testing the instance $instance&amp;quot; {
Context &amp;quot;SQL Agent Jobs&amp;quot; {
It &amp;quot;Backups Should have Succeeeded&amp;quot; {
$Where = {$\_IsEnabled -eq $true -and $\_. Name -like '\*databasebackup\*'}
$Should = @{
BeTrue = $true
Because = &amp;quot;WE NEED BACKUPS - OMG &amp;quot;
}
(Get-DbaAgentJob -SqlInstance $instance| Where-Object $where).LastRunOutcome -NotContains 'Failed' | Should @Should
}
Context &amp;quot;Logins&amp;quot; {
It &amp;quot;Should only have Windows groups as logins&amp;quot; {
$Should = @{
Befalse = $true
Because = &amp;quot;Our Security Policies say we must only have Windows groups as logins - See this document&amp;quot;
}
(Get-DbaLogin -SqlInstance $instance -WindowsLogins).LoginType -contains 'WindowsUser' | Should @Should
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This will be a useful improvement to Pester when it is released and enable you to write validation checks with explanations.&lt;/p>
&lt;blockquote>
&lt;p>Come and Learn Some PowerShell Magic* at &lt;a class="link" href="https://twitter.com/hashtag/SQLBits?src=hash&amp;amp;ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>#SQLBits&lt;/a> with &lt;a class="link" href="https://twitter.com/cl?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>@cl&lt;/a> and I&lt;br>
Details &lt;a class="link" href="https://t.co/7OfK75e6Y1" target="_blank" rel="noopener"
>https://t.co/7OfK75e6Y1&lt;/a>&lt;br>
Registration &lt;a class="link" href="https://t.co/RDSkPlfMMx" target="_blank" rel="noopener"
>https://t.co/RDSkPlfMMx&lt;/a>&lt;br>
*PowerShell is not magic – it just might appear that way &lt;a class="link" href="https://t.co/5czPzYR3QD" target="_blank" rel="noopener"
>pic.twitter.com/5czPzYR3QD&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/935143475418402816?ref_src=twsrc%5Etfw" target="_blank" rel="noopener"
>November 27, 2017&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p></description></item><item><title>Using the AST in Pester for dbachecks</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</link><pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-ast-in-pester-for-dbachecks/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2018/01/02-Pester-results-1.png" alt="Featured image of post Using the AST in Pester for dbachecks" />&lt;p>TagLine – My goal – Chrissy will appreciate Unit Tests one day 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/new-module-coming-soon/" target="_blank" rel="noopener"
>Chrissy has written about dbachecks&lt;/a> the new up and coming community driven open source PowerShell module for SQL DBAs to validate their SQL Server estate. we have taken some of the ideas that we have presented about a way of using &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> with &lt;a class="link" href="https://github.com/Pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> to validate that everything is how it should be and placed them into a meta data driven framework to make things easy for anyone to use. It is looking really good and I am really excited about it. It will be released very soon.&lt;/p>
&lt;p>Chrissy and I will be doing a pre-con at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> where we will talk in detail about how this works. &lt;a class="link" href="http://sqlbits.com/information/event17/Reliable_Repeatable__Automated_PowerShell_for_DBAs/trainingdetails.aspx" target="_blank" rel="noopener"
>You can find out more and sign up here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://claudioessilva.eu/" target="_blank" rel="noopener"
>Cláudio Silva&lt;/a> has improved my &lt;a class="link" href="https://blog.robsewell.com/a-pretty-powerbi-pester-results-template-file/" target="_blank" rel="noopener"
>PowerBi For Pester&lt;/a> file and made it beautiful and whilst we were discussing this we found that if the Pester Tests were not formatted correctly the Power Bi looked … well rubbish to be honest! Chrissy asked if we could enforce some rules for writing our Pester tests.&lt;/p>
&lt;p>The rules were&lt;/p>
&lt;p>The Describe title should be in double quotes&lt;br>
The Describe should use the plural Tags parameter&lt;br>
The Tags should be singular&lt;br>
The first Tag should be a unique tag in Get-DbcConfig&lt;br>
The context title should end with $psitem&lt;br>
The code should use Get-SqlInstance or Get-ComputerName&lt;br>
The Code should use the forEach method&lt;br>
The code should not use $_&lt;br>
The code should contain a Context block&lt;/p>
&lt;p>She asked me if I could write the Pester Tests for it and this is how I did it. I needed to look at the Tags parameter for the Describe. It occurred to me that this was a job for the Abstract Syntax Tree (AST). I don’t know very much about the this but I sort of remembered reading a blog post by &lt;a class="link" href="http://www.lazywinadmin.com/2016/08/powershellpester-make-sure-your.html" target="_blank" rel="noopener"
>Francois-Xavier Cat about using it with Pester&lt;/a> so I went and read that and &lt;a class="link" href="https://stackoverflow.com/questions/39909021/parsing-powershell-script-with-ast" target="_blank" rel="noopener"
>found an answer on Stack Overflow&lt;/a> as well. These looked just like what I needed so I made use of them. Thank you very much to Francois-Xavier and wOxxOm for sharing.&lt;/p>
&lt;p>The first thing I did was to get the Pester Tests which we have located in a checks folder and loop through them and get the content of the file with the Raw parameter&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Describes titles and tags&amp;quot; {
&lt;/code>&lt;/pre>
&lt;p>Then I decided to look at the Describes using the method that wOxxOm (I know no more about this person!) showed.&lt;/p>
&lt;pre>&lt;code>$Describes = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\]\] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'describe'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
$tagIdx = $CE.IndexOf(($CE |Where ParameterName -eq'Tags') ) + 1
$tags = if ($tagIdx -and $tagIdx -lt $CE.Count) {
$CE\[$tagIdx\].Extent
}
New-Object PSCustomObject -Property @{
Name = $secondString
Tags = $tags
}
}
&lt;/code>&lt;/pre>
&lt;p>As I understand it, this code is using the Parser on the $check (which contains the code from the file) and finding all of the Describe commands and creating an object of the title of the Describe with the StaticType equal to String and values from the Tag parameter.&lt;/p>
&lt;p>When I ran this against the database tests file I got the following results&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/01-describes-1.png"
loading="lazy"
>&lt;/p>
&lt;p>Then it was a simple case of writing some tests for the values&lt;/p>
&lt;pre>&lt;code>@($describes).Foreach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$title Should Use a double quote after the Describe&amp;quot; {
$PSItem.Name.ToString().Startswith('&amp;quot;')| Should be $true
$PSItem.Name.ToString().Endswith('&amp;quot;')| Should be $true
}
It &amp;quot;$title should use a plural for tags&amp;quot; {
$PsItem.Tags| Should Not BeNullOrEmpty
}
# a simple test for no esses apart from statistics and Access!!
if ($null -ne $PSItem.Tags) {
$PSItem.Tags.Text.Split(',').Trim().Where{($_ -ne '$filename') -and ($_ -notlike '\*statistics\*') -and ($_ -notlike '\*BackupPathAccess\*') }.ForEach{
It &amp;quot;$PsItem Should Be Singular&amp;quot; {
$_.ToString().Endswith('s')| Should Be $False
}
}
It &amp;quot;The first Tag Should Be in the unique Tags returned from Get-DbcCheck&amp;quot; {
$UniqueTags -contains $PSItem.Tags.Text.Split(',') \[0\].ToString()| Should Be $true
}
}
else {
It &amp;quot;You haven't used the Tags Parameter so we can't check the tags&amp;quot; {
$false| Should be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>The Describes variable is inside @() so that if there is only one the ForEach Method will still work. The unique tags are returned from our command Get-DbcCheck which shows all of the checks. We will have a unique tag for each test so that they can be run individually.&lt;/p>
&lt;p>Yes, I have tried to ensure that the tags are singular by ensuring that they do not end with an s (apart from statistics) and so had to not check  BackupPathAccess and statistics. Filename is a variable that we add to each Describe Tags so that we can run all of the tests in one file. I added a little if block to the Pester as well so that the error if the Tags parameter was not passed was more obvious&lt;/p>
&lt;p>I did the same with the context blocks as well&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Contexts&amp;quot; {
## Find the Contexts
$Contexts = \[Management.Automation.Language.Parser\] ::ParseInput($check, \[ref\]$tokens, \[ref\]$errors).
FindAll(\[Func\[Management.Automation.Language.Ast, bool\] \] {
param($ast)
$ast.CommandElements -and
$ast.CommandElements\[0\].Value -eq 'Context'
}, $true) |
ForEach {
$CE = $_.CommandElements
$secondString = ($CE |Where { $_.StaticType.name -eq 'string' })\[1\]
New-Object PSCustomObject -Property @{
Name = $secondString
}
}
@($Contexts).ForEach{
$title = $PSItem.Name.ToString().Trim('&amp;quot;').Trim('''')
It &amp;quot;$Title Should end with `$psitem So that the PowerBi will work correctly&amp;quot; {
$PSItem.Name.ToString().Endswith('psitem&amp;quot;')| Should Be $true
}
}
}
&lt;/code>&lt;/pre>
&lt;p>This time we look for the Context command and ensure that the string value ends with psitem as the PowerBi parses the last value when creating columns&lt;/p>
&lt;p>Finally I got all of the code and check if it matches some coding standards&lt;/p>
&lt;pre>&lt;code>Context &amp;quot;$($_.Name) - Checking Code&amp;quot; {
## This just grabs all the code
$AST = \[System.Management.Automation.Language.Parser\] ::ParseInput($Check, \[ref\]$null, \[ref\]$null)
$Statements = $AST.EndBlock.statements.Extent
## Ignore the filename line
@($Statements.Where{$_.StartLineNumber -ne 1}).ForEach{
$title = \[regex\]::matches($PSItem.text, &amp;quot;Describe(. *)-Tag&amp;quot;).groups\[1\].value.Replace('&amp;quot;', '').Replace ('''', '').trim()
It &amp;quot;$title Should Use Get-SqlInstance or Get-ComputerName&amp;quot; {
($PSItem.text -Match 'Get-SqlInstance') -or ($psitem.text -match 'Get-ComputerName')| Should be $true
}
It &amp;quot;$title Should use the ForEach Method&amp;quot; {
($Psitem.text -match 'Get-SqlInstance\\).ForEach {') -or ($Psitem.text -match 'Get-ComputerName\\). ForEach{')| Should Be $true# use the \ to escape the )
}
It &amp;quot;$title Should not use `$_&amp;quot; {
($Psitem.text -match '$_')| Should Be $false
}
It &amp;quot;$title Should Contain a Context Block&amp;quot; {
$Psitem.text -match 'Context'| Should Be $True
}
}
&lt;/code>&lt;/pre>
&lt;p>I trim the title from the Describe block so that it is easy to see where the failures (or passes) are with some regex and then loop through each statement apart from the first line to ensure that the code is using our internal commands Get-SQLInstance or Get-ComputerName to get information, that we are looping through each of those arrays using the ForEach method rather than ForEach-Object and using $psitem rather than $_ to reference the “This Item” in the array and that each Describe block has a context block.&lt;/p>
&lt;p>This should ensure that any new tests that are added to the module follow the guidance we have set up on the Wiki and ensure that the Power Bi results still look beautiful!&lt;/p>
&lt;p>Anyone can run the tests using&lt;/p>
&lt;pre>&lt;code>Invoke-Pester .\\tests\\Unit.Tests.ps1 -show Fails
&lt;/code>&lt;/pre>
&lt;p>before they create a Pull request and it looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/02-Pester-results-1.png"
loading="lazy"
>&lt;/p>
&lt;p>if everything is Green then they can submit their Pull Request 🙂 If not they can see quickly that something needs to be fixed. (fail early 🙂 )&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2018/01/03-fails.png"
loading="lazy"
alt="03 fails.png"
>&lt;/p></description></item><item><title>Converting a Datarow to a JSON object with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-a-datarow-to-a-json-object-with-powershell/</link><pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-a-datarow-to-a-json-object-with-powershell/</guid><description>&lt;p>This is just a quick post. As is frequent with these they are as much for me to refer to in the future and also because the very act of writing it down will aid me in remembering. I encourage you to do the same. Share what you learn because it will help you as well as helping others.&lt;/p>
&lt;p>Anyway, I was writing some Pester tests for a module that I was writing when I needed some sample data. I have &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>written before about using Json for this purpose&lt;/a> This function required some data from a database so I wrote the query to get the data and used &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> to run the query against the database using &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase" target="_blank" rel="noopener"
>Get-DbaDatabase&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance $Instance -Database $Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Simple enough. I wanted to be able to Mock &lt;code>$variable.&lt;/code> I wrapped the code above in a function, let’s call it &lt;code>Run-Query&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Run-Query {(Param $query)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance $Instance -Database $Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Which meant that I could easily separate it for mocking in my test. I ran the code and investigated the $variable variable to ensure it had what I wanted for my test and then decided to convert it into JSON using &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/convertto-json?view=powershell-5.1?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>ConvertTo-Json&lt;/a>&lt;/p>
&lt;p>Lets show what happens with an example using WideWorldImporters and a query I found on &lt;a class="link" href="https://littlekendra.com/2016/09/13/deadlock-code-for-the-wideworldimporters-sample-database/" target="_blank" rel="noopener"
>Kendra Littles blogpost about deadlocks&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SELECT Top 10 CityName, StateProvinceName, sp.LatestRecordedPopulation, CountryName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM Application.Cities AS city
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN Application.StateProvinces AS sp on
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">city.StateProvinceID = sp.StateProvinceID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN Application.Countries AS ctry on
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sp.CountryID=ctry.CountryID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE sp.StateProvinceName = N&amp;#39;Virginia&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ORDER BY CityName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = Get-DbaDatabase -SqlInstance rob-xps -Database WideWorldImporters
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$variable = $db.Query($Query)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If I investigate the &lt;code>$variable&lt;/code> variable I get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/data-results.png"
loading="lazy"
alt="data results"
>&lt;/p>
&lt;p>The results were just what I wanted so I thought I will just convert them to JSON and save them in a file and bingo I have some test data in a mock to ensure my code is doing what I expect. However, when I run&lt;/p>
&lt;p>&lt;code>$variable | ConvertTo-Json&lt;/code>&lt;/p>
&lt;p>I get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/json-error.png"
loading="lazy"
alt="json error.png"
>&lt;/p>
&lt;p>and thats just for one row!&lt;/p>
&lt;p>The way to resolve this is to only select the data that we need. The easiest way to do this is to exclude the properties that we don’t need&lt;/p>
&lt;p>&lt;code>$variable | Select-Object * -ExcludeProperty ItemArray, Table, RowError, RowState, HasErrors | ConvertTo-Json&lt;/code>&lt;/p>
&lt;p>which gave me what I needed and a good use case for -ExcludeProperty&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/12/json-fixed.png"
loading="lazy"
alt="json fixed.png"
>&lt;/p></description></item><item><title>Handling Missing Instances when Looping with Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/handling-missing-instances-when-looping-with-pester/</link><pubDate>Thu, 30 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/handling-missing-instances-when-looping-with-pester/</guid><description>&lt;p>In my previous posts about &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>writing your first Pester Test&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/2-ways-to-loop-through-collections-in-pester/" target="_blank" rel="noopener"
>looping through instances&lt;/a> I described how you can start to validate that your SQL Server is how YOU want it to be.&lt;/p>
&lt;h2 id="unavailable-machines">Unavailable machines&lt;/h2>
&lt;p>Once you begin to have a number of tests for a number of instances you want to be able to handle any machines that are not available cleanly otherwise you might end up with something like this.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-error.png"
loading="lazy"
alt="01 - error.png"
>&lt;/p>
&lt;p>In this (made up) example we loop through 3 instances and try to check the DNS Server entry is correct but for one of them we get a massive error and if we had created a large number of tests for each machine we would have a large number of massive errors.&lt;/p>
&lt;h2 id="empty-collection">Empty Collection&lt;/h2>
&lt;p>If we don’t successfully create our collection we might have an empty collection which will give us a different issue. No tests&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/02-no-tests.png"
loading="lazy"
alt="02 - no tests.png"
>&lt;/p>
&lt;p>If this was in amongst a whole number of tests we would not have tested anything in this Describe block and might be thinking that our tests were OK because we had no failures of our tests. We would be wrong!&lt;/p>
&lt;h2 id="dealing-with-empty-collections">Dealing with Empty Collections&lt;/h2>
&lt;p>One way of dealing with empty collections is to test that they have more than 0 members&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($instances.count -gt 0) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Tests in here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - The collection is empty. Did you set `$Instances correctly?&amp;#34;}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice the backtick ` before the $ to escape it in the Write-Warning. An empty collection now looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/03-uh-oh.png"
loading="lazy"
alt="03 - uh-oh.png"
>&lt;/p>
&lt;p>Which is much better and provides useful information to the user&lt;/p>
&lt;h2 id="dealing-with-unavailable-machines">Dealing with Unavailable Machines&lt;/h2>
&lt;p>If we want to make sure we dont clutter up our test results with a whole load of failures when a machine is unavailable we can use similar logic.&lt;/p>
&lt;p>First we could check if it is responding to a ping (assuming that ICMP is allowed by the firewall and switches) using&lt;/p>
&lt;p>&lt;code>Test-Connection -ComputerName $computer -Count 1 -Quiet -ErrorAction SilentlyContinue&lt;/code>&lt;/p>
&lt;p>This will just try one ping and do it quietly only returning True or False and if there are any errors it shouldn’t mention it&lt;/p>
&lt;p>In the example above I am using PSRemoting and we should make sure that that is working too. So whilst I could use&lt;/p>
&lt;p>&lt;code>Test-WSMan -ComputerName $computer&lt;/code>&lt;/p>
&lt;p>this only checks if a WSMAN connection is possible and not other factors that could be affecting the ability to run remote sessions. Having been caught by this before I have always used &lt;a class="link" href="http://www.leeholmes.com/blog/2009/11/20/testing-for-powershell-remoting-test-psremoting/" target="_blank" rel="noopener"
>this function from Lee Holmes&lt;/a> (Thank you Lee) and thus can use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $computer = $_.Split(&amp;#39;\\&amp;#39;)\[0\]# To get the computername if there is an instance name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if machine responds to ping
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!(Test-Connection-ComputerName $computer-Count 1-Quiet -ErrorAction SilentlyContinue))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - $Computer is not responding to a ping - aborting the tests for this machine&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if PSremoting is possible for this machine
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Requires Test-PSRemoting by Lee Holmes http://www.leeholmes.com/blog/2009/11/20/testing-for-powershell-remoting-test-psremoting/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!(Test-PsRemoting$computer))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - $Computer is not able to use PSRemoting - aborting the tests for this machine&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Testing Instance $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Put tests in here
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which provides a result like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/04-better-handling.png"
loading="lazy"
alt="04 - better handling.png"
>&lt;/p>
&lt;p>Which is much better I think 🙂&lt;/p>
&lt;h2 id="let-dbatools-do-the-error-handling-for-you">Let dbatools do the error handling for you&lt;/h2>
&lt;p>If your tests are only using the dbatools module then there is built in error handling that you can use. By default dbatools returns useful messages rather than the exceptions from PowerShell (You can enable the exceptions using the -EnableExceptions parameter if you want/need to) so if we run our example from the previous post it will look like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/05-dbatools-handling.png"
loading="lazy"
alt="05 - dbatools handling.png"
>&lt;/p>
&lt;p>which is fine for a single command but we don’t really want to waste time and resources repeatedly trying to connect to an instance if we know it is not available if we are running multiple commands against each instance.&lt;/p>
&lt;h2 id="dbatools-at-the-beginning-of-the-loop">dbatools at the beginning of the loop&lt;/h2>
&lt;p>We can use &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a>to perform a check at the beginning of the loop as we discussed in the &lt;a class="link" href="https://blog.robsewell.com/2-ways-to-loop-through-collections-in-pester/" target="_blank" rel="noopener"
>previous post&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!((Test-DbaConnection-SqlInstance $_ -WarningAction SilentlyContinue).ConnectSuccess))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - we cannot connect to $_ - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that we have used &lt;code>-WarningAction SilentlyContinue&lt;/code> to hide the warnings from the command this tiime. Our test now looks like&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/06-dbatools-test-dbaconnection.png"
loading="lazy"
alt="06 - dbatools test-dbaconnection.png"
>&lt;/p>
&lt;p>&lt;code>Test-DbaConnection&lt;/code> performs a number of tests so you can check for ping SQL version, domain name and remoting if you want to exclude tests on those basis&lt;/p>
&lt;h2 id="round-up">Round Up&lt;/h2>
&lt;p>In this post we have covered some methods of ensuring that your Pester Tests return what you expect. You don’t want empty collections of SQL Instances making you think you have no failed tests when you have not actually run any tests.&lt;/p>
&lt;p>You can do this by checking how many instances are in the collection&lt;/p>
&lt;p>You also dont want to keep running tests against a machine or instance that is not responding or available.&lt;/p>
&lt;p>You can do this by checking a ping with &lt;code>Test-Connection&lt;/code> or if remoting is required by using the &lt;code>Test-PSRemoting&lt;/code> function from Lee Holmes&lt;/p>
&lt;p>If you want to use dbatools exclusively you can use &lt;code>Test-DbaConnection&lt;/code>&lt;/p>
&lt;p>Here is a framework to put your tests inside. You will need to provide the values for the $Instances and place your tests inside the Describe Block&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($instances.count -gt 0) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $TestConnection = Test-DbaConnection-SqlInstance $_ -WarningAction SilentlyContinue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if machine responds to ping
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.IsPingable))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - $_ is not responding to a ping - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if we have remote access to the machine
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.PsRemotingAccessible))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - $_ is not able to use PSRemoting - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Check if we have SQL connection to the Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!($TestConnection.ConnectSuccess))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - - we cannot connect to SQL on $_ - aborting the tests for this instance&amp;#34;; Return}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;Testing Instance $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Now put your tests in here - seperate them with context blocks if you want to
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Networks&amp;#34; { }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## If the collection is empty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Warning &amp;#34;Uh-Oh - The Beard is Sad! - The collection is empty. Did you set `$Instances correctly?&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>2 Ways to Loop through collections in Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</link><pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</guid><description>&lt;p>In my last post I showed you &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>how to write your first Pester test&lt;/a> to validate something. Here’s a recap&lt;/p>
&lt;ul>
&lt;li>Decide the information you wish to test&lt;/li>
&lt;li>Understand how to get it with PowerShell&lt;/li>
&lt;li>Understand what makes it pass and what makes it fail&lt;/li>
&lt;li>Write a Pester Test&lt;/li>
&lt;/ul>
&lt;p>You probably have more than one instance that you want to test, so how do you loop through a collection of instances? There are a couple of ways.&lt;/p>
&lt;h2 id="getting-the-latest-version-of-the-module">Getting the Latest Version of the Module&lt;/h2>
&lt;p>Steve Jones wrote about getting the latest version of Pester and the correct way to do it. You can &lt;a class="link" href="https://voiceofthedba.com/2017/11/27/installing-pester/" target="_blank" rel="noopener"
>find the important information here&lt;/a>&lt;/p>
&lt;h2 id="test-cases">Test Cases&lt;/h2>
&lt;p>The first way is to use the Test Case parameter of the It command (the test) which I have written about when &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>using TDD for Pester here&lt;/a>&lt;/p>
&lt;p>Lets write a test first to check if we can successfully connect to a SQL Instance. Running&lt;/p>
&lt;p>&lt;code>Find-DbaCommand connection&lt;/code>&lt;/p>
&lt;p>shows us that the &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a> command is the one that we want from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>. We should always run Get-Help to understand how to use any PowerShell command. This shows us that the results will look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-gethelp-test-dbaconnection.png"
loading="lazy"
alt="01 - gethelp test-dbaconnection"
>&lt;/p>
&lt;p>So there is a ConnectSuccess result which returns True or false. Our test can look like this for a single instance&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to ROB-XPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    It &amp;#34;Connects successfully to ROB-XPS&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        (Test-DbaConnection-SqlInstance ROB-XPS).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which gives us some test results that look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/successful-test.png"
loading="lazy"
alt="successful test.png"
>&lt;/p>
&lt;p>which is fine for one instance but we want to check many.&lt;/p>
&lt;p>We need to gather the instances into a $Instances variable. In my examples I have hard coded a list of SQL Instances but you can, and probably should, use a more dynamic method, maybe the results of a query to a configuration database. Then we can fill our TestCases variable which can be done like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we can write our test like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to SQL Instances&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Put the TestCases &amp;#39;Name&amp;#39; in &amp;lt;&amp;gt; and add the TestCases parameter
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Connects successfully to &amp;lt;Instance&amp;gt;&amp;#34; -TestCases $TestCases {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Add a Parameter to the test with the same name as the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param($Instance)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write the test using the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Test-DbaConnection -SqlInstance $Instance).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Within the title of the test we refer to the instance inside &amp;lt;&amp;gt; and add the parameter TestCases with a value of the $TestCases variable. We also need to add a Param() to the test with the same name and then use that variable in the test.&lt;/p>
&lt;p>This looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/Testcases-test.png"
loading="lazy"
alt="Testcases test.png"
>&lt;/p>
&lt;h2 id="pester-is-powershell">Pester is PowerShell&lt;/h2>
&lt;p>The problem with  Test Cases is that we can only easily loop through one collection, but as Pester is just PowerShell we can simply use ForEach if we wanted to loop through multiple ones, like instances and then databases.&lt;/p>
&lt;p>I like to use the ForEach method as it is slightly quicker than other methods. It will only work with PowerShell version 4 and above. Below that version you need to pipe the collection to For-EachObject.&lt;/p>
&lt;p>Lets write a test to see if our databases have trustworthy set on. We can do this using the Trustworthy property returned from &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase/" target="_blank" rel="noopener"
>&lt;code>Get-DbaDatabase&lt;/code>&lt;/a>&lt;/p>
&lt;p>We loop through our Instances using the ForEach method and create a Context for each Instance to make the test results easier to read. We then place the call to &lt;code>Get-DbaDatabase &lt;/code>inside braces and loop through those and check the Trustworthy property&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing user databases&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the instances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Create a Context for each Instance.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing User Databases on $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the User databases on the instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Get-DbaDatabase -SqlInstance $_ -ExcludeAllSystemDb).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Refer to the database name and Instance name inside a $()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Database $($_.Name) on Instance $($_.Parent.Name) should not have TRUSTWORTHY ON&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $_.Trustworthy | Should Be $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and it looks like this&lt;/p>
&lt;h2 id="testdatabasetrustworthypnghttpsblogrobsewellcomassetsuploads201711testdatabasetrustworthypng">&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/testdatabasetrustworthy.png"
loading="lazy"
alt="testdatabasetrustworthy.png"
>&lt;/h2>
&lt;p>So there you have two different ways to loop through collections in your Pester tests. Hopefully this can help you to write some good tests to validate your environment.&lt;/p>
&lt;p>Happy Pestering&lt;/p>
&lt;h2 id="spend-a-whole-day-with-chrissy--i-at-sqlbits">Spend a Whole Day With Chrissy &amp;amp; I at SQLBits&lt;/h2>
&lt;p>If you would like to spend a whole day with Chrissy LeMaire and I at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> in London in February – we have a pre-con on the Thursday&lt;/p>
&lt;p>You can find out more about the pre-con &lt;a class="link" href="http://sqlps.io/bitsprecon" target="_blank" rel="noopener"
>sqlps.io/bitsprecon&lt;/a>&lt;/p>
&lt;p>and you can register at &lt;a class="link" href="http://sqlps.io/bitsreg" target="_blank" rel="noopener"
>sqlps.io/bitsreg&lt;/a>&lt;/p></description></item><item><title>2 Ways to Loop through collections in Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</link><pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2-ways-to-loop-through-collections-in-pester/</guid><description>&lt;p>In my last post I showed you &lt;a class="link" href="https://blog.robsewell.com/write-your-first-pester-test-today/" target="_blank" rel="noopener"
>how to write your first Pester test&lt;/a> to validate something. Here’s a recap&lt;/p>
&lt;ul>
&lt;li>Decide the information you wish to test&lt;/li>
&lt;li>Understand how to get it with PowerShell&lt;/li>
&lt;li>Understand what makes it pass and what makes it fail&lt;/li>
&lt;li>Write a Pester Test&lt;/li>
&lt;/ul>
&lt;p>You probably have more than one instance that you want to test, so how do you loop through a collection of instances? There are a couple of ways.&lt;/p>
&lt;h2 id="getting-the-latest-version-of-the-module">Getting the Latest Version of the Module&lt;/h2>
&lt;p>Steve Jones wrote about getting the latest version of Pester and the correct way to do it. You can &lt;a class="link" href="https://voiceofthedba.com/2017/11/27/installing-pester/" target="_blank" rel="noopener"
>find the important information here&lt;/a>&lt;/p>
&lt;h2 id="test-cases">Test Cases&lt;/h2>
&lt;p>The first way is to use the Test Case parameter of the It command (the test) which I have written about when &lt;a class="link" href="https://blog.robsewell.com/writing-dynamic-and-random-tests-cases-for-pester/" target="_blank" rel="noopener"
>using TDD for Pester here&lt;/a>&lt;/p>
&lt;p>Lets write a test first to check if we can successfully connect to a SQL Instance. Running&lt;/p>
&lt;p>&lt;code>Find-DbaCommand connection&lt;/code>&lt;/p>
&lt;p>shows us that the &lt;a class="link" href="https://dbatools.io/functions/test-dbaconnection/" target="_blank" rel="noopener"
>&lt;code>Test-DbaConnection&lt;/code>&lt;/a> command is the one that we want from the &lt;a class="link" href="http://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a>. We should always run Get-Help to understand how to use any PowerShell command. This shows us that the results will look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/01-gethelp-test-dbaconnection.png"
loading="lazy"
alt="01 - gethelp test-dbaconnection"
>&lt;/p>
&lt;p>So there is a ConnectSuccess result which returns True or false. Our test can look like this for a single instance&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to ROB-XPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    It &amp;#34;Connects successfully to ROB-XPS&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        (Test-DbaConnection-SqlInstance ROB-XPS).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which gives us some test results that look like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/successful-test.png"
loading="lazy"
alt="successful test.png"
>&lt;/p>
&lt;p>which is fine for one instance but we want to check many.&lt;/p>
&lt;p>We need to gather the instances into a $Instances variable. In my examples I have hard coded a list of SQL Instances but you can, and probably should, use a more dynamic method, maybe the results of a query to a configuration database. Then we can fill our TestCases variable which can be done like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we can write our test like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create an empty array
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$TestCases = @()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Fill the Testcases with the values and a Name of Instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances.ForEach{$TestCases += @{Instance = $_}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing connection to SQL Instances&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Put the TestCases &amp;#39;Name&amp;#39; in &amp;lt;&amp;gt; and add the TestCases parameter
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Connects successfully to &amp;lt;Instance&amp;gt;&amp;#34; -TestCases $TestCases {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Add a Parameter to the test with the same name as the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param($Instance)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Write the test using the TestCases Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Test-DbaConnection -SqlInstance $Instance).ConnectSuccess | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Within the title of the test we refer to the instance inside &amp;lt;&amp;gt; and add the parameter TestCases with a value of the $TestCases variable. We also need to add a Param() to the test with the same name and then use that variable in the test.&lt;/p>
&lt;p>This looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/Testcases-test.png"
loading="lazy"
alt="Testcases test.png"
>&lt;/p>
&lt;h2 id="pester-is-powershell">Pester is PowerShell&lt;/h2>
&lt;p>The problem with  Test Cases is that we can only easily loop through one collection, but as Pester is just PowerShell we can simply use ForEach if we wanted to loop through multiple ones, like instances and then databases.&lt;/p>
&lt;p>I like to use the ForEach method as it is slightly quicker than other methods. It will only work with PowerShell version 4 and above. Below that version you need to pipe the collection to For-EachObject.&lt;/p>
&lt;p>Lets write a test to see if our databases have trustworthy set on. We can do this using the Trustworthy property returned from &lt;a class="link" href="https://dbatools.io/functions/Get-DbaDatabase/" target="_blank" rel="noopener"
>&lt;code>Get-DbaDatabase&lt;/code>&lt;/a>&lt;/p>
&lt;p>We loop through our Instances using the ForEach method and create a Context for each Instance to make the test results easier to read. We then place the call to &lt;code>Get-DbaDatabase &lt;/code>inside braces and loop through those and check the Trustworthy property&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Get a list of SQL Servers
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Use whichever method suits your situation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Maybe from a configuration database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># I&amp;#39;m just using a hard-coded list for example
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instances = &amp;#39;ROB-XPS&amp;#39;,&amp;#39;ROB-XPS\DAVE&amp;#39;,&amp;#39;ROB-XPS\BOLTON&amp;#39;,&amp;#39;ROB-XPS\SQL2016&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing user databases&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the instances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances.ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Create a Context for each Instance.
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Testing User Databases on $($_)&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Loop through the User databases on the instance
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (Get-DbaDatabase -SqlInstance $_ -ExcludeAllSystemDb).ForEach{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Refer to the database name and Instance name inside a $()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;Database $($_.Name) on Instance $($_.Parent.Name) should not have TRUSTWORTHY ON&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $_.Trustworthy | Should Be $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and it looks like this&lt;/p>
&lt;h2 id="testdatabasetrustworthypnghttpsblogrobsewellcomassetsuploads201711testdatabasetrustworthypng">&lt;img src="https://blog.robsewell.com/assets/uploads/2017/11/testdatabasetrustworthy.png"
loading="lazy"
alt="testdatabasetrustworthy.png"
>&lt;/h2>
&lt;p>So there you have two different ways to loop through collections in your Pester tests. Hopefully this can help you to write some good tests to validate your environment.&lt;/p>
&lt;p>Happy Pestering&lt;/p>
&lt;h2 id="spend-a-whole-day-with-chrissy--i-at-sqlbits">Spend a Whole Day With Chrissy &amp;amp; I at SQLBits&lt;/h2>
&lt;p>If you would like to spend a whole day with Chrissy LeMaire and I at &lt;a class="link" href="http://sqlbits.com" target="_blank" rel="noopener"
>SQLBits&lt;/a> in London in February – we have a pre-con on the Thursday&lt;/p>
&lt;p>You can find out more about the pre-con &lt;a class="link" href="http://sqlps.io/bitsprecon" target="_blank" rel="noopener"
>sqlps.io/bitsprecon&lt;/a>&lt;/p>
&lt;p>and you can register at &lt;a class="link" href="http://sqlps.io/bitsreg" target="_blank" rel="noopener"
>sqlps.io/bitsreg&lt;/a>&lt;/p></description></item><item><title>Write Your first Pester Test Today</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/write-your-first-pester-test-today/</link><pubDate>Thu, 16 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/write-your-first-pester-test-today/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>TSQL2sDay – Folks Who Have Made a Difference</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-folks-who-have-made-a-difference/</link><pubDate>Tue, 14 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-folks-who-have-made-a-difference/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Comparing Agent Jobs across Availability Group Replicas with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/comparing-agent-jobs-across-availability-group-replicas-with-powershell/</link><pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/comparing-agent-jobs-across-availability-group-replicas-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Plaster To Create a New PowerShell Module</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-plaster-to-create-a-new-powershell-module/</link><pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-plaster-to-create-a-new-powershell-module/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>dbatools with SQL on Docker and running SQL queries</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-with-sql-on-docker-and-running-sql-queries/</link><pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-with-sql-on-docker-and-running-sql-queries/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>$srv.Query($Query)&lt;/p>
&lt;p>$srv.Query($Query).column1&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>A Pretty PowerBi Pester Results Template File</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-pretty-powerbi-pester-results-template-file/</link><pubDate>Sun, 29 Oct 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-pretty-powerbi-pester-results-template-file/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>TSQL2sDay – Get-PostRoundup</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</link><pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-get-postroundup/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>#TSQL2sDay – Starting Out with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-starting-out-with-powershell/</link><pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-starting-out-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Automatically updating the version number in a PowerShell Module – How I do regex</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/automatically-updating-the-version-number-in-a-powershell-module-how-i-do-regex/</link><pubDate>Sat, 09 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/automatically-updating-the-version-number-in-a-powershell-module-how-i-do-regex/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>[version]$Version = [regex]::matches($file, &amp;ldquo;\s&lt;em>ModuleVersion\s=\s&amp;rsquo;(\d&lt;/em>.\d*.\d*)&amp;rsquo;\s*&amp;rdquo;).groups[1].value&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h1 id="use-regex-to-get-the-version-number-and-set-it-as-a-version-datatype">Use RegEx to get the Version Number and set it as a version datatype&lt;/h1>
&lt;h1 id="s---between-0-and-many-whitespace">\s* - between 0 and many whitespace&lt;/h1>
&lt;h1 id="moduleversion---literal">ModuleVersion - literal&lt;/h1>
&lt;h1 id="s---1-whitespace">\s - 1 whitespace&lt;/h1>
&lt;h1 id="---literal">= - literal&lt;/h1>
&lt;h1 id="s---1-whitespace-1">\s - 1 whitespace&lt;/h1>
&lt;h1 id="---literal-1">&amp;rsquo; - literal&lt;/h1>
&lt;h1 id="---capture-group">() - capture Group&lt;/h1>
&lt;h1 id="d---between-0-and-many-digits">\d* - between 0 and many digits&lt;/h1>
&lt;h1 id="---literal-2">&amp;rsquo; - literal&lt;/h1>
&lt;h1 id="s-between-0-and-many-whitespace">\s* between 0 and many whitespace&lt;/h1>
&lt;p>[version]$Version = [regex]::matches($file, &amp;ldquo;\s&lt;em>ModuleVersion\s=\s&amp;rsquo;(\d&lt;/em>.\d*.\d*)&amp;rsquo;\s*&amp;rdquo;).groups[1].value
Write-Output &amp;ldquo;Old Version - $Version&amp;rdquo;&lt;/p>
&lt;h1 id="add-one-to-the-build-of-the-version-number">Add one to the build of the version number&lt;/h1>
&lt;p>[version]$NewVersion = &amp;ldquo;{0}.{1}.{2}&amp;rdquo; -f $Version.Major, $Version.Minor, ($Version.Build + 1)
Write-Output &amp;ldquo;New Version - $NewVersion&amp;rdquo;&lt;/p>
&lt;h1 id="replace-old-version-number-with-new-version-number-in-the-file">Replace Old Version Number with New Version number in the file&lt;/h1>
&lt;p>try {
(Get-Content .\BeardAnalysis.psd1) -replace $version, $NewVersion | Out-File .\BeardAnalysis.psd1
Write-Output &amp;ldquo;Updated Module Version from $Version to $NewVersion&amp;rdquo;
}
catch {
$_
Write-Error &amp;ldquo;failed to set file&amp;rdquo;
}
&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>TSQL2sday #94 Lets get all Posh!</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</link><pubDate>Tue, 05 Sep 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/tsql2sday-#94-lets-get-all-posh/</guid><description>&lt;p>Write-Output &amp;ldquo;What are you going to automate today?&amp;rdquo;&lt;/p>
&lt;p> &lt;/p>
&lt;p>Welcome to T-SQL Tuesday for September 2017!&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/08/tsql2sday.jpg"
loading="lazy"
alt="tsql2sday"
>
&lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>T-SQL Tuesday&lt;/a> is a chance for you to join in the SQL Server community and write a blog post on a suggested topic. It makes for a great way to find a bunch of blog posts showing the same subject from many different viewpoints. Please join in and write a blog post, maybe it&amp;rsquo;s your first ever, maybe you haven&amp;rsquo;t blogged for a while but even if you blog every day come and join the party and share your knowledge.&lt;/p>
&lt;p>To participate:&lt;/p>
&lt;ol>
&lt;li>Write a post on the topic below&lt;/li>
&lt;li>Schedule the post to go live on Tuesday, September 12th (between zero am and midnight, UTC)&lt;/li>
&lt;li>Include the &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2010/06/01/t-sql-tuesday-007-and-t-sql-tuesday-has-a-logo.aspx" target="_blank" rel="noopener"
>TSQL Tuesday logo&lt;/a> in the top of your post&lt;/li>
&lt;li>Link the post back to this one (it’s easier if you comment on this post and link it)&lt;/li>
&lt;li>Optional: Tweet a link to your post using the &lt;a class="link" href="https://twitter.com/hashtag/TSQL2sday?src=hash" target="_blank" rel="noopener"
>#tsql2sday hash tag on Twitter&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Extra credit: if you’d like to host your own TSQL Tuesday in the future, &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2017/01/03/t-sql-tuesday-rules-of-engagement.aspx" target="_blank" rel="noopener"
>read the full rules for info on how to sign up&lt;/a>. Just like I did but don&amp;rsquo;t forget its your month!!&lt;/p>
&lt;h2 id="this-months-topic-lets-get-all-posh---what-are-you-going-to-automate-today">This month’s topic: Let&amp;rsquo;s get all Posh - What are you going to automate today?&lt;/h2>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/PowerShell.png"
loading="lazy"
alt="PowerShell"
>
It is no surprise to those that know me that I will choose PowerShell as the topic for this month. I am passionate about PowerShell because it has enabled me to have the career I have today and to visit numerous countries all around the world, meet people and talk about PowerShell. By my reckoning &lt;a class="link" href="http://tsqltuesday.com/?s=PowerShell" target="_blank" rel="noopener"
>searching the TSQL Tuesday website&lt;/a> it has been over 3 years since we had a topic specific to PowerShell. So I would like you to blog about PowerShell and SQL Server (or other interesting data platform products)&lt;/p>
&lt;p>If you don&amp;rsquo;t know or use PowerShell GREAT! That&amp;rsquo;s awesome.&lt;/p>
&lt;p>Please spend an hour or so with it and tell us how you got on and what and how you learned. Just like &lt;a class="link" href="https://www.brentozar.com/archive/2017/07/live-blogging-erik-vs-PowerShell/" target="_blank" rel="noopener"
>Erik and Brent did&lt;/a>. You could install one of the community modules like &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>, &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> , &lt;a class="link" href="https://www.PowerShellgallery.com/packages/SQLDiagAPI" target="_blank" rel="noopener"
>SQLDiagAPI&lt;/a>  or the Microsoft ones &lt;a class="link" href="https://www.PowerShellgallery.com/packages/Sqlserver" target="_blank" rel="noopener"
>sqlserver&lt;/a> or &lt;a class="link" href="https://github.com/Microsoft/ReportingServicesTools" target="_blank" rel="noopener"
>SSRS&lt;/a> and try them out and tell us what you learned.&lt;/p>
&lt;p>If you want help whilst doing this please make use of the #PowerShellhelp channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a>&lt;/p>
&lt;p>This will be of so much benefit to all people who don&amp;rsquo;t use PowerShell and want to start to learn about it.&lt;/p>
&lt;p>If you do use PowerShell and SQL then either tell the tale of the best thing you have automated or a beginners post to show people how to start using PowerShell. I have heard many stories and am looking forward to tales of&lt;/p>
&lt;ul>
&lt;li>testing backups&lt;/li>
&lt;li>doing migrations&lt;/li>
&lt;li>resetting log shipping&lt;/li>
&lt;li>creating things in the cloud and on premises&lt;/li>
&lt;li>SQL on Linux with PowerShell on Linux&lt;/li>
&lt;li>using Pester for testing&lt;/li>
&lt;li>automating manual tasks&lt;/li>
&lt;li>automating incident knowledge gathering&lt;/li>
&lt;li>continuous integration and delivery&lt;/li>
&lt;/ul>
&lt;p>and many more. I will read all of them and do a write up of them later next week.&lt;/p>
&lt;p>Invoke-Coffee&lt;/p>
&lt;p>Start-BlogWriting -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Get-BlogProofRead&lt;/p>
&lt;p>Post-Blog -Date ‘September 12th 2017’ -Title &amp;lsquo;Cool PowerShell Post&amp;rsquo;&lt;/p>
&lt;p>Write-Tweet -Hashtag ‘TSQL2sday’ -Message &amp;lsquo;This is my cool blogpost&amp;rsquo;&lt;/p>
&lt;p> &lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/09/keep-calm-and-PowerShell.jpg"
loading="lazy"
alt="keep calm and PowerShell.jpg"
>&lt;/p></description></item><item><title>PSDay.UK Tickets are on sale</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/psday.uk-tickets-are-on-sale/</link><pubDate>Sun, 13 Aug 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/psday.uk-tickets-are-on-sale/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using PowerShell to check if your password has been in a breach</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-check-if-your-password-has-been-in-a-breach/</link><pubDate>Wed, 09 Aug 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-check-if-your-password-has-been-in-a-breach/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>I Hate Interviews – TSQL2sDay</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/i-hate-interviews-tsql2sday/</link><pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/i-hate-interviews-tsql2sday/</guid><description>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/08/tsql2sday.jpg" alt="Featured image of post I Hate Interviews – TSQL2sDay" />&lt;p>&lt;a class="link" href="https://littlekendra.com/2017/08/01/tsql-tuesday-93-interviewing-patterns-anti-patterns/" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/08/tsql2sday.jpg"
loading="lazy"
alt="tsql2sday"
>&lt;/a>&lt;/p>
&lt;p>This month’s &lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>T-SQL Tuesday&lt;/a> is hosted by &lt;a class="link" href="https://littlekendra.com/2017/08/01/tsql-tuesday-93-interviewing-patterns-anti-patterns/" target="_blank" rel="noopener"
>Kendra Little and is on the topic of interviews &lt;/a>&lt;/p>
&lt;p>I hate interviews as an interviewee. I have had many memorable experiences with them. Even writing this blog post has been challenging as I relive some of them. I haven’t shared a lot of the worst ones!&lt;/p>
&lt;h2 id="when-i-was-a-lad">When I was a lad&lt;/h2>
&lt;p>My first interview was for a waiter/washer up at a local country pub aged 15 or so. I stumbled and stammered and stuttered my way through and I think it was only because they needed someone that evening that I got the job.&lt;/p>
&lt;p>When I was 17 I wanted a car and whilst doing my A-Levels I got a job at a local private school to achieve this. It was about a 10 minute cycle from my college to the school and I was so nervous that about half-way I was incapable of riding my bike and had to walk. I then was faced with two people interviewing me which I was not expecting or prepared for. I remember nothing of the interview other than leaving it soaking in sweat.&lt;/p>
&lt;h2 id="nerves">Nerves&lt;/h2>
&lt;p>As a young man I interviewed for numerous jobs and things got progressively worse for me. I would get so incredibly nervous. I could not sleep or eat before an interview. This meant I often was feeling very nauseous and tired during an interview. I would arrive incredibly early and have to waste time wandering around, giving me more time to think about how nervous I was and, of course, making it worse. Obviously I wouldn’t give a good impression and didn’t get the jobs which meant more interviews and more nerves.&lt;/p>
&lt;p>I tried many things, I sought advice and information from many sources and approached the situation in a number of different ways without much change to my internal responses.&lt;/p>
&lt;h2 id="preparation-practice-knowledge-and-distraction">Preparation, Practice, Knowledge and Distraction&lt;/h2>
&lt;p>To this day I hate interviews even after 20 years of having to do them. I can still get so overcome by nerves that I forget even the simplest and most obvious things such as what the N in DNS stands for or what the question is that I should be answering.&lt;/p>
&lt;p>To minimise this, I try my best to prepare as well as I possibly can. I learn and revise the things I think I will need to show that I know by reading the job descriptions and adverts carefully.&lt;/p>
&lt;p>I also split the whole process into separate boxes. Revising and researching a company and a job was one part. Getting ready and travelling and arriving was another and the actual interview was then just the last part consisting of talking to some people. This definitely reduced the overall stress and improved my performance in interviews.&lt;/p>
&lt;p>A previous shop provided interviewer training and needed volunteers to be interviewed for those courses. I volunteered as often as I was able to and treated them as realistically as was feasible. This helped me a lot and also enabled me (sometimes) to view an interview as just a chat. If you suffer with nerves and this is available I would recommend doing so. If not, ask someone who interviews for some practice interviews and treat them as realistically as you feel is necessary.&lt;/p>
&lt;p>A wise person told me to remember that interviewers are people too and also that good interviewers will recognise nerves and assist the interviewee. After all, they are trying to find the right person to fulfil their needs and want to know if you meet their requirements for that position.&lt;/p>
&lt;p>Another wise person told me, during an interview, that it was ok to ask for clarification about a question. A decade or more of interviews before I knew that. It enables me to pull back from a spiral of nerves making me gabble and to be able to return to the question required. When I find that I am rambling in my answer or that the answer has disappeared from my mind I ask the interviewer for clarification and get some much needed breathing space.&lt;/p>
&lt;p>To reduce the impact of nervousness before the interview I learnt to distract myself in the couple of hours prior to an interview. I have been known to go and see a film if a cinema is close to the interview or do the weekly shopping. Anything that can occupy my mind without risking me being late. This may be of no use to many people but it works for me.&lt;/p>
&lt;h2 id="the-other-side-of-the-table">The other side of the table&lt;/h2>
&lt;p>As an interviewer, I hope that I recognise when people are nervous and am able to assist them and also coax out the information that I need to be able to make the best decision about the candidate for the position.&lt;/p>
&lt;p>Interviewing is tiring.&lt;/p>
&lt;p>When I worked in &lt;a class="link" href="https://en.wikipedia.org/wiki/Psychiatric_hospital#Secure_units" target="_blank" rel="noopener"
>secure units&lt;/a> we would sometimes spend 2 continuous days interviewing. It is hard work. You need to look after yourself in these situations. It is important to drink plenty of water, to ensure that you eat and at least get up and stretch in between interviews. The very last person you interview might be the perfect candidate don’t miss that because you have switched off.&lt;/p>
&lt;h2 id="you-are-being-interviewed-too">You are being interviewed too&lt;/h2>
&lt;p>The person that you are interviewing is also interviewing you. They are considering if they want to come and work for your company with the people they meet. That might only be the people in the interview so it is important I think to ensure that you make a good impression as well. During a day of interviewing many candidates try to reset before each person.&lt;/p>
&lt;p>Being courteous, attentive and professional is important during the interview even if the interviewers recognise that the person is not suitable for that role within 2 minutes. They may be ideal for another position or you may come across them later in your career. Leave a good impression.&lt;/p>
&lt;h2 id="preparation">Preparation&lt;/h2>
&lt;p>A shop I worked at employed a new DBA who had impressed the manager in interview with their knowledge as they had passed a lot of exams. The manager was very pleased and looking forward to the new arrival. This changed quite quickly when it became obvious that the new DBA was missing some basic knowledge about installing SQL Server and creating new databases which was a significant part of their role. A lot of time was wasted by the other DBAs in the team re-doing and re-checking the work that this person had done and team dynamics went downhill very quickly (although I did learn a lot about Policy Based Management from this experience!)&lt;/p>
&lt;p>When I was working in secure units focusing on people with Autism we knew that communication skills both verbal and non-verbal were vital to all members of our team. We had an excellent set of questions and scenarios early in the interview to establish peoples capabilities in these areas and this allowed us to close off interviews early when we could see that the candidate did not meet our requirements as well as ensuring we employed people with the right skills for a very challenging workplace.&lt;/p>
&lt;p>Before the interviews for a replacement DBA the manager asked how to avoid a repeat of that situation. I described the situation above and as a team we identified the basic skills, knowledge and approaches that we wanted in our future team members and designed a set of questions and scenarios so that candidates could demonstrate them. This was excellent for ensuring the entire team felt that they had some input into the recruiting process and also added confidence in the new team member. I think it was an excellent piece of team management as well.&lt;/p>
&lt;p>The biggest take away from this post, I hope, is preparation. For both sides of the table preparation is a vital part of any interview process. Also if you see me all dressed up and in the queue for a film I am probably very nervous and won’t want to chat!!&lt;/p>
&lt;blockquote>
&lt;p>Make sure that you go and visit the round-up post that &lt;a class="link" href="https://littlekendra.com" target="_blank" rel="noopener"
>Kendra posts on her blog&lt;/a> to read further posts on the interviewing process from others in the SQL Community. You can also find all the archives at &lt;a class="link" href="http://tsqltuesday.com/" target="_blank" rel="noopener"
>http://tsqltuesday.com/&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Any resemblance to any living people in this post apart from myself is complete co-incidence&lt;/p></description></item><item><title>Presentation Nerves</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/presentation-nerves/</link><pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/presentation-nerves/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Announcing PSDay.UK – Whats a PSDay?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-psday.uk-whats-a-psday/</link><pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/announcing-psday.uk-whats-a-psday/</guid><description>&lt;p>On Thursday evening I attended the joint London WinOps and PowerShell User Group. It was an excellent evening with two great sessions by Jaap Brasser and Filip Verloy.&lt;/p>
&lt;h2 id="psdayuk">PSDay.UK&lt;/h2>
&lt;p>There was also an exciting announcement about PSDay.UK  &lt;a class="link" href="https://psday.uk" target="_blank" rel="noopener"
>https://psday.uk&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Look look&lt;br>
A whole day of PowerShell&lt;br>
In London&lt;br>
Just after &lt;a class="link" href="https://twitter.com/WinOpsLDN" target="_blank" rel="noopener"
>@WinOpsLDN&lt;/a>&lt;br>
It&amp;rsquo;s going to be awesome&lt;a class="link" href="https://t.co/CAQqoc2cgX" target="_blank" rel="noopener"
>https://t.co/CAQqoc2cgX&lt;/a>&lt;br>
Follow &lt;a class="link" href="https://twitter.com/psdayuk" target="_blank" rel="noopener"
>@psdayuk&lt;/a> &lt;a class="link" href="https://t.co/3RFHpXpRI1" target="_blank" rel="noopener"
>pic.twitter.com/3RFHpXpRI1&lt;/a>&lt;/p>
&lt;p>— Rob Sewell (@sqldbawithbeard) &lt;a class="link" href="https://twitter.com/sqldbawithbeard/status/888111785022169088" target="_blank" rel="noopener"
>July 20, 2017&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>PSDay.UK is a one day PowerShell event providing the opportunity for you to spend a whole day learning PowerShell from renowned experts from the UK and international speaking community. It will be held at&lt;/p>
&lt;p>Skills Matter | CodeNode, 10 South Place, London, EC2M 7EB, GB&lt;/p>
&lt;p>on&lt;/p>
&lt;p>Friday 22nd September 2017  &lt;a class="link" href="https://calendar.google.com/calendar/ical/pvrdkbsp8qbkgpt1cg6cethp0o%40group.calendar.google.com/public/basic.ics" target="_blank" rel="noopener"
>.ics&lt;/a>&lt;/p>
&lt;p>We will be running two tracks&lt;/p>
&lt;ul>
&lt;li>PowerShell Zero to Hero&lt;/li>
&lt;li>DevOps with PowerShell&lt;/li>
&lt;/ul>
&lt;h2 id="register-your-interest">Register your interest&lt;/h2>
&lt;p>Please go and &lt;a class="link" href="https://psday.uk" target="_blank" rel="noopener"
>visit the website&lt;/a> and have a look and register your interest to get further notifications about the event.&lt;/p>
&lt;p>Follow the &lt;a class="link" href="https://twitter.com/@PSDayUK" target="_blank" rel="noopener"
>@PSDayUK&lt;/a> twitter account and Facebook page &lt;a class="link" href="https://www.facebook.com/PSDayUK/" target="_blank" rel="noopener"
>https://www.facebook.com/PSDayUK/&lt;/a> and keep yourself informed on this fantastic new event.&lt;/p>
&lt;h2 id="want-to-speak-at-psdayuk-">Want to Speak at PSDay.UK ?&lt;/h2>
&lt;p>We already have some fantastic speakers lined up but we would like to invite people to send us submissions for more sessions. If you have a PowerShell talk that will fit into one of the tracks and experience of delivering sessions at events &lt;a class="link" href="https://psday.uk/submit-talk/" target="_blank" rel="noopener"
>please send us submissions via the website.&lt;/a>&lt;br>
If you have questions about speaking feel free to contact me via twitter at &lt;a class="link" href="https://twitter.com/sqldbawithbeard" target="_blank" rel="noopener"
>@sqldbawithbeard&lt;/a>&lt;/p>
&lt;h2 id="what-is-a-psday-">What is a PSDay ?&lt;/h2>
&lt;p>The International PowerShell community has three main global events which run over a number of days with top notch international speakers and Microsoft PowerShell team members, delivering in-depth information about the latest PowerShell trends and technologies, and connecting national communities with another.&lt;/p>
&lt;ul>
&lt;li>&lt;a class="link" href="http://psconf.eu/" target="_blank" rel="noopener"
>psconf.eu&lt;/a> covers the European communities, Hannover, Germany April 16-20 2018&lt;/li>
&lt;li>&lt;a class="link" href="http://psconf.asia" target="_blank" rel="noopener"
>psconf.asia&lt;/a> targets the Asian communities, Singapore October 27-28 2017&lt;/li>
&lt;li>&lt;a class="link" href="https://powershell.org/summit/" target="_blank" rel="noopener"
>PowerShell+DevOps Global Summit&lt;/a> targets the US communities April 9-12 2018&lt;/li>
&lt;/ul>
&lt;p>There are a number of other PowerShell events that have been organised by wonderful volunteers in numerous countries and we feel there is an opportunity to create national events which complement the global events and help PowerShell passionates and professionals to get in touch and learn from another with a similar branding of PSDay.&lt;/p>
&lt;p>We foresee PSDays to be smaller one day national events promoting speakers from the host country supported by other international speakers with the aim of increasing the exposure of national PowerShell user groups as well as providing excellent PowerShell training.&lt;/p>
&lt;p>There will be a board of PowerShell community folk set up who will approve requests to use the PSDay name and shield logo providing the event is professionally organized and offer help with technical questions, viral marketing, and experience. We hope that this will enable people to set up their own PSDay in their own country and increase the exposure of the PowerShell community as well as PowerShell knowledge whilst sharing resources, knowledge, experience and skills and ensuring a good standard of PowerShell community national events.&lt;/p>
&lt;p>Further details of this will be forthcoming and we welcome offers of assistance from people with relevant experience&lt;/p></description></item><item><title>Writing Dynamic and Random Tests Cases for Pester</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/writing-dynamic-and-random-tests-cases-for-pester/</link><pubDate>Thu, 06 Jul 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/writing-dynamic-and-random-tests-cases-for-pester/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Get-SQLDiagFix to get information from the SQL Server Diagnostic API with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-get-sqldiagfix-to-get-information-from-the-sql-server-diagnostic-api-with-powershell/</link><pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-get-sqldiagfix-to-get-information-from-the-sql-server-diagnostic-api-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Creating a PowerShell Module and TDD for Get-SQLDiagRecommendations</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</link><pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-powershell-module-and-tdd-for-get-sqldiagrecommendations/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>PowerShell Module for the SQL Server Diagnostics API – 1st Command Get-SQLDiagRecommendations</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-module-for-the-sql-server-diagnostics-api-1st-command-get-sqldiagrecommendations/</link><pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-module-for-the-sql-server-diagnostics-api-1st-command-get-sqldiagrecommendations/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>VSCode – PowerShell extension 1.4.0 new command Out-CurrentFile</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vscode-powershell-extension-1.4.0-new-command-out-currentfile/</link><pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vscode-powershell-extension-1.4.0-new-command-out-currentfile/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>dbatools at #SQLSatDublin</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-at-#sqlsatdublin/</link><pubDate>Wed, 21 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dbatools-at-#sqlsatdublin/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>VS Code – Automatic Dynamic PowerShell Help</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-automatic-dynamic-powershell-help/</link><pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-automatic-dynamic-powershell-help/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Pester for Presentations – Ensuring it goes ok</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-for-presentations-ensuring-it-goes-ok/</link><pubDate>Tue, 16 May 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-for-presentations-ensuring-it-goes-ok/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>}
&lt;/code>&lt;/pre>
&lt;p>}&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>Pester Test Inception and the Show Parameter</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-test-inception-and-the-show-parameter/</link><pubDate>Tue, 09 May 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/pester-test-inception-and-the-show-parameter/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</link><pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png" alt="Featured image of post PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value" />&lt;p>I was chatting on the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Community Slack&lt;/a> with my friend Sander Stad &lt;a class="link" href="http://www.sqlstad.nl/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/sqlstad" target="_blank" rel="noopener"
>t&lt;/a> about some functions he is writing for the amazing PowerShell SQL Server Community module &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a>. He was asking my opinion as to how to enable user choice or options for Agent Schedules and I said that he should validate the input of the parameters. He said that was difficult as if the parameter was Weekly the frequency values required would be different from if the parameter was Daily or Monthly. That’s ok, I said, you can still validate the parameter.&lt;/p>
&lt;p>You can read more about Parameters either online &lt;a class="link" href="https://msdn.microsoft.com/en-us/powershell/reference/5.1/microsoft.powershell.core/about/about_parameters" target="_blank" rel="noopener"
>here&lt;/a> or &lt;a class="link" href="https://msdn.microsoft.com/en-us/powershell/reference/5.1/microsoft.powershell.core/about/about_functions_advanced_parameters" target="_blank" rel="noopener"
>here&lt;/a> or by running&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Get-Help About_Parameters
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-Help About_Functions_Parameters
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can also find more help information with&lt;/p>
&lt;p>&lt;code>Get-Help About_*Parameters*&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/01-more-help.png"
loading="lazy"
alt="01 more help.PNG"
>&lt;/a>&lt;/p>
&lt;p>This is not a post about using Parameters, &lt;a class="link" href="https://www.google.co.uk/search?q=powershell&amp;#43;about&amp;#43;paramters&amp;amp;ie=&amp;amp;oe=#safe=strict&amp;amp;q=powershell&amp;#43;parameters&amp;amp;spf=370" target="_blank" rel="noopener"
>google for those&lt;/a> but this is what I showed him.&lt;/p>
&lt;p>Lets create a simple function that accepts 2 parameters Word and Number&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can run it with any parameters&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/02-any-parameters.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/02-any-parameters.png"
loading="lazy"
alt="02 any parameters"
>&lt;/a>&lt;/p>
&lt;p>If we wanted to restrict the Word parameter to only accept Sun, Moon or Earth we can use the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/ms714434%28v=vs.85%29.aspx" target="_blank" rel="noopener"
>ValidateSetAttribute&lt;/a> as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now if we try and set a value for the $Word parameter that isn’t sun moon or earth then we get an error&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/03-parameter-error.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/03-parameter-error.png"
loading="lazy"
alt="03 parameter error.PNG"
>&lt;/a>&lt;/p>
&lt;p>and it tells us that the reason for the error is that TheBeard! does not belong to the set sun, moon, earth.&lt;/p>
&lt;p>But what Sander wanted was to validate the value of the second parameter depending on the value of the first one. So lets say we wanted&lt;/p>
&lt;ul>
&lt;li>If word is sun, number must be 1 or 2&lt;/li>
&lt;li>If word is moon, number must be 3 or 4&lt;/li>
&lt;li>If word is earth, number must be 5 or 6&lt;/li>
&lt;/ul>
&lt;p>We can use the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/system.management.automation.validatescriptattribute%28v=vs.85%29.aspx" target="_blank" rel="noopener"
>ValidateScriptAttribute&lt;/a>  to do this. This requires a script block which returns True or False. You can access the current parameter with &lt;code>$_&lt;/code> so we can use a script block like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The function now looks like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateScript({
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        })]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>It will still fail if we use the wrong “Word” in the same way but now if we enter earth and 7 we get this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/04-parameter-error.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/04-parameter-error.png"
loading="lazy"
alt="04 parameter error.PNG"
>&lt;/a>&lt;/p>
&lt;p>But if we enter sun and 1 or moon and 3 or earth and 5 all is well&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/05-working.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/05-working.png"
loading="lazy"
alt="05 working"
>&lt;/a>&lt;/p>
&lt;p>I would add one more thing. We should always write PowerShell functions that are easy for our users to self-help. Of course, this means write good help for the function. here is a great place to start from June Blender&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/06-june.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/06-june.png"
loading="lazy"
alt="06 June.PNG"
>&lt;/a>&lt;/p>
&lt;p>In this example, the error message&lt;/p>
&lt;blockquote>
&lt;p>Test-validation : Cannot validate argument on parameter ‘number’. The ”&lt;br>
if($word -eq ‘Sun’){$_ -eq 1 -or $_ -eq 2}&lt;br>
elseif($word -eq ‘Moon’){$_ -eq 3 -or $_ -eq 4}&lt;br>
elseif($word -eq ‘earth’){$_ -eq 5 -or $_ -eq 6}&lt;br>
” validation script for the argument with value “7” did not return a result of True. Determine why the validation script failed, and then try the&lt;br>
command again.&lt;br>
At line:1 char:39&lt;/p>
&lt;ul>
&lt;li>Test-validation -Word “earth” -number 007&lt;br>
+                                       ~~~&lt;/li>
&lt;li>CategoryInfo          : InvalidData: (:) [Test-validation], ParameterBindingValidationException&lt;/li>
&lt;li>FullyQualifiedErrorId : ParameterArgumentValidationError,Test-validation&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>is not obvious to a none-coder so we could make it easier. As we are passing in a script block we can just add a comment like this. I added a spare line above and below to make it stand out a little more&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Test-validation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    Param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateSet(&amp;#34;sun&amp;#34;, &amp;#34;moon&amp;#34;, &amp;#34;earth&amp;#34;)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [string]$Word,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [ValidateScript({
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            # Sun Accepts 1 or 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Moon Accepts 3 or 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Earth Accepts 5 or 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            if($Word -eq &amp;#39;Sun&amp;#39;){$_ -eq 1 -or $_ -eq 2}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;Moon&amp;#39;){$_ -eq 3 -or $_ -eq 4}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">            elseif($Word -eq &amp;#39;earth&amp;#39;){$_ -eq 5 -or $_ -eq 6}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        })]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">        [int]$Number
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">    )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return &amp;#34;$Word and $Number&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now if you enter the wrong parameter you get this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/07-more-help.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/04/07-more-help.png"
loading="lazy"
alt="07 more help.PNG"
>&lt;/a>&lt;/p>
&lt;p>which I think makes it a little more obvious&lt;/p></description></item><item><title>PowerShell Function – Validating a Parameter Depending On A Previous Parameter’s Value</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</link><pubDate>Wed, 26 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-function-validating-a-parameter-depending-on-a-previous-parameters-value/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Setting the default file type for a new file in VS Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-the-default-file-type-for-a-new-file-in-vs-code/</link><pubDate>Mon, 24 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-the-default-file-type-for-a-new-file-in-vs-code/</guid><description>&lt;p>Just a short post today. When you open a new file in VS Code (Using CTRL + N) it opens by default as a plain text file.&lt;/p>
&lt;p>To change the language for the file use CTRL +K, M.&lt;/p>
&lt;p>That’s CTRL and K together and then M afterwards separately.&lt;/p>
&lt;p>then you can choose the language for the file. It looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/01-change-language.gif"
loading="lazy"
alt="01 - Change language"
>&lt;/p>
&lt;p>However, if you just want your new file to open as a particular language every time you can change this in the settings.&lt;/p>
&lt;p>Click File –&amp;gt; Preferences –&amp;gt; Settings&lt;/p>
&lt;p>or by clicking CTRL + ,&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/02-open-preferences.png"
loading="lazy"
alt="02 - Open Preferences.PNG"
>&lt;/p>
&lt;p>This opens the settings.json file. Search in the bar for default and scroll down until you see file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/03-file-defaults.png"
loading="lazy"
alt="03 - File defaults.PNG"
>&lt;/p>
&lt;p>If you hover over the setting that you want to change, you will see a little pencil. Click on that and then Copy to Settings which will copy it to your user settings in the right hand pane.&lt;/p>
&lt;p>NOTE – You will need to enter powershell and not PowerShell. For other languages, click on the language in the bottom bar and look at the value in the brackets next to the language name&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/04-langauge.png"
loading="lazy"
alt="04 - langauge.PNG"
>&lt;/p>
&lt;p>Once you have entered the new settings save the file (CTRL + S) and then any new file you open will be using the language you have chosen&lt;/p>
&lt;p>It looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/05-change-settings.gif"
loading="lazy"
alt="05 - Change settings.gif"
>&lt;/p>
&lt;p>and now every new file that you open will be opened as a PowerShell file (or whichever language you choose)&lt;/p>
&lt;p>You will still be able to change the language with CTRL K, m&lt;/p>
&lt;p>Just to be clear, because people sometimes get this wrong. That’s CTRL and K, let go and then M. You will know you are doing correctly when you see&lt;/p>
&lt;blockquote>
&lt;p>(CTRL + K) was pressed waiting for second key of chord……&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/06-waiting-for-key.png"
loading="lazy"
alt="06 - waiting for key"
>&lt;/p>
&lt;p>If you get it wrong and Press CTRL + K + M then you will open the Extensions search for keymaps.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/07-incorrect.png"
loading="lazy"
alt="07 - incorrect.PNG"
>&lt;/p>
&lt;p>This is a brilliant feature enabling you to copy key mappings for the programmes you use all the time and save you from learning the Code key mappings. You can find the keymaps in the &lt;a class="link" href="https://marketplace.visualstudio.com/search?target=vscode&amp;amp;category=Keymaps&amp;amp;sortBy=Relevance" target="_blank" rel="noopener"
>Extensions Marketplace&lt;/a> as well as by pressing CTRL + K + M&lt;/p></description></item><item><title>Using Twitter with VS Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-twitter-with-vs-code/</link><pubDate>Wed, 19 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-twitter-with-vs-code/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Why VS Code Increases my Productivity</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-vs-code-increases-my-productivity/</link><pubDate>Thu, 13 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-vs-code-increases-my-productivity/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Why Volunteer at SQLBits ?</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-volunteer-at-sqlbits/</link><pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-volunteer-at-sqlbits/</guid><description>&lt;p>WARNING – Contains Orange and light-hearted photos 😉&lt;/p>
&lt;p>I have returned home from SQLBits 2017 The Disco Edition. I am exhausted, my body is pointing out to me in a variety of ways that this is the only week of the year that I spend so much time on my feet. Why would anyone do it?&lt;/p>
&lt;h2 id="many-months-of-work">Many months of work&lt;/h2>
&lt;p>First though, you need to know that the SQLBits conference is organised and run by volunteers. All of the committee spend many, many long hours, out of their own free time, for many months before and after the event to ensure that the attendees, sponsors, speakers and volunteers experience is trouble free. I think that they do an amazing and fantastic job and repeatedly pull off the best, most enjoyable conference that I have been to.&lt;/p>
&lt;p>&lt;strong>Thank you&lt;/strong> Simon, Chris, Darren, Allan, Alex, Jonathan, Annette&lt;/p>
&lt;p>Thank you also to their families as well, who undoubtedly miss out on time with them whilst they are organising everything to do with the event, from finding venues, organising dates, speakers, marketing, website, sponsors, printing, audio visual, THE PARTY!! and all the other big and small things that it takes to make an event of that size occur.&lt;/p>
&lt;h2 id="orange-shirted-wonderful-folk">Orange Shirted Wonderful Folk&lt;/h2>
&lt;p>There is another group of volunteers that you will have seen at SQLBits. For the last couple of years we have been the ones in the orange shirts.&lt;/p>
&lt;p>Here is the Class of 2017&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_17_27_05_pro.jpg"
loading="lazy"
alt="WP_20170406_17_27_05_Pro.jpg"
>&lt;/p>
&lt;p>I think this is a brilliant colour as it makes us easy to spot (although a couple of attendees who also had orange tops on did get stopped and asked for directions 🙂 )&lt;/p>
&lt;h2 id="what-do-they-do">What do they do?&lt;/h2>
&lt;p>These folk come in early and get everything set up. Sometimes we have to explain that the event isn’t ready for you yet&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_07_31_20_pro.jpg"
loading="lazy"
alt="WP_20170406_07_31_20_Pro.jpg"
>We sort out the registration desk and greet every attendee, speaker and sponsor and assist them.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170405_08_11_25_pro.jpg"
loading="lazy"
alt="WP_20170405_08_11_25_Pro.jpg"
>&lt;/p>
&lt;p>We help the speakers get set up&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170405_08_15_38_pro.jpg"
loading="lazy"
alt="WP_20170405_08_15_38_Pro.jpg"
>&lt;/p>
&lt;p>and ensure they have everything they need.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/aaron-bertrand.jpg"
loading="lazy"
alt="aaron bertrand.jpg"
>&lt;/p>
&lt;p>Aaron Bertrand (above) and John Martin from SentryOne said that it is the best experience for a speaker that they have had anywhere.&lt;/p>
&lt;p>We direct and assist the attendees to be in the right place, sometimes with some flair!&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170404_21_13_03_pro.jpg"
loading="lazy"
alt="WP_20170404_21_13_03_Pro.jpg"
>&lt;/p>
&lt;p>We ensure that any issues are resolved quickly and with as little distraction as possible. The room is too hot, too cold, too noisy or too quiet. The projector isn’t working or the speakers microphone has a buzz, there is too much light or too little. The water coolers are empty. The rubbish needs picking up. All these and many other minor complications are communicated and passed to the correct people to get resolved.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170404_17_51_33_pro-2.jpg"
loading="lazy"
alt="WP_20170404_17_51_33_Pro (2).jpg"
>&lt;/p>
&lt;p>Sometimes we have to resolve our own issues. We had folks who were called by their work and had to stop helping and go back to their day jobs for a few hours. We all understand what it is like for people working in technology and adapt and manage accordingly. In almost every photo I took, there is someone in an orange shirt to be seen.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_10_43_41_pro.jpg"
loading="lazy"
alt="WP_20170406_10_43_41_Pro.jpg"
>&lt;/p>
&lt;p>We answer numerous questions from the 1500 or so attendees (and the odd sheep) who came this year.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/rchard.jpg"
loading="lazy"
alt="rchard.jpg"
>&lt;/p>
&lt;p>From timings and locations to taxi numbers or restaurants. Unfortunately I did &lt;a class="link" href="https://blog.robsewell.com/a-day-in-the-life-of-a-sqlbits-volunteer/" target="_blank" rel="noopener"
>not beat last years&lt;/a> “Best question I have been asked at SQLBits” which was&lt;/p>
&lt;blockquote>
&lt;p>Excuse me, I have a Dalek in the van . What would you like me to do with it?&lt;/p>
&lt;/blockquote>
&lt;p>I was even asked questions on the way back to the hotel gone midnight on Saturday!!&lt;/p>
&lt;p>We stay afterwards and help to get ready for the next day, putting out the new signs for the domes and the required paperwork.&lt;/p>
&lt;h2 id="so-why-do-we-do-it">So why do we do it?&lt;/h2>
&lt;p>I asked the guys and gals this question and in their own words, this is why they do it&lt;/p>
&lt;blockquote>
&lt;p>Being a volunteer at SQLBits is not easy. I’m writing this three days after the event and my legs are still sore. Most days are 11 hours long and you will be standing for most of them. Very often the sessions are full, so you’ll be giving up your seat to one of the attendees. Lunches and breaks are shorter as you are either cleaning down the last session or getting ready for the next. When things go wrong, and they do, you’ll need to get them fixed as quickly as possible even if you have not had  coffee yet.&lt;/p>
&lt;p>You do get to attend sessions but you might not always get your first choice. This can be both a good and bad thing. Very often I have filled in on sessions that I normally wouldn’t attend as they are outside my direct area of work, only to find them the most interesting as I get to see how the other half lives.&lt;/p>
&lt;p>So why do I keep coming back? Well it’s fun. We have a laugh, even on reception when it’s busy you get to joke with the attendees, speakers and other helpers. There is pizza, beer and jokes while bag packing. Odd expresso calls!  Working along side some else is a great way to get to know them. I live outside the normal SQL community structures, my nearest user group is a 150 miles away. So I don’t get to interact with other SQL family members as often as others. But even so, I know as soon as I walk into SQL Bits, there will be a chorus of, “Hey Conan, how have you been?” from people I haven’t seen in a year. There is also something about wearing a bright orange shirt that seems to attract interactions from the attendees.&lt;/p>
&lt;p>All because of the of the experience that is being a volunteer.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/sqldub" target="_blank" rel="noopener"
>Conan Farrell&lt;/a>&lt;/p>
&lt;p>![WP_20170406_10_33_15_Pro (2).jpg](&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_10_33_15_pro-2.jpg" target="_blank" rel="noopener"
>https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_10_33_15_pro-2.jpg&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>I owe a lot to the SQL Community. It was at SQLBits a few years ago that someone convinced me to start speaking. That encouragement and acceptance from the #SQLFamily put into motion a series of events that lead to me &lt;a class="link" href="http://workingwithdevs.com/im-leaving-redgate/" target="_blank" rel="noopener"
>quitting the best job of my life&lt;/a> last year in favour of &lt;a class="link" href="http://workingwithdevs.com/introducing-dlm-consultants-mission/" target="_blank" rel="noopener"
>an adventure to set up my own company&lt;/a>. It’s been a wonderful journey and if it had not been for SQLBits (and SQL Relay, and SQL Saturdays, and others) I wouldn’t have taken it.&lt;/p>
&lt;p>I have a debt to pay. And it’s wonderful to be able to contribute towards giving other people the same opportunities that the community has given me.&lt;/p>
&lt;p>Also, for similar reasons, I recently joined the committee for &lt;a class="link" href="https://sqlrelay.co.uk" target="_blank" rel="noopener"
>SQL Relay&lt;/a>. While I’ve been a sponsor and a speaker a lot before, I am fairly inexperienced at organising events. Helping out with the awesome SQLBits team has been a great learning curve. I hope to take what I have learned and apply it to my role for &lt;a class="link" href="https://sqlrelay.co.uk" target="_blank" rel="noopener"
>SQL Relay&lt;/a>.&lt;/p>
&lt;p>Finally, frankly, there are so many great people in the SQL Community it is just wonderful to be able to work with them during the day. (And share some beers with them in the evening!)&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/_AlexYates_" target="_blank" rel="noopener"
>Alex Yates&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/alex2.jpg"
loading="lazy"
alt="alex2"
>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>I volunteer at SQLBits and in the wider Data Platform community for various reasons. The community is the glue in our industry and being part of that glue is both a privilege and an honour. Without volunteers these awesome events couldn’t function and we couldn’t share knowledge as freely. There also would not be the same opportunities to network with such great people and experts in the same field. I am proud to be part of the SQL Family and facilitate the learning that being a volunteer offers to professionals just like me. Stronger together.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/mrpaulandrew" target="_blank" rel="noopener"
>Paul Andrew&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170404_16_03_17_pro-2.jpg"
loading="lazy"
alt="WP_20170404_16_03_17_Pro (2).jpg"
>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>When I volunteered, I felt I’d like to give back to the SQL Community a bit of the much I’ve received from them. I wanted to become more engaged.
I didn’t even dream it would be like this, the terrific team I found here was so great that I can barely wait for the next one.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/moliveira_xpto" target="_blank" rel="noopener"
>Miguel Oliveira&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>Volunteering gives you the experience of the effort &amp;amp; reward of running an event.. You build an appreciation of generating success, creating networks of colleagues and friends, being quick to react, and helps you walk away with the feeling of “I contributed to this”. Everyone should volunteer, even if its just once.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/benrebooted?lang=en" target="_blank" rel="noopener"
>Ben Watt&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170405_09_31_24_pro-2.jpg"
loading="lazy"
alt="WP_20170405_09_31_24_Pro (2).jpg"
>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>This year was my 10th sqlbits (remembering we skipped unlucky 13) and 7th I’ve been on the helping team for. I started helping when I learned my original conference companions were moving on to different technologies. Something I’ve never understood.&lt;/p>
&lt;p>Historically I’ve worked in multiple companies as a lone dba, something I’ve found many at SQLBits can relate to. Through user groups and SQLBits I’ve met lots of others in the same boat over the years. It can be a frustrating job defending servers, implementing best practice and writing sql when all your application team want to do is add columns and ship the next release!&lt;/p>
&lt;p>Yes, there are good networking opportunities and the parties are great but at the core is great quality training. I’ve had a great time playing a small part in helping deliver the experience over the years. Occasionally I have to shout about feedback forms or seating arrangements but on the whole folk are fine with it.  If I’m honest they are long days. A typical day involves a start and end meeting in addition to sessions you are monitoring. Add to that hotel commutes, catching up with the friends you made last year, meals, drinks etc and its 1am. Oh, and tomorrow’s meeting is 7.30 eek….&lt;/p>
&lt;p>It’s been a great journey watching the progression of events. Each one adds to the last, they run a lot slicker now. The sponsors are first class and always embrace the theme with their stalls and giveaways. I do wish more folk would enter the prize draws and stop me winning though, it’s getting embarrassing now 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/r5d4" target="_blank" rel="noopener"
>Richard Doering&lt;/a> &lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/rich2.jpg"
loading="lazy"
alt="rich2"
>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>The best Data Platform conference in Europe! I couldn’t miss the opportunity to be much more than just an attendee.&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/DataHubert" target="_blank" rel="noopener"
>Hubert Kobierzewski&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;blockquote>
&lt;p>I volunteer for sqlbits, to get experience from a multi day event that has a lot of attendees. Lots of take aways to make local community events run smoother for the delegates.
Thats my main reason&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/vestergaardj" target="_blank" rel="noopener"
>Jens Vestergard&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>There is no way I could not use this next photo celebrate this years Most Valuable Helper.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_20_45_12_pro-2.jpg"
loading="lazy"
alt="WP_20170407_20_45_12_Pro (2).jpg"
>&lt;/p>
&lt;p>Thank you &lt;a class="link" href="https://twitter.com/wheeliedba" target="_blank" rel="noopener"
>Shaun Atkinson&lt;/a> you were amazing and thank you for looking after my former intern James as a first time volunteer&lt;/p>
&lt;h2 id="how-can-i-do-it-next-year">How can I do it next year?&lt;/h2>
&lt;p>We always welcome new people to our team. If you would like to volunteer your time to help at the next SQLBits please send an email to &lt;a class="link" href="mailto:helpers@sqlbits.com" >helpers@sqlbits.com&lt;/a> with a subject of I would like to volunteer or something similar. Nearer the time of next years SQLBits (No I don’t know when or where it is, I will know when you do) the awesome, amazing, fantastic, brilliant, organising amazeballs also known as &lt;a class="link" href="https://twitter.com/mrs_fatherjack" target="_blank" rel="noopener"
>Annette&lt;/a> will get in touch with you with further details&lt;/p>
&lt;p>You can expect to have a lot of fun, make new friends and help make the best data platform conference the best data platform conference&lt;/p>
&lt;p>Oh and sometimes theres free pizza 🙂&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170404_18_31_58_pro.jpg"
loading="lazy"
alt="WP_20170404_18_31_58_Pro"
>&lt;/p>
&lt;h2 id="another-thank-you">Another Thank You&lt;/h2>
&lt;p>Some lovely people, (I am really sorry but I didn’t get everyones name) brought sweets, biscuits, cakes and other goodies for the crew. Thank you, they were very much appreciated.&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170408_08_03_34_pro.jpg"
loading="lazy"
>&lt;/p>
&lt;h2 id="pictures-because-smiles-">Pictures because smiles 🙂&lt;/h2>
&lt;p>Not all of the volunteers wanted to give feedback publically but I had some cracking photos so I thought I would share them as well. Enjoy&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_22_41_36_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_21_51_50_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170405_12_55_59_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_21_05_52_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_20_43_45_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170407_20_37_17_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170405_16_52_49_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_09_57_06_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_12_48_46_pro.jpg"
loading="lazy"
>
&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/wp_20170406_16_05_06_pro.jpg"
loading="lazy"
>&lt;/p></description></item><item><title>Export SQL User Permissions to T-SQL script using PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/export-sql-user-permissions-to-t-sql-script-using-powershell-and-dbatools/</link><pubDate>Mon, 10 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/export-sql-user-permissions-to-t-sql-script-using-powershell-and-dbatools/</guid><description>&lt;p>NOTE - Updated November 2022 for this site and the correct command name.&lt;/p>
&lt;p>There are times when DBA’s are required to export database user permissions to a file. This may be for a number of reasons. Maybe for DR purposes, for auditing, for transfer to another database or instance. Sometimes we need to create a new user with the same permissions as another user or perhaps nearly the same permissions. I was having a conversation with my good friend and &lt;a class="link" href="https://twitter.com/claudioessilva" target="_blank" rel="noopener"
>MVP Cláudio Silva&lt;/a> and we were talking about how &lt;a class="link" href="https://docs.dbatools.io/Export-DbaUser" target="_blank" rel="noopener"
>Export-DbaUser&lt;/a> from &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> could help in these situations and he suggested that I blogged about it so here it is.&lt;/p>
&lt;p>The &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> (for those that don’t know) is a PowerShell module written by amazing folks in the community designed to make administrating your SQL Server significantly easier using PowerShell. The instructions for installing it are &lt;a class="link" href="https://dbatools.io/getting-started/" target="_blank" rel="noopener"
>available here&lt;/a> It comprises of 182 separate commands at present&lt;/p>
&lt;p>Cláudio wrote &lt;a class="link" href="https://docs.dbatools.io/Export-DbaUser" target="_blank" rel="noopener"
>Export-DbaUser&lt;/a> to solve a problem. You should always start with Get-Help whenever you are starting to use a new PowerShell command&lt;/p>
&lt;p>&lt;code>Get-Help Export-DbaUser -ShowWindow&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/01-get-help.png"
loading="lazy"
alt="01 - get help.PNG"
>&lt;/p>
&lt;p>The command exports users creation and its permissions to a T-SQL file or host. Export includes user, create and add to role(s), database level permissions, object level permissions and also the Create Role statements for any roles, although the script does not create IF NOT EXISTS statements which would be an improvement. It also excludes the system databases so if you are scripting users who need access to those databases then that needs to be considered. Cláudio is aware of these and is looking at improving the code to remove those limitations.&lt;/p>
&lt;p>It takes the following parameters&lt;/p>
&lt;ul>
&lt;li>SqlInstance&lt;br>
The SQL Server instance name. SQL Server 2000 and above supported.&lt;/li>
&lt;li>User&lt;br>
Export only the specified database user(s). If not specified will export all users from the database(s)&lt;/li>
&lt;li>DestinationVersion&lt;br>
Which SQL version the script should be generated using. If not specified will use the current database compatibility level&lt;/li>
&lt;li>FilePath&lt;br>
The filepath to write to export the T-SQL.&lt;/li>
&lt;li>SqlCredential&lt;br>
Allows you to login to servers using alternative credentials&lt;/li>
&lt;li>NoClobber&lt;br>
Do not overwrite the file&lt;/li>
&lt;li>Append&lt;br>
Append to the file&lt;/li>
&lt;li>Databases&lt;br>
Not in the help but a dynamic parameter allowing you to specify one or many databases&lt;/li>
&lt;/ul>
&lt;p>Lets take a look at it in action&lt;/p>
&lt;p>&lt;code>Export-DbaUser -SqlInstance SQL2016N2 -FilePath C:\temp\SQL2016N2-Users.sql&lt;/code>
&lt;code>Notepad C:\temp\SQL2016N2-Users.sql&lt;/code>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/02-export-user-server.png"
loading="lazy"
alt="02 - Export user server.PNG"
>&lt;/p>
&lt;p>Lets take a look at a single database&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -FilePath C:\temp\SQL2016N2-Fadetoblack.sql -Databases Fadetoblack
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad C:\temp\SQL2016N2-Fadetoblack.sql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/03-single-database.png"
loading="lazy"
alt="03 single database.PNG"
>&lt;/p>
&lt;p>This is so cool and so easy. It is possible to do this in T-SQL. I found this script on &lt;a class="link" href="http://www.sqlservercentral.com/scripts/Security/71562/" target="_blank" rel="noopener"
>SQLServerCentral&lt;/a> for example which is 262 lines and would then require some mouse action to save to a file&lt;/p>
&lt;p>We can look at a single user as well. Lets see what Lars Ulrich can see on the FadeToBlack database&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/04-export-lars.png"
loading="lazy"
alt="04 - export lars.PNG"
>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [FadetoBlack]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CREATE USER [UlrichLars] FOR LOGIN [UlrichLars] WITH DEFAULT_SCHEMA=[dbo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GRANT CONNECT TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DENY INSERT ON [dbo].[Finances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DENY SELECT ON [dbo].[RealFinances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GRANT SELECT ON [dbo].[Finances] TO [UlrichLars]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So he can select data from the Finances table but cannot insert and cannot read the RealFinances data. Now lets suppose a new manager comes in and he wants to be able to look at the data in this database. As the manager though he wants to be able to read the RealFinances table  and insert into the Finances table. He requests that we add those permissions to the database. We can create the T-SQL for Lars user and then do a find and replace for &lt;code>UlrichLars&lt;/code> with &lt;code>TheManager&lt;/code> , &lt;code>DENY INSERT ON [dbo].[Finances]&lt;/code> with &lt;code>GRANT INSERT ON [dbo].[Finances]&lt;/code> and &lt;code>DENY SELECT ON [dbo].[RealFinances]&lt;/code> with &lt;code>GRANT SELECT ON [dbo].[RealFinances]&lt;/code> and save to a new file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$LarsPermsFile = &amp;#39;C:\temp\SQL2016N2-Lars-Fadetoblack.sql&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPermsFile = &amp;#39;C:\temp\SQL2016N2-Manager-Fadetoblack.sql&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -FilePath $LarsPermsFile -User UlrichLars -Databases Fadetoblack
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = Get-Content $LarsPermsFile
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## replace permissions
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;DENY INSERT ON [dbo].[Finances]&amp;#39;,&amp;#39;GRANT INSERT ON [dbo].[Finances]&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;DENY SELECT ON [dbo].[RealFinances]&amp;#39;,&amp;#39;GRANT SELECT ON [dbo].[RealFinances]&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ManagerPerms = $ManagerPerms.Replace(&amp;#39;UlrichLars&amp;#39;,&amp;#39;TheManager&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Set-Content -path $ManagerPermsFile -Value $ManagerPerms
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I will open this in Visual Studio Code Insiders using&lt;/p>
&lt;p>&lt;code>code-insiders $LarsPermsFile , $ManagerPermsFile&lt;/code>&lt;/p>
&lt;p>if you are not using the insiders preview remove the “-insiders”&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/05-code-insiders.png"
loading="lazy"
alt="05 - code insiders.PNG"
>&lt;/p>
&lt;p>You can right click on the Lars file and click select for compare and then right click on the Managers file and select compare with Lars File and get a nice colour coded diff&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/06-compare.gif"
loading="lazy"
alt="06 - compare.gif"
>&lt;/p>
&lt;p>Perfect, we can run that code and complete the request. When we impersonate Lars we get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/07-lars.png"
loading="lazy"
alt="07 - lars.PNG"
>&lt;/p>
&lt;p>but when we run as the manager we get&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/08-the-manager.png"
loading="lazy"
alt="08 - the manager.PNG"
>&lt;/p>
&lt;p>Excellent! All is well.&lt;/p>
&lt;p>It turns out that there is another Fadetoblack database on a SQL2000 instance which for reasons lost in time never had its data imported into the newer database. It is still used for reporting purposes. The manager needs to have the same permissions as on the SQL2016N2 instance. Obviously the T-SQL we have just created will not work as that syntax did not exist for SQL 2000 but Cláudio has thought of that too. We can use the DestinationVersion parameter to create the SQL2000 (2005,2008/20008R2,2012,2014,2016) code&lt;/p>
&lt;p>We just run&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Export-DbaUser -SqlInstance SQL2016N2 -Databases FadetoBlack -User TheManager  -FilePath C:\temp\S
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">QL2016N2-Manager-2000.sql  -DestinationVersion SQLServer2000
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Notepad C:\temp\SQL2016N2-Manager-2000.sql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and our SQL2000 compatible code is created&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/04/09-manager-2000.png"
loading="lazy"
alt="09- manager 2000.PNG"
>&lt;/p>
&lt;p>Simply awesome. Thank you Cláudio&lt;/p>
&lt;p>Happy Automating&lt;/p>
&lt;p>NOTE – The major 1.0 release of dbatools due in the summer 2017 may have breaking changes which will stop the above code from working. There are also new commands coming which may replace this command. This blog post was written using dbatools version 0.8.942 You can check your version using&lt;/p>
&lt;p>&lt;code>Get-Module dbatools&lt;/code>&lt;/p>
&lt;p>and update it using an Administrator PowerShell session with&lt;/p>
&lt;p>&lt;code>Update-Module dbatools&lt;/code>&lt;/p>
&lt;p>You may find that you get no output from Update-Module as you have the latest version. If you have not installed the module from the PowerShell Gallery using&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>Then you can use&lt;/p>
&lt;p>&lt;code>Update-dbatools&lt;/code>&lt;/p></description></item><item><title>Testing SQL Server Access to a share with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-sql-server-access-to-a-share-with-powershell-using-dbatools/</link><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-sql-server-access-to-a-share-with-powershell-using-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Testing the Identity Column usage in SQL Server with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-the-identity-column-usage-in-sql-server-with-powershell-and-dbatools/</link><pubDate>Fri, 07 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-the-identity-column-usage-in-sql-server-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Pester with Get-DbaLastGoodCheckDb from dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-get-dbalastgoodcheckdb-from-dbatools/</link><pubDate>Thu, 06 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-get-dbalastgoodcheckdb-from-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Getting SQLServers Last Known Good DBCC Checkdb with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sqlservers-last-known-good-dbcc-checkdb-with-powershell-and-dbatools/</link><pubDate>Wed, 05 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sqlservers-last-known-good-dbcc-checkdb-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Test the SQL Server database collation with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-the-sql-server-database-collation-with-powershell-and-dbatools/</link><pubDate>Mon, 03 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-the-sql-server-database-collation-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Max Length of a column in a DataTable in PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/max-length-of-a-column-in-a-datatable-in-powershell/</link><pubDate>Sat, 01 Apr 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/max-length-of-a-column-in-a-datatable-in-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&amp;ldquo;@
}
New-IseSnippet @snippet
}&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>Getting SQL Server File Sizes and Space Used with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-file-sizes-and-space-used-with-dbatools/</link><pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/getting-sql-server-file-sizes-and-space-used-with-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Test your Sqlserver backups on Linux with PowerShell and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-your-sqlserver-backups-on-linux-with-powershell-and-dbatools/</link><pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/test-your-sqlserver-backups-on-linux-with-powershell-and-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Using Pester with dbatools Test-DbaLastBackup</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-dbatools-test-dbalastbackup/</link><pubDate>Sat, 25 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-pester-with-dbatools-test-dbalastbackup/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Backing up SQL Server on Linux using Ola Hallengrens Maintenance Solution</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-sql-server-on-linux-using-ola-hallengrens-maintenance-solution/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-sql-server-on-linux-using-ola-hallengrens-maintenance-solution/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Taking dbatools Test-DbaLastBackup a little further</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/taking-dbatools-test-dbalastbackup-a-little-further/</link><pubDate>Wed, 22 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/taking-dbatools-test-dbalastbackup-a-little-further/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Testing Your SQL Server Backups the Easy Way with PowerShell &amp; dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-your-sql-server-backups-the-easy-way-with-powershell-dbatools/</link><pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/testing-your-sql-server-backups-the-easy-way-with-powershell-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Restoring an entire SQL Server user databases with PowerShell using dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/restoring-an-entire-sql-server-user-databases-with-powershell-using-dbatools/</link><pubDate>Sat, 18 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/restoring-an-entire-sql-server-user-databases-with-powershell-using-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Adding a PowerShell Job Step to an existing SQL Agent Job Step with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-powershell-job-step-to-an-existing-sql-agent-job-step-with-powershell/</link><pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-powershell-job-step-to-an-existing-sql-agent-job-step-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>}&lt;!-- raw HTML omitted -->&lt;/p>
&lt;!-- raw HTML omitted --></description></item><item><title>VS Code PowerShell Snippets</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-powershell-snippets/</link><pubDate>Sun, 12 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/vs-code-powershell-snippets/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Quickly Creating Test Users in SQL Server with PowerShell using the sqlserver module and dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/</link><pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/02/remove-them-all.png" alt="Featured image of post Quickly Creating Test Users in SQL Server with PowerShell using the sqlserver module and dbatools" />&lt;p>One of the most visited posts on my blog is nearly two and half years old now – &lt;!-- raw HTML omitted -->Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users&lt;!-- raw HTML omitted -->. I thought it was time to update it and use the &lt;!-- raw HTML omitted -->latest sqlserver module&lt;!-- raw HTML omitted --> and the &lt;!-- raw HTML omitted -->dbatools module&lt;!-- raw HTML omitted -->.&lt;/p>
&lt;p>You can get the latest version of the sqlserver module by installing SSMS 2016. The &lt;!-- raw HTML omitted -->PASS PowerShell Virtual Chapter&lt;!-- raw HTML omitted --> have created a short link to make this easier for you to remember: &lt;!-- raw HTML omitted -->&lt;a class="link" href="https://sqlps.io/dl" target="_blank" rel="noopener"
>https://sqlps.io/dl&lt;/a>&lt;!-- raw HTML omitted -->
Once you have downloaded and installed SSMS you can load the module.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Import-Module sqlserver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is one situation where you will get an error loading the sqlserver module into PowerShell. If you have the SQLPS module already imported then you will get the following error:&lt;/p>
&lt;blockquote>
&lt;p>Import-Module : The following error occurred while loading the extended type data file:&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/sqlserver-module-error.png"
loading="lazy"
alt="sqlserver-module-error"
>&lt;/p>
&lt;p>In that case you will need to remove the SQLPS module first.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Remove-Module sqlps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module sqlserver
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The original post dealt with creating a number of test users for a database and assigning them to different roles quickly and easily.
First let’s quickly create a list of Admin users and a list of Service Users and save them in a text file.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$i = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">while ($I -lt 100) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Beard_Service_User$i&amp;#34; | Out-File &amp;#39;C:\temp\Users.txt&amp;#39; -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $i++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$i = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">while ($I -lt 10) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;Beard_Service_Admin_$i&amp;#34; | Out-File &amp;#39;C:\temp\Admins.txt&amp;#39; -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $i++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now that we have those users in files we can assign them to a variable by using &lt;code>Get-Content&lt;/code>&lt;/p>
&lt;p>&lt;code>$Admins = Get-Content 'C:\temp\Admins.txt'&lt;/code>&lt;/p>
&lt;p>Of course we can use any source for our users&lt;/p>
&lt;ul>
&lt;li>a database&lt;/li>
&lt;li>an excel file&lt;/li>
&lt;li>Active Directory&lt;/li>
&lt;li>or even just type them in.&lt;/li>
&lt;/ul>
&lt;p>We can use the &lt;code>Add-SQLLogin&lt;/code> command from the sqlserver module to add our users as SQL Logins, but at present we cannot add them as database users and assign them to a role.&lt;br>
If we want to add a Windows Group or a Windows User to our SQL Server we can do so using:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Add-SqlLogin -ServerInstance $Server -LoginName $User -LoginType WindowsUser -DefaultDatabase tempdb -Enable -GrantConnectSql
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice that we need to enable and grant connect SQL to the user.&lt;/p>
&lt;p>If we want to add a SQL login the code is pretty much the same but we either have to enter the password in an authentication box or pass in a PSCredential object holding the username and password. Keeping credentials secure in PowerShell scripts is outside the scope of this post and the requirement is for none-live environments so we will pass in the same password for all users as a string to the script. You may want or be required to achieve this in a different fashion.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Pass = ConvertTo-SecureString -String $Password -AsPlainText -Force
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Credential = New-Object -TypeName System.Management.Automation.PSCredential -ArgumentList $User, $Pass
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Add-SqlLogin -ServerInstance $Server -LoginName $User -LoginType $LoginType -DefaultDatabase tempdb -Enable -GrantConnectSql -LoginPSCredential $Credential
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can ensure that we are not trying to add logins that already exist using&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if(!($srv.Logins.Contains($User)))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The &lt;code>$srv&lt;/code> is a &lt;!-- raw HTML omitted -->SQL Server Management Server Object&lt;!-- raw HTML omitted --> which you can create using a snippet. I blogged about &lt;!-- raw HTML omitted -->snippets here&lt;!-- raw HTML omitted --> and you can find my &lt;!-- raw HTML omitted -->list of snippets on GitHub here&lt;!-- raw HTML omitted -->. However, today I am going to use the &lt;!-- raw HTML omitted -->dbatools module &lt;!-- raw HTML omitted -->to create a SMO Server Object using the &lt;!-- raw HTML omitted -->Connect-DbaInstance command&lt;!-- raw HTML omitted --> and assign the server and the database to a variable:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"># Create a SQL Server SMO Object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = Connect-DbaInstance -SqlInstance $server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $srv.Databases[$Database]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once we have our Logins we need to create our database users:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$usr = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.User&amp;#39;) ($db, $User)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$usr.Login = $User
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$usr.Create()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and add them to a database role.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#Add User to the Role
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db.roles[$role].AddMember($User)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I created a little function to call in the script and then simply loop through our users and admins and call the function.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($User in $Users) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Add-UserToRole -Password $Password -User $user -Server $server -Role $Userrole -LoginType SQLLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($User in $Admins) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Add-UserToRole -Password $Password -User $user -Server $server -Role $adminrole -LoginType SQLLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To check that they have been added correctly I simply use the &lt;!-- raw HTML omitted -->Get-DbaRoleMember&lt;!-- raw HTML omitted -->;command from dbatools and output it to &lt;!-- raw HTML omitted -->Out-GridView&lt;!-- raw HTML omitted --> using the alias ogv as I am on the command line:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Get-DbaRoleMember -SqlInstance $server |ogv
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which looks like this:&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/get-dbarole-memebr.png"
loading="lazy"
alt="get-dbarole-memebr"
>&lt;/p>
&lt;p>Once we need to clean up the logins and users we can use the &lt;!-- raw HTML omitted -->Get-SQLLogin&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Remove-SQLLogin&lt;!-- raw HTML omitted --> commands from the sqlserver module to remove the logins and if we do that first we can then use the dbatools command &lt;!-- raw HTML omitted -->Remove-SQLOrphanuser&lt;!-- raw HTML omitted --> to remove the orphaned users 🙂 (I thought that was rather cunning!)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">(Get-SqlLogin -ServerInstance $server).Where{$_.Name -like &amp;#39;*Beard_Service_*&amp;#39;}|Remove-SqlLogin
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Remove-SQLOrphanUser -SqlServer $Server -databases $database
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Remove-SQLLogin will prompt for confirmation and the result of the Remove-SQLOrphanUser looks like this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/02/remove-them-all.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;p>When you are looking at doing this type of automation with PowerShell, you should remember always to make use of &lt;!-- raw HTML omitted -->Get-Command&lt;!-- raw HTML omitted -->, &lt;!-- raw HTML omitted -->Get-Help&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Get-Member&lt;!-- raw HTML omitted -->. That will enable you to work out how to do an awful lot. I have a short video on youtube about this:&lt;/p>
&lt;p>{% include youtubePlayer.html id=&amp;ldquo;zC-KpI89fkg&amp;rdquo; %}&lt;/p>
&lt;p>and when you get stuck come and ask in the SQL Server Slack at &lt;!-- raw HTML omitted -->&lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;!-- raw HTML omitted -->. You will find a powershellhelp channel in there.&lt;br>
Here is the complete code:&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="lnt">71
&lt;/span>&lt;span class="lnt">72
&lt;/span>&lt;span class="lnt">73
&lt;/span>&lt;span class="lnt">74
&lt;/span>&lt;span class="lnt">75
&lt;/span>&lt;span class="lnt">76
&lt;/span>&lt;span class="lnt">77
&lt;/span>&lt;span class="lnt">78
&lt;/span>&lt;span class="lnt">79
&lt;/span>&lt;span class="lnt">80
&lt;/span>&lt;span class="lnt">81
&lt;/span>&lt;span class="lnt">82
&lt;/span>&lt;span class="lnt">83
&lt;/span>&lt;span class="lnt">84
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-v" data-lang="v">&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#Requires -module sqlserver&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="cp">#Requires -module dbatools&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">###&lt;/span> &lt;span class="nc">Define&lt;/span> &lt;span class="nv">some&lt;/span> &lt;span class="nv">variables&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;Password&amp;#34;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Database&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;TheBeardsDatabase&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Admins&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Content&lt;/span> &lt;span class="s1">&amp;#39;C:&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">emp\Admins.txt&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">Users&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Content&lt;/span> &lt;span class="s1">&amp;#39;C:&lt;/span>&lt;span class="se">\t&lt;/span>&lt;span class="s1">emp\Users.txt&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;SQLLogin&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">userrole&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">&amp;amp;&lt;/span>&lt;span class="nv">nbsp&lt;/span>&lt;span class="p">;&lt;/span> &lt;span class="s1">&amp;#39;Users&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">adminrole&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s1">&amp;#39;Admin&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">#&lt;/span> &lt;span class="nc">Create&lt;/span> &lt;span class="nv">a&lt;/span> &lt;span class="nc">SQL&lt;/span> &lt;span class="nc">Server&lt;/span> &lt;span class="nc">SMO&lt;/span> &lt;span class="nc">Object&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">Connect&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">DbaSqlServer&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">SqlServer&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Databases&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Database&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">function&lt;/span> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">param&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">(&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateNotNullOrEmpty&lt;/span>&lt;span class="p">()]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">Role&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">Parameter&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nc">Mandatory&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipeline&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromPipelineByPropertyName&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">true&lt;/span>&lt;span class="p">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">ValueFromRemainingArguments&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="kc">false&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nc">ValidateSet&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;SQLLogin&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;WindowsGroup&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s2">&amp;#34;WindowsUser&amp;#34;&lt;/span>&lt;span class="p">)]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">[&lt;/span>&lt;span class="nb">string&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">srv&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Logins&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Contains&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)))&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;SQLLogin&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nc">Pass&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">ConvertTo&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SecureString&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">String&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">AsPlainText&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Force&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nc">Credential&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">New&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Object&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">TypeName&lt;/span> &lt;span class="nc">System&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Management&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Automation&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">PSCredential&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ArgumentList&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Pass&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SqlLogin&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ServerInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginName&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">DefaultDatabase&lt;/span> &lt;span class="nv">tempdb&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Enable&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">GrantConnectSql&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginPSCredential&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Credential&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nv">elseif&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;WindowsGroup&amp;#39;&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="k">or&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nv">eq&lt;/span> &lt;span class="s1">&amp;#39;WindowsUser&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">SqlLogin&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">ServerInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginName&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">DefaultDatabase&lt;/span> &lt;span class="nv">tempdb&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Enable&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">GrantConnectSql&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">!&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Users&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Contains&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)))&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">#&lt;/span> &lt;span class="nc">Add&lt;/span> &lt;span class="nv">user&lt;/span> &lt;span class="nv">to&lt;/span> &lt;span class="nv">database&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="nc">New&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">Object&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Microsoft.SqlServer.Management.Smo.User&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Login&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">usr&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nc">Create&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="cp">#Add User to the Role&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">$&lt;/span>&lt;span class="nv">db&lt;/span>&lt;span class="p">.&lt;/span>&lt;span class="nv">roles&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nv">role&lt;/span>&lt;span class="p">].&lt;/span>&lt;span class="nc">AddMember&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">foreach&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Users&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">user&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Role&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Userrole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="nc">SQLLogin&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nv">foreach&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="o">$&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="k">in&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Admins&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="p">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="nc">Add&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">UserToRole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nc">Password&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">User&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">user&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Server&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">Role&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">adminrole&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">LoginType&lt;/span> &lt;span class="nc">SQLLogin&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="p">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="nc">Get&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="nc">DbaRoleMember&lt;/span> &lt;span class="o">-&lt;/span>&lt;span class="nc">SqlInstance&lt;/span> &lt;span class="o">$&lt;/span>&lt;span class="nv">server&lt;/span> &lt;span class="o">|&lt;/span> &lt;span class="nv">ogv&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Happy Automating!&lt;/p></description></item><item><title>SQL VNext sp_configure on Windows and Linux with dbatools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-vnext-sp_configure-on-windows-and-linux-with-dbatools/</link><pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-vnext-sp_configure-on-windows-and-linux-with-dbatools/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Adding a T-SQL Job Step to a SQL Agent Job with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-t-sql-job-step-to-a-sql-agent-job-with-powershell/</link><pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/adding-a-t-sql-job-step-to-a-sql-agent-job-with-powershell/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Altering a Job Step on Hundreds of SQL Servers with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/altering-a-job-step-on-hundreds-of-sql-servers-with-powershell/</link><pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/altering-a-job-step-on-hundreds-of-sql-servers-with-powershell/</guid><description>&lt;img src="https://dbatools.io/wp-content/uploads/2016/05/dbatools-logo-1.png" alt="Featured image of post Altering a Job Step on Hundreds of SQL Servers with PowerShell" />&lt;p>I flew to Utrecht last week to present with &lt;!-- raw HTML omitted -->Chrissy LeMaire&lt;!-- raw HTML omitted --> and &lt;!-- raw HTML omitted -->Sander Stad&lt;!-- raw HTML omitted --> for the joint Dutch SQL and PowerShell User Groups. Whilst I was sat at the airport I got a phone call from my current client.&lt;/p>
&lt;blockquote>
&lt;p>Them - We need to change the backup path for all of the servers to a different share, how long will it take you?&lt;/p>
&lt;p>Me - About 5 minutes&lt;/p>
&lt;/blockquote>
&lt;p>(PowerShell is very powerful – be careful when following these examples 😉 )&lt;/p>
&lt;p>This code was run using PowerShell version 5 and will not work on Powershell version 3 or lower as it uses the where method.
Lets grab all of our jobs on the estate. (You will need to fill the $Servers variable with the names of your instances, maybe from a database or CMS or a text file)&lt;!-- raw HTML omitted -->$Jobs = Get-SQLAgentJob -ServerInstance $Servers&lt;!-- raw HTML omitted -->
Once we have the jobs we need to iterate only through the ones we need to. This step could also have been done in the line above. Lets assume we are using the Ola Hallengren Solution to backup our estate&lt;!-- raw HTML omitted -->Foreach($job in $Jobs.Where{$&lt;em>.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo; -and $&lt;/em>.isenabled -eq $true})&lt;!-- raw HTML omitted -->
Then because I have to target a specific job step I can iterate through those and filter in the same way&lt;!-- raw HTML omitted -->foreach ($Step in $Job.jobsteps.Where{$_.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo;})&lt;!-- raw HTML omitted -->
Now all I need to do is to replace C:\Backup with C:\MSSQL\Backup (in this example I am using my labs backup paths)&lt;!-- raw HTML omitted -->$Step.Command = $Step.Command.Replace(&amp;ldquo;Directory = N&amp;rsquo;C:\Backup&amp;rsquo;&amp;rdquo;,&amp;ldquo;Directory = N&amp;rsquo;C:\MSSQL\Backup&amp;rsquo;&amp;rdquo;)&lt;!-- raw HTML omitted -->
And then call the Alter method&lt;!-- raw HTML omitted -->$Step.Alter()&lt;!-- raw HTML omitted -->
And that is all there is to it. Here is the full script I used&lt;!-- raw HTML omitted -->$Jobs = Get-SQLAgentJob -ServerInstance $Servers&lt;/p>
&lt;p>Foreach($job in $Jobs.Where{$&lt;em>.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo; -and $&lt;/em>.isenabled -eq $true})
{
foreach ($Step in $Job.jobsteps.Where{$_.Name -like &amp;lsquo;&lt;em>DatabaseBackup&lt;/em>&amp;rsquo;})
{
$Step.Command = $Step.Command.Replace(&amp;ldquo;Directory = N&amp;rsquo;C:\Backup&amp;rsquo;&amp;rdquo;,&amp;ldquo;Directory = N&amp;rsquo;C:\MSSQL\Backup&amp;rsquo;&amp;rdquo;)
$Step.Alter()
}
}&lt;!-- raw HTML omitted -->
In only a few minutes I had altered several hundred instances worth of Ola Hallengren Jobs 🙂
This is one of the many reasons I love PowerShell, it enables me to perform mass changes very quickly and easily. Of course, you need to make sure that you know that what you are changing is what you want to change. I have caused severe issues by altering the SQL alerts frequency to 1 second instead of one hour on an estate!! Although the beauty of PowerShell meant that I was able to change it very quickly once the problem was realised&lt;!-- raw HTML omitted -->You can change a lot of settings. If you look at what is available at a job step level&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->&lt;!-- raw HTML omitted -->Happy Automating&lt;/p></description></item><item><title>Using the PowerShell SQL Provider with SQL Authentication</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-powershell-sql-provider-with-sql-authentication/</link><pubDate>Thu, 12 Jan 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-powershell-sql-provider-with-sql-authentication/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>A Whole Day of PowerShell and SQL – Join Chrissy LeMaire &amp; I at #sqlsatvienna</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-whole-day-of-powershell-and-sql-join-chrissy-lemaire-i-at-#sqlsatvienna/</link><pubDate>Mon, 09 Jan 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-whole-day-of-powershell-and-sql-join-chrissy-lemaire-i-at-#sqlsatvienna/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Running SQL Queries with Visual Studio Code</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-sql-queries-with-visual-studio-code/</link><pubDate>Thu, 05 Jan 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/running-sql-queries-with-visual-studio-code/</guid><description>&lt;p>Reading this blog post by &lt;a class="link" href="http://www.sqlshack.com/introduction-visual-studio-code-dbas/" target="_blank" rel="noopener"
>Shawn Melton Introduction of Visual Studio Code for DBAs&lt;/a> reminded me that whilst I use Visual Studio Code (which I shall refer to as Code from here on) for writing PowerShell and Markdown and love how easily it interacts with Github I hadn’t tried T-SQL. If you are new to Code (or if you are not) go and read Shawns blog post but here are the steps I took to running T-SQL code using Code&lt;/p>
&lt;p>To download Code go to this link &lt;a class="link" href="https://code.visualstudio.com/download" target="_blank" rel="noopener"
>https://code.visualstudio.com/download&lt;/a> and choose your operating system. Code works on Windows, Linux and Mac&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/00-code-download.png"
loading="lazy"
alt="00-code-download"
>&lt;/p>
&lt;p>Once you have downloaded and installed hit CTRL SHIFT and P which will open up the command palette&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/01-ctrlshiftp.png"
loading="lazy"
alt="01-ctrlshiftp"
>&lt;/p>
&lt;p>Once you start typing the results will filter so type ext and then select Extensions : Install Extension&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/02-extensions.png"
loading="lazy"
alt="02-extensions"
>&lt;/p>
&lt;p>Which will open the Extensions tab ( You could have achieved the same end result just by clicking this icon)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/03-install-extensions.png"
loading="lazy"
alt="03-install-extensions"
>&lt;/p>
&lt;p>But then you would not have learned about the command palette 🙂&lt;/p>
&lt;p>So, with the extensions tab open, search for mssql and then click install&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/04-search-mssql.png"
loading="lazy"
alt="04-search-mssql"
>&lt;/p>
&lt;p>Once it has installed the button will change to Reload so click it&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/05-reload.png"
loading="lazy"
alt="05-reload"
>&lt;/p>
&lt;p>And you will be prompted to Reload the window&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/06-reload-prompt.png"
loading="lazy"
alt="06-reload-prompt"
>&lt;/p>
&lt;p>Accept the prompt and then open a new file (CTRL N) and then change the language for the file.&lt;/p>
&lt;p>You can do this by clicking CTRL K and then M (Not CTRL K CTRL M) or click the language button&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/07-choose-langauga.png"
loading="lazy"
alt="07-choose-langauga"
>&lt;/p>
&lt;p>And then choose SQL&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/08-choose-sql.png"
loading="lazy"
alt="08-choose-sql"
>&lt;/p>
&lt;p>This will start a download so make sure you are connected (and allowed to connect to the internet)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/09-start-download.png"
loading="lazy"
alt="09-start-download"
>&lt;/p>
&lt;p>Once it has finished it will show this&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/10-finished-downloading.png"
loading="lazy"
alt="10-finished-downloading"
>&lt;/p>
&lt;p>And offer you the chance to read the release notes&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/11-release-notes.png"
loading="lazy"
alt="11-release-notes"
>&lt;/p>
&lt;p>Which you can get for any extension anytime by finding the extension in the extensions tab and clicking on it. This has links to tutorials as well as information about the release&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/12-release-notes.png"
loading="lazy"
alt="12-release-notes"
>&lt;/p>
&lt;p>The mssql extension enables Intellisence for T-SQL when you open a .sql file or when you change the language to SQL as shown above for a new file&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/13-intellisense.png"
loading="lazy"
alt="13-intellisense"
>&lt;/p>
&lt;p>Write your T-SQL Query and press CTRL SHIFT and E or Right Click and choose Execute Query. This will ask you to choose a Connection Profile (and display any existing profiles)&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/14-execute.png"
loading="lazy"
alt="14-execute"
>&lt;/p>
&lt;p>Choose Create Connection Profile and answer the prompts&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/15-enter-servername.png"
loading="lazy"
alt="15-enter-servername"
>&lt;/p>
&lt;p>The query will then run&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/16-query-runs.png"
loading="lazy"
alt="16-query-runs"
>&lt;/p>
&lt;p>You can then output the results to csv or json if you wish&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2017/01/17-results.png"
loading="lazy"
alt="17-results"
>&lt;/p>
&lt;p>You can find a video showing this whole process with some typos and an error here&lt;/p>
&lt;p>&lt;a class="link" href="https://youtu.be/_qTNKohFzPE" target="_blank" rel="noopener"
>Using SQL with VS Code&lt;/a>&lt;/p></description></item><item><title>2016 - That was a Year :-)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/2016-that-was-a-year-/</link><pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/2016-that-was-a-year-/</guid><description>&lt;p>Its the time of year for reflection and I have had the most amazing 2016, I am blessed that I love what I do so much. I thoroughly enjoy writing and talking and sharing and commenting and supporting and cherishing all the SQL and PowerShell things. &lt;a class="link" href="http://sqldbawithabeard.com/2016/10/29/powerbi-and-api-visualising-my-checkins/" target="_blank" rel="noopener"
>I wrote about using Power Bi to display my checkins&lt;/a>. I only started this in June and this is where I have been :-)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2017/01/swarm.png"
loading="lazy"
alt="swarm"
>&lt;/p>
&lt;p>I learnt about &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> and ended the year incorporating it into &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a>. I also started using &lt;a class="link" href="https://github.com/SQLDBAWithABeard" target="_blank" rel="noopener"
>GitHub&lt;/a> It is quite surprising to me how much time I now spend using both. I also had to start learning &lt;a class="link" href="https://msdn.microsoft.com/en-us/PowerShell/dsc/overview" target="_blank" rel="noopener"
>DSC&lt;/a> for the client I was working with because as &amp;rsquo;the PowerShell guy&amp;rsquo; I was the one who could the easiest. I learnt things and &lt;a class="link" href="http://sqldbawithabeard.com/2016/01/31/PowerShell-pester-the-script-failed-due-to-call-depth-overflow/" target="_blank" rel="noopener"
>then forgot them causing me to find this Pester post via google later in the year!!&lt;/a> (That&amp;rsquo;s a big reason for blogging by the way)&lt;/p>
&lt;p>Early in the year we organised with &lt;a class="link" href="http://www.sqlsaturday.com/496/EventHome.aspx" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://www.facebook.com/mark.pryce.maher/videos/10153333580360863/?pnref=story.unseen-section" target="_blank" rel="noopener"
>https://www.facebook.com/mark.pryce.maher/videos/10153333580360863/?pnref=story.unseen-section&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>The Beard says&lt;/p>
&lt;blockquote>
&lt;p>When you go to an event -  Say thank you to the organisers and volunteers&lt;/p>
&lt;/blockquote>
&lt;p>and a TERRIBLE thing happened - I broke my DBA Team mug&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/WP_20160223_07_51_03_Pro.jpg"
loading="lazy"
>&lt;/p>
&lt;p>Luckily the fine folk at &lt;a class="link" href="http://www.red-gate.com/" target="_blank" rel="noopener"
>redgate&lt;/a> sorted me out with a replacement from deep in the stores somewhere and gave it to me at SQL Saturday Exeter :-) Thank you.&lt;/p>
&lt;p>I spoke at the PowerShell Conference Europe and met and made some great friends which lead to me speaking at the PowerShell Monday in Munich and the Dutch PowerShell Usergroup. SQL Saturday Dublin was a blast, its a wonderful city, Manchester had a whole PowerShell Track :-) and Cambridge was memorable for the appalling journey as well as the chance to share a stage with &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy&lt;/a>. PowerShell Conference Asia in the sovereign city-state of Singapore was such a good event and place. Lastly of course was Slovenia with its fantastic Christmas lights and awesome event organisation. I visited some user groups too. Southampton run by my good friends &lt;a class="link" href="https://twitter.com/sqldiplomat" target="_blank" rel="noopener"
>John Martin&lt;/a> and &lt;a class="link" href="https://twitter.com/steph_middleton" target="_blank" rel="noopener"
>Steph Middleton&lt;/a> Congratulations to John on his first MVP award yesterday, Cardiff for the Return of the Battle of the Beards with Terry McCann and Tobiasz Koprowski where the projector threw its toys out of the pram and Birmingham in the school hall which was slightly chilly (theres a joke there for some people)&lt;/p>
&lt;p>Amazing things happened&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted -->
&lt;p>And that&amp;rsquo;s the biggest and bestest thing about this year. Some amazing new friends and spending time with all my other friends. I started writing out a list but was terrified I would have missed someone out, so to all my friends&lt;/p>
&lt;p>THANK YOU for a brilliant 2016 and 2017 shall be just as good :-)&lt;/p>
&lt;p>Here are a few of my pics from the year with a lot of my friends&lt;/p>
&lt;p>[gallery type=&amp;ldquo;circle&amp;rdquo; columns=&amp;ldquo;9&amp;rdquo; ids=&amp;ldquo;3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3077,3075,3074,3073,3067,3068,3069,3070,3071,3072,3066,3065,3064,3063,3062,3061,3055,3056,3057,3058,3059,3060,3054,3053,3052,3051,3050,3049,2943,2950,2897,2923,3046,2924,2927,3047,2933,3048&amp;rdquo;]&lt;/p></description></item><item><title>Deploying a Windows Data Science Virtual Machine to Azure with PowerShell easily</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-windows-data-science-virtual-machine-to-azure-with-powershell-easily/</link><pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/deploying-a-windows-data-science-virtual-machine-to-azure-with-powershell-easily/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png" alt="Featured image of post Deploying a Windows Data Science Virtual Machine to Azure with PowerShell easily" />&lt;p>This weekend (10 December 2016), I went to Slovenia for a &lt;a class="link" href="http://www.sqlsaturday.com/567/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday&lt;/a>. As always, it was an amazing event well organised by &lt;a class="link" href="https://twitter.com/MladenPrajdic" target="_blank" rel="noopener"
>Mladen Prajdic&lt;/a>, &lt;a class="link" href="http://sqlblog.com/blogs/dejan_sarka/default.aspx" target="_blank" rel="noopener"
>Dejan Sarka&lt;/a>, and &lt;a class="link" href="https://twitter.com/MatijaLah" target="_blank" rel="noopener"
>Matija Lah&lt;/a> in a fabulous setting amongst fabulous scenery. I highly recommend it and, also, &lt;a class="link" href="https://en.wikipedia.org/wiki/Ljubljana" target="_blank" rel="noopener"
>Ljubljana&lt;/a>  is a wonderful place to be in December with all the lights and markets.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/wp_20161209_19_21_06_pro.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/wp_20161209_19_21_06_pro.jpg"
loading="lazy"
alt="WP_20161209_19_21_06_Pro.jpg"
>&lt;/a>&lt;/p>
&lt;p>Whilst I was there I was asked by someone if you could deploy data science virtual machines in Azure with PowerShell. I said I was sure that it could be done and agreed I would write a blog post, so here it is.&lt;/p>
&lt;p>According to the &lt;a class="link" href="https://azure.microsoft.com/en-gb/marketplace/partners/microsoft-ads/standard-data-science-vm/" target="_blank" rel="noopener"
>Azure documentation&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>The Data Science Virtual Machine running on a Windows Server 2012 contains popular tools for data exploration, modeling and development activities. The main tools include Microsoft R Server Developer Edition (An enterprise ready scalable R framework) , Anaconda Python distribution, Jupyter notebooks for Python and R, Visual Studio Community Edition with Python, R and node.js tools, Power BI desktop, SQL Server 2016 Developer edition including support In-Database analytics using Microsoft R Server. It also includes open source deep learning tools like Microsoft Cognitive Toolkit (CNTK 2.0) and mxnet; ML algorithms like xgboost, Vowpal Wabbit. The Azure SDK and libraries on the VM allows you to build your applications using various services in the cloud that are part of the Cortana Analytics Suite which includes Azure Machine Learning, Azure data factory, Stream Analytics and SQL Datawarehouse, Hadoop, Data Lake, Spark and more.&lt;/p>
&lt;/blockquote>
&lt;p>I have created a function to wrap around the process to make it easier for none PowerShell  people to do this. There are a series of steps to follow below and you should be able to create a machine in about 10 minutes once you have completed the pre-requisites.&lt;/p>
&lt;h2 id="enable-programmatically-deployment">Enable Programmatically Deployment&lt;/h2>
&lt;p>First, an annoyance. To be able to deploy Data Science virtual machines in Azure programmatically  you first have to login to the portal and click some buttons.&lt;/p>
&lt;p>In the &lt;a class="link" href="https://portal.aure.com" target="_blank" rel="noopener"
>Portal&lt;/a> click new and then marketplace and then search for data science. Choose the Windows Data Science Machine and under the blue Create button you will see a link which says “Want to deploy programmatically? Get started” Clicking this will lead to the following blade.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/set-up-programmatically1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/set-up-programmatically1.png"
loading="lazy"
alt="set-up-programmatically"
>&lt;/a>&lt;/p>
&lt;p>Click Enable and then save and you then move to PowerShell 🙂&lt;/p>
&lt;h2 id="azure-powershell-cmdlets">Azure PowerShell Cmdlets&lt;/h2>
&lt;p>Follow the instructions &lt;a class="link" href="https://docs.microsoft.com/en-us/powershell/azureps-cmdlets-docs/" target="_blank" rel="noopener"
>here&lt;/a> to install the Azure PowerShell modules. In the examples you see here I am using Windows 10 and PowerShell version 5.1.14393.479 and I installed the Azure modules using the Install-Module method&lt;/p>
&lt;h2 id="get-the-script">Get the script&lt;/h2>
&lt;p>To install a data science VM, we’ll use the &lt;code>New-WindowsDataScienceVM.ps1&lt;/code> script. In this script, I’m using version 1.2, but any version of this script published in PowerShell Gallery is fine.&lt;/p>
&lt;p>To install the &lt;code>New-WindowsDataScienceVM&lt;/code> script from the PowerShell gallery, type:&lt;/p>
&lt;p>&lt;code>Install-Script New-WindowsDataScienceVM&lt;/code>&lt;/p>
&lt;p>For  more information about using the PowerShellGet cmdlets to install scripts and modules from PowerShell Gallery, &lt;a class="link" href="https://msdn.microsoft.com/powershell/gallery/readme" target="_blank" rel="noopener"
>read this page&lt;/a>. The PowerShellGet modules is included in PowerShell 5.0 and later on Windows 10, but you can install PowerShellGet for PowerShell 3.0 and 4.0. If you cannot connect to the gallery or prefer not to install the module, you can also find the &lt;a class="link" href="https://raw.githubusercontent.com/SQLDBAWithABeard/DataScienceVM/master/New-WindowsDataScienceVM.ps1" target="_blank" rel="noopener"
>script on GitHub&lt;/a>.&lt;/p>
&lt;h2 id="login-to-azure">Login to Azure&lt;/h2>
&lt;p>You can login to Azure using the command&lt;/p>
&lt;p>&lt;code>Login-AzureRMAccount&lt;/code>&lt;/p>
&lt;p>which will pop-up a prompt for you to log into Azure&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login.png"
loading="lazy"
alt="login"
>&lt;/a>&lt;/p>
&lt;h2 id="enable-simple-mode">Enable Simple Mode&lt;/h2>
&lt;p>The &lt;code>New-WindowsDataScienceVM&lt;/code> function comes with a &lt;strong>Simple&lt;/strong> switch parameter.&lt;/p>
&lt;p>If you use &lt;strong>-Simple&lt;/strong>, the function prompts you only for the admin username and password for the virtual machine. It creates a randomly-named, standard_DS1_v2-sized machine in the ukwest data centre with standard, locally redundant storage in a randomly named Resource Group. All of the required objects have random names, too. If that is not what you want, there is more information at the end of this post. I am considering offering a pop-up to choose location in Simple Mode. Let me know here if that would be something you would like&lt;/p>
&lt;p>To create a simple data science VM, run:&lt;/p>
&lt;p>&lt;code>New-WindowsDataScienceVM -Simple&lt;/code>&lt;/p>
&lt;h2 id="enter-local-admin-password">Enter Local Admin Password&lt;/h2>
&lt;p>When you run the function, it prompts for a local admin username and password to log into the virtual machine. The password must have 3 of the following 1 Upper case, 1 lower case, I special character and 1 number. Don’t lose it, you will need it.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/local-admin.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/local-admin.png"
loading="lazy"
alt="Local Admin.PNG"
>&lt;/a>&lt;/p>
&lt;p>Grab a cuppa, creating your VM and its resources will take 5 – 10 minutes. (In my testing it reliably took between 7 and 8 minutes)  The screen will look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/deploying.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/deploying.png"
loading="lazy"
alt="deploying.PNG"
>&lt;/a>&lt;/p>
&lt;p>When the script has finished running you will have deployed a set of resources like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/portal.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/portal.png"
loading="lazy"
alt="portal"
>&lt;/a>&lt;/p>
&lt;h2 id="login-to-the-virtual-machine">Login to the Virtual Machine&lt;/h2>
&lt;p>Copy and paste the correct code from the output at the end of the script to launch the RDP session and save the RDP file to your documents folder for later use.&lt;/p>
&lt;p>Or you can find the Virtual machine name in the portal or by running&lt;/p>
&lt;p>&lt;code>Get-AzureRmVM -ResourceGroupName &amp;lt;ResourceGroup&amp;gt; | Where-Object {$_.Name -like 'DSVM*'}&lt;/code>&lt;/p>
&lt;p>You can then use the code below to download a RDP file and log into the virtual machine using this code&lt;/p>
&lt;p>&lt;code>Get-AzureRmRemoteDesktopFile -ResourceGroupName &amp;lt;ResourceGroup&amp;gt; -Name &amp;lt;VMName&amp;gt;  -LocalPath C:\WIP\DataScienceVM.rdp -Launch&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/rdp-file.png"
loading="lazy"
alt="rdp file.PNG"
>&lt;/a>&lt;/p>
&lt;p>You will need to login with the local admin account you set up previously, which means that you will need to click on more choices and then the &lt;code>machinename\Username&lt;/code>. In this case the machine name is &lt;code>DSVMZIAgd&lt;/code>&lt;/p>
&lt;p>You can copy the correct Virtual Machine name and Username from the output at the end of the script.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login-screen.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/login-screen.png"
loading="lazy"
alt="login screen.PNG"
>&lt;/a>&lt;/p>
&lt;p>If you have forgotten your password, you can reset it in the Portal.&lt;/p>
&lt;h2 id="enjoy-the-data-science-virtual-machine">Enjoy the Data Science Virtual Machine&lt;/h2>
&lt;p>You are then logged in and can carry on. Once the Azure PowerShell modules and script are installed you would be able to have a machine up and running within 10 minutes.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/vm-desktop.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/12/vm-desktop.png"
loading="lazy"
alt="vm-desktop"
>&lt;/a>&lt;/p>
&lt;h2 id="cleaning-up">Cleaning Up&lt;/h2>
&lt;p>To remove the resource group and ALL resources in the resource group, including the data science VM, run:&lt;/p>
&lt;p>&lt;code>Remove-AzureRmResourceGroup -Name &amp;lt;ResourceGroup&amp;gt;  -Force&lt;/code>&lt;/p>
&lt;p>This will remove ALL resources in that resource group, so be careful if you have deployed anything else.&lt;/p>
&lt;h2 id="customising-the-deployment">Customising the Deployment&lt;/h2>
&lt;p>If you want to use different settings for the deployment or want to script the creation of a number of machines, you can run&lt;/p>
&lt;p>&lt;code>Get-Help New-WindowsDataScienceVM -Full&lt;/code>&lt;/p>
&lt;p>and see all the options and further examples. Any questions please feel free to comment&lt;/p></description></item><item><title>Enabling Cortana for dbareports PowerBi</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/enabling-cortana-for-dbareports-powerbi/</link><pubDate>Sun, 13 Nov 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/enabling-cortana-for-dbareports-powerbi/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png" alt="Featured image of post Enabling Cortana for dbareports PowerBi" />&lt;p>Last week at the Birmingham user group I gave a presentation about PowerShell and SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/saved-image-from-tweetium-8.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/saved-image-from-tweetium-8.jpg"
loading="lazy"
alt="saved-image-from-tweetium-8"
>&lt;/a>&lt;/p>
&lt;p>It was a very packed session as I crammed in the &lt;a class="link" href="https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/30/sql-powershell-july-2016-update/" target="_blank" rel="noopener"
>new sqlserver module&lt;/a>, &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> 🙂 On reflection I think this is a bit too much for a one hour session but at the end of the session I demo’d live Cortana using the dbareports dataset and returning a Cortana PowerBi page.&lt;/p>
&lt;p>As always it took a couple of goes to get it right but when it goes correctly it is fantastic. I call it a salary increasing opportunity! Someone afterwards asked me how it was done so I thought that was worth a blog post&lt;/p>
&lt;p>There is a video below but the steps are quite straightforward.&lt;/p>
&lt;h2 id="add-cortana-specific-pages">Add Cortana Specific Pages&lt;/h2>
&lt;p>Whilst you can just enable Cortana to access your dataset, as shown later in this post, which enables Cortana to search available datasets and return an appropriate visualisation it is better to provide specific pages for Cortana to use and display. You can do this in PowerBi Desktop&lt;/p>
&lt;p>Start by adding a new page in your report by clicking on the plus button&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/add-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/add-page.png"
loading="lazy"
alt="add page.PNG"
>&lt;/a>&lt;/p>
&lt;p>and then change the size of the report page by clicking on the paintbrush icon in the visualisation page.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/page-size.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/page-size.png"
loading="lazy"
alt="page-size"
>&lt;/a>&lt;/p>
&lt;p>This creates a page that is optimised for Cortana to display and also will be the first place that Cortana will look to answer the question&lt;/p>
&lt;blockquote>
&lt;p>Power BI first looks for answers in &lt;a class="link" href="https://powerbi.microsoft.com/en-us/documentation/powerbi-service-cortana-desktop-entity-cards/" target="_blank" rel="noopener"
>Answer Pages&lt;/a> and then searches your datasets and reports for other answers and displays them in the form of visualizations. The highest-scoring results display first as &lt;em>best matches&lt;/em>, followed by links to other possible answers and applications. Best matches come from Power BI Answer Pages or Power BI reports.&lt;/p>
&lt;/blockquote>
&lt;p>Rename the page so that it contains the words or phrase you expect to be in the question such as “Servers By Version” You will help Cortana and PowerBi to get your results better if you use some of the column names in your dataset&lt;/p>
&lt;p>Then it is just another report page and you can add visualisations just like any other page&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-page.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-page.png"
loading="lazy"
alt="cortana page.PNG"
>&lt;/a>&lt;/p>
&lt;h2 id="make-cortana-work-for-you-and-your-users">Make Cortana work for you and your users&lt;/h2>
&lt;p>If your users are likely to use a number of different words in their questions you can assist Cortana to find the right answer by adding alternate names. So maybe if your page is sales by store you might add shop, building, results, amount, orders. This is also useful when Cortana doesn’t understand the correct words as you will notice in the screenshot below I have added “service” for “servers” and “buy” for “by” to help get the right answer. You can add these alternate words by clicking the paintbrush under visualisations and then Page Information&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-additional.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-additional.png"
loading="lazy"
alt="cortana-additional"
>&lt;/a>&lt;/p>
&lt;h2 id="publish-your-pbix-file-to-powerbicom">Publish your PBIX file to PowerBi.com&lt;/h2>
&lt;p>To publish your PowerBi report to &lt;a class="link" href="https://powerbi.com" target="_blank" rel="noopener"
>PowerBi.com&lt;/a> either via the Publish button in &lt;a class="link" href="http://go.microsoft.com/fwlink/?LinkID=521662" target="_blank" rel="noopener"
>PowerBi desktop&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/publish.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/publish.png"
loading="lazy"
alt="publish"
>&lt;/a>&lt;/p>
&lt;p>or by using the &lt;a class="link" href="https://github.com/DevScope/powerbi-powershell-modules" target="_blank" rel="noopener"
>PowerBiPS module&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Install-Module -Name PowerBIPS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Grab the token, will require a sign in
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $authToken = Get-PBIAuthToken –Verbose
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Import-PBIFile –authToken $authToken –filePath “Path to PBIX file” –verbose
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="enable-cortana">Enable Cortana&lt;/h2>
&lt;p>In your browser log into &lt;a class="link" href="https://powerbi.com" target="_blank" rel="noopener"
>https://powerbi.com&lt;/a> and then click on the cog and then settings&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/powerbicom.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/powerbicom.png"
loading="lazy"
alt="powerbicom.PNG"
>&lt;/a>&lt;/p>
&lt;p>then click on Datasets&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/settings.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/settings.png"
loading="lazy"
alt="settings"
>&lt;/a>&lt;/p>
&lt;p>Then choose the dataset – in this case dbareports SQL Information sample and click the tick box to Allow Cortana to access the this dataset and then click apply&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/dataset-settings.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/dataset-settings.png"
loading="lazy"
alt="dataset settings.PNG"
>&lt;/a>&lt;/p>
&lt;h2 id="use-cortana-against-your-powerbi-data">Use Cortana against your PowerBi data&lt;/h2>
&lt;p>You can type into the Cortana search box and it will offer the opportunity for you to choose your PowerBi data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search.png"
loading="lazy"
alt="cortana-search"
>&lt;/a>&lt;/p>
&lt;p>but it is so much better when you let it find the answer 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-11.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-11.png"
loading="lazy"
alt="cortana-search-1"
>&lt;/a>&lt;/p>
&lt;p>and if you want to go to the PowerBi report there is a handy link at the bottom of the Cortana page&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/11/cortana-search-2.png"
loading="lazy"
alt="cortana-search-2"
>&lt;/a>&lt;/p>
&lt;p>I absolutely love this, I was so pleased when I got it to work and the response when I show people is always one of wonder for both techies and none-techies alike&lt;/p>
&lt;h2 id="the-conditions-for-cortana-to-work">The conditions for Cortana to work&lt;/h2>
&lt;p>You will need to have added your work or school Microsoft ID to the computer or phone that you want to use Cortana on and that account must be able to access the dataset either because it is the dataset owner or because a dashboard using that dataset has been shared with that account.&lt;/p>
&lt;p>&lt;strong>&lt;a class="link" href="https://powerbi.microsoft.com/en-us/documentation/powerbi-service-cortana-enable/" target="_blank" rel="noopener"
>From this page on PowerBi.com&lt;/a>&lt;/strong>&lt;/p>
&lt;blockquote>
&lt;p>When a new dataset or custom Cortana Answer Page is added to Power BI and enabled for Cortana it can take up to 30 minutes for results to begin appearing in Cortana. Logging in and out of Windows 10, or otherwise restarting the Cortana process in Windows 10, will allow new content to appear immediately.&lt;/p>
&lt;/blockquote>
&lt;h2 id="its-not-perfect">It’s not perfect!&lt;/h2>
&lt;p>When you start using Cortana to query your data you will find that at times it is very frustrating. My wife was in fits of giggles listening to me trying to record the video below as Cortana refused to understand that I was saying “servers” and repeatedly searched Bing for “service” Whilst you can negate the effect by using the alternate names for the Q and A settings it is still a bit hit and miss at times.&lt;/p>
&lt;h2 id="it-is-amazing">It is amazing&lt;/h2>
&lt;p>There is something about giving people the ability to just talk to their device in a meeting and for example with dbareports ask&lt;/p>
&lt;blockquote>
&lt;p>Which clients are in Bolton&lt;/p>
&lt;/blockquote>
&lt;p>or&lt;/p>
&lt;blockquote>
&lt;p>When was the last backup for client The Eagles&lt;/p>
&lt;/blockquote>
&lt;p>and get the information they require and a link to the report in PowerBi.com. I am certain that the suits will be absolutely delighted at being able to show off in that way which is why I call it a salary increasing opportunity 🙂&lt;/p>
&lt;h2 id="we-would-love-you-to-come-and-join-us-at-the-sql-community-collaborative">We would love YOU to come and join us at the SQL Community Collaborative&lt;/h2>
&lt;p>Help us make &lt;code>dbatools&lt;/code>, &lt;code>dbareports&lt;/code> and &lt;code>Invoke-SQLCmd2&lt;/code> even better. You can join in by forking the repos in GitHub and writing your code and then performing a PR but we would much rather that you came and discussed new requests in our Trello boards, raised issues in GitHub and generally discussed the modules in the SQL Server Community Slack &lt;code>#dbatools&lt;/code> &lt;code>#dbareports&lt;/code>. We are also looking for assistance with our wiki pages, Pester tests and appveyor integration for our builds and any comments people want to make&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/sqlcollaborative/" target="_blank" rel="noopener"
>SQL Server Collaborative GitHub Organisation holding the modules.&lt;/a> Go here to raise issues, fork the repositories or download the code&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>dbatools Trello for discussion about new cmdlets&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://dbatools.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> where you can find #dbatools and #dbareports as well as over 1100 people discussing all aspects of the Data Platform, events, jobs, presenting&lt;/p>
&lt;p>COME AND JOIN US&lt;/p></description></item><item><title>Speaking? You? Go on. #tsql2sday #84</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/speaking-you-go-on.-#tsql2sday-%2384/</link><pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/speaking-you-go-on.-#tsql2sday-%2384/</guid><description>&lt;p>This is a blog post for &lt;a class="link" href="https://sqlbek.wordpress.com/2016/10/25/t-sql-tuesday-84-growing-new-speakers/" target="_blank" rel="noopener"
>this month&amp;rsquo;s T-SQL Tuesday post&lt;/a>, hosted by Andy Yun (&lt;a class="link" href="https://sqlbek.wordpress.com/author/sqlbek/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/SQLBek" target="_blank" rel="noopener"
>t&lt;/a>). &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>T-SQL Tuesday&lt;/a> is a monthly blog event started by Adam Machanic (&lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/adammachanic" target="_blank" rel="noopener"
>t&lt;/a>). The T-SQL Tuesday topic this month was about advice for new speakers. Thanks Andy for hosting. I have created a channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> for presenting which everyone can make use of to ask and to answer questions&lt;/p>
&lt;h2 id="i-think-you-should-share-what-you-know-with-others">I think you should share what you know with others.&lt;/h2>
&lt;p>You will be amazing.&lt;/p>
&lt;p>I will give you some great advice I learnt from a &lt;a class="link" href="https://www.brentozar.com/archive/2012/08/become-presenter-change-your-life/" target="_blank" rel="noopener"
>blog post&lt;/a>&lt;/p>
&lt;ol>
&lt;li>Start speaking&lt;/li>
&lt;li>Keep going&lt;/li>
&lt;li>Listen to feedback&lt;/li>
&lt;li>That’s it.&lt;/li>
&lt;/ol>
&lt;p>Kendra has said it all, you don&amp;rsquo;t need to read any further ;-)&lt;/p>
&lt;p> &lt;/p>
&lt;p> &lt;/p>
&lt;p> &lt;/p>
&lt;p> &lt;/p>
&lt;p>However..&lt;/p>
&lt;h2 id="not-all-plain-sailing">Not all plain sailing&lt;/h2>
&lt;p>I love giving sessions but I never knew or thought that I would. My journey to speaking started at my SQL user group in Exeter and two fabulous people &lt;a class="link" href="https://twitter.com/FatherJack" target="_blank" rel="noopener"
>Jonathan&lt;/a> and &lt;a class="link" href="https://twitter.com/Mrs_FatherJack" target="_blank" rel="noopener"
>Annette Allen&lt;/a> who encouraged me to share some PowerShell with the group. I was terrified, didn&amp;rsquo;t think I was worthy, my HDMI output wasn&amp;rsquo;t strong enough to power the projector, I had to transfer my slides and demo to Jonathans laptop. It was a fraught and frustrating experience.&lt;/p>
&lt;p>My second presentation was done on &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>Stuart Moores&lt;/a> MacBook Pro using Office Online for presentations and Azure for demos. Again a change right at the last minute and using a machine I didn&amp;rsquo;t know (and a different keyboard set-up).&lt;/p>
&lt;p>Stuff will go wrong. Murphy&amp;rsquo;s Law will always show his head somewhere and no matter how often you test and re-test your demos, sometimes an odd thing will make them stop working&lt;/p>
&lt;p>There will be problems and issues, you can mitigate some of them by following the 6 P&amp;rsquo;s&lt;/p>
&lt;blockquote>
&lt;p>Proper Preparation Prevents Pretty Poor Performance.&lt;/p>
&lt;/blockquote>
&lt;p>You can read some great blog posts in this T-SQL Tuesday Series and also &lt;a class="link" href="https://voiceofthedba.wordpress.com/2016/10/13/why-i-practice-presentations/" target="_blank" rel="noopener"
>this one from Steve Jones&lt;/a> or &lt;a class="link" href="https://www.brentozar.com/archive/tag/presenting/" target="_blank" rel="noopener"
>any of these&lt;/a> But also accept that these things happen and you must be prepared to shine on through the darkness if the power runs out or use pen and paper or even plastic cups like &lt;a class="link" href="https://twitter.com%5csqldiplomat" target="_blank" rel="noopener"
>John Martin&lt;/a> :-)&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;h2 id="you-never-know-you-might-enjoy-it">You never know you might enjoy it&lt;/h2>
&lt;p>I found I enjoyed it and wanted to do more and since then I have presented sessions in a wide variety of places. It was very strange to have been sat watching and listening to all of these fantastic presenters thinking I could never do that and then find out that actually it is something that I enjoy doing and find fun. You can do that too.&lt;/p>
&lt;p>Equally, it&amp;rsquo;s ok to not enjoy it, think its not worth the stress and hassle and support the community in a different way but at least give it a go&lt;/p>
&lt;h2 id="you-will-be-nervous">You will be nervous&lt;/h2>
&lt;p>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2016/11/quote-joan-jett-you-want-to-have-butterflies-in-your-185899.png?w=1972"
loading="lazy"
alt="quote-joan-jett-you-want-to-have-butterflies-in-your-185899"
>&lt;/p>
&lt;p>I shared a train across Germany with someone who had attended the PSMonday conference in Munich and they were astonished when I said that I get very nervous before speaking. It&amp;rsquo;s ok to be nervous, the trick is to make use of that nervous energy and turn it into something positive.&lt;/p>
&lt;p>I get very nervous before presentations. My hands shake, I sweat, I either babble or loose my voice. I fret and fidget and check everything a thousandillion times. I find it is better for me if I am sat in the room during the previous presentation as that generally helps me to feel more relaxed as I can listen to their talk and also out of respect for the presenter and the organisation it forces me to sit quietly.&lt;/p>
&lt;p>You will find your own way to deal with this, maybe listening to music on headphones or just sitting quietly somewhere. Don&amp;rsquo;t worry if it is not immediately obvious, try some different things, talk with others and believe me, it will be ok.&lt;/p>
&lt;p>Don&amp;rsquo;t try to numb it with alcohol&lt;/p>
&lt;p>Once I get up and its &amp;lsquo;my&amp;rsquo; turn I take a few deep breaths and suddenly presenter turns on and I forget all about being nervous.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/173101-everything-you-want-is-on-the-other-side-of-fear.jpg"
loading="lazy"
alt="173101-everything-you-want-is-on-the-other-side-of-fear"
>&lt;/p>
&lt;h2 id="something-to-talk-about">Something to talk about&lt;/h2>
&lt;p>I have nothing to talk about.&lt;/p>
&lt;p>Or everyone else knows more than I do.&lt;/p>
&lt;p>Or X Y and Z talk about this much better than I do.&lt;/p>
&lt;p>I&amp;rsquo;m scared&lt;/p>
&lt;p>&lt;a class="link" href="https://twitter.com/splappy" target="_blank" rel="noopener"
>Richard Munn&lt;/a> and I gave an impromptu session at SQL Relay in Cardiff where we talked about and hopefully encouraged people to start speaking and these statements came up.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/wp_20161004_13_59_32_pro.jpg"
loading="lazy"
alt="wp_20161004_13_59_32_pro"
>&lt;/p>
&lt;p>Heres (a little of) what we said&lt;/p>
&lt;p>No-one knows everything. Many people know a hell of a lot but not everything. You know a lot more than you realise and you also know things that no-one else does.&lt;/p>
&lt;p>If you are stuck for things to talk about think about the you of 6 months or a year ago and something that you have learnt in that time and write the session that you wish you could have seen then. There will be other people at a similar stage who will appreciate it.&lt;/p>
&lt;p>Don&amp;rsquo;t be scared, they are only people.&lt;/p>
&lt;h2 id="practice">Practice&lt;/h2>
&lt;p>My dog is the one person who has been present at my presentations the most. He has listened (sometimes intently) to me practicing.&lt;/p>
&lt;p>You need to practice speaking out loud.&lt;/p>
&lt;p>You need to understand the timings&lt;/p>
&lt;p>You need to be comfortable with hearing yourself speaking out aloud&lt;/p>
&lt;p>You need to practice speaking out loud&lt;/p>
&lt;p>A double reminder because I think it is important. You should practice and practice and practice with an eye on your timings and if you have a good friend who is technical or a small group at work for a lunchtime maybe then ask them if they will listen and give feedback.&lt;/p>
&lt;h2 id="wanna-chat">Wanna chat?&lt;/h2>
&lt;p>I am very passionate about community involvement and lucky enough to be involved in two fantastic communities - the SQL community and the PowerShell community and have made some great friends along the way. I was amazed and proud when very soon after my second presentation someone told me that I had inspired them to start to present.&lt;/p>
&lt;p>Since then I have gone out of my way to encourage other people to speak and to blog and am really enjoying watching them blossom. If you want to have a chat via email or via &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>slack&lt;/a> about speaking or blogging or getting involved in the community please feel free to contact me and I promise you I will get back to you. Better still go to the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Community Slack&lt;/a> and ask questions in #presentingorspeaking&lt;/p>
&lt;h2 id="go-find-out-more">Go find out more&lt;/h2>
&lt;p>We are good at sharing and learning technical content but we can share and learn about so much more, about all aspects of our life. Go and read all of the other posts in this T-SQL Tuesday for starters :-) and develop&lt;/p></description></item><item><title>PowerBi and API – Visualising my Checkins</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powerbi-and-api-visualising-my-checkins/</link><pubDate>Sat, 29 Oct 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powerbi-and-api-visualising-my-checkins/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi6.png%29%5D%28/assets/uploads/2016/10/powerbi6.png" alt="Featured image of post PowerBi and API – Visualising my Checkins" />&lt;p>For my own amusement and also to show my wife where I have been I use the &lt;a class="link" href="https://www.swarmapp.com/" target="_blank" rel="noopener"
>Swarm&lt;/a> check-in app on my phone and check-in to places. Also for my own amusement I used PowerBi to visualise the data via the API and allow me to filter it in various ways.&lt;/p>
&lt;p>Whilst at the &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/psconfasia-2016/" >PowerShell Conference in Asia&lt;/a> I was showing the mobile app to a group over some food and saying how easy it was and &lt;a class="link" href="http://twitter.com/@juneb_get_help" target="_blank" rel="noopener"
>June Blender&lt;/a>, the mother of PowerShell help, said that I ought to blog about it. So I have 🙂&lt;/p>
&lt;p>Follow these steps and you can create this report.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi8.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi8.png"
loading="lazy"
alt="powerbi8.PNG"
>&lt;/a> and add your own access token to it should you wish. Details at the end of the post&lt;/p>
&lt;p>I am using the swarm API but the principle is the same for any other API that provides you with data. For example, I used the same principles to create the &lt;a class="link" href="http://powershell.sqlpass.org/Reporting.aspx" target="_blank" rel="noopener"
>embedded reports&lt;/a> on the PASS PowerShell Virtual Chapter page showing the status of the cards suggesting improvements to the sqlserver module for the product team to work on. Hopefully, this post will give you some ideas to work on and show you that it is quite easy to get excellent data visualisation from APIs&lt;/p>
&lt;p>First up we need to get the data. I took a look at the &lt;a class="link" href="https://developer.foursquare.com/" target="_blank" rel="noopener"
>Swarm developers page&lt;/a> ( The Trello is &lt;a class="link" href="https://developers.trello.com/advanced-reference" target="_blank" rel="noopener"
>here by the way&lt;/a>) I had to register for an app, which gave me a client id and a secret. I then followed the &lt;a class="link" href="https://developer.foursquare.com/overview/auth.html" target="_blank" rel="noopener"
>steps here to get my user token&lt;/a> I was only interested in my own check ins so I used the steps under Token flow Client applications to get my access token which I used in an URL like this.&lt;/p>
&lt;blockquote>
&lt;p>&lt;a class="link" href="https://api.foursquare.com/v2/users/self/checkins?limit=5000&amp;amp;oauth_token=ACCESS_TOKEN&amp;amp;v=YYYYMMDD" target="_blank" rel="noopener"
>https://api.foursquare.com/v2/users/self/checkins?limit=5000&amp;amp;oauth_token=ACCESS_TOKEN&amp;amp;v=YYYYMMDD&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>I added the limit 5000 as the default number of checkins returned was too small for my needs and the date was that days date.&lt;/p>
&lt;p>You can do this in Powershell using code I got from the magnificent &lt;a class="link" href="https://foxdeploy.com/2015/11/02/using-powershell-and-oauth/" target="_blank" rel="noopener"
>Stephen Owen’s blog post&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## Enter the details
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Clientid =&amp;#39;&amp;#39;  ## Enter ClientId from foursquare
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$redirect = &amp;#39;&amp;#39; ## enter redirect url from client app in foursquare
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">##Create the URL:
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$URL = &amp;#34;https://foursquare.com/oauth2/authenticate?client_id=$Clientid&amp;amp;response_type=token&amp;amp;redirect_uri=$redirect&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## function from https://foxdeploy.com/2015/11/02/using-powershell-and-oauth/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Function Show-OAuthWindow {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Add-Type -AssemblyName System.Windows.Forms
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$form = New-Object -TypeName System.Windows.Forms.Form -Property @{Width=440;Height=640}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$web  = New-Object -TypeName System.Windows.Forms.WebBrowser -Property @{Width=420;Height=600;Url=($url -f ($Scope -join &amp;#34;%20&amp;#34;)) }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DocComp  = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Global:uri = $web.Url.AbsoluteUri
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Global:Uri -match &amp;#34;error=[^&amp;amp;]*|code=[^&amp;amp;]*&amp;#34;) {$form.Close() }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$web.ScriptErrorsSuppressed = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$web.Add_DocumentCompleted($DocComp)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$form.Controls.Add($web)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$form.Add_Shown({$form.Activate()})
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$form.ShowDialog() | Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#endregion
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#login to get an access code then close the redirect window
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Show-OAuthWindow -URL $URl
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## grab the token
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$regex = &amp;#39;(?&amp;lt;=access_token=)(.*)&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$authCode  = ($uri | Select-string -pattern $regex).Matches[0].Value
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$global:AuthToken = $authCode
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-output &amp;#34;Received a token, $AuthToken&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;So the URL for your PowerBi Data is :-&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PowerBiUrl = &amp;#34;https://api.foursquare.com/v2/users/self/checkins?limit=5000&amp;amp;oauth_token=$AuthToken&amp;amp;v=20160829&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PowerBiUrl | Clip
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I checked the URL in a browser and confirmed that it returned a json object. Keep that URL safe you will need it in a minute. That code above has placed it in your clipboard. If you want to jump straight to the report using the download stop here and go to the end&lt;/p>
&lt;p>So now lets move to Power BI. Go to &lt;a class="link" href="http://powerbi.com" target="_blank" rel="noopener"
>powerbi.com&lt;/a> and download the PowerBi Desktop. Its free. You will need to create an account using a school or work email address if you wish to put your reports in powerbi.com&lt;/p>
&lt;p>Once you have downloaded and installed PowerBi Desktop you will be faced with a window like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi.png"
loading="lazy"
alt="powerbi"
>&lt;/a>&lt;/p>
&lt;p>Start by clicking Get Data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi2.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi2.png"
loading="lazy"
alt="powerbi2"
>&lt;/a>&lt;/p>
&lt;p>Then choose Web and paste the URL from above into the filename and press ok which will give you this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi3.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi3.png"
loading="lazy"
alt="powerbi3"
>&lt;/a>&lt;/p>
&lt;p>Now we need to put the data into a format that is of more use to us&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power1.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power1.gif"
loading="lazy"
alt="power1"
>&lt;/a>&lt;/p>
&lt;p>I clicked on the record link for response, then converted to table, then the little icon at the top of the column to expand the value.items column and then the value.items column again. It doesn’t look much yet but we are a step closer.&lt;/p>
&lt;p>Next I looked in the table for the venue column, expanded that and the location column and the formatted address column.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power2.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power2.gif"
loading="lazy"
alt="power2"
>&lt;/a>&lt;/p>
&lt;p>You can also expand the categories so that you can look at those too by expanding Value.items.venue.categories and Value.items.venue.categories1&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi4.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi4.gif"
loading="lazy"
alt="powerbi4.gif"
>&lt;/a>&lt;/p>
&lt;p>Now you will see that we have some duplicates in the data so we need to remove those. I did that by deleting the first 3 columns and then clicking remove duplicates under Delete Rows&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power3b.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/power3b.gif"
loading="lazy"
alt="power3b.gif"
>&lt;/a>&lt;/p>
&lt;p>Then click close and apply. Then click on the data button as we need to rename and remove some more columns so that our data makes a little sense. I renamed the columns like this&lt;/p>
&lt;ul>
&lt;li>Value.items.createdAt –&amp;gt; CreatedAt&lt;/li>
&lt;li>Value.items.shout –&amp;gt; Comment&lt;/li>
&lt;li>Value.items.venue.name –&amp;gt; VenueName&lt;/li>
&lt;li>Value.items.venue.location.address –&amp;gt; VenueAddress&lt;/li>
&lt;li>Value.items.timeZoneOffset –&amp;gt; TimeZoneOffset&lt;/li>
&lt;li>Value.items.venue.location.lat –&amp;gt; VenueLat&lt;/li>
&lt;li>Value.items.venue.location.lng –&amp;gt; VenueLong&lt;/li>
&lt;li>Value.items.venue.location.postalCode –&amp;gt; VenuePostalCode&lt;/li>
&lt;li>Value.items.venue.location.cc –&amp;gt; CountryCode&lt;/li>
&lt;li>Value.items.venue.location.city –&amp;gt; City&lt;/li>
&lt;li>Value.items.venue.location.state –&amp;gt; State&lt;/li>
&lt;li>Value.items.venue.location.country –&amp;gt; Country&lt;/li>
&lt;li>Value.items.venue.location.formattedAddress –&amp;gt; VenueAddress&lt;/li>
&lt;li>Value.items.venue.url –&amp;gt; VenueURL&lt;/li>
&lt;li>Value.items.venue.categories.name –&amp;gt; Catogory&lt;/li>
&lt;li>Value.items.venue.categories.pluralName –&amp;gt; Categories&lt;/li>
&lt;/ul>
&lt;p>and remove all of the other columns. You can also do this in the Edit Queries window, I am just showing you that there are multiple ways to do the same thing&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi5.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi5.gif"
loading="lazy"
alt="powerbi5.gif"
>&lt;/a>&lt;/p>
&lt;p>Once you have done that you should have a window that looks like this. Notice I renamed the query to checkins as well&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi4.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi4.png"
loading="lazy"
alt="powerbi4.PNG"
>&lt;/a>&lt;/p>
&lt;p>Now we need to create a calculated column for the time and a measure for the count of checkins. This is done using this code&lt;/p>
&lt;p>&lt;code>Time = VAR UnixDays = [createdAt]/(60*60*24)
RETURN (DATEVALUE(&amp;quot;1/1/1970&amp;quot;)+UnixDays)&lt;/code>&lt;/p>
&lt;p>&lt;code>CountCheckins = COUNT(checkins[Time])&lt;/code>&lt;/p>
&lt;p>and we can move onto the report side of things. Frist we are going to download a custom visual. Go to the &lt;a class="link" href="https://app.powerbi.com/visuals/" target="_blank" rel="noopener"
>PowerBi Custom Visuals Page&lt;/a> and download the Timeline visual&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi5.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi5.png"
loading="lazy"
alt="powerbi5.PNG"
>&lt;/a>&lt;/p>
&lt;p>and then import it into your PowerBi report. I have embedded a YouTube video below showing the steps I took to turn this into the PowerBi report. Its pretty easy, you will be able to click on the visuals and then click on the data columns and alter them until you have the report that you want.&lt;/p>
&lt;p>Once you have done this, you can upload it to PowerBi if you wish by clicking on the Publish button in PowerBi desktop and signing into PowerBi.com with your work email address.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi6.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi6.png"
loading="lazy"
alt="powerbi6.PNG"
>&lt;/a>&lt;/p>
&lt;p>and your report is available for you on PowerBi.com 🙂 By clicking on the pins on a visualisation you can add them to a dashboard.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi8.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi8.gif"
loading="lazy"
alt="powerbi8.gif"
>&lt;/a>&lt;/p>
&lt;p>Once you have a dashboard you can then use the natural language query to ask questions of your data. Here are some examples&lt;/p>
&lt;p>How many checkins are in GB&lt;br>
How many checkins are in airports&lt;br>
How many checkins by month&lt;br>
How many checkins by month in GB&lt;br>
Which airports&lt;br>
Show me hotel venuename and time&lt;br>
How many hotels by country&lt;br>
Show me hotel venuename and checkins count&lt;br>
metro stations venuename and count checkins as a map&lt;br>
Show me count checkins in Amsterdam by category as a donut&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi7.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi7.png"
loading="lazy"
alt="powerbi7.PNG"
>&lt;/a>&lt;/p>
&lt;p>If you want to use the blank report, &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/PowerBi%20and%20Api%20Blog%20Demo.pbix" target="_blank" rel="noopener"
>download it from here&lt;/a> open it in PowerBi Desktop, click Edit Queries and Source and add your own URL and click Apply and then Refresh&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi9.gif" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/10/powerbi9.gif"
loading="lazy"
alt="powerbi9.gif"
>&lt;/a>&lt;/p>
&lt;p>Hopefully, this has given you some ideas of ways that you can create some reports from many of the data sources available to you via API&lt;/p></description></item><item><title>PSConfAsia 2016</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/psconfasia-2016/</link><pubDate>Mon, 24 Oct 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/psconfasia-2016/</guid><description>&lt;p>I have just got back to the UK from Singapore following the amazing &lt;a class="link" href="http://www.psconf.asia/" target="_blank" rel="noopener"
>PSConfAsia&lt;/a> conference. I must say that Matt, Milton, Sebastian and Ben did a fantastic job organising this conference and were proud that there was a notable increase in attendees from last year.&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5csebastians-photo.jpg"
loading="lazy"
alt="sebastians-photo"
>&lt;/p>
&lt;p> &lt;/p>
&lt;p>The conference began (unofficially) with a PowerShell User group session in the Microsoft Offices on Wednesday where &lt;a class="link" href="http://www.ravichaganti.com/blog/" target="_blank" rel="noopener"
>Ravi Chaganti&lt;/a> spoke about DSC&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161019_19_56_07_pro-2.jpg"
loading="lazy"
alt="WP_20161019_19_56_07_Pro (2).jpg"
>&lt;/p>
&lt;p>and then Desmond Lee lead a Q and A session. In the end we decided that all the answers were&lt;/p>
&lt;blockquote>
&lt;p>It Depends and Test in your Environment&lt;/p>
&lt;/blockquote>
&lt;p>That evening, I even managed to jump on the PASS PowerShell Virtual Chapter session by Scott Sutherland &lt;a class="link" href="https://www.youtube.com/watch?v=npoORzfP7rw" target="_blank" rel="noopener"
>Hacking SQL Servers on Scale using PowerShell the recording of which is here&lt;/a>  A session organised and managed online in three different time zones by Aaron Chrissy and myself :-).&lt;/p>
&lt;p>On Thursday the conference proper started with a pre-con day at the Amazon Web Services office. Yes, you read that right. This conference really highlighted the cross-platform direction and adoption of open-source that Microsoft is taking.  &lt;a class="link" href="http://twitter.com/@JasonYoder_MCT" target="_blank" rel="noopener"
>Jason Yoder&lt;/a> spent all day teaching a group &amp;ldquo;PowerShell for Beginners&amp;rdquo; in one room&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_09_24_43_pro.jpg"
loading="lazy"
alt="WP_20161020_09_24_43_Pro.jpg"
>&lt;/p>
&lt;p>while The Amazon Web Services Team showed DevOps on AWS with PowerShell in the morning and &lt;a class="link" href="https://twitter.com/juneb_get_help" target="_blank" rel="noopener"
>June Blender&lt;/a> gave a SAPIEN Toolmaking Seminar.fter this we went back to the Microsoft Offices for another User Group where Jason Yoder gave a (nother) session with &lt;a class="link" href="https://twitter.com/jaap_brasser" target="_blank" rel="noopener"
>Jaap Brasser&lt;/a> on PowerShell Tips and Tricks (&lt;a class="link" href="https://onedrive.live.com/?authkey=%21AJyNBdDeTNtAS18&amp;amp;id=4B0EFD9B34E1210E%2124928&amp;amp;cid=4B0EFD9B34E1210E" target="_blank" rel="noopener"
>Demo&lt;/a>)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_19_26_24_pro-2.jpg"
loading="lazy"
alt="WP_20161020_19_26_24_Pro (2).jpg"
>&lt;/p>
&lt;p>Friday started with The PowerShell Team represented by &lt;a class="link" href="https://twitter.com/khansenhansen" target="_blank" rel="noopener"
>Kenneth Hansen&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/angelcalvos" target="_blank" rel="noopener"
>Angel Calvo&lt;/a> talking about PowerShell Past, Present and Future. It was really good that there was such great access to the product team at the conference and I saw lots of interaction around the conference as well, in addition to the sessions they provided.&lt;/p>
&lt;p>Next up for me was another session from the PowerShell Team, this time &lt;a class="link" href="https://twitter.com/hemanmahawar" target="_blank" rel="noopener"
>Hemant Mahawar&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/lzybkr" target="_blank" rel="noopener"
>Jason Shirk&lt;/a> taking us on a Journey Through the Ages of PowerShell Security&lt;/p>
&lt;blockquote>
&lt;p>Execution Policy is not a security feature&lt;/p>
&lt;/blockquote>
&lt;p>That took us to lunch, we were treated to excellent lunches at this conference&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161020_12_07_14_pro-2.jpg"
loading="lazy"
alt="WP_20161020_12_07_14_Pro (2).jpg"
>&lt;/p>
&lt;p>After lunch I sat in the PowerShell Teams Ask Us Anything session although I was mainly preparing for my own session PowerShell Profile Prepares Perfect Production Purlieu which followed. There were excellent sessions on JEA, Nano Server, Chef and DSC, Containers, ETS and securing PowerShell against malware whilst I attended &lt;a class="link" href="http://flynnbundy.com" target="_blank" rel="noopener"
>Flynn Bundy&amp;rsquo;s&lt;/a> session about Windows Containers and Building GUIs with XAML with &lt;a class="link" href="https://twitter.com/david_das_neves" target="_blank" rel="noopener"
>David Das Neves&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cwp_20161021_15_58_12_pro-2.jpg"
loading="lazy"
alt="WP_20161021_15_58_12_Pro (2).jpg"
>&lt;/p>
&lt;p>That evening, organisers, speakers and attendees all went to the Penny Black pub on Marina Bay and enjoyed some food, refreshments and networking&lt;/p>
&lt;p>Saturday started slowly after the rain (another impressive &amp;lsquo;feature&amp;rsquo; of Singapore)  but the first session was a brilliant one with &lt;a class="link" href="https://twitter.com/hemanmahawar" target="_blank" rel="noopener"
>Hemant Mahawar&lt;/a> &amp;amp; &lt;a class="link" href="https://twitter.com/lzybkr" target="_blank" rel="noopener"
>Jason Shirk&lt;/a> talking Pragmatic PowerShell and answering questions. I am glad Jason used &lt;a class="link" href="https://github.com/Code52/carnac" target="_blank" rel="noopener"
>Carnac&lt;/a> to show what he was typing so that people could (just about :-) ) keep up. I then attended the excellent session about contribution with Microsoft.&lt;/p>
&lt;p>The rest of the day had amazing sessions on Azure Automation, IoT, AWS Cloud Formation, Centralised Repository Server, Chef, Puppet, Professional Help, Nano Server, Docker, DSC, Release Pipeline and of course some bearded fella talking about Installing SQL Scripts and creating Pester Tests for them and combining PowerShell, SQL, SSRS, PowerBi and Cortana :-)&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/..%5cassets%5cuploads%5c2016%5c10%5cjason-yoders-photo.jpg"
loading="lazy"
alt="Jason Yoder&amp;rsquo;s photo.jpg"
>&lt;/p>
&lt;p>My takeaways from the conference were that Microsoft is very open to all members of the open source community, DevOps is a very important topic and also the following points from the PowerShell team&lt;/p>
&lt;blockquote>
&lt;p>PowerShell Team want YOU to contribute. Interact with them File bugs Feature Requests Documentation Tests Code&lt;/p>
&lt;/blockquote>
&lt;p>and&lt;/p>
&lt;blockquote>
&lt;p>Fixing is better than complaining :-) &lt;a class="link" href="https://twitter.com/@HemanMahawar" target="_blank" rel="noopener"
>@HemanMahawar&lt;/a> &lt;a class="link" href="https://twitter.com/search?q=%23psconfasia" target="_blank" rel="noopener"
>#psconfasia&lt;/a> You can help fix the documentation. Use the contribute button on the doc&lt;/p>
&lt;/blockquote>
&lt;p>and&lt;/p>
&lt;blockquote>
&lt;p>If you are thinking of starting or run a PowerShell usergroup Microsoft would like help. Tag 1 of the team such as &lt;a class="link" href="https://twitter.com/@ANGELCALVOS" target="_blank" rel="noopener"
>@ANGELCALVOS&lt;/a> &lt;a class="link" href="https://twitter.com/search?q=%23psconfasia" target="_blank" rel="noopener"
>#psconfasia&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>Special thanks and congratulations must go to Matt, Milton, Sebastian and Ben for their excellent organisation and for creating an awesome event. I am looking forward to seeing how they can better it next year and also hoping that seeing all the fabulous speakers and sessions will inspire some attendees from this years event to share their own knowledge and experience at local user groups and even next years conference.&lt;/p></description></item><item><title>PowerShell, Pester and Ola Hallengrens Maintenance Solution</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-and-ola-hallengrens-maintenance-solution/</link><pubDate>Sat, 24 Sep 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-and-ola-hallengrens-maintenance-solution/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/pester-ola-check.png" alt="Featured image of post PowerShell, Pester and Ola Hallengrens Maintenance Solution" />&lt;p>If you are a SQL DBA you will have heard of &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>Ola Hallengrens Maintenance solution&lt;/a> If you haven’t go and click the link and look at the easiest way to ensure that all of your essential database maintenance is performed. You can also &lt;a class="link" href="https://sqlbits.com/Sessions/Event9/Inside_Ola_Hallengrens_Maintenance_Solution" target="_blank" rel="noopener"
>watch a video from Ola at SQL Bits&lt;/a>&lt;br>
Recently I was thinking about how I could validate that this solution was installed in the way that I wanted it to be so I turned to &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> You can find a great &lt;a class="link" href="https://mcpmag.com/articles/2016/05/19/test-powershell-modules-with-pester.aspx" target="_blank" rel="noopener"
>how to get started here&lt;/a> which will show you how to get Pester and how to get started with TDD.&lt;br>
This isn’t TDD though this is Environment Validation and this is how I went about creating my test.&lt;br>
First I thought about what I would look for in SSMS when I had installed the maintenance solution and made a list of the things that I would check which looked something like this. This would be the checklist you would create (or have already created) for yourself or a junior following this install. This is how easy you can turn that checklist into a Pester Test and remove the human element and open your install for automated testing&lt;/p>
&lt;ul>
&lt;li>SQL Server Agent is running – Otherwise the jobs won’t run 🙂&lt;/li>
&lt;li>We should have 4 backup jobs with a name of&lt;/li>
&lt;li>DatabaseBackup – SYSTEM_DATABASES – FULL&lt;/li>
&lt;li>DatabaseBackup – USER_DATABASES – FULL&lt;/li>
&lt;li>DatabaseBackup – USER_DATABASES – DIFF&lt;/li>
&lt;li>DatabaseBackup – USER_DATABASES – LOG&lt;/li>
&lt;li>We should have Integrity Check and Index Optimisation Jobs&lt;/li>
&lt;li>We should have the clean up jobs&lt;/li>
&lt;li>All jobs should be scheduled&lt;/li>
&lt;li>All jobs should be enabled&lt;/li>
&lt;li>The jobs should have succeeded&lt;/li>
&lt;/ul>
&lt;p>I can certainly say that I have run through that check in my head and also written it down in an installation guide in the past. If I was being more careful I would have checked if there were the correct folders in the folder I was backing up to.&lt;/p>
&lt;p>Ola’s script uses a default naming convention so this makes it easy. There should be a &lt;code>SERVERNAME&lt;/code> or &lt;code>SERVERNAME$INSTANCENAME&lt;/code> folder or if there is an Availability Group a &lt;code>CLUSTERNAME$AGNAME&lt;/code> and in each of those a FULL DIFF and LOG folder which I can add to my checklist&lt;/p>
&lt;p>So now we have our checklist we just need to turn in into a Pester Environmental Validation script&lt;/p>
&lt;p>It would be useful to be able to pass in a number of instances so we will start with a foreach loop and then a &lt;a class="link" href="https://github.com/pester/Pester/wiki/Describe" target="_blank" rel="noopener"
>Describe Block&lt;/a> then split the server name and instance name, get the agent jobs and set the backup folder name&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$ServerName = $Server.Split(&amp;#39;\&amp;#39;)[0]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$InstanceName = $Server.Split(&amp;#39;\&amp;#39;)[1]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName.ToUpper()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#39;Testing $Server Backup solution&amp;#39;{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BeforeAll {$Jobs = Get-SqlAgentJob -ServerInstance $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SQLServer.Management.SMO.Server $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$dbs = $Srv.Databases.Where{$_.status -eq &amp;#39;Normal&amp;#39;}.name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($InstanceName)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DisplayName = &amp;#39;SQL Server Agent ($InstanceName)&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Folder = $ServerName + &amp;#39;$&amp;#39; + $InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DisplayName = &amp;#39;SQL Server Agent (MSSQLSERVER)&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Folder = $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($CheckForBackups -eq $true)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CheckForDBFolders -eq $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Root = $Share + &amp;#39;\&amp;#39; + $Folder
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also set the Agent service display name so I can get its status. I split the jobs up using a &lt;a class="link" href="https://github.com/pester/Pester/wiki/Context" target="_blank" rel="noopener"
>Context block&lt;/a>, one each for Backups, Database maintenance and solution clean up but they all follow the same pattern. .First get the jobs&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Jobs = $Jobs.Where{($_.Name -like &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL*&amp;#39; + $JobSuffix + &amp;#39;*&amp;#39;) -or ($_.Name -like &amp;#39;DatabaseBackup - USER_DATABASES - FULL*&amp;#39; + $JobSuffix + &amp;#39;*&amp;#39;) -or ($_.Name -like &amp;#39;DatabaseBackup - USER_DATABASES - DIFF*&amp;#39; + $JobSuffix + &amp;#39;*&amp;#39;) -or ($_.Name -like &amp;#39;DatabaseBackup - USER_DATABASES - LOG*&amp;#39; + $JobSuffix + &amp;#39;*&amp;#39;)}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we can iterate through them and check them but first lets test the Agent Service. You do this with an &lt;a class="link" href="https://github.com/pester/Pester/wiki/It" target="_blank" rel="noopener"
>It Block&lt;/a> and in it put a single test like this&lt;/p>
&lt;p>&lt;code>actual-value | Should Be expected-value&lt;/code>&lt;/p>
&lt;p>So to check the Agent Job is running we can do this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">(Get-service -ComputerName $ServerName -DisplayName $DisplayName).Status | Should Be &amp;#39;Running&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To find out how to get the right values for any test I check using get member so to see what is available for a job I gathered the Agent Jobs into a variable using the &lt;code>Get-SQLAgentJob&lt;/code> command in the new sqlserver module (which you can get by installing the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/mt238290.aspx" target="_blank" rel="noopener"
>latest SSMS from here&lt;/a>) and then explored their properties using &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849928.aspx" target="_blank" rel="noopener"
>Get-Member&lt;/a> and the values using &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849895.aspx" target="_blank" rel="noopener"
>Select Object&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$jobs = Get-SqlAgentJob -ServerInstance $server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">($Jobs | Get-Member -MemberType Property).name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs[0] | Select-Object *
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>then using a foreach to loop through them I can check that the jobs, exists, is enabled, has a schedule and succeeded last time it ran like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Jobs = $Jobs.Where{($_.Name -eq &amp;#39;DatabaseIntegrityCheck - SYSTEM_DATABASES&amp;#39;) -or ($_.Name -eq &amp;#39;DatabaseIntegrityCheck - USER_DATABASES&amp;#39;) -or ($_.Name -eq &amp;#39;IndexOptimize - USER_DATABASES&amp;#39;)}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach($job in $Jobs)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobName = $Job.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;$JobName Job Exists&amp;#39;{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job | Should Not BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;$JobName Job is enabled&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.IsEnabled | Should Be &amp;#39;True&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;$JobName Job has schedule&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job.HasSchedule | Should Be &amp;#39;True&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($DontCheckJobOutcome -eq $false)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;$JobName Job succeeded&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job.LastRunOutCome | Should Be &amp;#39;Succeeded&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So I have checked the agent and the jobs and now I want to check the folders exist. First for the instance using &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849776.aspx" target="_blank" rel="noopener"
>&lt;code>Test-Path&lt;/code>&lt;/a> so the user running the PowerShell session must have privileges and access to list the files and folders&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Context &amp;#39;$Share Share For $Server&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Should have the root folder $Root&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-Path $Root | Should Be $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The for every database we need to set some variables for the Folder path. We don’t back up tempdb so we ignore that and then check if the server is SQL2012 or above and if it is check if the database is a member of an availability group and set the folder name appropriately&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">  foreach($db in $dbs.Where{$_ -ne &amp;#39;tempdb&amp;#39;})
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Srv.VersionMajor -ge 11)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">If($srv.Databases[$db].AvailabilityGroupName)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AG = $srv.Databases[$db].AvailabilityGroupName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cluster = $srv.ClusterName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$OLAAg = $Cluster + &amp;#39;$&amp;#39; + $AG
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Share.StartsWith(&amp;#39;\\&amp;#39;) -eq $False)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$UNC = $Share.Replace(&amp;#39;:&amp;#39;,&amp;#39;$&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Root = &amp;#39;\\&amp;#39; + $ServerName + &amp;#39;\&amp;#39; + $UNC + &amp;#39;\&amp;#39; + $OlaAG
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Root = &amp;#39;\\&amp;#39; + $ServerName + &amp;#39;\&amp;#39; + $UNC + &amp;#39;\&amp;#39; + $Folder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Share.StartsWith(&amp;#39;\\&amp;#39;) -eq $False)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$UNC = $Share.Replace(&amp;#39;:&amp;#39;,&amp;#39;$&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Root = &amp;#39;\\&amp;#39; + $ServerName + &amp;#39;\&amp;#39; + $UNC + &amp;#39;\&amp;#39; + $Folder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Root = $Share + &amp;#39;\&amp;#39; + $Folder
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $db.Replace(&amp;#39; &amp;#39;,&amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Dbfolder = $Root + &amp;amp;amp;quot;\$db&amp;amp;amp;quot;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Full = $Dbfolder + &amp;#39;\FULL&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Diff = $Dbfolder + &amp;#39;\DIFF&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Log  = $Dbfolder + &amp;#39;\LOG&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">If($CheckForDBFolders -eq $True)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Context &amp;amp;amp;quot;Folder Check for $db on $Server on $Share&amp;amp;amp;quot; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;amp;amp;quot;Should have a folder for $db database&amp;amp;amp;quot; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-Path $Dbfolder |Should Be $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>But we need some logic for checking for folders because Ola is smart and checks for Log Shipping databases so as not to break the LSN chain and system databases only have full folders and simple recovery databases only have full and diff folders. I used the &lt;code>System.IO.Directory&lt;/code> Exists method as I found it slightly quicker for UNC Shares&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">If($CheckForDBFolders -eq $True)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Context &amp;#39;Folder Check for $db on $Server on $Share&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Should have a folder for $db database&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-Path $Dbfolder |Should Be $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Db -notin (&amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;model&amp;#39;) -and ($Srv.Databases[$db].RecoveryModel -ne &amp;#39;Simple&amp;#39;) -and ( $LSDatabases -notcontains $db))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Full Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Full) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Diff Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Diff) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Log Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Log) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">} #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">elseif(($Srv.Databases[$db].RecoveryModel -eq &amp;#39;Simple&amp;#39;) -and $Db -notin (&amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;model&amp;#39;) -or ( $LSDatabases -contains $db) )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Full Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Full) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Diff Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Diff) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">} #
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has a Full Folder&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.IO.Directory]::Exists($Full) | Should Be $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">} # End Check for db folders
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and a similar thing for the files in the folders although this caused me some more issues with performance. I first used Get-ChildItem but in folders where a log backup is running every 15 minutes it soon became very slow. So I then decided to compare the create time of the folder with the last write time which was significantly quicker for directories with a number of files but then fell down when there was a single file in the directory so if the times match I revert back to &lt;code>Get-ChildItem&lt;/code>.&lt;/p>
&lt;p>If anyone has a better more performant option I would be interested in knowing. I used Øyvind Kallstad PowerShell Conference session Chasing the seconds &lt;a class="link" href="https://github.com/psconfeu/2016/tree/master/%C3%98yvind%20Kallstad" target="_blank" rel="noopener"
>Slides&lt;/a> and &lt;a class="link" href="https://www.youtube.com/watch?v=erwAsXZnQ58" target="_blank" rel="noopener"
>Video&lt;/a> and tried the methods in there with &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849910.aspx" target="_blank" rel="noopener"
>Measure-Command&lt;/a> but this was the best I came up with&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">If($CheckForBackups -eq $true)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Context &amp;#39; File Check For $db on $Server on $Share&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Fullcreate = [System.IO.Directory]::GetCreationTime($Full)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$FullWrite = [System.IO.Directory]::GetLastWriteTime($Full)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Fullcreate -eq $FullWrite)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the FULL folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-ChildItem $Full*.bak | Should Not BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the FULL folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$FullCreate | Should BeLessThan $FullWrite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Full File Folder was written to within the last 7 days&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Fullwrite |Should BeGreaterThan (Get-Date).AddDays(-7)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Db -notin (&amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;model&amp;#39;))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Diffcreate = [System.IO.Directory]::GetCreationTime($Diff)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DiffWrite = [System.IO.Directory]::GetLastWriteTime($Diff)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Diffcreate -eq $DiffWrite)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the DIFF folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-ChildItem $Diff*.bak | Should Not BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the DIFF folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DiffCreate | Should BeLessThan $DiffWrite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}&amp;amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;lt;div&amp;amp;amp;amp;amp;amp;gt;It &amp;#39;Diff File Folder was written to within the last 24 Hours&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Diffwrite |Should BeGreaterThan (Get-Date).AddHours(-24)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Db -notin (&amp;#39;master&amp;#39;,&amp;#39;msdb&amp;#39;,&amp;#39;model&amp;#39;) -and ($Srv.Databases[$db].RecoveryModel -ne &amp;#39;Simple&amp;#39;) -and ( $LSDatabases -notcontains $db))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Logcreate = [System.IO.Directory]::GetCreationTime($Log)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogWrite = [System.IO.Directory]::GetLastWriteTime($Log)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Logcreate -eq $LogWrite)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the LOG folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-ChildItem $Log*.trn | Should Not BeNullOrEmpty
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Has Files in the LOG folder for $db&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogCreate | Should BeLessThan $LogWrite
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Log File Folder was written to within the last 30 minutes&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Logwrite |Should BeGreaterThan (Get-Date).AddMinutes(-30)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}# Simple Recovery
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}# Check for backups
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You could just run the script you have just created from your check-list, hopefully this blog post can help you see that you  can do so.&lt;/p>
&lt;p>But I like the message showing number of tests and successes and failures at the bottom and I want to use parameters in my script. I can do this like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">[CmdletBinding()]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Pester Test to check OLA
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Param(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Instance,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CheckForBackups,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CheckForDBFolders,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobSuffix ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Share ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[switch]$NoDatabaseRestoreCheck,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[switch]$DontCheckJobOutcome
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then call it using &lt;a class="link" href="https://github.com/pester/Pester/wiki/Invoke-Pester" target="_blank" rel="noopener"
>&lt;code>Invoke-Pester&lt;/code>&lt;/a> with the parameters like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Script = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Path = $Path;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Parameters = @{ Instance = Instance;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CheckForBackups = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CheckForDBFolders = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JobSuffix = &amp;#39;BackupShare1&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Share = &amp;#39;\\Server1\BackupShare1&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NoDatabaseRestoreCheck= $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DontCheckJobOutcome = $true}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-Pester -Script $Script
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>but that’s a bit messy, hard to remember and won’t encourage people newer to Powershell to use it so I wrapped it in a function with some help and examples and put it in GitHub &lt;code>Test-OlaInstance.ps1&lt;/code> and &lt;code>Test-Ola&lt;/code>. There is one thing to remember. You will need to add the path to &lt;code>Test-Ola.ps1&lt;/code> on Line 90 of &lt;code>Test-OlaInstance &lt;/code>so that the script can find it&lt;/p>
&lt;p>Once you have that you can call it for a single instance or a number of instances like so. Here I check for Folders and Backup files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Servers =  &amp;#39;SQL2008Ser2008&amp;#39;,&amp;#39;SQL2012Ser08AG1&amp;#39;,&amp;#39;SQL2012Ser08AG2&amp;#39;,&amp;#39;SQL2014Ser12R2&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-OLAInstance -Instance $Servers -Share &amp;#39;H:\&amp;#39; -CheckForBackups
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and get  a nice result like this. In a little under 20 seconds I completed my checklist for 4 servers including checking if the files and folders exist for 61 databases 🙂 (The three failures were my Integrity Check jobs holding some test corrupt databases)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/pester-ola-check.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/pester-ola-check.png"
loading="lazy"
alt="pester ola check.PNG"
>&lt;/a>&lt;/p>
&lt;p>This gives me a nice and simple automated method of checking if Ola’s maintenance script has been correctly installed. I can use this for one server or many by passing in an array of servers (although they must use the same folder for backing up whether that is UNC or local) I can also add this to an automated build process to ensure that everything has been deployed correctly.&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions" target="_blank" rel="noopener"
>You can find the two scripts on GitHub here&lt;/a>&lt;/p>
&lt;p>I hope you find it useful&lt;/p></description></item><item><title>The SQL Server Community Collaborative GitHub Organisation is born</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</link><pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-sql-server-community-collaborative-github-organisation-is-born/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" alt="Featured image of post The SQL Server Community Collaborative GitHub Organisation is born" />&lt;p>My wonderful friend &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>Chrissy LeMaire&lt;/a> and I are the creators of two GitHub repositories for SQL Server and PowerShell called &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> and &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a>&lt;/p>
&lt;p>If you are working with SQL Server I highly recommend that you take a look at the vast number of commands available to you at &lt;a class="link" href="https://dbatools.io/" target="_blank" rel="noopener"
>dbatools&lt;/a> which will help you complete tasks within SQL Server especially for Instance migrations and also a growing number of best practice implementations&lt;/p>
&lt;p>Both of these modules are not just the work of one person any more. We have over 20 people who have collaborated on the modules THANK YOU ALL and more that have provided guidance and comments via the Slack Channels in the SQL Server Community Slack &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a> and via the Trello boards &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>https://dbatools.io/trello&lt;/a> and &lt;a class="link" href="https://dbareports/trello" target="_blank" rel="noopener"
>https://dbareports/trello&lt;/a>&lt;/p>
&lt;p>At SQL Saturday Cambridge this weekend I was proud to join Chrissy in her presentation as we talked about both modules. Heres a fabulous picture of us with Buck Woody&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/wp_20160910_10_14_58_pro.jpg"
loading="lazy"
alt="wp_20160910_10_14_58_pro"
>&lt;/a>&lt;/p>
&lt;p>We had discussed previously that it didn’t feel quite right that these community tools were under our own personal accounts and it also caused some administration issues with allowing access. So with that in mind after a naming discussion in the slack channel we created an organisation to hold them both&lt;/p>
&lt;h2 id="sql-server-community-collaborative"> SQL Server Community Collaborative&lt;/h2>
&lt;p>is born at &lt;a class="link" href="https://github.com/sqlcollaborative" target="_blank" rel="noopener"
>https://github.com/sqlcollaborative&lt;/a>&lt;/p>
&lt;p>Nothing much changes except the name. we have even found that all the old links work and GitHub desktop updated. We will continue to make great commands with all of our fantastic collaborators. Discussions will happen in Slack and organisation in Trello and we will continue to grow and learn and teach and share and create together.&lt;/p>
&lt;p>We would love you to come and join us&lt;/p></description></item><item><title>Converting SQL Agent Job Duration to TimeSpan using PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-sql-agent-job-duration-to-timespan-using-powershell/</link><pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/converting-sql-agent-job-duration-to-timespan-using-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/timespan.png" alt="Featured image of post Converting SQL Agent Job Duration to TimeSpan using PowerShell" />&lt;p>When you look in msdb for the SQL Agent Job duration you will find that it is an int.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/sysjobshistoiry.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/sysjobshistoiry.png"
loading="lazy"
alt="sysjobshistoiry"
>&lt;/a>&lt;/p>
&lt;p>This is also the same when you look at &lt;code>Get-SQLAgentJobHistory &lt;/code>from the sqlserver module. (You can get this by &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/mt238290.aspx" target="_blank" rel="noopener"
>downloading the latest SSMS release from here&lt;/a>)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/agentjobhistoryproperties.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/agentjobhistoryproperties.png"
loading="lazy"
alt="agentjobhistoryproperties"
>&lt;/a>&lt;/p>
&lt;p>This means that when you look at the various duration of the Agent Jobs you get something like this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/duration1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/duration1.png"
loading="lazy"
alt="duration.PNG"
>&lt;/a>&lt;/p>
&lt;p>The first job took 15 hours 41 minutes  53 seconds, the second 1 minute 25 seconds, the third 21 seconds. This makes it quite tricky to calculate the duration in a suitable datatype. In T-SQL people use scripts like the following from &lt;a class="link" href="https://www.mssqltips.com/sqlservertip/2850/querying-sql-server-agent-job-history-data/" target="_blank" rel="noopener"
>MSSQLTips.com&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">((run_duration/10000*3600 + (run_duration/100)%100*60 + run_duration%100 + 31 ) / 60)  as &amp;#39;RunDurationMinutes&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I needed more information than the number of minutes so I have this which will convert the Run Duration to a timespan&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$FormattedDuration = @{Name = &amp;#39;FormattedDuration&amp;#39; ; Expression = {[timespan]$_.RunDuration.ToString().PadLeft(6,&amp;#39;0&amp;#39;).insert(4,&amp;#39;:&amp;#39;).insert(2,&amp;#39;:&amp;#39;)}}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/formatted.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/formatted.png"
loading="lazy"
alt="formatted.PNG"
>&lt;/a>&lt;/p>
&lt;p>So how did I get to there?&lt;/p>
&lt;p>First I tried to just convert it. In PowerShell you can define a datatype in square brackets and PowerShell will try to convert it&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/timespan.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/timespan.png"
loading="lazy"
alt="timespan"
>&lt;/a>&lt;/p>
&lt;p>It did its best but it converted it to ticks! So we need to convince PowerShell that this is a proper timespan. First we need to convert the run duration to a standard length, you can use the PadLeft method of a string to do this which will ensure that a string has a length and precede the current string with a value you choose until the string is that length.&lt;/p>
&lt;p>Lets have a length of 6 and preceding zeros PadLeft(6,’0′)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/padlefterror.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/padlefterror.png"
loading="lazy"
alt="padlefterror"
>&lt;/a>&lt;/p>
&lt;p>But this works only if it is a string!! Remember red text is useful, it will often contain the information you need to resolve your error. Luckily there is a method to turn an int to a string. I am using the foreach method to demonstrate&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/padleft-with-string.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/padleft-with-string.png"
loading="lazy"
alt="padleft-with-string"
>&lt;/a>&lt;/p>
&lt;p>Now every string is 6 characters long starting with zeros. So all that is left is to format this with colons to separate the hours and minutes and the minutes and seconds. We can do this with the insert method. You can find out the methods using Get-Member or its alias gm&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/methods.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/methods.png"
loading="lazy"
alt="methods.PNG"
>&lt;/a>&lt;/p>
&lt;p>So the insert method takes an int for the startindex and a string value to enter&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/insert.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/insert.png"
loading="lazy"
alt="insert"
>&lt;/a>&lt;/p>
&lt;p>There we go now we have some proper formatted timespans however they are still strings. We can then convert them using [timespan] Now we can format the results within the select by using an expression as shown below&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/select.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/select.png"
loading="lazy"
alt="select"
>&lt;/a>&lt;/p>
&lt;p>and as you can see it is a timespan now&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/timespan-property.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/timespan-property.png"
loading="lazy"
alt="timespan property.PNG"
>&lt;/a>&lt;/p>
&lt;p>On a slight side note. I needed the durations for Agent Jobs with a certain name within the last 6 days.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/getting-agent-jobs1.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/09/getting-agent-jobs1.png"
loading="lazy"
alt="getting-agent-jobs"
>&lt;/a>&lt;/p>
&lt;p>I did this by passing an array of servers (which I got from my &lt;a class="link" href="https://dbareports.io" target="_blank" rel="noopener"
>dbareports&lt;/a> database) to &lt;code>Get-SQLAgentJobHistory&lt;/code>. I then used the Where method to filter for JobName and the Job Outcome step of the history. I compared the RunDate property  to &lt;code>Get-Date&lt;/code> (today) adding -6 days using the &lt;code>AddDays&lt;/code> method 🙂&lt;/p>
&lt;p>Hopefully this will be of use to people and also I have it recorded for the next time I need to do it 🙂&lt;/p></description></item><item><title>Making Start-Demo work with multi-line commands without a backtick</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/making-start-demo-work-with-multi-line-commands-without-a-backtick/</link><pubDate>Mon, 29 Aug 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/making-start-demo-work-with-multi-line-commands-without-a-backtick/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo2.png" alt="Featured image of post Making Start-Demo work with multi-line commands without a backtick" />&lt;p>I love to speak about PowerShell. I really enjoy giving presentations and when I saw Start-Demo being used at the PowerShell Conference in Hanover I started to make use of it in my presentations.&lt;/p>
&lt;p>&lt;code>Start-Demo&lt;/code> was written in 2007 by a fella who knows PowerShell pretty well 🙂  &lt;a class="link" href="https://blogs.msdn.microsoft.com/powershell/2007/03/03/start-demo-help-doing-demos-using-powershell/" target="_blank" rel="noopener"
>https://blogs.msdn.microsoft.com/powershell/2007/03/03/start-demo-help-doing-demos-using-powershell/&lt;/a>&lt;/p>
&lt;p>It was then updated in 2012 by Max Trinidad &lt;a class="link" href="http://www.maxtblog.com/2012/02/powershell-start-demo-now-allows-multi-lines-onliners/" target="_blank" rel="noopener"
>http://www.maxtblog.com/2012/02/powershell-start-demo-now-allows-multi-lines-onliners/&lt;/a>&lt;/p>
&lt;p>This enabled support for multi-line code using backticks at the end of each line. This works well but I dislike having to use the backticks in foreach loops, it confuses people who think that they need to be included and to my mind looks a bit messy&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo.png"
loading="lazy"
alt="start-demo"
>&lt;/a>&lt;/p>
&lt;p>This didn’t bother me enough to look at the code but I did mention it to my friend Luke &lt;a class="link" href="https:%5C%5Ctwitter.com%5Clduddridge" target="_blank" rel="noopener"
>t&lt;/a> | &lt;a class="link" href="https://github.com/ChocolateMonkey" target="_blank" rel="noopener"
>g&lt;/a> who decided to use it as a challenge for his Friday lunch-time codeathon and updated the function so that it works without needing a backtick&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo2.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo2.png"
loading="lazy"
alt="start-demo2"
>&lt;/a>&lt;/p>
&lt;p>It also works with nested loops&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo3.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/08/start-demo3.png"
loading="lazy"
alt="start-demo3"
>&lt;/a>&lt;/p>
&lt;p>just a little improvement but one I think that works well and looks good&lt;/p>
&lt;p>You can find it at&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/Start-Demo.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/Start-Demo.ps1&lt;/a>&lt;/p>
&lt;p>and a little demo showing what it can and cant do&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/Presentations/blob/master/start-demotest.ps1" target="_blank" rel="noopener"
>https://github.com/SQLDBAWithABeard/Presentations/blob/master/start-demotest.ps1&lt;/a>&lt;/p>
&lt;p>Load the &lt;code>Start-Demo.ps1&lt;/code> file and then run&lt;/p>
&lt;p>&lt;code>Start-Demo PATHTO\start-demotest.ps1&lt;/code>&lt;/p>
&lt;p>Enjoy!&lt;/p></description></item><item><title>Remove-SQLDatabaseSafely My First Contribution to DBATools</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</link><pubDate>Wed, 20 Jul 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/remove-sqldatabasesafely-my-first-contribution-to-dbatools/</guid><description>&lt;p>What is DBA Tools?&lt;/p>
&lt;blockquote>
&lt;p>A collection of modules for SQL Server DBAs. It initially started out as ‘sqlmigration’, but has now grown into a collection of various commands that help automate DBA tasks and encourage best practices.&lt;/p>
&lt;/blockquote>
&lt;p>You can read more about &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>here&lt;/a> and it is &lt;a class="link" href="https://github.com/ctrlbold/dbatools" target="_blank" rel="noopener"
>freely available for download on GitHub&lt;/a> I thoroughly recommend that &lt;a class="link" href="https://www.youtube.com/watch?v=PciYdDEBiDM" target="_blank" rel="noopener"
>you watch this quick video&lt;/a> to see just how easy it is to migrate an entire SQL instance in one command (&lt;a class="link" href="https://www.youtube.com/watch?v=kQYUrSlb0wg" target="_blank" rel="noopener"
>Longer session here&lt;/a> )&lt;/p>
&lt;p>Installing it is as easy as&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>which will get you over 80 commands . Visit &lt;a class="link" href="https://dbatools.io/functions/" target="_blank" rel="noopener"
>https://dbatools.io/functions/&lt;/a> to find out more information about them&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/cmdlets.png"
loading="lazy"
alt="cmdlets"
>&lt;/a>&lt;/p>
&lt;p>The journey to &lt;code>Remove-SQLDatabaseSafely&lt;/code> started with William Durkin &lt;a class="link" href="http://williamdurkin.com/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/sql_williamd" target="_blank" rel="noopener"
>t&lt;/a> who presented to the &lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>SQL South West User Group&lt;/a>  (&lt;a class="link" href="http://www.sqlsaturday.com/269/Sessions/Details.aspx?sid=28201" target="_blank" rel="noopener"
>You can get his slides here)&lt;/a>&lt;/p>
&lt;p>Following that session  I wrote a Powershell Script to gather information about the last used date for databases &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-one/" >which I blogged about here&lt;/a> and then a T-SQL script to take a final backup and create a SQL Agent Job to restore from that back up &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/rationalisation-of-database-with-powershell-and-t-sql-part-two-2/" >which I blogged about here&lt;/a> The team have used this solution (updated to load the DBA Database and a report instead of using Excel) ever since and it proved invaluable when a read-only database was dropped and could quickly and easily be restored with no fuss.&lt;/p>
&lt;p>I was chatting with Chrissy LeMaire who founded DBATools &lt;a class="link" href="https://blog.netnerds.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/cl" target="_blank" rel="noopener"
>t&lt;/a> about this process and when she asked for contributions in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>SQL Server Community Slack&lt;/a> I offered my help and she suggested I write this command. I have learnt so much. I thoroughly enjoyed and highly recommend working on projects collaboratively to improve your skills. It is amazing to work with such incredible professional PowerShell people.&lt;/p>
&lt;p>I went back to the basics and thought about what was required and watched one of my favourite videos again. &lt;a class="link" href="https://sqlps.io/backuprant" target="_blank" rel="noopener"
>Grant Fritcheys Backup Rant&lt;/a>&lt;/p>
&lt;p>I decided that the process should be as follows&lt;/p>
&lt;ol>
&lt;li>Performs a DBCC CHECKDB&lt;/li>
&lt;li>Database is backed up WITH CHECKSUM&lt;/li>
&lt;li>Database is restored with VERIFY ONLY on the source&lt;/li>
&lt;li>An Agent Job is created to easily restore from that backup&lt;/li>
&lt;li>The database is dropped&lt;/li>
&lt;li>The Agent Job restores the database&lt;/li>
&lt;li>performs a DBCC CHECKDB and drops the database for a final time&lt;/li>
&lt;/ol>
&lt;p>This (hopefully) passes all of Grants checks. This is how I created the command&lt;/p>
&lt;p>I check that the SQL Agent is running otherwise we wont be able to run the job. I use a while loop with a timeout like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$agentservice = Get-Service -ComputerName $ipaddr -Name $serviceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($agentservice.Status -ne &amp;#39;Running&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentservice.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $timeout = new-timespan -seconds 60
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $sw = [diagnostics.stopwatch]::StartNew()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $agentstatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($dbStatus -ne &amp;#39;Running&amp;#39; -and $sw.elapsed -lt $timeout) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $dbStatus = (Get-Service -ComputerName $ipaddr -Name $serviceName).Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There are a lot more checks and logic than I will describe here to make sure that the process is as robust as possible. For example, the script can exit after errors are found using DBCC CHECKDB or continue and label the database backup file and restore job appropriately. Unless the force option is used it will exit if the job name already exists. We have tried to think of everything but if something has been missed or you have suggestions let us know (details at end of post)&lt;/p>
&lt;p>The only thing I didn’t add was a LARGE RED POP UP SAYING ARE YOU SURE YOU WANT TO DROP THIS DATABASE but I considered it!!&lt;/p>
&lt;h2 id="performs-a-dbcc-checkdb">Performs a DBCC CHECKDB&lt;/h2>
&lt;p>Running DBCC CHECKDB with Powershell is as easy as this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$sourceserver = New-Object Microsoft.SQLServer.Management.Smo.Server &amp;#34;ServerName&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db = $sourceserver.databases[$dbname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $db.CheckTables(&amp;#39;None&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.database.checktables.aspx" target="_blank" rel="noopener"
>you can read more on MSDN&lt;/a>&lt;/p>
&lt;h2 id="database-is-backed-up-with-checksum">Database is backed up WITH CHECKSUM&lt;/h2>
&lt;p>Stuart Moore is my go to for doing &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>backups and restores with SMO&lt;/a>&lt;/p>
&lt;p>I ensured that the backup was performed with checksum like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$backup = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Backup
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Action = [Microsoft.SqlServer.Management.SMO.BackupActionType]::Database
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.BackupSetDescription = &amp;#34;Final Full Backup of $dbname Prior to Dropping&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$backup.Checksum = $True
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="database-is-restored-with-verify-only-on-the-source">Database is restored with VERIFY ONLY on the source&lt;/h2>
&lt;p>I used SMO all the way through this command and performed the restore verify only like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$restoreverify = New-Object &amp;#39;Microsoft.SqlServer.Management.Smo.Restore&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Database = $dbname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$restoreverify.Devices.AddDevice($filename, $devicetype)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$result = $restoreverify.SqlVerify($sourceserver)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="an-agent-job-is-created-to-easily-restore-from-that-backup">An Agent Job is created to easily restore from that backup&lt;/h2>
&lt;p>First I created a category for the Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Function New-SqlAgentJobCategory {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ([string]$categoryname,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [object]$jobServer)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!$jobServer.JobCategories[$categoryname]) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Pscmdlet.ShouldProcess($sourceserver, &amp;#34;Creating Agent Job Category $categoryname&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Creating Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category = New-Object Microsoft.SqlServer.Management.Smo.Agent.JobCategory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Parent = $jobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Name = $categoryname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $category.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Created Agent Job Category $categoryname&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Exception $_
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> throw &amp;#34;FAILED : To Create Agent Job Category $categoryname - Aborting&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then generated the TSQL for the restore step by using the &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.restore.script.aspx" target="_blank" rel="noopener"
>script method on the Restore SMO object&lt;/a>&lt;/p>
&lt;p>This is how to create an Agent Job&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$job = New-Object Microsoft.SqlServer.Management.Smo.Agent.Job $jobServer, $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Name = $jobname
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.OwnerLoginName = $jobowner
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$job.Description = &amp;#34;This job will restore the $dbname database using the final backup located at $filename&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then to add a job step to run the restore command&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$jobStep = new-object Microsoft.SqlServer.Management.Smo.Agent.JobStep $job, $jobStepName $jobStep.SubSystem = &amp;#39;TransactSql&amp;#39; # &amp;#39;PowerShell&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.DatabaseName = &amp;#39;master&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.Command = $jobStepCommmand
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnSuccessAction = &amp;#39;QuitWithSuccess&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$jobStep.OnFailAction = &amp;#39;QuitWithFailure&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Pscmdlet.ShouldProcess($destination, &amp;#34;Creating Agent JobStep on $destination&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $null = $jobStep.Create()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.ApplyToTargetServer($destination)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.StartStepID = $jobStartStepid
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Alter()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-database-is-dropped">The database is dropped&lt;/h2>
&lt;p>We try 3 different methods to drop the database&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$server.KillDatabase($dbname)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$server.databases[$dbname].Drop()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$null = $server.ConnectionContext.ExecuteNonQuery(&amp;#34;DROP DATABASE &amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;h2 id="the-agent-job-restores-the-database">The Agent Job restores the database&lt;/h2>
&lt;p>To run the Agent Job I call the start method of the Job SMO Object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $job = $destserver.JobServer.Jobs[$jobname]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> while ($status -ne &amp;#39;Idle&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;amp;quot; Restore Job for $dbname on $destination is $status&amp;amp;quot;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $job.Refresh()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $status = $job.CurrentRunStatus
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Start-Sleep -Seconds 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we drop the database for the final time with the confidence that we have a safe backup and an easy one click method to restore it from that backup (as long as the backup is in the same location)&lt;/p>
&lt;p>There are further details on the &lt;a class="link" href="https://dbatools.io/functions/remove-sqldatabasesafely/" target="_blank" rel="noopener"
>functions page on dbatools&lt;/a>&lt;/p>
&lt;p>Some videos of it in action are on YouTube &lt;a class="link" href="http://dbatools.io/video" target="_blank" rel="noopener"
>http://dbatools.io/video&lt;/a>&lt;/p>
&lt;p>You can take a look at &lt;a class="link" href="https://github.com/ctrlbold/dbatools/blob/fbd2f19b4442a8065f3cb133d385fde9b2cddea0/functions/Remove-SqlDatabaseSafely.ps1" target="_blank" rel="noopener"
>the code on GitHub here&lt;/a>&lt;/p>
&lt;p>You can install it with&lt;/p>
&lt;p>&lt;code>Install-Module dbatools&lt;/code>&lt;/p>
&lt;p>You can provide feedback via the &lt;a class="link" href="https://dbatools.io/trello" target="_blank" rel="noopener"
>Trello Board&lt;/a> or discuss it in the #dbatools channel in the &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>Sqlserver Community Slack&lt;/a>&lt;/p>
&lt;p>You too can also become a contributor &lt;a class="link" href="https://dbatools.io/join-us/" target="_blank" rel="noopener"
>https://dbatools.io/join-us/&lt;/a> Come and write a command to make it easy for DBAs to (this bit is up to your imagination).&lt;/p></description></item><item><title>Using the new SQLServer Powershell module to get SQL Agent Job Information</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-new-sqlserver-powershell-module-to-get-sql-agent-job-information/</link><pubDate>Sun, 03 Jul 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-the-new-sqlserver-powershell-module-to-get-sql-agent-job-information/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/getcomand-sqlagent.png" alt="Featured image of post Using the new SQLServer Powershell module to get SQL Agent Job Information" />&lt;p>So with the July Release of SSMS everything changed for using PowerShell with SQL. &lt;a class="link" href="https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/30/sql-powershell-july-2016-update/" target="_blank" rel="noopener"
>You can read the details here&lt;/a> As I mentioned in my previous post the name of the module has changed to sqlserver&lt;/p>
&lt;blockquote>
&lt;p>&lt;em>This means that if you have a PowerShell script doing&lt;/em> Import-Module SQLPS_, it will need to be changed to be_ Import-Module SqlServer &lt;em>in order to take advantage of the new provider functionality and new CMDLETs. The new module will be installed to&lt;/em> “%Program Files\WindowsPowerShell\Modules\SqlServer_” and hence no update to $env:PSModulePath is required._&lt;/p>
&lt;/blockquote>
&lt;p>You can download &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/mt238290.aspx" target="_blank" rel="noopener"
>the latest SSMS release here&lt;/a> Once you have installed and rebooted you can start to look at the new Powershell CMDlets&lt;/p>
&lt;p>&lt;code>Import-module sqlserver&lt;/code>&lt;/p>
&lt;p>Take a look at cmdlets&lt;/p>
&lt;p>&lt;code> Get-command -module sqlserver&lt;/code>&lt;/p>
&lt;p>Today I want to look at agent jobs&lt;/p>
&lt;p>&lt;code> Get-command *sqlagent*&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/getcomand-sqlagent.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/getcomand-sqlagent.png"
loading="lazy"
alt="getcomand sqlagent"
>&lt;/a>&lt;/p>
&lt;p>So I decided to see how to gather the information I gather for the DBADatabase &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/power-bi-powershell-and-sql-agent-jobs/" >as described here&lt;/a>&lt;/p>
&lt;p>This is the query I use to insert the data for the server level agent job information.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INSERT INTO [Info].[AgentJobServer]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ([Date]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[NumberOfJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[SuccessfulJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[FailedJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DisabledJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[UnknownJobs])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> (GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,(SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$JobCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$successCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$failedCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$JobsDisabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$UnknownCount&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So Get-SQLAgentJob looks like the one I need. Lets take a look at the help. This should be the starting point whenever you use a new cmdlet&lt;/p>
&lt;p>&lt;code> Get-Help Get-SqlAgentJob -Full&lt;/code>&lt;/p>
&lt;p>Which states&lt;/p>
&lt;blockquote>
&lt;p>Returns a SQL Agent Job object for each job that is present in the target instance of SQL Agent.&lt;/p>
&lt;/blockquote>
&lt;p>That sounds like it will meet my needs. Lets take a look&lt;/p>
&lt;p>&lt;code> Get-SqlAgentJob -ServerInstance $Connection|ft -AutoSize&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/sqlinstances.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/sqlinstances.png"
loading="lazy"
alt="sqlinstances"
>&lt;/a>&lt;/p>
&lt;p>I can get the information I require like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $JobCount = (Get-SqlAgentJob -ServerInstance $Connection ).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$successCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Succeeded&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$failedCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Failed&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobsDisabled = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.IsEnabled -eq $false}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$UnknownCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Unknown&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>NOTE – That code is for PowerShell V4 and V5, if you are using earlier versions of PowerShell you would need to use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $JobCount = (Get-SqlAgentJob -ServerInstance $Connection ).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$successCount = (Get-SqlAgentJob -ServerInstance $Connection|Where-Object {$_.LastRunOutcome -eq &amp;#39;Succeeded&amp;#39;}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$failedCount = (Get-SqlAgentJob -ServerInstance $Connection |Where-Object {$_.LastRunOutcome -eq &amp;#39;Failed&amp;#39;}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobsDisabled = (Get-SqlAgentJob -ServerInstance $Connection |Where-Object{$_.IsEnabled -eq $false}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$UnknownCount = (Get-SqlAgentJob -ServerInstance $Connection |Where-Object{$_.LastRunOutcome -eq &amp;#39;Unknown&amp;#39;}).Count
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>But to make the code more performant it is better to do this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> [pscustomobject]$Jobs= @{}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs.JobCount = (Get-SqlAgentJob -ServerInstance $Connection ).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs.successCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Succeeded&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs.failedCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Failed&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs.JobsDisabled = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.IsEnabled -eq $false}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs.UnknownCount = (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.LastRunOutcome -eq &amp;#39;Unknown&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/jobs.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/jobs.png"
loading="lazy"
alt="jobs"
>&lt;/a>&lt;/p>
&lt;p>Using Measure-Command showed that this completed in&lt;br>
TotalSeconds : 0.9889336&lt;br>
Rather than&lt;br>
TotalSeconds : 2.9045701&lt;/p>
&lt;p>Note that&lt;/p>
&lt;p>&lt;code> (Get-SqlAgentJob -ServerInstance $Connection ).where{$_.Enabled -eq $false}.Count&lt;/code>&lt;/p>
&lt;p>Does not work. I had to check the properties using&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Get-SqlAgentJob -ServerInstance $Connection |Get-Member -Type Properties
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Which showed me&lt;/p>
&lt;p>&lt;code>IsEnabled Property bool IsEnabled {get;set;}&lt;/code>&lt;/p>
&lt;p>So I tested this against the various SQL versions I had in my lab using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Table = $null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table = New-Object System.Data.DataTable &amp;#34;Jobs&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col1 = New-Object System.Data.DataColumn ServerName,([string])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col2 = New-Object System.Data.DataColumn JobCount,([int])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col3 = New-Object System.Data.DataColumn SuccessCount,([int])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col4 = New-Object System.Data.DataColumn FailedCount,([int])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col5 = New-Object System.Data.DataColumn DisabledCount,([int])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Col6 = New-Object System.Data.DataColumn UnknownCount,([int])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col2)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col3)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col4)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col5)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Columns.Add($Col6)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($ServerName in $DemoServers)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$InstanceName =  $ServerName|Select-Object InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Port = $ServerName| Select-Object Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName|Select-Object ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">catch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Failed to connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Failed to Connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[pscustomobject]$Jobs= @{}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobHistory = Get-SqlAgentJob -ServerInstance $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row = $Table.NewRow()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.ServerName = $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.JobCount = $JobHistory.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.SuccessCount = $JobHistory.where{$_.LastRunOutcome -eq &amp;#39;Succeeded&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.FailedCount = $JobHistory.where{$_.LastRunOutcome -eq &amp;#39;Failed&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.DisabledCount = $JobHistory.where{$_.IsEnabled -eq $false}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Row.UnknownCount = $JobHistory.where{$_.LastRunOutcome -eq &amp;#39;Unknown&amp;#39;}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table.Rows.Add($row)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Table|ft
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Here are the results&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/job-data-table.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/job-data-table.png"
loading="lazy"
alt="job data table"
>&lt;/a>&lt;/p>
&lt;p>I also had a look at Get-SQLAgentJobHistory Lets take a look at the help&lt;/p>
&lt;p>&lt;code> Get-help get-SQLAgentJobHistory -showwindow&lt;/code>&lt;/p>
&lt;blockquote>
&lt;p>DESCRIPTION&lt;/p>
&lt;p>Returns the JobHistory present in the target instance of SQL Agent.&lt;/p>
&lt;p>This cmdlet supports the following modes of operation to return the JobHistory:&lt;/p>
&lt;ol>
&lt;li>By specifying the Path of the SQL Agent instance.&lt;/li>
&lt;li>By passing the instance of the SQL Agent in the input.&lt;/li>
&lt;li>By invoking the cmdlet in a valid context.&lt;/li>
&lt;/ol>
&lt;/blockquote>
&lt;p>So I ran&lt;/p>
&lt;p>&lt;code>Get-SqlAgentJobHistory -ServerInstance sql2014ser12r2&lt;/code>&lt;/p>
&lt;p>And got back a whole load of information. Every job history available on the server. Too much to look it immediately to work out what to do&lt;/p>
&lt;p>So I looked at just one job&lt;/p>
&lt;p>&lt;code> Get-SqlAgentJobHistory -ServerInstance SQL2014Ser12R2 -JobName 'DatabaseBackup - SYSTEM_DATABASES - FULL - Local G Drive'&lt;/code>&lt;/p>
&lt;p>And got back the last months worth of history for that one job as that is the schedule used to purge the job history for this server So then I added -Since Yesterday to only get the last 24 hours history&lt;/p>
&lt;p>&lt;code> Get-SqlAgentJobHistory -ServerInstance SQL2014Ser12R2 -JobName 'DatabaseBackup - SYSTEM_DATABASES - FULL - Local G Drive' -Since Yesterday&lt;/code>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/agentjobdetail.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/agentjobdetail.png"
loading="lazy"
alt="agentjobdetail"
>&lt;/a>&lt;/p>
&lt;p>The Since Parameter is described as&lt;/p>
&lt;blockquote>
&lt;p>-Since &lt;!-- raw HTML omitted -->&lt;/p>
&lt;p>A convenient abbreviation to avoid using the -StartRunDate parameter.&lt;br>
It can be specified with the -EndRunDate parameter.&lt;/p>
&lt;p>Do not specify a -StartRunDate parameter, if you want to use it.&lt;/p>
&lt;p>Accepted values are:&lt;br>
– Midnight (gets all the job history information generated after midnight)&lt;br>
– Yesterday (gets all the job history information generated in the last 24 hours)&lt;br>
– LastWeek (gets all the job history information generated in the last week)&lt;br>
– LastMonth (gets all the job history information generated in the last month)&lt;/p>
&lt;/blockquote>
&lt;p>When I run&lt;/p>
&lt;p>&lt;code> Get-SqlAgentJobHistory -ServerInstance SQL2014Ser12R2 -JobName 'DatabaseBackup - SYSTEM_DATABASES - FULL - Local G Drive' -Since Yesterday |Measure-Object&lt;/code>&lt;/p>
&lt;p>I get&lt;/p>
&lt;p>&lt;code>Count : 3&lt;/code>&lt;/p>
&lt;p>And if I run&lt;/p>
&lt;p>&lt;code> Get-SqlAgentJobHistory -ServerInstance SQL2014Ser12R2 -JobName 'DatabaseBackup - SYSTEM_DATABASES - FULL - Local G Drive' -Since Yesterday |select RunDate,StepID,Server,JobName,StepName,Message|Out-GridView&lt;/code>&lt;/p>
&lt;p>I get&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/agent-job-out-gridview.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/agent-job-out-gridview.png"
loading="lazy"
alt="agent job out gridview"
>&lt;/a>&lt;/p>
&lt;p>Which matches the view I see in SSMS Agent Job History&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/jobhistory.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/07/jobhistory.png"
loading="lazy"
alt="jobhistory"
>&lt;/a>&lt;/p>
&lt;p>So &lt;code>Get-SqlAgentJobHistory&lt;/code> will enable you to use PowerShell to gather information about the Job history for each step of the Agent Jobs and also the message which I can see being very useful.&lt;/p>
&lt;p>Come and join us in the SQL Community Slack to discuss these CMDLets and all things SQL Community &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;/p>
&lt;h2 id="call-to-action">&lt;strong>CALL TO ACTION&lt;/strong>&lt;/h2>
&lt;p>Microsoft are engaging with the community to improve the tools we all use in our day to day work. There is are two Trello boards set up for &lt;strong>YOU&lt;/strong> to use to contribute&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/vote" target="_blank" rel="noopener"
>https://sqlps.io/vote&lt;/a> for SQLPS sqlserver PowerShell module&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/ssms" target="_blank" rel="noopener"
>https://sqlps.io/ssms&lt;/a> for SSMS&lt;/p>
&lt;p>Go and join them and upvote &lt;strong>YOUR&lt;/strong> preferred choice of the next lot of CMDlets&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/06/trellocount.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/06/trellocount.png"
loading="lazy"
alt="trellocount"
>&lt;/a>&lt;/p>
&lt;p>We have also set up a SQL Community Slack for anyone in the community to discuss all things related to SQL including the Trello board items and already it seems a good place for people to get help with 150+ members in a few days. You can get an invite here &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;/p>
&lt;p>Come and join us&lt;/p></description></item><item><title>PowerShell CMDLets added for SQL2016 Always Encrypted</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-cmdlets-added-for-sql2016-always-encrypted/</link><pubDate>Thu, 30 Jun 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-cmdlets-added-for-sql2016-always-encrypted/</guid><description>&lt;p>&lt;a class="link" href="https://blogs.technet.microsoft.com/dataplatforminsider/2016/06/30/sql-PowerShell-july-2016-update/" target="_blank" rel="noopener"
>The post on the SQLServer blog at TechNet by the SQL Server Tools Team today&lt;/a> made me jump out of my seat.&lt;/p>
&lt;blockquote>
&lt;p>The July update for SSMS includes the first substantial improvement in SQL PowerShell in many years. We owe a lot of thanks for this effort to the great collaboration with our community. We have several new CMDLETs to share with you&lt;/p>
&lt;/blockquote>
&lt;p>In one release there are &lt;strong>twenty-five&lt;/strong> new CMDLets for the new sqlserver module&lt;/p>
&lt;blockquote>
&lt;p>This means that if you have a PowerShell script doing &lt;em>Import-Module SQLPS&lt;/em>, it will need to be changed to be &lt;em>Import-Module SqlServer&lt;/em> in order to take advantage of the new provider functionality and new CMDLETs. The new module will be installed to &lt;em>“%Program Files\WindowsPowerShell\Modules\SqlServer&lt;/em>” and hence no update to $env:PSModulePath is required.&lt;/p>
&lt;/blockquote>
&lt;p>So SQLPS will still continue to work but will not be updated and will not contain the new CMDlets or the future new CMDlets.&lt;/p>
&lt;h2 id="so-what-new-things-do-we-have">So what new things do we have?&lt;/h2>
&lt;blockquote>
&lt;p>This month we introduce CMDLETs for the following areas:&lt;/p>
&lt;ul>
&lt;li>Always Encrypted&lt;/li>
&lt;li>SQL Agent&lt;/li>
&lt;li>SQL Error Logs&lt;/li>
&lt;/ul>
&lt;/blockquote>
&lt;p>Chrissy LeMaire has written about the &lt;a class="link" href="https://blog.netnerds.net/2016/06/the-sql-server-PowerShell-module-formerly-known-as-sqlps/" target="_blank" rel="noopener"
>new SQL Agent cmdlets&lt;/a>&lt;/p>
&lt;p>Aaron Nelson has written about the &lt;a class="link" href="http://sqlvariant.com/2016/06/webinar-on-25-new-PowerShell-cmdlets-for-sql-server-and-more/" target="_blank" rel="noopener"
>new Get-SqlErrorLog cmdlet&lt;/a>&lt;/p>
&lt;p>Laerte Junior has written about &lt;a class="link" href="https://www.simple-talk.com/blogs/2016/06/30/invoke-sqlcmd-just-got-better/" target="_blank" rel="noopener"
>Invoke-SQLCmd&lt;/a>&lt;/p>
&lt;p>All four of us will be presenting a webinar on the new CMDlets via the &lt;a class="link" href="http://PowerShell.sqlpass.org/" target="_blank" rel="noopener"
>PowerShell Virtual Chapter&lt;/a> Wed, Jul 06 2016 12:00 Eastern Daylight Time If you cant make it a recording will be made available on YouTube on the VC Channel &lt;a class="link" href="https://sqlps.io/video" target="_blank" rel="noopener"
>https://sqlps.io/video&lt;/a>&lt;/p>
&lt;h2 id="always-encrypted-cmdlets">Always Encrypted CMDlets&lt;/h2>
&lt;p>That leaves the Always Encrypted CMDLets and there are 17 of those!&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p> &lt;/p>
&lt;p>That seems to cover setting up Always Encrypted with PowerShell , removing it and getting information about it. When the new SSMS update is dropped you will be able to start using all of this new functionality.&lt;/p>
&lt;p>Just remember Import-Module sqlserver&lt;/p>
&lt;h2 id="call-to-action">CALL TO ACTION&lt;/h2>
&lt;p>Microsoft are engaging with the community to improve the tools we all use in our day to day work. There is are two Trello boards set up for &lt;strong>YOU&lt;/strong> to use to contribute&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/vote" target="_blank" rel="noopener"
>https://sqlps.io/vote&lt;/a>  for SQLPS  sqlserver PowerShell module&lt;/p>
&lt;p>&lt;a class="link" href="https://sqlps.io/ssms" target="_blank" rel="noopener"
>https://sqlps.io/ssms&lt;/a> for SSMS&lt;/p>
&lt;p>Go and join them and upvote &lt;strong>YOUR&lt;/strong> preferred choice of the next lot of CMDlets&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/trellocount.png"
loading="lazy"
alt="trellocount"
>&lt;/p>
&lt;p> &lt;/p>
&lt;p>We have also set up a SQL Community Slack for anyone in the community to discuss all things related to SQL including the Trello board items and already it seems a good place for people to get help with 150+ members in a few days. You can get an invite here &lt;a class="link" href="https://sqlps.io/slack" target="_blank" rel="noopener"
>https://sqlps.io/slack&lt;/a>&lt;/p>
&lt;p>Come and join us&lt;/p></description></item><item><title>Some Pester Tests for SQL Defaults</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/some-pester-tests-for-sql-defaults/</link><pubDate>Tue, 24 May 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/some-pester-tests-for-sql-defaults/</guid><description>&lt;p>When I was at &lt;a class="link" href="http://www.psconf.eu/" target="_blank" rel="noopener"
>PowerShell Conference EU&lt;/a> in Hannover last month (The videos are available now – &lt;a class="link" href="https://www.youtube.com/c/powershellconferenceeu" target="_blank" rel="noopener"
>click here&lt;/a> and the &lt;a class="link" href="https://github.com/psconfeu/2016" target="_blank" rel="noopener"
>slides and code here&lt;/a>) I found out about &lt;a class="link" href="https://pshirwin.wordpress.com/2016/04/08/active-directory-operations-test/" target="_blank" rel="noopener"
>Irwin Strachans Active Directory Operations Test&lt;/a> which got me thinking.&lt;/p>
&lt;p>I decided to do the same for my usual SQL Set-up. Treating all of your servers to the same defaults makes it even easier to manage at scale remotely.&lt;/p>
&lt;p>I am comfortable with using SMO to gather and change properties on SQL Instances so I started by doing this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> It &amp;#39;Should have a default Backup Directory of F:\SQLBACKUP\BACKUPS&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SqlServer.Management.Smo.Server .
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">return $srv.BackupDirectory}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$State = Invoke-Command -ComputerName ROB-SURFACEBOOK -ScriptBlock $Scriptblock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$State |Should Be &amp;#39;F:\SQLBACKUP\BACKUPS&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is the how to find the properties that you want&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> ## Load the Assemblies
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Create a Server SMO object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SqlServer.Management.Smo.Server SERVERNAME
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Explore it
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv|gm
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## If you find an array pick the first one and expand and then explore that
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.Databases[0] | select *
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.Databases[0] | gm
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I quickly found as I added more tests that it was taking a long time to perform the tests (about 5 seconds each test) and that it took an age to fail each of the tests if the server name was incorrect or the server unavailable.&lt;/p>
&lt;p>I fixed the first one by testing with a ping before running the tests&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> ## Check for connectivity
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if((Test-Connection $Server -count 1 -Quiet) -eq $false){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Error &amp;#39;Could not connect to $Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$_
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The continue is there because I wanted to loop through an array of servers&lt;/p>
&lt;p>I improved the performance using a remote session and a custom object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> Describe &amp;#34;$Server&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BeforeAll {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[pscustomobject]$Return = @{}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = &amp;#39;&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SQLAdmins = $Using:SQLAdmins
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[void][reflection.assembly]::LoadWithPartialName(&amp;#39;Microsoft.SqlServer.Smo&amp;#39;);
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object Microsoft.SQLServer.Management.SMO.Server $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.DBAAdminDb = $Srv.Databases.Name.Contains(&amp;#39;DBA-Admin&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Logins = $srv.Logins.Where{$_.IsSystemObject -eq $false}.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SQLAdmins = @(Compare-Object $Logins $SQLAdmins -SyncWindow 0).Length - $Logins.count -eq $SQLAdmins.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$SysAdmins = $Srv.Roles[&amp;#39;sysadmin&amp;#39;].EnumMemberNames()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SQLAdmin = @(Compare-Object $SysAdmins $SQLAdmins -SyncWindow 0).Length - $SysAdmins.count -eq $SQLAdmins.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.BackupDirectory = $srv.BackupDirectory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.DataDirectory = $srv.DefaultFile
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The BeforeAll script block is run, as it sounds like it should, once before all of the tests, BeforeEach would run once before each of the tests. I define an empty custom object and then create an SMO object and add the properties I am interested in testing to it. I then return the custom object at the end&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Return.Alerts82345Exist = ($srv.JobServer.Alerts |Where {$_.Messageid -eq 823 -or $_.Messageid -eq 824 -or $_.Messageid -eq 825}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Enabled = ($srv.JobServer.Alerts |Where {$_.Messageid -eq 823 -or $_.Messageid -eq 824 -or $_.Messageid -eq 825 -and $_.IsEnabled -eq $true}).Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.SysDatabasesFullBackupToday = $srv.Databases.Where{$_.IsSystemObject -eq $true -and $_.Name -ne &amp;#39;tempdb&amp;#39; -and $_.LastBackupDate -lt (Get-Date).AddDays(-1)}.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Return $Return
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return = Invoke-Command -ScriptBlock $Scriptblock -ComputerName $Server -ErrorAction Stop
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">catch {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Error &amp;#34;Unable to Connect to $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">I was then able to test against the property of the custom object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#39;Should have Alerts for Severity 20 and above&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts20SeverityPlusExist | Should Be 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Severity 20 and above Alerts should be enabled&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts20SeverityPlusEnabled | Should Be 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Should have alerts for 823,824 and 825&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Exist |Should Be 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">It &amp;#39;Alerts for 823,824 and 825 should be enebled&amp;#39; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.Alerts82345Enabled |Should Be 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Occasionally, for reasons I haven’t explored I had to test against the value property of the returned object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It &amp;#34;The Full User Database Backup should be scheduled Weekly $OlaUserFullSchedule&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Return.OlaUserFullSchedule.value | Should Be $OlaUserFullSchedule
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I wanted to be able to run the tests against environments or groups of servers with different default values so I parameterised the Test Results as well and then the logical step was to turn it into a function and then I could do some parameter splatting. This also gives me the opportunity to show all of the things that I am currently giving parameters to the test for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Parms = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Servers = &amp;#39;SQLServer1&amp;#39;,&amp;#39;SQLServer2&amp;#39;,&amp;#39;SQLServer3&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SQLAdmins = &amp;#39;THEBEARD\Rob&amp;#39;,&amp;#39;THEBEARD\SQLDBAsAlsoWithBeards&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BackupDirectory = &amp;#39;C:\MSSQL\Backup&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DataDirectory = &amp;#39;C:\MSSQL\Data\&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogDirectory = &amp;#39;C:\MSSQL\Logs\&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">MaxMemMb = &amp;#39;4096&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Collation = &amp;#39;Latin1_General_CI_AS&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TempFiles = 4 ;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaSysFullFrequency = &amp;#39;Daily&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaSysFullStartTime = &amp;#39;21:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullFrequency = 1 ;## 1 for Sunday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserFullStartTime = &amp;#39;22:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffFrequency = 126; ## 126 for every day except Sunday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserDiffStartTime = &amp;#39;22:00:00&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserLogSubDayInterval = 15;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">OlaUserLoginterval = &amp;#39;Minute&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitz = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitzCache = $True;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPBlitzIndex = $True;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPAskBrent = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HASSPBlitzTrace = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">HasSPWhoisActive = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogWhoIsActiveToTable = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTable = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableEnabled = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableScheduled = $true;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableSchedule = &amp;#39;Weekly&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableFrequency = 2 ; # 2 means Monday
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">LogSPBlitzToTableStartTime = &amp;#39;03:00:00&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Test-SQLDefault @Parms
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have some other tests which always return what I want, particularly the firewall rules which you will have to modify to suit your own environment&lt;/p>
&lt;p>To be able to run this you will need to have the Pester Module. If you are using Windows 10 then it is installed by default, if not&lt;/p>
&lt;p>&lt;code>Find-Module –Name 'Pester' | Install-Module&lt;/code>&lt;/p>
&lt;p>You can find more about Pester &lt;a class="link" href="https://mcpmag.com/articles/2016/05/11/testing-powershell-scripts-with-pester.aspx?utm_content=buffer5606b&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer" target="_blank" rel="noopener"
>here&lt;/a> and &lt;a class="link" href="http://mikefrobbins.com/category/pester/" target="_blank" rel="noopener"
>here&lt;/a> and also these &lt;a class="link" href="https://www.youtube.com/channel/UCxgrI58XiKnDDByjhRJs5fg/search?query=pester" target="_blank" rel="noopener"
>videos from the conference&lt;/a>&lt;br>
You can find the tests on &lt;a class="link" href="https://github.com/SQLDBAWithABeard/Functions/blob/master/Test-SQLDefaults.ps1" target="_blank" rel="noopener"
>GitHub here&lt;/a> and I will continue to add to the defaults that I check.&lt;br>
This is not a replacement for other SQL configuration tools such as PBM but it is a nice simple way of giving a report on the current status of a SQL installation either at a particular point in time when something is wrong or after an installation prior to passing the server over to another team or into service&lt;/p></description></item><item><title>DBA Database scripts are on Github</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dba-database-scripts-are-on-github/</link><pubDate>Mon, 16 May 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dba-database-scripts-are-on-github/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/tweets.png%29%5D%28/assets/uploads/2016/05/tweets.png" alt="Featured image of post DBA Database scripts are on Github" />&lt;p>It started with a tweet from Dusty&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/tweets.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/tweets.png"
loading="lazy"
alt="Tweets"
>&lt;/a>&lt;/p>
&lt;p>The second session I presented at the fantastic &lt;a class="link" href="http://psconf.eu" target="_blank" rel="noopener"
>PowerShell Conference Europe&lt;/a> was about using the DBA Database to automatically install DBA scripts like &lt;a class="link" href="https://www.brentozar.com/first-aid/sql-server-downloads/" target="_blank" rel="noopener"
>sp_Blitz, sp_AskBrent, sp_Blitzindex from Brent Ozar&lt;/a> , &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>Ola Hallengrens Maintenance Solution&lt;/a> , &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2012/03/22/released-who-is-active-v11-11.aspx" target="_blank" rel="noopener"
>Adam Mechanics sp_whoisactive&lt;/a> , &lt;a class="link" href="https://www.brentozar.com/responder/log-sp_whoisactive-to-a-table/" target="_blank" rel="noopener"
>This fantastic script for logging the results from sp_whoisactive to a table&lt;/a> , Extended events sessions and other goodies for the sanity of the DBA.&lt;/p>
&lt;p>By making use of the &lt;code>dbo.InstanceList &lt;/code>in my DBA database I am able to target instances, by SQL Version, OS Version, Environment, Data Centre, System, Client or any other variable I choose. An agent job that runs every night will automatically pick up the instances and the scripts that are marked as needing installing. This is great when people release updates to the above scripts allowing you to target the development environment and test before they get put onto live.&lt;/p>
&lt;p>I talked to a lot of people in Hannover and they all suggested that I placed the scripts onto GitHub and after some how-to instructions from a few people (Thank you Luke) I spent the weekend updating and cleaning up the code and you can now find it on &lt;a class="link" href="https://github.com/SQLDBAWithABeard/DBA-Database" target="_blank" rel="noopener"
>GitHub here&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/github.png" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/github.png"
loading="lazy"
alt="github"
>&lt;/a>&lt;/p>
&lt;p>I have added the DBA Database project, the Powershell scripts and Agent Job creation scripts to call those scripts and everything else I use. Some of the DBA Scripts I use (and links to those you need to go and get yourself for licensing reasons) and the Power Bi files as well. I will be adding some more jobs that I use to gather other information soon.&lt;/p>
&lt;p>Please go and have a look and see if it is of use to you. It is massively customisable and I have spoken to various people who have extended it in interesting ways so I look forward to hearing about what you do with it.&lt;/p>
&lt;p>As always, questions and comments welcome&lt;/p></description></item><item><title>A Day In The Life of a SQLBits Volunteer</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-day-in-the-life-of-a-sqlbits-volunteer/</link><pubDate>Tue, 10 May 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-day-in-the-life-of-a-sqlbits-volunteer/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/05/dscn0286-3.jpg" alt="Featured image of post A Day In The Life of a SQLBits Volunteer" />&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/dscn0286-3.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/dscn0286-3.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>So SQLBits has finished for another year. About 1500 people registered for the largest SQL Conference in Europe held over 4 days in Liverpool last week. 2 days of full day sessions and 2 days of shorter sessions, a pub quiz, a party (literally) out of this world.&lt;/p>
&lt;p>It is organised and run by volunteers&lt;/p>
&lt;p>Yes, you’re right.&lt;/p>
&lt;p>Wow.&lt;/p>
&lt;p>Of course we must pay special thanks to Simon, Darren, Chris, Jonathan, Annette, Allan and Alex without forgetting all that JRJ has done. They ensured that the venue, sessions, speakers, sponsors, audio visual and not forgetting the amazing party by &lt;!-- raw HTML omitted -->Sneaky Experience (Thank you Julia),&lt;!-- raw HTML omitted --> all occurred at the right time in the right place with the right people and the work and effort they have put in cannot be over-estimated but this post isn’t about those generous, inspiring, amazing folk
Several people asked me what a volunteer does and how they can become one and hopefully this post will answer both of those questions. More than 40 people volunteered to help at SQL Bits&lt;/p>
&lt;p>Some volunteers arrived on Tuesday to help with the set up. Making sure that we knew where everything was and helping to lift and carry all of the things that needed moving.
&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_07_13_44_pro-2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_07_13_44_pro-2.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>We wanted to begin the process of packing the swag bags so that all the attendees on Wednesday could have them as they arrived but unfortunately we were let down by a delivery firm and that was not possible. That job was completed by some very dedicated helpers during all of Wednesday and finished off by all helpers after Wednesdays sessions had finished. Many, many thanks and respect particularly to Bob and Conan for their dedication to the bag-packing cause, although I did hear “If I ever see another bag again ……..”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/bean-bags.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/bean-bags.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>All of the registration desks with badges, lanyards and booklets were set up ready for the next day, the covers were put on the tables, the bean bags put out. (They were needed later!!)&lt;/p>
&lt;p>We started every morning with a helpers briefing at 7am&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_07_40_18_pro-2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_07_40_18_pro-2.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>where we ensured that everyone knew what was happening that day. Most helpers took some part in registration whether it was being at the desks handing out badges, assisting speakers and sponsors on arrival with questions and some the other jobs that needed doing such as putting the table cloths on the tables in the domes and getting out the bags.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_10_31_33_pro-2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_10_31_33_pro-2.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/dscn0284.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/dscn0284.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>During every session there were two room monitors. Their responsibility was to ensure that everything went smoothly during the day and during each of the sessions on Friday and Saturday. They assisted the speaker with drinks, timings and the other foibles that technology can throw, they would have known what to do if there were issues with the domes.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/dome-monitoring.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/dome-monitoring.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>They also made sure that everyone was in the correct session and answered lots of questions. The bit that hopefully most attendees missed was that in the case of any issues they called in one of the 5 or 6 super helpers who were patrolling the arena, who could go and get the AV guys or the venue staff to iron out the wrinkles, making sure that the water coolers got re-filled etc
They took all of your feedback forms and took them to the main desk. There were always people at the front desk helping, although Alex, Annette and Terri spent almost all of their time there.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_15_32_59_pro.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_15_32_59_pro.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course it doesn’t stop there. During the breaks and particularly at lunchtime the helpers were available and indeed noticeable. They assisted with the queues at lunchtime and for the key-note&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_09_37_35_pro.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_09_37_35_pro.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>answered questions and they helped attendees with session choices. There were always people and questions that they were willing to answer or to find someone who could.
Once the sessions had finished, the helpers didn’t. They manned and womanned the registration desks in the evening. Returned all of the feedback forms and helped with sorting out the venue ready for the next day. There was also a de-brief for any lessons learned.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_17_54_40_pro-21.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160504_17_54_40_pro-21.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>They even gave out the free drinks tokens at the entrance to the party!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/dscn0376-2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/dscn0376-2.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>So why do they do it? They are all part of this amazing community dedicated to providing great events for people to learn. Many of them are volunteers at other events and/or user group leaders and attendees and want to give something back to the community.) . They were able to choose the full day and hour sessions that they attended so were still able to learn from the amazing speakers at the brilliant sessions available. Everyone was able to choose which days they helped it doesn’t have to be for every day you are at the conference. They are a wonderful group of people and I have made some fantastic friendships by volunteering and get great hugs 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_09_15_33_pro-2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/wp_20160506_09_15_33_pro-2.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You also get asked the most brilliant questions like “Excuse me, I have a Dalek in my van, what would you like me to do with it?”
If that sounds like something you would like to do, you just need to email &lt;a class="link" href="mailto:helpers@sqlbits.com" >helpers@sqlbits.com&lt;/a> with ‘I would like to be a helper next year at SQLBits’ in the subject. You can also offer to help at your local user group or at other events, speak to your user group leaders for more details on that
If it’s not for you, that’s cool but please, for me, the next time you see them at an event just say thank you. It really means a lot and they thoroughly deserve every word of thanks that we give them.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2016/05/thankyou.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2016/05/thankyou.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item><item><title>Using PowerShell to set Extended Events Sessions to AutoStart</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-set-extended-events-sessions-to-autostart/</link><pubDate>Mon, 28 Mar 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-set-extended-events-sessions-to-autostart/</guid><description>&lt;p>When you look after more than a few SQL Servers you will need to perform the same actions against a number of  them and that is where PowerShell will be of great benefit. Recently I needed to ensure that all SQL Servers had a certain Extended Event Session set to auto-start and that it was running. I have used the Always On health session in the example below but you could use the same code below and do this for any Extended Event session. Just note that the code below checks for the existence of an Availability Group which may not be what you require.&lt;/p>
&lt;p>As always when I started to look at Powershell for a solution &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/ff877887.aspx" target="_blank" rel="noopener"
>I turned to MSDN and found this page&lt;/a> and also a quick search &lt;a class="link" href="http://www.mikefal.net/2015/06/09/tsql2sday-powershell-and-extended-events/" target="_blank" rel="noopener"
>found Mike Fals blogpost&lt;/a> which showed me how to get going.&lt;/p>
&lt;p>I used my &lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/using-power-bi-with-my-dba-database/" >DBA Database as described in my previous posts &lt;/a>and created a query to check for all of the servers that were active and contactable&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [dbo].[InstanceList] IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and used Invoke-SQLCMD to gather the Server Names
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Results = (Invoke-Sqlcmd -ServerInstance $DBADatabaseServer -Database DBADatabase -Query $query -ErrorAction Stop).ServerName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then it was a case of looping through the servers and connecting to the XEvent Store and checking if the required extended event was started and set to auto-start and if not altering those settings&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## Can we connect to the XEStore?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if(Test-Path SQLSERVER:\XEvent\$Server)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$XEStore = get-childitem -path SQLSERVER:\XEvent\$Server -ErrorAction SilentlyContinue  | where {$_.DisplayName -ieq &amp;#39;default&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AutoStart = $XEStore.Sessions[$XEName].AutoStart
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Running = $XEStore.Sessions[$XEName].IsRunning
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;$server for $AGNames --- $XEName -- $AutoStart -- $Running&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($AutoStart -eq $false)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$XEStore.Sessions[$XEName].AutoStart = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$XEStore.Sessions[$XEName].Alter()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Running -eq $false)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$XEStore.Sessions[$XEName].Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Very quick and simple and hopefully of use to people, this could easily be turned into a function. The full script is below and also available &lt;a class="link" href="https://www.powershellgallery.com/packages/Set-ExtendedEventsSessionstoAutoStart/1.0/DisplayScript" target="_blank" rel="noopener"
>here on the Powershell gallery&lt;/a> or by running  &lt;code>Save-Script -Name Set-ExtendedEventsSessionstoAutoStart -Path &amp;lt;path&amp;gt;&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;span class="lnt">66
&lt;/span>&lt;span class="lnt">67
&lt;/span>&lt;span class="lnt">68
&lt;/span>&lt;span class="lnt">69
&lt;/span>&lt;span class="lnt">70
&lt;/span>&lt;span class="lnt">71
&lt;/span>&lt;span class="lnt">72
&lt;/span>&lt;span class="lnt">73
&lt;/span>&lt;span class="lnt">74
&lt;/span>&lt;span class="lnt">75
&lt;/span>&lt;span class="lnt">76
&lt;/span>&lt;span class="lnt">77
&lt;/span>&lt;span class="lnt">78
&lt;/span>&lt;span class="lnt">79
&lt;/span>&lt;span class="lnt">80
&lt;/span>&lt;span class="lnt">81
&lt;/span>&lt;span class="lnt">82
&lt;/span>&lt;span class="lnt">83
&lt;/span>&lt;span class="lnt">84
&lt;/span>&lt;span class="lnt">85
&lt;/span>&lt;span class="lnt">86
&lt;/span>&lt;span class="lnt">87
&lt;/span>&lt;span class="lnt">88
&lt;/span>&lt;span class="lnt">89
&lt;/span>&lt;span class="lnt">90
&lt;/span>&lt;span class="lnt">91
&lt;/span>&lt;span class="lnt">92
&lt;/span>&lt;span class="lnt">93
&lt;/span>&lt;span class="lnt">94
&lt;/span>&lt;span class="lnt">95
&lt;/span>&lt;span class="lnt">96
&lt;/span>&lt;span class="lnt">97
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.Synopsis
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   Connects to the servers in the DBA Database and for Servers above 2012 sets alwayson_health Extended Events Sessions to Auto-Start and starts it if it is not running
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.DESCRIPTION
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   Sets Extended Events Sessions to Auto-Start and starts it if it is not running
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.EXAMPLE
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   Alter the XEvent name and DBADatabase name or add own server list and run
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.NOTES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   AUTHOR - Rob Sewell
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   BLOG -
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   DATE - 20/03/2016
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DBADatabaseServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$XEName = &amp;#39;AlwaysOn_health&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## Query to gather the servers required
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [dbo].[InstanceList] IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Results = (Invoke-Sqlcmd -ServerInstance $DBADatabaseServer -Database DBADatabase -Query $query -ErrorAction Stop).ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">catch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Error &amp;#34;Unable to Connect to the DBADatabase - Please Check&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach($Server in $Results)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> catch
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34; Failed to connect to $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # To ensure we have a connection to the server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34; Failed to Connect to $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($srv.versionmajor -ge &amp;#39;11&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## NOTE this checks if there are Availability Groups - you may need to change this
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($srv.AvailabilityGroups.Name)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGNames = $srv.AvailabilityGroups.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Can we connect to the XEStore?
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if(Test-Path SQLSERVER:\XEvent\$Server)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XEStore = get-childitem -path SQLSERVER:\XEvent\$Server -ErrorAction SilentlyContinue | where {$_.DisplayName -ieq &amp;#39;default&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AutoStart = $XEStore.Sessions[$XEName].AutoStart
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Running = $XEStore.Sessions[$XEName].IsRunning
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;$server for $AGNames --- $XEName -- $AutoStart -- $Running&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($AutoStart -eq $false)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XEStore.Sessions[$XEName].AutoStart = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XEStore.Sessions[$XEName].Alter()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Running -eq $false)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XEStore.Sessions[$XEName].Start()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Output &amp;#34;Failed to connect to XEvent on $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Write-Output &amp;#34;No AGs on $Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## Write-Output &amp;#34;$server not 2012 or above&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Backing up to URL container name – case is important</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-to-url-container-name-case-is-important/</link><pubDate>Thu, 03 Mar 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/backing-up-to-url-container-name-case-is-important/</guid><description>&lt;p>If you use &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn435916.aspx" target="_blank" rel="noopener"
>SQL Backup to URL&lt;/a> to backup your databases to Azure blob storage remember that for the container name case is important&lt;/p>
&lt;p>So&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">BACKUP LOG [DatabaseName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TO URL = N&amp;#39;https://storageaccountname.blob.core.windows.net/containername/databasename_log_dmmyyhhss.trn&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CHECKSUM, NO_COMPRESSION, CREDENTIAL = N&amp;#39;credential&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>will work but&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">BACKUP LOG [DatabaseName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">TO URL = N&amp;#39;https://storageaccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CHECKSUM, NO_COMPRESSION, CREDENTIAL = N&amp;#39;credential&amp;#39;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>will give an (400) Bad Request Error which may not be easy to diagnose&lt;/p>
&lt;blockquote>
&lt;p>Msg 3271, Level 16, State 1, Line 1
A nonrecoverable I/O error occurred on file &amp;ldquo;&lt;a class="link" href="https://storageacccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn%27:%22" target="_blank" rel="noopener"
>https://storageacccountname.blob.core.windows.net/CONTAINERNAME/databasename_log_dmmyyhhss.trn':"&lt;/a> Backup to URL received an exception from the remote endpoint.
Exception Message: The remote server returned an error: (400) Bad Request..
Msg 3013, Level 16, State 1, Line 1
BACKUP LOG is terminating abnormally.&lt;/p>
&lt;/blockquote>
&lt;p>If you are using Ola Hallengrens jobs to perform your backup then your job step will look like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">sqlcmd -E -S $(ESCAPE_SQUOTE(SRVR)) -d DBA-Admin -Q &amp;#34;EXECUTE [dbo].[DatabaseBackup] @Databases = &amp;#39;USER_DATABASES&amp;#39;,&amp;amp;nbsp; @URL = &amp;#39;https://storageaccountname.blob.core.windows.net/containername&amp;#39;, @Credential = &amp;#39;credential&amp;#39;, @BackupType = &amp;#39;LOG&amp;#39;, @ChangeBackupType = &amp;#39;Y&amp;#39;, @Verify = &amp;#39;Y&amp;#39;, @CheckSum = &amp;#39;Y&amp;#39;, @LogToTable = &amp;#39;Y&amp;#39;&amp;#34; -b
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Note the &lt;code>@ChangeBackupType = ‘Y’&lt;/code> parameter which is not created by default but I think is very useful. If you have just created a database and take log backups every 15 minutes but differential (or full) every night the log backup will fail until a full backup has been taken. This parameter will check if a log backup is possible and if not take a full backup meaning that you still can keep to your RTO/RPO requirements even for newly created databases&lt;/p></description></item><item><title>PowerShell Pester – The script failed due to call depth overflow.</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-the-script-failed-due-to-call-depth-overflow./</link><pubDate>Sun, 31 Jan 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-the-script-failed-due-to-call-depth-overflow./</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-success_thumb1.jpg" alt="Featured image of post PowerShell Pester – The script failed due to call depth overflow." />&lt;p>This error caught me out. I am putting this post here firstly to remind me if I do it again and also to help others who may hit the same issue.&lt;/p>
&lt;p>I also have been looking at &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> which is a framework for running unit tests within PowerShell&lt;/p>
&lt;p>You will find some good blog posts about starting with Pester here&lt;/p>
&lt;p>So I created a function script file &lt;code>Create-HyperVFromBase.ps1&lt;/code> and a tests script file &lt;code>Create-HyperVFromBase.tests.ps1&lt;/code> as shown.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-scripts_thumb.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-scripts_thumb.jpg"
loading="lazy"
alt="pester scripts"
>&lt;/a>&lt;/p>
&lt;p>The tests contained this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $here = Split-Path -Parent $MyInvocation.MyCommand.Path
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;#34;.Tests.&amp;#34;, &amp;#34;.&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">. {&amp;#39;$here\$sut&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Describe &amp;#34;Create Hyper V from Base Tests&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Context &amp;#34;Parameter Values,Validations and Errors&amp;#34; {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> It exists {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> test-path function:\create-hypervmfrombase | should be $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>When I ran the test I got the following error&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error1_thumb1.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error1_thumb1.jpg"
loading="lazy"
alt="pester error1"
>&lt;/a>&lt;/p>
&lt;p>or&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error2_thumb1.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error2_thumb1.jpg"
loading="lazy"
alt="pester error2"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://www.google.co.uk/search?q=pester&amp;#43;The&amp;#43;script&amp;#43;failed&amp;#43;due&amp;#43;to&amp;#43;call&amp;#43;depth&amp;#43;overflow.&amp;amp;ie=&amp;amp;oe=#q=pester&amp;#43;%22The&amp;#43;script&amp;#43;failed&amp;#43;due&amp;#43;to&amp;#43;call&amp;#43;depth&amp;#43;overflow.%22" target="_blank" rel="noopener"
>Googling pester “The script failed due to call depth overflow.”&lt;/a> returned only 7 results but the &lt;a class="link" href="https://www.reddit.com/r/PowerShell/comments/3kkbgm/confused_about_pester/" target="_blank" rel="noopener"
>Reddit link&lt;/a> contained the information I needed&lt;/p>
&lt;blockquote>
&lt;p>&lt;code>.Replace() &lt;/code>is case sensitive. It didn’t remove the .tests. keyword from your file name. So it calls your test script again and repeats the same mistake over and over.&lt;/p>
&lt;/blockquote>
&lt;p>and so I renamed the tests script file to &lt;code>Create-HyperVFromBase.Tests.ps1&lt;/code> With a Capital T! and bingo&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-success_thumb1.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-success_thumb1.jpg"
loading="lazy"
alt="pester success"
>&lt;/a>&lt;/p>
&lt;p>Don’t forget to name your Pester Tests scripts with a capital T when loading the script in this way and remember that &lt;code>Replace()&lt;/code> is case sensitive.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$here = Split-Path -Parent $MyInvocation.MyCommand.Path
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;#34;.Tests.&amp;#34;, &amp;#34;.&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">. &amp;#34;$here\$sut&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>PowerShell Pester Testing for Parameter Validation</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-testing-for-parameter-validation/</link><pubDate>Sun, 31 Jan 2016 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-pester-testing-for-parameter-validation/</guid><description>&lt;p>This error caught me out. I am putting this post here firstly to remind me if I do it again adn also to help others who may hit the same issue.&lt;/p>
&lt;p>Today I am rewriting a function to create a Hyper-V VM so that I can properly script the creation of my labs for demos and other things. I am doing this because I want to use DSC to create an availability group and want to be able to tear down and recreate the machines (but thats for another day)&lt;/p>
&lt;p>I also have been looking at &lt;a class="link" href="https://github.com/pester/Pester" target="_blank" rel="noopener"
>Pester&lt;/a> which is a framework for running unit tests within PowerShell&lt;/p>
&lt;p>You will find some good blog posts about starting with Pester &lt;a class="link" href="https://www.google.co.uk/search?q=PowerShell&amp;#43;pester&amp;#43;tutorial&amp;amp;ie=&amp;amp;oe=" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>Here is the start of the function. I validate the VMName parameter to ensure that there a VM with that  name does not already exist&lt;/p>
&lt;p>function Create-HyperVMFromBase {
[cmdletbinding()]
param (
[Parameter(Mandatory = $true,HelpMessage=&amp;ldquo;Enter a VMName for the VM that does not exist&amp;rdquo;)] [ValidateScript({(!(Get-VM -Name $_))})]
[string]$VMName,&lt;/p>
&lt;p>and my Pester test looks like this&lt;/p>
&lt;p>$here = Split-Path -Parent $MyInvocation.MyCommand.Path
$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;quot;.Tests.&amp;quot;, &amp;ldquo;.&amp;rdquo;)
. {&amp;rsquo;$here$sut'}&lt;/p>
&lt;p>Describe &amp;ldquo;Create Hyper V from Base Tests&amp;rdquo; {
Context &amp;ldquo;Parameter Values,Validations and Errors&amp;rdquo; {
It exists {
test-path function:\create-hypervmfrombase | should be $true
}
It &amp;ldquo;Should error when VMName exists&amp;rdquo; {
$VMName = (Get-VM|Select -First 1 Name).Name
create-hypervmfrombase -VMName $VMName |should throw
}&lt;/p>
&lt;p>I thought that what I was testing was that the function threw an error when an incorrect parameter was passed. The should throw should be true but what I got was&lt;/p>
&lt;p>&lt;a class="link" href="../assets/uploads/2016/01/pester-error3.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-error3_thumb.jpg"
loading="lazy"
alt="pester error3"
>&lt;/a>&lt;/p>
&lt;p>So I was getting the correct error but not passing the test. It was a simple fix. Simply adding curly braces around the call to the function&lt;/p>
&lt;p>$here = Split-Path -Parent $MyInvocation.MyCommand.Path
$sut = (Split-Path -Leaf $MyInvocation.MyCommand.Path).Replace(&amp;quot;.Tests.&amp;quot;, &amp;ldquo;.&amp;rdquo;)
. &amp;ldquo;$here$sut&amp;rdquo;
Describe &amp;ldquo;Create Hyper V from Base Tests&amp;rdquo; {
Context &amp;ldquo;Parameter Values,Validations and Errors&amp;rdquo; {
It exists {
test-path function:\create-hypervmfrombase | should be $true
}
It &amp;ldquo;Should error when VMName exists&amp;rdquo; {
$VMName = (Get-VM|Select -First 1 Name).Name
{create-hypervmfrombase -VMName $VMName} |should throw
}
}
}&lt;/p>
&lt;p>and we pass the test.&lt;/p>
&lt;p>&lt;a class="link" href="../assets/uploads/2016/01/pester-success2.jpg" >&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2016/01/pester-success2_thumb.jpg"
loading="lazy"
alt="pester success2"
>&lt;/a>&lt;/p></description></item><item><title>Power Bi, PowerShell and SQL Agent Jobs</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/power-bi-powershell-and-sql-agent-jobs/</link><pubDate>Mon, 28 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/power-bi-powershell-and-sql-agent-jobs/</guid><description>&lt;p>Continuing &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>my series on using Power Bi with my DBA Database&lt;/a> I am going to show in this post how I create the most useful daily report for DBAs - The SQL Agent Job report. &lt;a class="link" href="https://1drv.ms/f/s!Ah9eXQJC3wLIh8BKfjiXBs7g6m7hfw" target="_blank" rel="noopener"
>You can get the scripts and reports here&lt;/a>&lt;/p>
&lt;p>Please note this project became &lt;a class="link" href="http://dbareports.io" target="_blank" rel="noopener"
>dbareports.io&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag1.jpg?w=300"
loading="lazy"
alt="AG1"
>&lt;/a>&lt;/p>
&lt;p>This gives a quick overview of the status of the Agent Jobs across the estate and also quickly identifies recent failed jobs enabling the DBA to understand their focus and prioritise their morning efforts.&lt;/p>
&lt;p>I gather the information into 2 tables AgentJobDetail&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[AgentJobDetail](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgetnJobDetailID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Date] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Category] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[JobName] [nvarchar](250) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Description] [nvarchar](750) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[IsEnabled] [bit] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Status] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[LastRunTime] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Outcome] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_info.AgentJobDetail] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgetnJobDetailID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and AgentJobServer&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[AgentJobServer](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgentJobServerID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Date] [datetime] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[NumberOfJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[SuccessfulJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[FailedJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DisabledJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[UnknownJobs] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_Info.AgentJobServer] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AgentJobServerID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Detail table holds the results of every Agent Job and the Server table holds a roll up for each server. The script to gather this information is based on the script I used to put the information into an Excel Sheet as described in my post &lt;a class="link" href="https://blog.robsewell.com/blog/how-i-check-hundreds-of-sql-agent-jobs-in-60-seconds-with-powershell/" target="_blank" rel="noopener"
>How I Check Hundreds of Agent Jobs in 60 Seconds with PowerShell&lt;/a> which I also altered to send an HTML email to the DBA team each morning. This however is a much better solution and allows for better monitoring and trending.&lt;/p>
&lt;p>As I have explained &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>in my previous posts&lt;/a> I use an Instance List table to hold the information about each instance in the estate and a series of PowerShell scripts which run via Agent Jobs to gather the information into various tables. These posts describe the use of the Write-Log function and the methodology of gathering the required information and looping through each instance so I wont repeat that here. There is an extra check I do however for Express Edition as this does not contain the Agent service&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$edition = $srv.Edition
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($Edition -eq &amp;#39;Express&amp;#39;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Write-Log -Path $LogFile -Message &amp;#34;No Information gathered as this Connection $Connection is Express&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The Agent Job information can be found in SMO by exploring the &lt;code>$srv.JobServer.Jobs&lt;/code> object and I gather the information by iterating through each job and setting the values we require to variables&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">try {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JobCount = $srv.JobServer.jobs.Count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $successCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $failedCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $UnknownCount = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $JobsDisabled = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #For each job on the server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($jobin$srv.JobServer.Jobs)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobName = $job.Name;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobEnabled = $job.IsEnabled;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobLastRunOutcome = $job.LastRunOutcome;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Category = $Job.Category;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $RunStatus = $Job.CurrentRunStatus;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Time = $job.LastRunDate;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Time -eq &amp;#39;01/01/000100:00:00&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$Time = &amp;#39;&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Description = $Job.Description;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Counts for jobs Outcome
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($jobEnabled -eq $False)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$JobsDisabled += 1}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Failed&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$failedCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Succeeded&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$successCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> elseif ($jobLastRunOutcome -eq &amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$UnknownCount += 1; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I found that some Jobs had names and descriptions that had &amp;rsquo; in them which would cause the SQL update or insert statement to fail so I use the replace method to replace the &amp;rsquo; with ''&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($Description -eq $null) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Description = &amp;#39; &amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Description.replace(&amp;#39;&amp;#39;&amp;#39;&amp;#39;, &amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($jobName -eq $Null) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobName = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$JobName = $JobName.replace(&amp;#39;&amp;#39;&amp;#39;&amp;#39;, &amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then insert the data per job after checking that it does not already exist which allows me to re-run the job should a number of servers be uncontactable at the time of the job running without any additional work&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">IF NOT EXISTS (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SELECT [AgetnJobDetailID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[Info].[AgentJobDetail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">where jobname = &amp;#39;$jobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and InstanceID = (SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">and lastruntime = &amp;#39;$Time&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">INSERT INTO [Info].[AgentJobDetail]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">([Date]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Category]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[JobName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Description]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[IsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Status]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[LastRunTime]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[Outcome])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,(SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Category&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Description&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobEnabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$RunStatus&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$Time&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$jobLastRunOutcome&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I put this in a here-string variable and pass it to Invoke-SQLCmd I do the same with the roll up using this query&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">INSERT INTO [Info].[AgentJobServer]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">([Date]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[NumberOfJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[SuccessfulJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[FailedJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[DisabledJobs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,[UnknownJobs])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,(SELECT [InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE [ServerName] = &amp;#39;$ServerName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [InstanceName] = &amp;#39;$InstanceName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AND [Port] = &amp;#39;$Port&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$JobCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$successCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$failedCount&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$JobsDisabled&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,&amp;#39;$UnknownCount&amp;#39;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This job runs as a SQL Agent Job every morning a half an hour or so before the DBA arrives for the morning shift vastly improving the ability of the DBA to prioritise their morning routine.&lt;/p>
&lt;p>To create the report open Power Bi Desktop and click Get Data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag2.jpg?w=300"
loading="lazy"
alt="ag2"
>&lt;/a>&lt;/p>
&lt;p>Then choose SQL Server and click connect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag3.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag3.jpg?w=274"
loading="lazy"
alt="ag3"
>&lt;/a>&lt;/p>
&lt;p>Enter the Connection string, the database and the  query to gather the data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag5.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag5.jpg?w=300"
loading="lazy"
alt="ag5"
>&lt;/a>&lt;/p>
&lt;p>The query is&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Select IL.InstanceID,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.InstanceName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.Environment,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.Location,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Category,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Date,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Description,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.IsEnabled,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.JobName,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.LastRunTime,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Outcome,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AJD.Status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [dbo].[InstanceList] IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN [Info].[AgentJobDetail] AJD
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ON IL.InstanceID = AJD.InstanceID
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WHERE LastRunTime &amp;gt; DATEADD(Day,-31,GETDATE())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once we have gathered the data we then create some extra columns and measures for the reports. First I create a date column from the datetime Date Column&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayDate = DATE(YEAR(&amp;#39;Agent Job Detail&amp;#39;[Date]),MONTH(&amp;#39;Agent Job Detail&amp;#39;[Date]),DAY(&amp;#39;Agent Job Detail&amp;#39;[Date]))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also do the same for the LastRuntime. I create a day of the week column so that I can report on jobs outcome by day&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayyOfWeek = CONCATENATE(WEEKDAY(&amp;#39;Agent Job Detail&amp;#39;[Date],2),FORMAT(&amp;#39;Agent Job Detail&amp;#39;[Date],&amp;#34; -dddd&amp;#34;))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>My friend Terry McCann &lt;a class="link" href="http://hyperbi.co.uk" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/@sqlshark" target="_blank" rel="noopener"
>t&lt;/a> helped me create a column that returns true if the last run time is within 24 hours of the current time to help identify the recent jobs that have failed NOTE - On a Monday morning you will need to change this if you do not check your jobs on the weekend.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Last Run Relative Hour = ((1.0\*(NOW()-&amp;#39;Agent Job Detail&amp;#39;[LastRunTime]))\*24)&amp;lt;24
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a measure for Succeeded, Failed and Unknown&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Succeeded = IF(&amp;#39;Agent Job Detail&amp;#39;[Outcome] = &amp;#34;Succeeded&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, 0)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Next we have to create some measures for the sum of failed jobs and the averages This is the code for 7 day sum&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Failed7Days = CALCULATE(SUM(&amp;#39;Agent Job Detail&amp;#39;[Failed]),FILTER (
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALL ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ),
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#39;Agent Job Detail&amp;#39;[Last Run Date] &amp;gt; ( MAX ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ) - 7 )
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;amp;&amp;amp; &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] &amp;lt;= MAX ( &amp;#39;Agent Job Detail&amp;#39;[Last Run Date] ) ) )
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and for the 7 Day average&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Failed7DayAverage = DIVIDE([Failed7Days],7)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I did the same for 30 days. I used the &lt;a class="link" href="http://social.technet.microsoft.com/wiki/contents/articles/680.powerpivot-dax-filter-functions.aspx" target="_blank" rel="noopener"
>TechNet reference for DAX expressions&lt;/a> and got ideas from &lt;a class="link" href="http://blog.crossjoin.co.uk/category/dax/" target="_blank" rel="noopener"
>Chris Webbs blog&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag6.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag6.jpg?w=83"
loading="lazy"
alt="ag6"
>&lt;/a> First I created the 30 day historical trend chart using a Line and Clustered column chart using the last run date as the axis and the succeed measure as the column and the Failed, Failed 7 Day Average and failed 30 day average as the lines&lt;/p>
&lt;p>I then formatted the lines and title and column&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag7.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag7.jpg?w=300"
loading="lazy"
alt="ag7"
>&lt;/a>&lt;/p>
&lt;p>To create the gauge which shows how well we have done today I created a measure to quickly identify todays jobs&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">LastRun Relative Date Offset = INT(&amp;#39;Agent Job Detail&amp;#39;[LastRunTime] - TODAY())
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>which I use as a filter for the gauge as shown below. I also create two measures zero and twenty for the minimum and maximum for the gauge&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag8.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag8.jpg?w=300"
loading="lazy"
alt="ag8"
>&lt;/a>&lt;/p>
&lt;p>The rest of the report is measures for 7 day average and 30 day average, a slicer for environment  and two tables, one to show the historical job counts and one to show the jobs that have failed in the last 24 hours using the Last Run Relative Hour measure from above&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag9.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag9.jpg?w=300"
loading="lazy"
alt="ag9"
>&lt;/a>&lt;/p>
&lt;p>There are many other reports that you can or may want to create maybe by day of the week or by category depending on your needs. Once you have the data gathered you are free to play with the data as you see fit. Please add any further examples of reports you can run or would like to run in the comments below.&lt;/p>
&lt;p>Once you have your report written you can publish it to PowerBi.com and create a dashboard and query it with natural language. I have explained the process &lt;a class="link" href="https://blog.robsewell.com/tags/#dba-database" target="_blank" rel="noopener"
>in previous posts&lt;/a>&lt;/p>
&lt;p>For example - How many Jobs failed today&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag110.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag110.jpg?w=300"
loading="lazy"
alt="ag110"
>&lt;/a>&lt;/p>
&lt;p>Which server had most failed jobs&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag11.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag11.jpg?w=300"
loading="lazy"
alt="ag11"
>&lt;/a>&lt;/p>
&lt;p>or using the category field which database maintenance jobs failed today&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag13.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/ag13.jpg?w=300"
loading="lazy"
alt="ag13"
>&lt;/a>&lt;/p>
&lt;p>I hope these posts have given you ideas about how you can use PowerShell, a DBA Database and Power Bi to help you to manage and report on your environment.&lt;/p>
&lt;p>&lt;a class="link" href="https://1drv.ms/f/s!Ah9eXQJC3wLIh8BKfjiXBs7g6m7hfw" target="_blank" rel="noopener"
>You can get the scripts and reports here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - Databases</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-databases/</link><pubDate>Tue, 22 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-databases/</guid><description>&lt;p>Following my post about &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db1.png?w=300"
loading="lazy"
alt="db1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db2.png?w=300"
loading="lazy"
alt="db2"
>&lt;/a>&lt;/p>
&lt;p>Although you will find so many items of data that I expect that you will want to create different reports for your own requirements. You will also want to put the report onto PowerBi.com and explore the natural language querying as I show at the end of this post&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts and PowerShell scripts here.&lt;/a>&lt;/p>
&lt;p>The SQLInfo table is created using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[Databases](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DatabaseID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceID] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Name] [nvarchar](256) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateAdded] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateChecked] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoClose] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoCreateStatisticsEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoShrink] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AutoUpdateStatisticsEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AvailabilityDatabaseSynchronizationState] [nvarchar](16) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AvailabilityGroupName] [nvarchar](128) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CaseSensitive] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Collation] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CompatibilityLevel] [nvarchar](15) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CreateDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DataSpaceUsageKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [EncryptionEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IndexSpaceUsageKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsAccessible] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsFullTextEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsMirroringEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsParameterizationForced] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsReadCommittedSnapshotOn] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsSystemObject] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsUpdateable] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastDifferentialBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LastLogBackupDate] [datetime2](7) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Owner] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [PageVerify] [nvarchar](17) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ReadOnly] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [RecoveryModel] [nvarchar](10) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ReplicationOptions] [nvarchar](40) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SizeMB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SnapshotIsolationState] [nvarchar](10) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SpaceAvailableKB] [float] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Status] [nvarchar](35) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [TargetRecoveryTime] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK_Databases] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DatabaseID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName = &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get the script &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>from here&lt;/a> or you can read on to see how it works and how to create the report and publish it to powerbi.com and query it with natural langauge&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible. I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called $ServerNames holding the server name, instance name and port&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and create a $Connection variable for my SMO connection string and connect to the server&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Even though I place the creation of the SMO server object in a try block you still need to an additional check to ensure that you can connect and populate the object as the code above creates an empty SMO Server object with the name property set to the $Connection variable if you can&amp;rsquo;t connect to that server and doesn’t error as you may expect The way I have always validated an SMO Server object is to check the version property. There is no justifiable reason for choosing that property, you could choose any one but that’s the one I have always used. I use an if statement to do this ( &lt;a class="link" href="https://blog.robsewell.com/blog/powershell-snippets-a-great-learning-tool/" target="_blank" rel="noopener"
>This post about Snippets will show you the best way to learn PowerShell code&lt;/a>) The reference I use for exiting a loop in the way that you want is &lt;a class="link" href="http://ss64.com/ps/break.html" target="_blank" rel="noopener"
>this one&lt;/a> In this case we use a continue to carry on iterating the loop&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Catch-Block &amp;#34; Failed to Connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the user databases&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach($db in $srv.databases|Where-Object {$_.IsSystemObject -eq $false })
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Name = $db.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Parent = $db.Parent.Name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To gather information on all databases just remove everything after the pipe symbol or if you wish to exclude certain databases from the collection gathering, maybe the database you keep &lt;a class="link" href="https://blog.robsewell.com/blog/making-a-change-log-easier-with-powershell/" target="_blank" rel="noopener"
>your Change log table&lt;/a> and DBA Team info in you can do that as well here&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Name = $db.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Parent = $db.Parent.Name
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you wish to view all of the different properties that you can gather information on in this way you can use this code to take a look. (This is something you should get used to doing when writing new PowerShell scripts)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Connection = &amp;#39;SERVERNAMEHERE&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv.databases | Get-Member
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>An alternative method of doing this is to set a variable to a $db and then to select all of the properties so that you can see the values and identify the ones you want. Again this a good thing to do when exploring new objects&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$db = $srv.databases[&amp;#39;DBNAMEHERE&amp;#39;]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$db| Select *
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can see from the screen shot below that there are 170 properties available to you on a SQL2014 instance. You can gather any or all of that information as long as you ensure that you have the columns with the correct data types in your table and that your script has the logic to deal with properties that do not exist although I have had less issue with this for the database object than the server object&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db3.png?w=300"
loading="lazy"
alt="db3"
>&lt;/a>&lt;/p>
&lt;p>You can look for the property that you want by using the Get-Member cmdlet as shown above or use MSDN to find it &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.database%28v=sql.120%29.aspx" target="_blank" rel="noopener"
>starting from here&lt;/a> or by GoogleBingDuckDuckGo ing &amp;ldquo;PowerShell SMO&amp;rdquo; and the property you wish to find.&lt;/p>
&lt;p>The rest of the script follows exactly the same pattern as &lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>the previous post&lt;/a> by checking the SQL Info table for an entry for that instance and updating the table if it exists and inserting if it does not.&lt;/p>
&lt;p>This is how I created the reports shown above.&lt;/p>
&lt;p>Connect to the DBA Database and run these queries to gather the data for the report.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Environment
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.Inactive
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,IL.NotContactable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DatabaseID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Name]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DateAdded]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoClose]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoCreateStatisticsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoShrink]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AutoUpdateStatisticsEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AvailabilityDatabaseSynchronizationState]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[AvailabilityGroupName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CaseSensitive]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Collation]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CompatibilityLevel]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[CreateDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[DataSpaceUsageKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[EncryptionEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IndexSpaceUsageKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsAccessible]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsFullTextEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsMirroringEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsParameterizationForced]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsReadCommittedSnapshotOn]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[IsUpdateable]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastDifferentialBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[LastLogBackupDate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Owner]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[PageVerify]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[ReadOnly]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[RecoveryModel]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[ReplicationOptions]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SizeMB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SnapshotIsolationState]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[SpaceAvailableKB]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[Status]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">,D.[TargetRecoveryTime]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">FROM [DBADatabase].[Info].[Databases] as D
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">JOIN [DBADatabase].[dbo].[InstanceList] as IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ON IL.InstanceID =D.InstanceID
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To get all the database and instance information and&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT C.ClientName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DatabaseID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Notes]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[ClientDatabaseLookup] as CDL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> JOIN [DBADatabase].[dbo].[Clients] as C
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON CDL.clientid = c.clientid
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To get the client information. The client information needs to be manually added to the table as this (in general) needs a human bean to understand. When the script runs every night it will pick up new databases and I add a default value of &amp;ldquo;Not Entered&amp;rdquo; to the table which makes it easier to identify the databases that need this additional work. (This also means that as a Team Leader I can monitor that my team are doing this) It can also be added to any scripts which create new databases for deployment.&lt;/p>
&lt;p>Then we need to create some measures and calculated columns for our report. I did this as I realised that I needed it when making the report rather than all up front.&lt;/p>
&lt;p>I created two calculated columns for size for the databases one for Gb and one for Tb by clicking on the data icon on the left and then new measure&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SizeGb = Query1[SizeMB]/1024
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SizeTb = Query1[SizeGb]/1024
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Some measures for count of Databases, Instances and Servers&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Databases = COUNT(Query1[DatabaseID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Instances = DISTINCTCOUNT(Query1[InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Servers = DISTINCTCOUNT(Query1[ServerName])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also wanted to be able to differentiate between &amp;lsquo;External&amp;rsquo; and &amp;lsquo;Internal&amp;rsquo; customers. So I created a calculated column for this value using a switch statement.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">External = SWITCH(Clients[ClientName],&amp;#34;Not Entered&amp;#34;, 0 , &amp;#34;Dev Team&amp;#34;,0,&amp;#34;Mi Team&amp;#34;,0,&amp;#34;DBA Team&amp;#34;,0,&amp;#34;Finance Department&amp;#34;,0,&amp;#34;HR&amp;#34;,0,&amp;#34;Operations&amp;#34;,0,&amp;#34;Payroll&amp;#34;,0,&amp;#34;Test Team&amp;#34;,0,&amp;#34;Systems Team&amp;#34;,0,&amp;#34;Unknown&amp;#34;,0,1)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I create a donut chart to show the size of the database in Gb by client (and no, my real clients are not rock bands :-) ) as shown below. I formatted the title, legend and background by clicking on the paintbrush in the visualisation pane. I would encourage you to investigate the options here.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db4.png?w=300"
loading="lazy"
alt="db4"
>&lt;/a> The other donut chart is number of clients per location (and those are SQL User group locations in the UK and my hometown Bolton)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db5.png?w=300"
loading="lazy"
alt="db5"
>&lt;/a>&lt;/p>
&lt;p>The rest of the visualisations on that report are cards and tables which I am sure that you can work out.&lt;/p>
&lt;p>I created a map to show the location of the databases&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db6.png?w=300"
loading="lazy"
alt="db6"
>&lt;/a>&lt;/p>
&lt;p>And after reading this post &lt;a class="link" href="http://sqldusty.com/2015/08/03/power-bi-tip-use-the-treemap-chart-as-a-colorful-slicer/" target="_blank" rel="noopener"
>http://sqldusty.com/2015/08/03/power-bi-tip-use-the-treemap-chart-as-a-colorful-slicer/&lt;/a> by Dustin Ryan I created a colourful slicer for environment and the client and then added some other information. The important thing here is to pick the information that the person looking at the report needs to see. So if it is recovery model, compatibility level, collation, page verify setting, mirroring, replication, size and number of databases then this report is correct but I doubt that’s what you want :-)&lt;/p>
&lt;p>You can slice this report by location, client or environment. For example, I can easily see which clients have data in Exeter and the size and number of databases&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db7.png?w=300"
loading="lazy"
alt="db7"
>&lt;/a>&lt;/p>
&lt;p>Or if Metallica ring me up I can quickly see that they have 4 databases, just under 69Gb of data in Exeter and it isn&amp;rsquo;t mirrored. You will notice that it is not easy to see the recovery model or the compatibility level. If you hover over the results you get a highlight figure which shows the data is filtered but it is not shown visually very well as there are over a thousand databases using full recovery model.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db8.png?w=300"
loading="lazy"
alt="db8"
>&lt;/a>&lt;/p>
&lt;p>If we are asked about the Integration environment we can see that it is hosted in Bolton, Manchester, Southampton and Exeter and comprises of 394 databases and 739 Gb of data. It is also easier to see the compatibility level and recovery model as the ratios are larger&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db9.png?w=300"
loading="lazy"
alt="db9"
>&lt;/a>&lt;/p>
&lt;p>Once we have created the report in the way that we want we can then publish it to powerbi.com and share it with others if we wish. Publishing is as easy as pressing the publish button and entering your powerbi credentials but if you want your data to automatically refresh (and this is the point of the exercise to remove manual work) then you will need to install and configure the PowerBi gateway and schedule a refresh I will post about this later.&lt;/p>
&lt;p>Once the report is published you can access it in the browser and create a dashboard by clicking the pin in the top right of a visualisation and a pop up will ask you which dashboard you wish to pin it to (Another recent update to Power Bi)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db10.png?w=300"
loading="lazy"
alt="db10"
>&lt;/a>&lt;/p>
&lt;p>Once you have a dashboard you can then perform some natural language question and answer on it. This can be quite interesting and not always quite what you (or your report readers) might expect but it is getting better all the time&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db11.png?w=300"
loading="lazy"
alt="db11"
>&lt;/a>&lt;/p>
&lt;p>You have to remember to use the names of the columns correctly&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db12.png?w=300"
loading="lazy"
alt="db12"
>&lt;/a>&lt;/p>
&lt;p>But once you have the query correct you can alter it by adding &amp;ldquo;as a VISUALISATION&amp;rdquo; and choose the visualisation&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db13.png?w=300"
loading="lazy"
alt="db13"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db14.png?w=300"
loading="lazy"
alt="db14"
>&lt;/a>&lt;/p>
&lt;p>And once you have the visualisation you can pin it to the dashboard&lt;/p>
&lt;p>I think you can see how useful it can be&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db15.png?w=263"
loading="lazy"
alt="db15"
>&lt;/a>&lt;/p>
&lt;p>This doesn’t work quite as you expect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db16.png?w=300"
loading="lazy"
alt="db16"
>&lt;/a>&lt;/p>
&lt;p>But this does&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db17.png?w=275"
loading="lazy"
alt="db17"
>&lt;/a>&lt;/p>
&lt;p>How about this (and yes it felt wrong to type!)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db18.png?w=300"
loading="lazy"
alt="db18"
>&lt;/a>&lt;/p>
&lt;p>And the auditors would love to be able to do this. (This is an old copy of the database in case The Eagles people are reading this - your database is backed up every 15 minutes)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db19.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db19.png?w=300"
loading="lazy"
alt="db19"
>&lt;/a>&lt;/p>
&lt;p>Or this for a DBA ( Yes, my obfuscation script database naming convention is a bit bland)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db20.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db20.png?w=300"
loading="lazy"
alt="db20"
>&lt;/a>&lt;/p>
&lt;p>Or the DBA team manager might choose this one&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db21.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/db21.png?w=300"
loading="lazy"
alt="db21"
>&lt;/a>&lt;/p>
&lt;p>The advantage that I cannot show via static pictures is that the data, visualisation and the suggestions alter in real time as you type&lt;/p>
&lt;p>I hope that you have found this useful and that you can see the benefits and advantages of using a DBA Database and empowering people to use self-service to answer their own questions leaving the DBA time to do more important things like drinking coffee :-)&lt;/p>
&lt;p>As always if you have any questions or comments please feel free to post them on the blog.&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Enterprise Strategies - A #TSQL2sDay post</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/enterprise-strategies-a-#tsql2sday-post/</link><pubDate>Tue, 08 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/enterprise-strategies-a-#tsql2sday-post/</guid><description>&lt;p>&lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/time-for-t-sql-tuesday-70/" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/TSQL2sDay150x150.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>This months TSQL2sDay blog post party is hosted by &lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/time-for-t-sql-tuesday-70/" target="_blank" rel="noopener"
>Jen McCown&lt;/a> and is about Enterprise Strategy.&lt;/p>
&lt;p>Adam Mechanic started &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/archive/2009/11/30/invitation-to-participate-in-t-sql-tuesday-001-date-time-tricks.aspx" target="_blank" rel="noopener"
>TSQL Tuesdays over 5 years ago&lt;/a> and you will find many brilliant posts under that heading if &lt;a class="link" href="https://www.google.co.uk/#q=tsql2sday" target="_blank" rel="noopener"
>you search for them&lt;/a>&lt;/p>
&lt;p>Managing SQL servers at enterprise scale is not a straightforward task. Your aim as a DBA should be to simplify it as much as possible and to automate everything that you possibly can. &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>This post by John Sansom&lt;/a> could have been written for this months party and I recommend that you read it.&lt;/p>
&lt;p>So here are a few points that I think you should consider if you look after SQL in an Enterprise environment.&lt;/p>
&lt;ul>
&lt;li>Enterprise Strategy will undoubtedly garner a whole host of excellent posts and Jen will provide a round up post which will I am certain will be an excellent resource. &lt;a class="link" href="http://www.midnightdba.com/Jen/2015/09/the-tsql2sday-70-roundup/" target="_blank" rel="noopener"
>Take a look here&lt;/a>&lt;/li>
&lt;li>Know where your instances are and have a single place that you can reference them from. Some people recommend a &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/bb895144.aspx?f=255&amp;amp;MSPPError=-2147217396" target="_blank" rel="noopener"
>Central Management Server&lt;/a> but I find this too restrictive for my needs. I use an InstanceList table in my DBA Database with the following columns [ServerName], [InstanceName] , [Port] , [AG] , [Inactive] , [Environment] and [Location]. This enables me to target instances not just by name but by environment (Dev, Test, Pre-Prod, Live etc), by location or by joining the InstanceList table with another table I can target by the application or any number of other factors. I also capture information about the servers at windows and SQL level to this database so I can target the SQL 2012 servers specifically if need be or any other metric. This is very powerful and enables far greater flexibility than the CMS in my opinion.&lt;/li>
&lt;li>Use PowerShell (no surprise I would mention this!) PowerShell is a brilliant tool for automation and I use it all of the time&lt;/li>
&lt;li>Get used to using this piece of PowerShell code&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName],[InstanceName],[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0 AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Notice the query variable above, this is where the power lies as it enables you to gather all the instances that you need for your task as described in the bullet post above. Once you get used to doing this you can do things like this identify all the instances with Remote DAC disabled using a query against the DBA Database and then enable it on all servers by adding this code to the loop above&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$srv.RemoteDacEnabled = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$srv.alter()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Very quick very simple and very very powerful. You can also use this to run TSQL scripts against the instances you target but there are some &lt;a class="link" href="https://www.bing.com/search?q=issues%20with%20invoke-sqlcmd&amp;amp;form=EDGEAR&amp;amp;qs=PF&amp;amp;cvid=bafe07c6afd54a6cb0ce7a1583300a79&amp;amp;pq=issues%20with%20invoke-sqlcmd&amp;amp;elv=AF!A!XC!KoOyC2FxnVd!deIwlgRcylR4EqUAG2rfVDNS" target="_blank" rel="noopener"
>added complications with Invoke-SQLCmd&lt;/a> that you need to be aware of&lt;/p>
&lt;ul>
&lt;li>BE CAREFUL. Test and understand and test before you run any script on a live system especially using a script like this which enables you to target ALL of your servers. You must definitely check that your $ServerNames array contains only the instances you need before you make any changes. You need to be ultra-cautious when it is possible to do great damage&lt;/li>
&lt;li>Write scripts that are robust and handle errors gracefully. I use Jason Wasser @wasserja Write-Log function to write to a text file and wrap my commands in a try catch block.&lt;/li>
&lt;li>Include comments in your scripts to assist either the future you or the folks in your position in 5 years time. I would also add one of my bug bears - Use the description block in Agent Jobs. The first place any DBA is going to go to when that job fails is to open the properties of the job. Please fill in that block so that anyone troubleshooting knows some information about what the job does or at the very least a link to some documentation about it&lt;/li>
&lt;li>Finally in my list, don&amp;rsquo;t overdo the alerts. Alerting is vital for any DBA it is a brilliant way to ensure that you quickly know about any issues affecting your estate but &lt;a class="link" href="http://thomaslarock.com/2012/02/the-minimalist-guide-to-database-administration/" target="_blank" rel="noopener"
>all alerts should be actionable&lt;/a> and in some cases you can automate the action that you can take but the message here is don&amp;rsquo;t send messages to the DBA team email for every single tiny thing or they will get swamped and ignore the vital one. This holds for whichever alerting or monitoring system that you use&lt;/li>
&lt;/ul>
&lt;p>This is but a small sub-section of things that you need to consider when responsible for a large SQL estate but if you need help and advice or just moral support and you don’t already interact with the SQL community then make today the day you start. Maybe &lt;a class="link" href="http://thomaslarock.com/sql-family/" target="_blank" rel="noopener"
>this post by Thomas La Rock&lt;/a> is a good place to start or &lt;a class="link" href="http://www.sqlpass.org/PASSChapters.aspx" target="_blank" rel="noopener"
>your nearest User Group/Chapter&lt;/a> or the &lt;a class="link" href="https://twitter.com/hashtag/sqlfamily" target="_blank" rel="noopener"
>#sqlfamily hashtag&lt;/a> or give me a shout and I will gladly help.&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - SQL Info</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-sql-info/</link><pubDate>Mon, 07 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-sql-info/</guid><description>&lt;p>Following my post about &lt;a class="link" href="http://wp.me/p3aio8-gj" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/2.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>Although you will find so many items of data that I expect that you will want to create different reports for your own requirements. You will also want to put the report onto PowerBi.com and explore the natural language querying as I show at the end of this post&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts and PowerShell scripts here.&lt;/a>&lt;/p>
&lt;p>The SQLInfo table is created using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;span class="lnt">61
&lt;/span>&lt;span class="lnt">62
&lt;/span>&lt;span class="lnt">63
&lt;/span>&lt;span class="lnt">64
&lt;/span>&lt;span class="lnt">65
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[SQLInfo](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLInfoID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateChecked] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DateAdded] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServerName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLVersionString] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLVersion] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServicePack] [nvarchar](3) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Edition] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ServerType] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [Collation] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsHADREnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLServiceAccount] [nvarchar](35) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLService] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLServiceStartMode] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BAckupDirectory] [nvarchar](256) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BrowserAccount] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [BrowserStartMode] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsSQLClustered] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterName] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterQuorumstate] [nvarchar](20) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ClusterQuorumType] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [C2AuditMode] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CostThresholdForParallelism] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MaxDegreeOfParallelism] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DBMailEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultBackupCComp] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [FillFactor] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MaxMem] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MinMem] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [RemoteDacEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [XPCmdShellEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [CommonCriteriaComplianceEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultFile] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [DefaultLog] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [HADREndpointPort] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [ErrorLogPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstallDataDirectory] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstallSharedDirectory] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsCaseSensitive] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [IsFullTextInstalled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LinkedServer] [nvarchar](max) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [LoginMode] [nvarchar](20) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MasterDBLogPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [MasterDBPath] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [NamedPipesEnabled] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [OptimizeAdhocWorkloads] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [InstanceID] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AGListener] [nvarchar](150) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [AGs] [nvarchar](150) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> CONSTRAINT [PK__SQL__50A5926BC7005F29] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [SQLInfoID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [Info].[SQLInfo] WITH CHECK ADD CONSTRAINT [FK_SQLInfo_InstanceList] FOREIGN KEY([InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">REFERENCES [dbo].[InstanceList] ([InstanceID])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">ALTER TABLE [Info].[SQLInfo] CHECK CONSTRAINT [FK_SQLInfo_InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName = &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>the script from here&lt;/a> or you can read on to see how it works and how to create the report and publish it to powerbi.com&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Catch-Block
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ([string]$Additional)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34; On $Connection &amp;#34; + $Additional + $_.Exception.Message + $_.Exception.InnerException.InnerException.message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Message = &amp;#34; This message came from the Automated PowerShell script updating the DBA Database with Server Information&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Msg = $Additional + $ErrorMessage + &amp;#34; &amp;#34; + $Message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message $ErrorMessage -Level Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-EventLog -LogName SQLAutoScript -Source &amp;#34;SQLAUTOSCRIPT&amp;#34; -EventId 1 -EntryType Error -Message $Msg
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the function an additional parameter which will hold each custom error message which I write to both the event log and a text message to enable easy troubleshooting and include the message from the $Error variable by accessing it with $_. I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called $ServerNames holding the server name, instance name and port&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SELECT [ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Port]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[dbo].[InstanceList]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Where Inactive = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> AND NotContactable = 0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$AlltheServers= Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerNames = $AlltheServers| Select ServerName,InstanceName,Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and create a &lt;code>$Connection&lt;/code> variable for my SMO connection string and connect to the server&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($ServerName in $ServerNames)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## $ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $InstanceName = $ServerName|Select InstanceName -ExpandProperty InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Port = $ServerName| Select Port -ExpandProperty Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ServerName = $ServerName|Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Connection = $ServerName + &amp;#39;\&amp;#39; + $InstanceName + &amp;#39;,&amp;#39; + $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> try
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Even though I place the creation of the SMO server object in a try block you still need to an additional check to ensure that you can connect and populate the object as the code above creates an empty SMO Server object with the name property set to the $Connection variable if you can&amp;rsquo;t connect to that server and doesn’t error as you may expect The way I have always validated an SMO Server object is to check the version property. There is no justifiable reason for choosing that property, you could choose any one but that’s the one I have always used. I use an if statement to do this ( &lt;a class="link" href="http://wp.me/p3aio8-cL" target="_blank" rel="noopener"
>This post about Snippets will show you the best way to learn PowerShell code&lt;/a>) The reference I use for exiting a loop in the way that you want is &lt;a class="link" href="http://ss64.com/ps/break.html" target="_blank" rel="noopener"
>this one&lt;/a> In this case we use a continue to carry on iterating the loop&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if (!( $srv.version)){
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Catch-Block &amp;#34; Failed to Connect to $Connection&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> continue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you wish to view all of the different properties that you can gather information on in this way you can use this code to take a look. (This is something you should get used to doing when writing new PowerShell scripts)&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$srv = New-Object (&amp;#39;Microsoft.SqlServer.Management.Smo.Server&amp;#39;) $Connection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv | Get-Member
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>As you can see from the screenshot below on my SQL2014 server there are 184 properties. I havent chosen to gather all of them, only the ones that are of interest to me, our team or others who request information from our team such as auditors and project managers etc&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>You can choose to use any or all of these properties as long as you ensure you have the columns in your table with the correct data type and that you have the correct knowledge and logic to stop the script from erroring if/when the property is not available. Here is an example&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if ($srv.IsHadrEnabled -eq $True)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$IsHADREnabled = $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGs = $srv.AvailabilityGroups|Select Name -ExpandProperty Name|Out-String
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Expression = @{Name = &amp;#39;ListenerPort&amp;#39; ; Expression = {$_.Name + &amp;#39;,&amp;#39; + $_.PortNumber }}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGListener = $srv.AvailabilityGroups.AvailabilityGroupListeners|select $Expression|select ListenerPort -ExpandProperty ListenerPort
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $IsHADREnabled = $false
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGs = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $AGListener = &amp;#39;None&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $BackupDirectory = $srv.BackupDirectory
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I check if the property &lt;code>IsHADREnabled&lt;/code> is true and if it is I then gather the information about the Availability Group names and the listener port and if it doesn’t exist I set the values to None.&lt;/p>
&lt;p>You will find that not all of the properties that you want are at the root of the Server SMO object. If you want you max and min memory values and you want to know if &lt;code>remote admin connections&lt;/code> or &lt;code>xp_cmdshell&lt;/code> are enabled you will need to look at the &lt;code>$Srv.Configuration&lt;/code> object&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $MaxMem = $srv.Configuration.MaxServerMemory.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $MinMem = $srv.Configuration.MinServerMemory.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $RemoteDacEnabled = $srv.Configuration.RemoteDacConnectionsEnabled.ConfigValue
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $XPCmdShellEnabled = $srv.Configuration.XPCmdShellEnabled.ConfigValue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can look for the property that you want by using the Get-Member cmdlet as shown above or use MSDN to find it &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.server.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>starting from here&lt;/a> or by GoogleBingDuckDuckGo ing &amp;ldquo;PowerShell SMO&amp;rdquo; and the property you wish to find.&lt;/p>
&lt;p>The rest of the script follows exactly the same pattern &lt;a class="link" href="http://sqldbawithabeard.com/2015/08/31/populating-my-dba-database-for-power-bi-with-PowerShell-server-info/" target="_blank" rel="noopener"
>as the previous post&lt;/a> by checking the SQL Info table for an entry for that instance and updating the table if it exists and inserting if it does not.&lt;/p>
&lt;p>There are other uses for gathering this information than just for reporting on it. You can target different versions of SQL for different scripts. You can identify values that are outside what is expected and change them. If xp_cmdshell should not be enabled, write the TSQL to gather the connection string of all of the servers from the DBADatabase where the SQLInfo table has &lt;code>XPCMDShellenabled = 1&lt;/code> and loop through them exactly as above and change the value of &lt;code>$srv.Configuration.XPCmdShellEnabled.ConfigValue&lt;/code> to 0 and then &lt;code>$Srv.Alter()&lt;/code>&lt;/p>
&lt;p>It is a very powerful way of dynamically targeting your estate if you are looking after many instances and with great power comes great responsibility.&lt;/p>
&lt;p>ALWAYS TEST THESE AND ANY SCRIPTS YOU FIND OR SCRIPTS YOU WRITE BEFORE YOU RUN THEM IN YOUR PRODUCTION ENVIRONMENT&lt;/p>
&lt;p>Yeah, I shouted and some people thought it was rude. But its important, it needs to be repeated and drilled in so that it becomes habitual. You can do great damage to your estate with only a few lines of PowerShell and a DBA Database so please be very careful and ensure that you have a suitable test subset of servers that you can use to test&lt;/p>
&lt;p>The other thing we can do is report on the data and with Power Bi we can create self service reports and dashboards and also make use of the natural language query at powerbi.com so that when your systems team ask &amp;ldquo;What are all the servers in X data center?&amp;rdquo; you can enable them to answer it themselves or when the compliance officer asks how many SQL 2005 instances do we have and which clients do they serve you can give them a dashboard they can query themselves.&lt;/p>
&lt;p>This is how I create the two reports you see at the top. I start by connecting to the data source, my DBA Database&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>And I use this query&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">SELECT
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> IL.ServerName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.InstanceName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Location
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Environment
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.Inactive
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,IL.NotContactable
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLInfoID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DateAdded]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstanceName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLVersionString]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLVersion]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServicePack]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[Edition]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ServerType]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[Collation]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsHADREnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLServiceAccount]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLService]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[SQLServiceStartMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BAckupDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BrowserAccount]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[BrowserStartMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsSQLClustered]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterQuorumstate]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ClusterQuorumType]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[C2AuditMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[CostThresholdForParallelism]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MaxDegreeOfParallelism]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DBMailEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultBackupCComp]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[FillFactor]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MaxMem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MinMem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[RemoteDacEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[XPCmdShellEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[CommonCriteriaComplianceEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultFile]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[DefaultLog]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[HADREndpointPort]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[ErrorLogPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstallDataDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstallSharedDirectory]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsCaseSensitive]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[IsFullTextInstalled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[LinkedServer]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[LoginMode]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MasterDBLogPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[MasterDBPath]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[NamedPipesEnabled]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[OptimizeAdhocWorkloads]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[InstanceID]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[AGListener]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,SI.[AGs]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> FROM [DBADatabase].[Info].[SQLInfo] as SI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> JOIN [DBADatabase].[dbo].[InstanceList] as IL
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ON IL.InstanceID = SI.InstanceID
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>So that I can easily add any and all the data to the reports if I choose or query using them in powerbi.com&lt;/p>
&lt;p>First I created 3 measures.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> AG = DISTINCTCOUNT(Query1[AGs]) Instances = DISTINCTCOUNT(Query1[InstanceID]) Servers = DISTINCTCOUNT(Query1[ServerName])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I click on map&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/5.png?w=300"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>And drag the location column to location and the Instances measure to both the Values and Color Saturation&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I then click on edit and format the title and change the colours for the data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>Next I created I heat map for Instances by Edition. The picture shows the details&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>And a column chart for Instances by Version&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/9.png?w=300"
loading="lazy"
alt="9"
>&lt;/a>&lt;/p>
&lt;p>I also add a table showing the number of instances in each location and a slicer for environment.&lt;/p>
&lt;p>Even though you have added one slicer, you are able to slice the data by clicking on the charts. If I click on Developer Edition I can quickly see which versions and locations they are in&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/10.png?w=300"
loading="lazy"
alt="10"
>&lt;/a>&lt;/p>
&lt;p>This works for the map and the column chart as well. This has all been created using live data as a base with all identifying information altered, Bolton is where I was born and the other locations are chosen at random, all other figures and rollups have also been altered.&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/11.png?w=300"
loading="lazy"
alt="11"
>&lt;/a>&lt;/p>
&lt;p>To create the other report I create two donut charts for Instances by version and by location using steps similar to my previous post and then add some tables for location, edition and xp_cmdshell enabled as well as some cards showing total numbers of Servers, Instances and Availability Groups and a slicer for environment to create a report like this, you can use the donut charts to slice the data as well&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/12.png?w=300"
loading="lazy"
alt="12"
>&lt;/a>&lt;/p>
&lt;p>But there are so many different points of information gathered by this script that you get extra value using the natural language query on powerbi.com.&lt;/p>
&lt;p>Click Publish and enter your powerbi.com credentials and then log into powerbi.com in a browser and you will see your report and your dataset. (Note, you can easily filter to find your dashboards, reports and data sets)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/13.png?w=173"
loading="lazy"
alt="13"
>&lt;/a>&lt;/p>
&lt;p>Click the plus sign to create a new dashboard and click the pin on any of the objects in your report to pin them to the dashboard&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/14.png?w=300"
loading="lazy"
alt="14"
>&lt;/a>&lt;/p>
&lt;p>Then you can view (and share) your dashboard&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/15.png?w=300"
loading="lazy"
alt="15"
>&lt;/a>&lt;/p>
&lt;p>Once you have done this you can query your data using natural language. It will cope with spelling mistakes and expects the column names so you may want to think about renaming them in your report by right clicking on them after you get your data.&lt;/p>
&lt;p>You can ask it questions and build up information on the fly and alter it as you need it. As a DBA doing this and imagining enabling others to be able to ask these questions whenever they want from a browser and as many times as they like, it was very cool!&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/16.png?w=300"
loading="lazy"
alt="16"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/17.png?w=300"
loading="lazy"
alt="17"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/18.png?w=300"
loading="lazy"
alt="18"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/19.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/19.png?w=300"
loading="lazy"
alt="19"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/09/20.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/09/20.png?w=300"
loading="lazy"
alt="20"
>&lt;/a>&lt;/p>
&lt;p>Pretty cool, I think you and any of your &amp;lsquo;requestors&amp;rsquo; would agree&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You can get all of the scripts here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Use Twitter to get #PowerShell help</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-twitter-to-get-#powershell-help/</link><pubDate>Sun, 06 Sep 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/use-twitter-to-get-#powershell-help/</guid><description>&lt;p>A quick post today just to add some weight to something that Mike Fal &lt;a class="link" href="http://www.mikefal.net/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/Mike_Fal" target="_blank" rel="noopener"
>t&lt;/a> has kicked off. The &lt;a class="link" href="https://twitter.com/hashtag/sqlhelp" target="_blank" rel="noopener"
>#SQLHelp hashtag&lt;/a> is well known and well used with in the SQL world. It is a fantastic resource and one that I recommend to all SQL folk I meet who are not aware of it. &lt;a class="link" href="https://www.brentozar.com/archive/2009/12/i-need-sqlhelp/" target="_blank" rel="noopener"
>Heres how it started&lt;/a>&lt;/p>
&lt;p>Mike has suggested that there should be a similar resource for PowerShell questions &lt;a class="link" href="https://twitter.com/search?q=%23PoShHelp" target="_blank" rel="noopener"
>#PoSHHelp&lt;/a>. We want to create a useful and positive place for people to go with their PowerShell queries and some good folks like Mike,  &lt;a class="link" href="http://t.co/NfvkfJXMjp" target="_blank" rel="noopener"
>Shawn Melton&lt;/a>(&lt;a class="link" href="https://twitter.com/wsmelton" target="_blank" rel="noopener"
>@wsmelton&lt;/a>), &lt;a class="link" href="http://t.co/K8jsx6WHcc" target="_blank" rel="noopener"
>Adam Bertram&lt;/a>(&lt;a class="link" href="https://twitter.com/adbertram" target="_blank" rel="noopener"
>@adbertram&lt;/a>), &lt;a class="link" href="http://t.co/U5LLtwWDPI" target="_blank" rel="noopener"
>Derik Hammer&lt;/a>(&lt;a class="link" href="https://twitter.com/SQLHammer" target="_blank" rel="noopener"
>@SQLHammer&lt;/a>), &lt;a class="link" href="http://learn-PowerShell.net/" target="_blank" rel="noopener"
>Boe Prox&lt;/a>(&lt;a class="link" href="https://twitter.com/proxb" target="_blank" rel="noopener"
>@proxb&lt;/a>), myself  and others will be looking for your PowerShell problems and try to assist you over Twitter with the same care and grace as Sqlhelp.&lt;/p>
&lt;p>As with Sqlhelp we would like there to be a few rules that we all can follow to ensure that this remains a brilliant resource. Mike has suggested the following&lt;/p>
&lt;ol>
&lt;li>Questions should fit into 140 characters.&lt;/li>
&lt;li>If they don’t, put your question and information on another site (like &lt;a class="link" href="http://serverfault.com/" target="_blank" rel="noopener"
>ServerFault.com&lt;/a>) and link to it.&lt;/li>
&lt;li>DO NOT SPAM THE HASH TAG. This is important, because in order to make it useful it needs to be kept clean. Don’t use it to advertise your blog posts or articles, but only for Q&amp;amp;A.&lt;/li>
&lt;li>Don’t be a dick, a.k.a. &lt;a class="link" href="http://knowyourmeme.com/memes/wheatons-law" target="_blank" rel="noopener"
>Wheaton’s Law&lt;/a>. It’s all too easy to let the anonymity of the internet get the better of us. Be polite and respectful to those using and accidentally mis-using the hash tag.&lt;/li>
&lt;/ol>
&lt;p>I notice that &lt;a class="link" href="http://sqlvariant.com/2010/07/please-join-us-for-poshhelp/" target="_blank" rel="noopener"
>Aaron Nelson had already suggested this a few years ago&lt;/a> but it seems like it has fallen by the wayside. I would like to see this grow for all PowerShell folk so I ask you all to do two things.&lt;/p>
&lt;p>Firstly, please add #PoSHHelp to your Tweetdeck column list or pin it to Tweetium (like I have) If you see a question you can help with then jump in and give your answer and help the community.&lt;/p>
&lt;p>Secondly, let people know, if you see or hear a question about PowerShell then advise them to make use of the hashtag. If you blog about PowerShell then write a quick blog post like this one and let your readers know.&lt;/p>
&lt;p>Pass on the word&lt;/p>
&lt;p>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/nRhfnZ0.png"
loading="lazy"
>&lt;/p></description></item><item><title>Populating My DBA Database for Power Bi with PowerShell - Server Info</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-server-info/</link><pubDate>Mon, 31 Aug 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/populating-my-dba-database-for-power-bi-with-powershell-server-info/</guid><description>&lt;p>Following my last post about &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>using Power Bi with my DBA Database&lt;/a> I have been asked if I would share the PowerShell scripts which I use to populate my database. They are the secondary part to my DBADatabase which I also use to automate the installation and upgrade of all of my DBA scripts as I started to blog about in this post &lt;a class="link" href="https://blog.robsewell.com/powershell/sql%20server/installing-and-upgrading-default-scripts-automation-part-one-introduction/" target="_blank" rel="noopener"
>Installing and upgrading default scripts automation - part one - Introduction&lt;/a> which is a series I will continue later.&lt;/p>
&lt;p>In this post I will show how to create the following report&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/18.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/18.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You will find the latest version of my DBADatabase creation scripts here&lt;/a>.&lt;/p>
&lt;p>I create the following tables&lt;/p>
&lt;ul>
&lt;li>dbo.ClientDatabaseLookup&lt;/li>
&lt;li>dbo.Clients&lt;/li>
&lt;li>dbo.InstanceList&lt;/li>
&lt;li>dbo.InstanceScriptLookup&lt;/li>
&lt;li>dbo.ScriptList&lt;/li>
&lt;li>Info.AgentJobDetail&lt;/li>
&lt;li>Info.AgentJobServer&lt;/li>
&lt;li>Info.Databases&lt;/li>
&lt;li>Info.Scriptinstall&lt;/li>
&lt;li>Info.ServerOSInfo&lt;/li>
&lt;li>Info.SQLInfo&lt;/li>
&lt;/ul>
&lt;p>By adding Server name, Instance Name , Port, Environment, NotContactable, and Location into the InstanceList table I can gather all of the information that I need and also easily add more information to other tables as I need to.&lt;/p>
&lt;p>The not contactable column is so that I am able to add instances that I am not able to contact due to permission or environment issues. I can still gather information about them manually and add it to the table. I use the same script and change it to generate the SQL query rather than run it, save the query and then run the query manually to insert the data. This is why I have the DateAdded and Date Checked column so that I know how recent the data is. I don’t go as far as recording the change however as that will be added to a DBA-Admin database on every instance which stores every change to the instance.&lt;/p>
&lt;p>The ServerOSInfo table is created like so&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\*\*\*\*\*\* Object: Table [Info].[ServerOSInfo] Script Date: 26/08/2015 19:50:38 \*\*\*\*\*\*
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SET ANSI_NULLS ON
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">SET QUOTED_IDENTIFIER ON
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CREATE TABLE [Info].[ServerOSInfo](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerOSInfoID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DateAdded] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DateChecked] [datetime] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[DNSHostName] [nvarchar](50) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Domain] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[OperatingSystem] [nvarchar](100) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[NoProcessors] [tinyint] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[IPAddress] [nvarchar](15) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[RAM] [int] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK__ServerOS__50A5926BC7005F29] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerOSInfoID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The PowerShell script uses Jason Wasser @wasserja Write-Log function to write to a text file but I also  enable some logging into a new event log by following the steps here &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.technet.com/b/heyscriptingguy/archive/2013/02/01/use-PowerShell-to-create-and-to-use-a-new-event-log.aspx&lt;/a> to create a log named SQLAutoScript with a source SQLAUTOSCRIPT&lt;/p>
&lt;p>To run the script I simply need to add the values for&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$CentralDBAServer = &amp;#39;&amp;#39; ## Add the address of the instance that holds the DBADatabase
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$CentralDatabaseName= &amp;#39;DBADatabase&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$LogFile = &amp;#34;\DBADatabaseServerUpdate_&amp;#34; + $Date + &amp;#34;.log&amp;#34; ## Set Path to Log File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And the script will do the rest. Call the script from a PowerShell Job Step and schedule it to run at the frequency you wish, I gather the information every week. You can get the &lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>script from here&lt;/a> or you can read on to see how it works and how to create the report&lt;/p>
&lt;p>I create a function called Catch-Block to save keystrokes and put my commands inside a try catch to make the scripts as robust as possible.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;span class="lnt">9
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Catch-Block{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param ([string]$Additional)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34; On $Connection &amp;#34; + $Additional + $_.Exception.Message + $_.Exception.InnerException.InnerException.message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Message = &amp;#34; This message came from the Automated PowerShell script updating the
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DBA Database with Server Information&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Msg = $Additional + $ErrorMessage + &amp;#34; &amp;#34; + $Message
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message $ErrorMessage -Level Error
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-EventLog -LogName SQLAutoScript -Source &amp;#34;SQLAUTOSCRIPT&amp;#34; -EventId 1 -EntryType Error -Message $Msg
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the function an additional parameter which will hold each custom error message which I write to both the event log and a text message to enable easy troubleshooting and include the message from the &lt;code>$Error&lt;/code> variable by accessing it with &lt;code>$_&lt;/code>. I won&amp;rsquo;t include the try catch in the examples below. I gather all of the server names from the InstanceList table and set the results to an array variable called &lt;code>$Servers&lt;/code>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$AlltheServers = Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query &amp;#34;SELECT DISTINCT [ServerName] FROM [DBADatabase].[dbo].[InstanceList] WHERE Inactive = 0 OR NotContactable = 1&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Servers = $AlltheServers| Select ServerName -ExpandProperty ServerName
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then loop through the array and gather the information with three WMI queries.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;Gathering Info for $Server &amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach($Server in $Servers)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;Gathering Info for $Servers&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DNSHostName = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Domain = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$OperatingSystem = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$IP = &amp;#39;NOT GATHERED&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">try{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Info = get-wmiobject win32_computersystem -ComputerName $Server -ErrorAction Stop|select DNSHostName,Domain,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">@{Name=&amp;#34;RAM&amp;#34;;Expression={&amp;#34;{0:n0}&amp;#34; -f($_.TotalPhysicalMemory/1gb)}},NumberOfLogicalProcessors
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I give the variables some default values in case they are not picked up and set the error action for the command to Stop to exit the try and the first query gathers the DNSHostName, Domain Name, the amount of RAM in GB and the number of logical processors, the second gathers the Operating System version but the third was the most interesting to do. There are many methods of gathering the IP Address using PowerShell and I tried a few of them before finding one that would work with all of the server versions that I had in my estate but the one that worked remotely the best for me and this is a good point to say that this works in my lab and in my shop but may not necessarily work in yours, so understand, check and test this and any other script that you find on the internet before you let them anywhere near your production environment.&lt;/p>
&lt;p>Unfortunately the one that worked everywhere remotely errored with the local server so I added a check to see if the server name in the variable matches the global environment variable of Computer Name&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$OS = gwmi Win32_OperatingSystem -ComputerName $Server| select @{name=&amp;#39;Name&amp;#39;;Expression={($_.caption)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if($Server -eq $env:COMPUTERNAME)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{$IP = (Get-WmiObject -ComputerName $Server -class win32_NetworkAdapterConfiguration -Filter &amp;#39;ipenabled = &amp;#34;true&amp;#34;&amp;#39; -ErrorAction Stop).ipaddress[0] }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else {$IP = [System.Net.Dns]::GetHostAddresses($Server).IPAddressToString }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Log -Path $LogFile -Message &amp;#34;WMI Info gathered for $Server &amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once I have all of the information I check if the server already exists in the ServerOs table and choose to either insert or update.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> $Exists = Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query &amp;#34;SELECT [ServerName] FROM [DBADatabase].[Info].[ServerOSInfo] WHERE ServerName = &amp;#39;$Server&amp;#39;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($Exists)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> UPDATE [Info].[ServerOSInfo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> SET [DateChecked] = GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[ServerName] = &amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DNSHostName] = &amp;#39;$DNSHostName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Domain] = &amp;#39;$Domain&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[OperatingSystem] = &amp;#39;$OperatingSystem&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[NoProcessors] = &amp;#39;$NOProcessors&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[IPAddress] = &amp;#39;$IP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[RAM] = &amp;#39;$RAM&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> WHERE ServerName = &amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Query = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> INSERT INTO [Info].[ServerOSInfo]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ([DateChecked]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DateAdded
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[ServerName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[DNSHostName]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[Domain]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[OperatingSystem]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[NoProcessors]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[IPAddress]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,[RAM])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> VALUES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ( GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,GetDate()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$Server&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$DNSHostName&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$Domain&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$OperatingSystem&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$NoProcessors&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$IP&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ,&amp;#39;$RAM&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-Sqlcmd -ServerInstance $CentralDBAServer -Database $CentralDatabaseName -Query $Query
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ```
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">And that’s it. Now if you wish to gather different data about your servers then you can examine the data available to you by
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>get-wmiobject Win32_OperatingSystem -ComputerName $Server | Get-Member
get-wmiobject win32_computersystem -ComputerName $Server | Get-Member&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">If you find something that you want to gather you can then add the property to the script and gather that information as well, make sure that you add the column to the table and to both the insert and update statements in the PowerShell Script
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">**Creating the report in Power Bi**
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">All data shown in the examples below has been generated from real-life data but all identifiable data has been altered or removed. I was born in Bolton and [SQL SouthWest](http://sqlsouthwest.co.uk/) is based in Exeter :-)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Open Power Bi Desktop and click get data. Add the connection details for your DBA Database server and database and add the query
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;pre>&lt;code>SELECT SOI.[ServerOSInfoID]
,SOI.[DateChecked]
,SOI.[ServerName]
,SOI.[DNSHostName]
,SOI.[Domain]
,SOI.[OperatingSystem]
,SOI.[NoProcessors]
,SOI.[IPAddress]
,SOI.[RAM]
,IL.ServerName
,IL.InstanceName
,IL.Location
,IL.Environment
,IL.Inactive
,IL.NotContactable
FROM [DBADatabase].[Info].[ServerOSInfo] as SOI
JOIN [dbo].[InstanceList] as IL
ON IL.ServerName = SOI.[ServerName]
```
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/21.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/21.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>Create a new column for the Operating Edition by clicking data on the left and using this code as described &lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>in my previous post&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Edition = SWITCH([OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And one for OS Version using this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">OS Version = SWITCH([OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;Server 2012 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I also created a new measure to count the distinct number of servers and instances as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Servers = DISTINCTCOUNT(Query1[Servers Name])
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Instances = COUNT(Query1[Instance])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then in the report area I start by creating a new text box and adding a title to the report and setting the page level filter to InActive is false so that all decommissioned servers are not included&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/31.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/31.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>I then create a donut chart for the number of servers by Operating System by clicking the donut chart in the visualisations and then dragging the OS version to the Details and the Servers Name to the Values&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/41.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/41.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>I then click the format button and added a proper title and the background colour&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/51.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/51.png?w=90"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>Then create the server numbers by location in the same way by clicking donut chart and adding location and count of server names and adding the formatting in the same way as the previous donut&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/61.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/61.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I created a number of charts to hold single values for Domain, Instance, Server, RAM, Processors and the number of Not Contactable to provide a quick easy view of those figures, especially when you filter the report by clicking on a value within the donut chart. I find that managers really like this feature. They are all created in the same way by clicking the card in the visualisation and choosing the value&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/71.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/71.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>I also add a table for the number of servers by operating system and the number of servers by location by dragging those values to a table visualisation. I find that slicers are very useful ways of enabling information to be displayed as required, use the live visualisation to do this, I add the environment column to slice so that I can easily see values for the live environment or the development environment&lt;/p>
&lt;p>I create a separate page in the report to display all of the server data as this can be useful for other teams such as the systems (server admin) team. I give them a lot of different slicers : - Domain, Location, Environment, OS Version, Edition and NotContactable with a table holding all of the relevant values to enable them to quickly see details&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/81.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/81.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://1drv.ms/1N4fqxt" target="_blank" rel="noopener"
>You can get all of the scripts here&lt;/a>&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/sql%20server/using-power-bi-with-my-dba-database/" target="_blank" rel="noopener"
>&lt;strong>Using Power Bi with my DBA Database&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Using Power Bi with my DBA Database</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-power-bi-with-my-dba-database/</link><pubDate>Sun, 16 Aug 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-power-bi-with-my-dba-database/</guid><description>&lt;p>Every good DBA should have a DBA database. A place to store information about all of their instances and databases.&lt;/p>
&lt;p>I have an InstanceList table which looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">CREATE TABLE [dbo].[InstanceList](
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] [int] IDENTITY(1,1) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[ServerName] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceName] [nvarchar](50) NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Port] [int] NOT NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[AG] [bit] NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Inactive] [bit] NULL CONSTRAINT [DF_InstanceList_Inactive] DEFAULT ((0)),
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Environment] [nvarchar](25) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Location] [nvarchar](30) NULL,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">CONSTRAINT [PK_InstanceList_ID] PRIMARY KEY CLUSTERED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[InstanceID] ASC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)WITH (PAD_INDEX = OFF, STATISTICS_NORECOMPUTE = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS = ON, ALLOW_PAGE_LOCKS = ON) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">) ON [PRIMARY]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I use this as the basis for all of my information gathering. By adding Server name, Instance Name , Port, Environment and Location to the table I use overnight Agent jobs to run PowerShell scripts to gather information about all of the instances. This way the information is dynamic and gathered from the server, so when we add RAM and change Max memory this is updated the next time the script runs. You can also automate your installation and decommission procedures (using PowerShell scripts) to add the information to the DBA database automatically&lt;/p>
&lt;p>I have 4 scripts&lt;/p>
&lt;ul>
&lt;li>ServerInfo which gathers Windows OS information such as Version and edition of the operating system, number of processors,amount of RAM, IP address, domain name etc&lt;/li>
&lt;li>SQLInfo which gathers information about the instance such as SQL version, edition, collation, max and min memory, MAXDOP , service accounts and start modes, default file locations etc&lt;/li>
&lt;li>Database information such as size, data usage, index usage, last backup dates, owner and many more&lt;/li>
&lt;li>Agent Job which gathers the outcome of the jobs that have run, their names, category into two tables one for a server rollup and one for details about each job&lt;/li>
&lt;/ul>
&lt;p>Recently I have received a lot of requests for information from various sources, auditors asking about encryption and backup policies, Project managers asking about database and sql versions, compliance asking about numbers of Windows 2003 servers or SQL 2005 servers, system teams asking which serves in a particular location can be turned off at which time dependant on which system they are supporting for a power down&lt;/p>
&lt;p>Before we had the DBA database holding all of the information about the instances we would have struggled to be able to compile this information and when I saw Power Bi was released to GA I thought that it would be a good place to start to learn about it. By using data that I understood and answering questions that I knew the format of the answer I could be more confident about experimenting - ie. if I know I have 100 servers then any result for servers that exceeds that is incorrect&lt;/p>
&lt;p>I have never been a BI guy, I claim no expertise in the correct methods of manipulating the data. There may very well be better methods of achieving these results and if there please feel free to comment below so that I can improve my knowledge and keep on learning&lt;/p>
&lt;p>All data shown in the examples below has been generated from real-life data but all identifiable data has been altered or removed. I have no servers in Bolton, it is where I am from originally!!&lt;/p>
&lt;p>I downloaded Power BI Desktop from powerbi.com and ran the installer and the first screen you see is this one&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>I then clicked on Get Data&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/2.png?w=276"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>And then SQL Server and filled in the details for my DBA Database and clicked connect&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>I used my current Windows credentials&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>It then asked me which tables I wanted to load so I said all of them :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/5.png?w=195"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>Once I had loaded the data I looked at the queries and renamed some of the columns to make more sense to me. I also created some calculated columns by clicking New Column&lt;/p>
&lt;p>I created a relative date column using this code from Chris Webb &lt;a class="link" href="http://blog.crossjoin.co.uk/2013/01/24/building-relative-date-reports-in-powerpivot/" target="_blank" rel="noopener"
>http://blog.crossjoin.co.uk/2013/01/24/building-relative-date-reports-in-powerpivot/&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Relative Date Offset=INT([Date] – TODAY()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Relative Date=IF([Relative Date Offset]=0
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, &amp;#34;Today&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">, &amp;#34;Today &amp;#34; &amp;amp; IF([Relative Date Offset]&amp;gt;0, &amp;#34;+&amp;#34;, &amp;#34;&amp;#34;) &amp;amp; [Relative Date Offset])
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This will enable me to show data for the last day&lt;/p>
&lt;p>I also did the same for days of the week&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">DayOfWeek = CONCATENATE(WEEKDAY(&amp;#39;Info AgentJobDetail&amp;#39;[LastRunTime],2),FORMAT(&amp;#39;InfoAgentJobDetail&amp;#39;[LastRunTime],&amp;#34; -dddd&amp;#34;))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Because I struggled to show the information about the Operating system I also created two columns for OS name and OS edition by adding columns as shown below&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Version = SWITCH(&amp;#39;Info ServerOSInfo&amp;#39;[OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Server 2012&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;Server 2012 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Server 2008 R2&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Server 2008&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Server 2003&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Operating System Edition = SWITCH(&amp;#39;Info ServerOSInfo&amp;#39;[OperatingSystem], &amp;#34;Microsoft Windows Server 2012 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 Standard&amp;#34;,&amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2012 R2 Datacenter&amp;#34;, &amp;#34;DataCenter&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows Server 2008 R2 Enterprise&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Standard&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft® Windows Server® 2008 Enterprise&amp;#34;,&amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Standard Edition&amp;#34;, &amp;#34;Standard&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft(R) Windows(R) Server 2003, Enterprise Edition&amp;#34;, &amp;#34;Enterprise&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Microsoft Windows 2000 Server&amp;#34;, &amp;#34;Server 2000&amp;#34;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then I started to play with the data.&lt;/p>
&lt;p>This is probably not how a professional would phrase it but I would say that if you don&amp;rsquo;t know how to use a new application be brave and give it a try.&lt;/p>
&lt;p>&lt;strong>OBVIOUSLY&lt;/strong> you are a &lt;strong>PROFESSIONAL DBA&lt;/strong> and will not do anything that would endanger production, use a backup of your database and work locally if you need to.&lt;/p>
&lt;p>The first thing I wanted to know was how many servers I had by operating system, how many by SQL version and the location of them so that I could answer the questions I had been asked. I had already written a query to get the correct information to give to the requestors so I knew the correct answers which was also an advantage. I did this like this&lt;/p>
&lt;p>I expanded the Info ServerOSInfo query and dragged the ServerName field to the report which created a table of names&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>I then changed the ServerName values to Count&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>I then dragged the calculated column Operating System Version to the table&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>If I click on the table and then donut chart in the visualisations it changes to&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/9.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/9.png?w=300"
loading="lazy"
alt="9"
>&lt;/a>&lt;/p>
&lt;p>So you can quickly see how you want the data displayed&lt;/p>
&lt;p>I then decided to look at the number of SQL 2005 instances that I had and as I had relationships between SQLInfo and Instancelist and Clients I could build a more dynamic report.&lt;/p>
&lt;p>I created a donut chart with SQLVersion as the legend and InstanceID as the values and a table of SQLVersion, ServerName and Instance Name. I also created a card that was count of InstanceID&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/10.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/10.png?w=300"
loading="lazy"
alt="10"
>&lt;/a>&lt;/p>
&lt;p>Now it starts getting really useful. If I want to know how many SQL 2005 instances I have I simply click on SQL2005 in the donut chart and the rest of the report changes&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/11.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/11.png?w=300"
loading="lazy"
alt="11"
>&lt;/a>&lt;/p>
&lt;p>This is very cool and I hope you can see how useful this could be and how brilliant it would be to enable relevant people within the organisation the ability to look at that report and answer their own questions.&lt;/p>
&lt;p>Lets take it to the next step. I have a location column in the InstanceList table which comprises of town names. If I choose a map and drag that column to the Location field and set Values and Color Saturation to the Count of InstanceID&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/12.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/12.png?w=166"
loading="lazy"
alt="12"
>&lt;/a>&lt;/p>
&lt;p>and create two tables one of client with a count of instanceid and one location with a count of instance id I can do this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/13.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/13.png?w=300"
loading="lazy"
alt="13"
>&lt;/a>&lt;/p>
&lt;p>Look at how it dynamically changes as you click on the data labels - This is very cool and makes me smile every time!! I altered the colour saturation colours to make it easier to see. Now if I am asked about SQL 2005 servers I can quickly click on SQL 2005 and&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/14.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/14.png?w=300"
loading="lazy"
alt="14"
>&lt;/a>&lt;/p>
&lt;p>I can see that there are 32 instances, most are in Southampton, and which clients they support&lt;/p>
&lt;p>If I click a location rather than SQL version the report alters like so&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/15.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/15.png?w=300"
loading="lazy"
alt="15"
>&lt;/a>&lt;/p>
&lt;p>So you can simply pass the report file to your colleagues to enable them to use it or you can publish it to Powerbi.com. &lt;a class="link" href="https://support.powerbi.com/knowledgebase/articles/685479-power-bi-pro-content-what-is-it?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>I am not going to go into any detail about the costs or licensing etc&lt;/a> I will just say it is as easy as clicking publish. If you wish to have the information automatically refreshed there are some &lt;a class="link" href="http://biinsight.com/power-bi-personal-gateway-five-things-you-must-know/" target="_blank" rel="noopener"
>more steps that you would need to go through which are detailed here which enable you to connect your on-premise database to Powerbi using the data management gateway&lt;/a>, alternatively you can simply refresh the data in the report and then publish it and replace the existing report.&lt;/p>
&lt;p>Once the report is in powerbi.com you can enable Q and A on the data. This is some kind of supernatural mystical magical query language which enables you to query your data with natural language and will alter the results as you type and even cope with (deliberate for screenshot) spelling mistakes :-)&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/16.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/16.png?w=300"
loading="lazy"
alt="16"
>&lt;/a>&lt;/p>
&lt;p>I also created a report for my Agent Jobs to enable me to quickly and easily see which Jobs have failed in the last day&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/08/17.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/08/17.png?w=300"
loading="lazy"
alt="17"
>&lt;/a>&lt;/p>
&lt;p>I did this by filtering the report by Relative Date Offset greater than -1 (today) and &lt;code>isenabled = True&lt;/code> and &lt;code>Outcome = Failed&lt;/code>&lt;/p>
&lt;p>There are many many more ways I can see this being useful and I hope I have given you some ideas and encouraged you to try for yourself and find out more&lt;/p>
&lt;p>I have written further posts about this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-server-info/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Server Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-sql-info" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – SQL Info&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/populating-my-dba-database-for-power-bi-with-powershell-databases/" target="_blank" rel="noopener"
>&lt;strong>Populating My DBA Database for Power Bi with PowerShell – Databases&lt;/strong>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/power%20bi/powershell/sql%20server/power-bi-powershell-and-sql-agent-jobs/" target="_blank" rel="noopener"
>&lt;strong>Power Bi, PowerShell and SQL Agent Jobs&lt;/strong>&lt;/a>&lt;/p></description></item><item><title>Setting Up and Using Azure VM SQL Automated Backup (and Restore)</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</link><pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/setting-up-and-using-azure-vm-sql-automated-backup-and-restore/</guid><description>&lt;p>This weekend I was creating some Azure VMs to test and was required to use the GUI for some screenshots. I have always used my PowerShell scripts &lt;a class="link" href="http://sqldbawithabeard.com/2013/05/14/spinning-up-and-shutting-down-windows-azure-lab-with-PowerShell/" target="_blank" rel="noopener"
>described here&lt;/a> to create my test systems and with a new job taking up a lot of my time had missed the &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>announcement about Azure SQL Automated Backup and Azure SQL Automated Patching&lt;/a> so was surprised to see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/1.png?w=300"
loading="lazy"
alt="1"
>&lt;/a>&lt;/p>
&lt;p>I read the announcement and also the details on MSDN &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn906091.aspx&lt;/a> which show that this requires the SQL Server IaaS Agent. This is a default option on new virtual machines.&lt;/p>
&lt;p>There are some other considerations too. It is only supported for SQL Server 2014 and Windows Server 2012 and 2012R2 at present and you can set a retention period to a maximum of 30 days but it is automated. You do not have to decide upon the backup strategy Azure will decide the frequency and type of backups dependent upon the workload of the database and some other factors such as&lt;/p>
&lt;p>A full backup is taken ○ when an instance is added to use Managed backup ○ When transaction log growth is 1Gb or more ○ At least once a week ○ If the log chain is broken ○ When a database is created&lt;/p>
&lt;p>A transaction log backup is taken - If no log backup is found - Transaction log space used is 5Mb or larger - At least once every two hours - Any time the transaction log backup is lagging behind a full database backup. The goal is to keep the log chain ahead of full backup.&lt;/p>
&lt;p>From &lt;a class="link" href="https://msdn.microsoft.com/en-gb/library/dn449496%28v=sql.120%29.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-gb/library/dn449496(v=sql.120).aspx&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>There are some restrictions - Only database backups are supported - System databases are not supported so you need to back those up yourself - You can only back up to Azure storage - Maximum backup size is 1Tb as this is the maximum size for a blob in Azure storage - Simple recovery is not supported - Maximum retention is 30 days - if you are required to keep your backups for longer than 30 days for regulatory or other reasons you could simply use Azure Automation to copy the files to another storage account in Azure)&lt;/p>
&lt;/blockquote>
&lt;p>How to set it up.&lt;/p>
&lt;p>If you are using the GUI then you will find SQL Automated Backup in the optional config blade of the set up. You can follow the steps &lt;a class="link" href="http://blogs.technet.com/b/dataplatforminsider/archive/2015/01/29/automated-backup-and-automated-patching-for-sql-server-in-azure-portal-and-PowerShell.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here to set it up&lt;/a>. If (like me) you want to use PowerShell then use the following code after you have created your Virtual Machine&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$storageaccount = &amp;#34;&amp;lt;storageaccountname&amp;gt;&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storageaccountkey = (Get-AzureStorageKey -StorageAccountName $storageaccount).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$storagecontext = New-AzureStorageContext -StorageAccountName $storageaccount -StorageAccountKey $storageaccountkey
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$encryptionpassword = (Get-Credential -message &amp;#39;Backup Encryption Password&amp;#39; -User &amp;#39;IGNOREUSER&amp;#39;).password
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$autobackupconfig = New-AzureVMSqlServerAutoBackupConfig -StorageContext $storagecontext -Enable -RetentionPeriod 10 -EnableEncryption -CertificatePassword $encryptionpassword
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-AzureVM -ServiceName &amp;lt;vmservicename&amp;gt; -Name &amp;lt;vmname&amp;gt; | Set-AzureVMSqlServerExtension -AutoBackupSettings $autobackupconfig | Update-AzureVM
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Once you have run the code, Azure will take care of the rest. Add a couple of databases to your instance and look in the storage account and you will see this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/2.png?w=300"
loading="lazy"
alt="2"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/3.png?w=300"
loading="lazy"
alt="3"
>&lt;/a>&lt;/p>
&lt;p>And in the automaticbackup container you will find the Certificates and master key backups&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/4.png?w=300"
loading="lazy"
alt="4"
>&lt;/a>&lt;/p>
&lt;p>It will also create a credential&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/5.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/blogrobsewell/images/5.png"
loading="lazy"
alt="5"
>&lt;/a>&lt;/p>
&lt;p>You can use the same credential to back up your system databases. If like me you use &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>Ola Hallengrens excellent Maintenance Solution&lt;/a> then simply change your systems backup job as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [msdb]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">EXEC msdb.dbo.sp_update_jobstep @job_name = &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL&amp;#39;, @step_id=1 ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> @command=N&amp;#39;sqlcmd -E -S $(ESCAPE_SQUOTE(SRVR)) -d master -Q &amp;#34;EXECUTE [dbo].[DatabaseBackup] @Databases = &amp;#39;&amp;#39;SYSTEM_DATABASES&amp;#39;&amp;#39;, &amp;#34;https://myaccount.blob.core.windows.net/mycontainer&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> , @Credential = &amp;#39;&amp;#39;AutoBackup_Credential&amp;#39;&amp;#39;, @BackupType = &amp;#39;&amp;#39;FULL&amp;#39;&amp;#39;, @Verify = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @CleanupTime = NULL, @CheckSum = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;, @LogToTable = &amp;#39;&amp;#39;Y&amp;#39;&amp;#39;&amp;#34; -b&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you need to restore your database then you can use the GUI and when you choose restore you will see this screen&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/6.png?w=300"
loading="lazy"
alt="6"
>&lt;/a>&lt;/p>
&lt;p>Enter your storage account and the key which you can get from the Azure portal. You will notice that the credential has already been selected, click connect and&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/7.png?w=300"
loading="lazy"
alt="7"
>&lt;/a>&lt;/p>
&lt;p>There are all of your backups ready to restore to any point in time that you choose. By clicking script the T-SQL is generated which looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">USE [master]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">BACKUP LOG [Test] TO URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_LogBackup_2015-07-16_06-21-26.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; ,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOFORMAT, NOINIT, NAME = N&amp;#39;Test_LogBackup_2015-07-16_06-21-26&amp;#39;,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">NOSKIP, NOREWIND, NOUNLOAD, NORECOVERY , STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE DATABASE [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714201240+00.bak&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714202740+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150714224241+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715005741+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715031242+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715052742+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715074243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715095743+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150715121243+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NORECOVERY, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">RESTORE LOG [Test] FROM URL = N&amp;#39;https://sqlbackupstoragebeard.blob.core.windows.net/asqlvm9-mssqlserver/Test_b8bb98d7a235487d9789b3ee8759cf3e_20150716060004+00.log&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">WITH CREDENTIAL = N&amp;#39;AutoBackup_Credential&amp;#39; , FILE = 1, NOUNLOAD, STATS = 5
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>There is an important note. Remember this when you have just set it up so that you don’t think that you have done it wrong (which is what I did!)&lt;/p>
&lt;p>When you enable Automated Patching for the first time, Azure configures the SQL Server IaaS Agent in the background. During this time, the portal will not show that Automated Patching is configured. Wait several minutes for the agent to be installed, configured. After that the portal will reflect the new settings.&lt;/p>
&lt;p>From &amp;lt;&lt;a class="link" href="https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx" target="_blank" rel="noopener"
>https://msdn.microsoft.com/en-us/library/azure/dn961166.aspx&lt;/a>&amp;gt;&lt;/p>
&lt;p>And also look out for this&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/07/8.png?w=300"
loading="lazy"
alt="8"
>&lt;/a>&lt;/p>
&lt;p>The password I had chosen was not complex enough but the PowerShell script had succeeded and not given me the warning&lt;/p>
&lt;p>To set up SQL Automated Patching you follow a similar steps. The setting is again on the OS Config blade and click enable and then you can choose the frequency and duration of the patching.&lt;/p>
&lt;p>It is important to remember to choose your maintenance window correctly. If you have set up your SQL VMs correctly you will have them in an availability set and be using either mirroring or Availability Groups and have the VMs set up in the same availability set to ensure availability during the underlying host patching but I had it confirmed by Principal Software Engineering Manager Sethu Srinivasan &lt;a class="link" href="http://twitter.com/sethusrinivasan" target="_blank" rel="noopener"
>t&lt;/a> via Microsoft PFE Arvind Shyamsundar &lt;a class="link" href="http://blogs.msdn.com/b/arvindsh/?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/arvisam" target="_blank" rel="noopener"
>t&lt;/a> that the SQL Automated Patching is not HA aware so you will need to ensure that you set the maintenance windows on each VM to ensure that they do not overlap&lt;/p></description></item><item><title>Installing and upgrading default scripts automation - part one - Introduction</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/installing-and-upgrading-default-scripts-automation-part-one-introduction/</link><pubDate>Mon, 08 Jun 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/installing-and-upgrading-default-scripts-automation-part-one-introduction/</guid><description>&lt;p>First I must say thank you to all of the wonderful people who have put time and effort into providing free tools and scripts to enable not only myself but all SQL DBAs to ease their work. For this series I especially thank&lt;/p>
&lt;ul>
&lt;li>Brent Ozar - &lt;a class="link" href="http://www.brentozar.com/" target="_blank" rel="noopener"
>w&lt;/a>|&lt;a class="link" href="https://twitter.com/BrentO" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;li>Ola Hallengren - &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>w&lt;/a>&lt;/li>
&lt;li>Adam Mechanic - &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/adammachanic" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;li>Jared Zagelbaum - &lt;a class="link" href="https://jaredzagelbaum.wordpress.com/" target="_blank" rel="noopener"
>b&lt;/a>|&lt;a class="link" href="https://twitter.com/JaredZagelbaum" target="_blank" rel="noopener"
>t&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The aim of this series is to share the methodology and the scripts that I have used to resolve this issue.&lt;/p>
&lt;p>How can I automate the deployment and update of backup, integrity ,index maintenance and troubleshooting scripts as well as other default required scripts to all of the instances under my control and easily target any instances by OS version, SQL version, Environment, System or any other configuration of my choosing&lt;/p>
&lt;p>This is Part 1 - Introduction I will link to the further posts here as I write them&lt;/p>
&lt;p>So the scenario that lead to this series is a varied estate of SQL servers and instances where I wanted an automated method of deploying the scripts and being able to target different servers. It needed to be easy to maintain, easy to use and easy to alter. I wanted to be able to update all of the scripts easily when required. I also wanted to automate the install of new instances and ensure that I could ensure that all required scripts were installed and documented.&lt;/p>
&lt;p>The method of doing this that I chose is just that - Its the way that I chose, whether it will work for you and your estate I don&amp;rsquo;t know but I hope you will find it of benefit. Of course you must test it first. Ensure that you understand what is happening, what it is doing and that that is what you want it to do. If you implement this methodology of installing scripts you will easily be able to start by targeting your Development Server and then gradually rolling it out to any other environments&amp;rsquo; whilst always making sure that you test, monitor and validate prior to moving to the next.&lt;/p>
&lt;p>I decided that I needed to have a DBA Database to start with. The role of the DBA Database is to be the single source of truth for the instances that are under my control, a source for the location of the scripts that I need to deploy and a place to hold the information that I gather from the servers. It is from this database that I will be able to target the instances as required and set the flags to update the scripts as and when I need to&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/06/agentjob1.png" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/06/agentjob1.png?w=300"
loading="lazy"
alt="agentjob"
>&lt;/a>&lt;/p>
&lt;p>On that instance I also chose to put the SQL Agent Job that will deploy all of the scripts. This is an important point. The account that you use to run that job whether it is the Agent Service Account or a proxy account will need to have privileges on every instance that you target. It will need to be able to run every script that you wish to target your servers. The privileges it requires are defined by the scripts that you want to run. How that is set up is unique to your environment and your system. I will only say that all errors are logged to the log files and will enable you to resolve these issues. You should always use the principle of least privilege required to get the job done. Domain and Sys Admin are not really the best answer here :-)&lt;/p>
&lt;p>I also created 2 further Agent Jobs to gather Windows and SQL Information from the servers. These jobs target all the instances and servers in the DBA Database and gather information centrally about Windows and SQL configurations making it easy to provide that information to any other teams that require it. I am always looking for methods to reduce the workload on DBAs and enabling people (using the correct permissions) to gather the information that they require by self-service is very beneficial&lt;/p>
&lt;p>Documentation and logging about the scripts are provided by the log files stored as text files to troubleshoot the script and also documented in the Change log table in a DBA database on each instance which I blogged about &lt;a class="link" href="http://sqldbawithabeard.com/2014/12/08/making-a-change-log-easier-with-PowerShell/" target="_blank" rel="noopener"
>previously here&lt;/a>&lt;/p>
&lt;p>The last thing was the script which needed to be modular and easy to add to and amend.&lt;/p>
&lt;p>Throughout this series of blog posts I will share and expand on the methods I used to do this. If you have any questions at any point please feel free to ask either by commenting on the post or by contacting me using the methods on my About Me page&lt;/p></description></item><item><title>Scheduling Ola Hallengrens Maintenance Solution Default Jobs with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/scheduling-ola-hallengrens-maintenance-solution-default-jobs-with-powershell/</link><pubDate>Wed, 06 May 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/scheduling-ola-hallengrens-maintenance-solution-default-jobs-with-powershell/</guid><description>&lt;p>If you are a SQL Server DBA you should know about Ola Hallengren and will probably have investigated his Maintenance Solution.&lt;/p>
&lt;p>If you haven&amp;rsquo;t please start here &lt;a class="link" href="https://ola.hallengren.com/" target="_blank" rel="noopener"
>https://ola.hallengren.com/&lt;/a>&lt;/p>
&lt;p>You can also watch his presentation at SQLBits at this link&lt;/p>
&lt;p>&lt;a class="link" href="http://sqlbits.com/Sessions/Event9/Inside_Ola_Hallengrens_Maintenance_Solution" target="_blank" rel="noopener"
>http://sqlbits.com/Sessions/Event9/Inside_Ola_Hallengrens_Maintenance_Solution&lt;/a>&lt;/p>
&lt;p>where he talks about and demonstrates the solution.&lt;/p>
&lt;p>It is possible to just run his script to install the solution and schedule the jobs and know that you have made a good start in keeping your databases safe. You should be more proactive than that and set specific jobs for your own special requirements but you can and should find that information in other places including the FAQ on Ola&amp;rsquo;s site&lt;/p>
&lt;p>I particularly like the parameter @ChangeBackupType which when running the transaction log or differential backup will change the backup type to full if the backup type cannot be taken. This is excellent for picking up new databases and backing them up soon after creation&lt;/p>
&lt;p>When you run the script the jobs are created but not scheduled and it is for this reason I created this function. All it does it schedule the jobs so that I know that they will be run when a new server is created and all the databases will be backed up. I can then go back at a later date and schedule them correctly for the servers workload or tweak them according to specific needs but this allows me that fuzzy feeling of knowing that the backups and other maintenance will be performed.&lt;/p>
&lt;p>To accomplish this I pass a single parameter $Server to the function this is the connection string and should be in the format of &lt;code>SERVERNAME&lt;/code>, &lt;code>SERVERNAME\INSTANCENAME &lt;/code>or &lt;code>SERVERNAME\INSTANCENAME,Port&lt;/code>&lt;/p>
&lt;p>I then create a &lt;code>$srv&lt;/code> SMO object as usual&lt;/p>
&lt;p>&lt;code>$srv = New-Object Microsoft.SQLServer.Management.SMO.Server $Server&lt;/code>&lt;/p>
&lt;p>Create a JobServer object and a Jobs array which holds the Jobs&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$JobServer = $srv.JobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Jobs = $JobServer.Jobs
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And set the schedule for each job. I pick each Job using the Where-Object Cmdlet and break out if the job does not exist&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Job = $Jobs|Where-Object {$_.Name -eq &amp;#39;DatabaseBackup - SYSTEM_DATABASES - FULL&amp;#39;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">       if ($Job -eq $Null)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">       {Write-Output &amp;#34;No Job with that name&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">       break}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then I create a Schedule object and set its properties and create the schedule&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Schedule = new-object Microsoft.SqlServer.Management.Smo.Agent.JobSchedule ($job, &amp;#39;Daily - Midnight ++ Not Sunday&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveEndDate = Get-Date -Month 12 -Day 31 -Year 9999
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveEndTimeOfDay = &amp;#39;23:59:59&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyTypes = &amp;#34;Weekly&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyRecurrenceFactor = 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencySubDayTypes = &amp;#34;Once&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.FrequencyInterval = 126 # Weekdays 62 + Saturdays 64 - &amp;lt;a href=&amp;#34;https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx&amp;#34;&amp;gt;https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx&amp;lt;/a&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.ActiveStartDate = get-date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$schedule.ActiveStartTimeOfDay = &amp;#39;00:16:00&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.IsEnabled = $true
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Schedule.Create()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I have picked this example for the blog as it shows some of the less obvious gotchas. Setting the active end date could only be achieved by using the Get-Date Cmdlet and defining the date. The schedule frequency interval above is for every day except Sundays. This achieved by using the following table from &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/microsoft.sqlserver.management.smo.agent.jobschedule.frequencyinterval.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>MSDN&lt;/a> which is always my first port of call when writing these scripts&lt;/p>
&lt;blockquote>
&lt;ul>
&lt;li>WeekDays.Sunday = 1&lt;/li>
&lt;li>WeekDays.Monday = 2&lt;/li>
&lt;li>WeekDays.Tuesday = 4&lt;/li>
&lt;li>WeekDays.Wednesday = 8&lt;/li>
&lt;li>WeekDays.Thursday = 16&lt;/li>
&lt;li>WeekDays.Friday = 32&lt;/li>
&lt;li>WeekDays.Saturday = 64&lt;/li>
&lt;li>WeekDays.WeekDays = 62&lt;/li>
&lt;li>WeekDays.WeekEnds = 65&lt;/li>
&lt;li>WeekDays.EveryDay = 127&lt;/li>
&lt;/ul>
&lt;p>Combine values using an OR logical operator to set more than a single day. For example, combine WeekDays.Monday and WeekDays.Friday (FrequencyInterval = 2 + 32 = 34) to schedule an activity for Monday and Friday.&lt;/p>
&lt;/blockquote>
&lt;p>It is easy using this to set up whichever schedule you wish by combining the numbers. I would advise commenting it in the script so that your future self or following DBAs can understand what is happening.&lt;/p>
&lt;p>You can tweak this script or use the code to work with any Agent Jobs and set the schedules accordingly and you can check that you have set the schedules correctly with this code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">   $srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $JObserver = $srv.JobServer
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $JObs = $JObserver.Jobs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $ActiveStartTimeOfDay = @{Name = &amp;#34;ActiveStartTimeOfDay&amp;#34;; Expression = {$_.JobSchedules.ActiveStartTimeOfDay}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $FrequencyInterval = @{Name = &amp;#34;FrequencyInterval&amp;#34;; Expression = {$_.JobSchedules.FrequencyInterval}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $FrequencyTypes = @{Name = &amp;#34;FrequencyTypes&amp;#34;; Expression = {$_.JobSchedules.FrequencyTypes}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $IsEnabled = @{Name = &amp;#34;IsEnabled&amp;#34;; Expression = {$_.JobSchedules.IsEnabled}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">   $Jobs|Where-Object{$_.Category -eq &amp;#39;Database Maintenance&amp;#39;}|select name,$IsEnabled,$FrequencyTypes,$FrequencyInterval,$ActiveStartTimeOfDay|Format-Table -AutoSize
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can get the script from Script Center via the link below or by searching for &amp;ldquo;Ola&amp;rdquo; using the &lt;a class="link" href="http://www.microsoft.com/en-us/download/details.aspx?id=42525?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>script browser add-in&lt;/a> straight from ISE&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/05/browser.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/05/browser.jpg?w=300"
loading="lazy"
alt="browser"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Schedule-Ola-Hallengrens-a66a3c89?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://gallery.technet.microsoft.com/scriptcenter/Schedule-Ola-Hallengrens-a66a3c89&lt;/a>&lt;/p></description></item><item><title>Spinach and Database Development- SQLSatExeter Keynote</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/spinach-and-database-development-sqlsatexeter-keynote/</link><pubDate>Thu, 30 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/spinach-and-database-development-sqlsatexeter-keynote/</guid><description>&lt;p>Last weekend, we held our SQL Saturday event in Exeter. It was a brilliant event for many reasons but we were delighted to have a world exclusive keynote video by Phil Factor about Spinach and Database Development. With many thanks to those that made it possible and particularly to Phil Factor I have linked to the video here and also transcribed it. Please watch and read and understand the message [youtube https://www.youtube.com/watch?v=F8qLrOfncZE]&lt;/p>
&lt;p>What has spinach got to do with Database Development?&lt;/p>
&lt;p>Generations of children were fed spinach in preference to more nutritious things, such as cardboard, because of the persistence of bad data.&lt;/p>
&lt;p>It wasn&amp;rsquo;t in fact the decimal point error of legend but confusion over the way that iron was measured in the late 19th century data. As a result nutritionists persisted in believing for generations that it was a rich source of iron that the body needs in order to create bloodcells. In fact, the very little iron that there is in spinach isn&amp;rsquo;t in a form that can be readily absorbed by the body anyway.&lt;/p>
&lt;p>The consequences of bad data can be dire&lt;/p>
&lt;p>Guarding the quality of your data is about the most important thing that you as a data professional can do. You may think that performance is important but it would just deliver you the wrong answer faster. Resilience? it would just make it more likely that you&amp;rsquo;d be able to deliver the wrong answer. Delivery? Yep you got it, the wrong answer quicker.&lt;/p>
&lt;p>The spinach example is a good one because bad data is hard to detect and can go unnoticed for generations. This is probably because people don&amp;rsquo;t inspect and challenge data as much as they should. You would have thought it strange that a vegetable like spinach should have fifty times as much iron as any other vegetable but the fact came from a very reputable source so people just shrugged and accepted it&lt;/p>
&lt;p>We have a touching faith in data,&lt;/p>
&lt;p>We, as a culture, assume its correct and complete, we like to believe that it&amp;rsquo;s impossible that either prejudice, bias, criminality or foolishness could affect the result, worse we think that valuable truth can be sifted from any data no matter the source. If there&amp;rsquo;s enough of it then there must be value in it. It&amp;rsquo;s like panning for gold dust from a river. The sad truth is that this is a delusion but very common in our society. We are, in our mass culture, in the bronze age rather than the information age struggling with silvery toys imbued with mystical magical powers&lt;/p>
&lt;p>A good database professional must be unequivocal.&lt;/p>
&lt;p>Bad data cannot be cleaned in the same way that one can clean mud of a diamond. If data contains bad data then the entire data set must be rejected&lt;/p>
&lt;p>There&amp;rsquo;s no such thing as data cleansing.&lt;/p>
&lt;p>You as a DBA may be asked to take out data that seems absurd such as ages that are negative or ages that are so great that the person couldn&amp;rsquo;t possibly be alive but then that leaves you in the same dataset, data that is plausible but wrong.&lt;/p>
&lt;p>Only in very exceptional circumstances when you know precisely why a minority of your data is wrong would you be justified in correcting it.&lt;/p>
&lt;p>Statistics can help us to make very confident assertions about large datasets if they conform to one of the common distributions but they cannot tell us anything about individual items of data. You can of course remove outliers but in fact outliers are just items of data that don&amp;rsquo;t conform to your assumptions about the data and the whole point of data analysis is to test your assumptions. By cleaning data, by removing outliers you can prove almost anything scientifically&lt;/p>
&lt;p>A well designed database is defended in depth at every possible opportunity.&lt;/p>
&lt;p>Depth is actually an interesting analogy because experience tells us that bad data seems to leak in under pressure, through every crack when the database is working hard. Like you will see in a World War 2 submarine movie, in a well-used OLTP database, we are like the crew, swivelling our eyes in terror savouring the futility of any remediation as ghastly drips run down the walls of our database and wishing we had put in more constraints.&lt;/p>
&lt;p>In terms of the defence of data, check constraints and foreign key constraints are excellent of course and triggers are good but there are other ways of getting warnings of errors in data such as sudden changes in the distribution of data and other anomalies. One check I like to do is the tourism check where you check your data all the way through back to source, this technique once famously picked up the fact that a famous motor manufacturer was reporting its deceleration figures in yards per second when it should have been metres per second.&lt;/p>
&lt;p>When you start putting in check constraints you say to yourself, this couldn&amp;rsquo;t possibly happen. This is the voice of superstition. A famous programmer of the 1970&amp;rsquo;s took to putting a message in his code saying &amp;ldquo;this error could never happen&amp;rdquo; and he put it in places where it couldn’t possibly ever be executed and the funny thing was the more he tested the programme, the more that error appeared on the screen and it is the same with constraints, the more traps you set the more critters you catch and you&amp;rsquo;re left wondering how on earth all that bad data was getting in&lt;/p>
&lt;p>Its misleading to go on about the value of the great flood of big data. There&amp;rsquo;s a strong superstition that data has some sort of intrinsic mystical value all of its own.&lt;/p>
&lt;p>Unless you can prove that data is correct its valueless because if you trust it you can end up with generations of children compelled to eat spinach for no good reason at all.&lt;/p></description></item><item><title>Instances and Ports with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/instances-and-ports-with-powershell/</link><pubDate>Wed, 22 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/instances-and-ports-with-powershell/</guid><description>&lt;p>Just a quick post and a day late for &lt;a class="link" href="https://twitter.com/hashtag/sqlnewblogger" target="_blank" rel="noopener"
>#SQLNewBlogger&lt;/a> There are some excellent posts on that hashtag and I recommend that you read them&lt;/p>
&lt;p>When you know a server name but not the name of the instances or the ports that they are using this function will be of use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.SYNOPSIS
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Shows the Instances and the Port Numbers on a SQL Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.DESCRIPTION
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">This function will show the Instances and the Port Numbers on a SQL Server using WMI
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.PARAMETER Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">The Server Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.EXAMPLE
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Get-SQLInstancesPort Fade2Black
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">This will display the instances and the port numbers on the server Fade2Black
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">.NOTES
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">AUTHOR: Rob Sewell sqldbawithabeard.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">DATE: 22/04/2015
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">function Get-SQLInstancesPort {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> param ([string]$Server)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [system.reflection.assembly]::LoadWithPartialName(&amp;#34;Microsoft.SqlServer.Smo&amp;#34;)|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> [system.reflection.assembly]::LoadWithPartialName(&amp;#34;Microsoft.SqlServer.SqlWmiManagement&amp;#34;)|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $mc = new-object Microsoft.SqlServer.Management.Smo.Wmi.ManagedComputer $Server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instances = $mc.ServerInstances
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($Instance in $Instances) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $port = @{Name = &amp;#34;Port&amp;#34;; Expression = {$_.ServerProtocols[&amp;#39;Tcp&amp;#39;].IPAddresses[&amp;#39;IPAll&amp;#39;].IPAddressProperties[&amp;#39;TcpPort&amp;#39;].Value}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Parent = @{Name = &amp;#34;Parent&amp;#34;; Expression = {$_.Parent.Name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Instance|Select $Parent, Name, $Port
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Checking SQL Server User Role Membership with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-server-user-role-membership-with-powershell/</link><pubDate>Tue, 14 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-server-user-role-membership-with-powershell/</guid><description>&lt;p>Please  go and check the New SQL Bloggers posting here &lt;a class="link" href="https://twitter.com/search?q=%23sqlnewblogger" title="https://twitter.com/search?q=%23sqlnewblogger"
target="_blank" rel="noopener"
>https://twitter.com/search?q=%23sqlnewblogger&lt;/a> There are some brilliant new and older bloggers adding great value to the SQL Community&lt;/p>
&lt;p>This is my most viewed post so I thought it made a good candidate to be updated and reblogged&lt;/p></description></item><item><title>PowerShelling SQL Saturday Sessions to the Guidebook app</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershelling-sql-saturday-sessions-to-the-guidebook-app/</link><pubDate>Tue, 07 Apr 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershelling-sql-saturday-sessions-to-the-guidebook-app/</guid><description>&lt;p>Following on from my &lt;a class="link" href="http://sqldbawithabeard.com/2015/03/21/parsing-xml-child-nodes-and-converting-to-datetime-with-PowerShell/" title="Parsing XML Child Nodes and Converting to DateTime with PowerShell"
target="_blank" rel="noopener"
>previous pos&lt;/a>t about parsing XML where I used the information from &lt;a class="link" href="https://voiceofthedba.wordpress.com/2015/01/26/downloading-sql-saturday-data/" target="_blank" rel="noopener"
>Steve Jones blog post&lt;/a> to get information from the &lt;a class="link" href="https://www.sqlsaturday.com/" target="_blank" rel="noopener"
>SQL Saturday web site&lt;/a> I thought that this information and script may be useful for others performing the same task.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Edit - This post was written prior to the updates to the SQL Saturday website over the weekend. When it can back up the script worked perfectly but the website is unavailable at the moment again so I will check and update as needed once it is back.&lt;/p>
&lt;p>We are looking at using &lt;a class="link" href="https://guidebook.com/" target="_blank" rel="noopener"
>the Guidebook app&lt;/a> to provide an app for our attendees with all the session details for &lt;a class="link" href="https://www.sqlsaturday.com/372" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>&lt;/p>
&lt;p>The Guidebook admin website requires the data for the sessions in a certain format. You can choose CSV or XLS.&lt;/p>
&lt;p>In the admin portal you can download the template&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/down.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/down.jpg?w=300"
loading="lazy"
alt="down"
>&lt;/a>&lt;/p>
&lt;p>which gives an Excel file like this&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/excel.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/excel.jpg?w=300"
loading="lazy"
alt="-excel"
>&lt;/a>&lt;/p>
&lt;p> &lt;/p>
&lt;p>So now all we need to do is to fill it with data.&lt;/p>
&lt;p>I have an Excel Object Snippet which I use to create new Excel Objects when using PowerShell to manipulate Excel. Here it is for you. Once you have run the code you will be able to press CTRL + J and be able to choose the New Excel Object Snippet any time.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$snippet = @{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Title = &amp;#34;New Excel Object&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Description = &amp;#34;Creates a New Excel Object&amp;#34;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Text = @&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a .com object for Excel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl = new-object -comobject excel.application
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl.Visible = \`$true # Set this to False when you run in production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$wb = \`$xl.Workbooks.Add() # Add a workbook
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$ws = \`$wb.Worksheets.Item(1) # Add a worksheet
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells=\`$ws.Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Do Some Stuff
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">perhaps
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells.item(\`$row,\`$col)=&amp;#34;Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$cells.item(\`$row,\`$col).font.size=16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$Cells.item(\`$row,\`$col).Columnwidth = 10
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$wb.Saveas(&amp;#34;C:\temp\Test\`$filename.xlsx&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">\`$xl.quit()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;#34;@
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-IseSnippet @snippet
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I needed to change this to open the existing file by using&lt;/p>
&lt;p>&lt;code>$wb = $xl.Workbooks.Open($GuideBookPath)&lt;/code>&lt;/p>
&lt;p>In the more help tab of the Excel workbook it says&lt;/p>
&lt;blockquote>
&lt;!-- raw HTML omitted -->
&lt;/blockquote>
&lt;p>So we need to do some manipulation of the data we gather. As before I selected the information from the XML as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Endtime = @{Name =&amp;#34;EndTime&amp;#34;; Expression = {[datetime]($_.EndTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Talks = $Sessions.event|Where-Object {$_.title -ne &amp;#39;Coffee Break&amp;#39; -and $_.title -ne &amp;#39;Room Change&amp;#39; -and $_.title -ne &amp;#39;Lunch Break&amp;#39; -and $_.title -ne &amp;#39;Raffle and Cream Tea&amp;#39;}| select $Speaker,$Room,$Starttime,$Endtime,Title,Description |Sort-Object StartTime
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then looped through the $Talks array and wrote each line to Excel like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach ($Talk in $Talks)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = $Talk.StartTime.ToString(&amp;#39;MM/dd/yyyy&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Start = $talk.StartTime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$End = $Talk.Endtime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Title = $Talk.Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Talk.Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = $Talk.Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Start
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $End
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I know that I converted the String to DateTime and then back to a String again but that was the easiest (quickest) way to obtain the correct format for the Excel file&lt;/p>
&lt;p>Then to finish save the file and quit Excel&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$wb.Save()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.quit()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then you upload the file in the Guidebook admin area &lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/import.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/import.jpg?w=300"
loading="lazy"
alt="import"
>&lt;/a>&lt;/p>
&lt;p>wait for the email confirmation and all your sessions are available in the guidebook&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/sched.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/sched.jpg?w=300"
loading="lazy"
alt="sched"
>&lt;/a>&lt;/p>
&lt;p>I hope that is useful to others. The full script is below&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;span class="lnt">30
&lt;/span>&lt;span class="lnt">31
&lt;/span>&lt;span class="lnt">32
&lt;/span>&lt;span class="lnt">33
&lt;/span>&lt;span class="lnt">34
&lt;/span>&lt;span class="lnt">35
&lt;/span>&lt;span class="lnt">36
&lt;/span>&lt;span class="lnt">37
&lt;/span>&lt;span class="lnt">38
&lt;/span>&lt;span class="lnt">39
&lt;/span>&lt;span class="lnt">40
&lt;/span>&lt;span class="lnt">41
&lt;/span>&lt;span class="lnt">42
&lt;/span>&lt;span class="lnt">43
&lt;/span>&lt;span class="lnt">44
&lt;/span>&lt;span class="lnt">45
&lt;/span>&lt;span class="lnt">46
&lt;/span>&lt;span class="lnt">47
&lt;/span>&lt;span class="lnt">48
&lt;/span>&lt;span class="lnt">49
&lt;/span>&lt;span class="lnt">50
&lt;/span>&lt;span class="lnt">51
&lt;/span>&lt;span class="lnt">52
&lt;/span>&lt;span class="lnt">53
&lt;/span>&lt;span class="lnt">54
&lt;/span>&lt;span class="lnt">55
&lt;/span>&lt;span class="lnt">56
&lt;/span>&lt;span class="lnt">57
&lt;/span>&lt;span class="lnt">58
&lt;/span>&lt;span class="lnt">59
&lt;/span>&lt;span class="lnt">60
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">## From http://www.sqlservercentral.com/blogs/steve_jones/2015/01/26/downloading-sql-saturday-data/
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$i = 372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$baseURL = “http://www.sqlsaturday.com/eventxml.aspx?sat=”
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DestinationFile = “E:\SQLSatData\SQLSat” + $i + “.xml”
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$GuideBookPath = &amp;#39;C:\temp\Guidebook_Schedule_Template.xls&amp;#39;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sourceURL = $baseURL + $i
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc = New-Object System.Xml.XmlDocument
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Load($sourceURL)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Save($DestinationFile)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Endtime = @{Name =&amp;#34;EndTime&amp;#34;; Expression = {[datetime]($_.EndTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Talks = $Sessions.event|Where-Object {$_.title -ne &amp;#39;Coffee Break&amp;#39; -and $_.title -ne &amp;#39;Room Change&amp;#39; -and $_.title -ne &amp;#39;Lunch Break&amp;#39; -and $_.title -ne &amp;#39;Raffle and Cream Tea&amp;#39;}| select $Speaker,$Room,$Starttime,$Endtime,Title,Description |Sort-Object StartTime
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a .com object for Excel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl = new-object -comobject excel.application
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.Visible = $true # Set this to False when you run in production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb = $xl.Workbooks.Open($GuideBookPath)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ws = $wb.Worksheets.item(1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells=$ws.Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(2,1) = &amp;#39;&amp;#39; # To clear that entry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(3,1) = &amp;#39;&amp;#39; # To clear that entry
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($Talk in $Talks)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = $Talk.StartTime.ToString(&amp;#39;MM/dd/yyyy&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Start = $talk.StartTime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$End = $Talk.Endtime.ToString(&amp;#39;hh:mm tt&amp;#39;) ## to put the info in the right format
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Title = $Talk.Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Description = $Talk.Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = $Talk.Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Title
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Start
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $End
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Room
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col ++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row,$col) = $Description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb.Save()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.quit()
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div></description></item><item><title>Parsing XML Child Nodes and Converting to DateTime with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/parsing-xml-child-nodes-and-converting-to-datetime-with-powershell/</link><pubDate>Sat, 21 Mar 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/parsing-xml-child-nodes-and-converting-to-datetime-with-powershell/</guid><description>&lt;p>As part of my organiser role for SQLSaturday Exeter (&lt;a class="link" href="http://sqlsatexeter.azurewebsites.net" target="_blank" rel="noopener"
>Training Day Information here&lt;/a> and &lt;a class="link" href="https://www.sqlsaturday.com/372/" target="_blank" rel="noopener"
>Saturday Information here&lt;/a>) I needed to get some schedule information to input into a database.&lt;/p>
&lt;p>I had read &lt;a class="link" href="https://voiceofthedba.wordpress.com/2015/01/26/downloading-sql-saturday-data/" target="_blank" rel="noopener"
>Steve Jones blog posts on Downloading SQL Saturday Data&lt;/a> and followed the steps there to download the data from the SQL Saturday website for our event.&lt;/p>
&lt;p>A typical session is held in the XML like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">&amp;lt;event&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;importID&amp;gt;27608&amp;lt;/importID&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;speakers&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;speaker&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;id&amp;gt;27608&amp;lt;/id&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;name&amp;gt;William Durkin&amp;lt;/name&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/speaker&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/speakers&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;track&amp;gt;Track 2&amp;lt;/track&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;location&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;name&amp;gt;Buccaneer&amp;#39;s Refuge &amp;lt;/name&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;/location&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;title&amp;gt;Stories from the Trenches: Upgrading SQL with Minimal Downtime&amp;lt;/title&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;description&amp;gt;SQL Server has come a long way in the last few years, with Microsoft investing heavily in High Availability features. This session will show you how to use these features to enable you to safely upgrade a SQL Server, while ensuring you have a return path if things should go wrong. You will leave the session knowing what features you can use to upgrade either the OS, Hardware or SQL Server version while keeping your maintenance window to a minimum. The session will apply to Standard Edition as well as Enterprise Edition, so doesn&amp;#39;t only apply to &amp;#39;High Rollers&amp;#39;!&amp;lt;/description&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;startTime&amp;gt;4/25/2015 3:20:00 PM&amp;lt;/startTime&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &amp;lt;endTime&amp;gt;4/25/2015 4:10:00 PM&amp;lt;/endTime&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;/event&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p> &lt;/p>
&lt;p>I needed to output the following details - Speaker Name , Room , Start time,Duration and Title&lt;/p>
&lt;p>To accomplish this I examined the node for Williams session&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$i = 372
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$baseURL = “http://www.sqlsaturday.com/eventxml.aspx?sat=”
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$DestinationFile = “E:\SQLSatData\SQLSat” + $i + “.xml”
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sourceURL = $baseURL + $i
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc = New-Object System.Xml.XmlDocument
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Load($sourceURL)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$doc.Save($DestinationFile)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then established that to get the speakers name I had to obtain the value from the child node which I accomplished as follows&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $Speaker #To check that it worked
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This is an easy way to obtain sub(or child) properties within a select in PowerShell and I would recommend that you practice and understand that syntax of @{Name=&amp;quot;&amp;quot;; Expression = {} } which will enable you to perform all kinds of manipulation on those objects. You are not just limited to obtaining child properties but can perform calculations as well&lt;/p>
&lt;p>I did the same thing to get the room and the start time&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {$_.StartTime}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $Speaker,$Room,$StartTime #To check that it worked
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then needed duration and thought that I could use&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Duration = @{Name =&amp;#34;Duration&amp;#34;; Expression = {($_.EndTime) - ($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event[39]|select $duration
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>However that just gave me a blank result so to troubleshoot I ran&lt;/p>
&lt;p>&lt;code>$Sessions.event[39].endtime - $sessions.event[39].startTime&lt;/code>&lt;/p>
&lt;p>Which errored with the (obvious when I thought about it) message&lt;/p>
&lt;blockquote>
&lt;p>Cannot convert value &amp;ldquo;4/25/2015 4:10:00 PM&amp;rdquo; to type &amp;ldquo;System.Int32&amp;rdquo;. Error: &amp;ldquo;Input string was not in a correct format.&amp;rdquo; At line:1 char:1 + $Sessions.event[39].endtime - $sessions.event[39].startTime + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidArgument: (:) [], RuntimeException + FullyQualifiedErrorId : InvalidCastFromStringToInteger&lt;/p>
&lt;/blockquote>
&lt;p>The value was stored as a string&lt;/p>
&lt;p>Running&lt;/p>
&lt;p>&lt;code>$Sessions.event[39].endtime |Get-Member&lt;/code>&lt;/p>
&lt;p>showed me that there was a method called ToDateTime but there is an easier way. By defining the datatype of an object PowerShell will convert it for you so the resulting code looks like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Sessions = $doc.GuidebookXML.events
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Speaker = @{Name=&amp;#34;Speaker&amp;#34;; Expression = {$_.speakers.speaker.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Room = @{Name=&amp;#34;Room&amp;#34;; Expression = {$_.location.name}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Duration = @{Name =&amp;#34;Duration&amp;#34;; Expression = {[datetime]($_.EndTime) - [datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$startTime = @{Name=&amp;#34;StartTime&amp;#34;; Expression = {[datetime]($_.StartTime)}}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Sessions.event|select $Speaker,$Room,$Starttime,$Duration,Title |Format-Table -AutoSize -Wrap
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and the resulting entry is finally as I required it. I believe that this will use the regional settings from the installation on the machine that you are using but I have not verified that. If anyone in a different region would like to run this code and check that that is the case I will update the post accordingly&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/03/zzcapture.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/03/zzcapture.jpg?w=300"
loading="lazy"
alt="zzCapture"
>&lt;/a>&lt;/p>
&lt;p>Hopefully you have learnt from this how you can extend select from the pipeline and how defining the datatype can be beneficial. Any questions please comment below&lt;/p></description></item><item><title>Speaking at PowerShell Virtual Chapter and SQL Cardiff User Group this month</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/speaking-at-powershell-virtual-chapter-and-sql-cardiff-user-group-this-month/</link><pubDate>Tue, 17 Mar 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/speaking-at-powershell-virtual-chapter-and-sql-cardiff-user-group-this-month/</guid><description>&lt;p>Just a quick post to say that I will be speaking at the PowerShell Virtual Chapter meeting this Thursday at 4pm GMT 12pm EDT and also at the Cardiff SQL User Group on Tuesday 31st March&lt;/p>
&lt;p>I will be giving my Making PowerShell Useful for your Team presentation&lt;/p>
&lt;p>You have heard about PowerShell and may be spent a little bit of time exploring some of the ways in which it will benefit you at work. You want to be able to perform tasks more specific to your organisation and need to share them with your team. I will show you how you can achieve this by demonstrating&lt;/p>
&lt;ul>
&lt;li>An easy way to learn the syntax&lt;/li>
&lt;li>How to explore SQL Server with PowerShell&lt;/li>
&lt;li>How to turn your one off scripts into shareable functions&lt;/li>
&lt;li>How to ensure that your team can easily and quickly make use of and contribute to PowerShell solutions&lt;/li>
&lt;li>Where else to go for help&lt;/li>
&lt;/ul>
&lt;p>You can find out more about the Virtual Chapter here&lt;/p>
&lt;p>&lt;a class="link" href="http://PowerShell.sqlpass.org/%c2%a0" title="http://PowerShell.sqlpass.org/ "
target="_blank" rel="noopener"
>http://PowerShell.sqlpass.org/&lt;/a> &lt;/p>
&lt;p>and the Cardiff meeting here&lt;/p>
&lt;p>&lt;a class="link" href="http://www.meetup.com/Cardiff-SQL-Server-User-Group/events/219492623/%c2%a0" title="http://www.meetup.com/Cardiff-SQL-Server-User-Group/events/219492623/ "
target="_blank" rel="noopener"
>http://www.meetup.com/Cardiff-SQL-Server-User-Group/events/219492623/&lt;/a> &lt;/p>
&lt;p>The Cardiff meeting has been named The Battle Of The Beards as it features Tobiasz Koprowski: talking about Windows Azure SQL Database - Tips and Tricks for beginners and Terry McCann with SSRS Inception. I will be giving the same presentation as at the Virtual Chapter&lt;/p>
&lt;p>I hope to see you at one or both sessions&lt;/p></description></item><item><title>Triggering a System Center Configuration Manager deployment task</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/triggering-a-system-center-configuration-manager-deployment-task/</link><pubDate>Wed, 18 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/triggering-a-system-center-configuration-manager-deployment-task/</guid><description>&lt;p>A slightly different topic today.&lt;/p>
&lt;p>Once you have built up knowledge, you become the person that people ask to solve things. This is something I really enjoy, taking a problem and solving it for people and in the process teaching them and enabling them to automate more things.&lt;/p>
&lt;p>A colleague was performing a new deployment of a product via SCCM and wanted to trigger the clients to update and receive the new update instead of waiting for it to be scheduled.&lt;/p>
&lt;p>They had found some code that would do this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>They had the idea of using this command and a text file containing the machines and PS Remote.&lt;/p>
&lt;p>I looked at it a different way and gave them a function so that they could provide the Collection Name (In SCCM a collection is a list of machines for a specific purpose) and the function would import the SCCM module, connect to the Site get the names of the machines in the collection and run the command on each one&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;span class="lnt">27
&lt;/span>&lt;span class="lnt">28
&lt;/span>&lt;span class="lnt">29
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Trigger-DeploymentCycle
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CollectionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># PS script to run
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## import SCCM module
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module (Join-Path $(Split-Path $env:SMS_ADMIN_UI_PATH) ConfigurationManager.psd1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#open drive for SCCM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cd &amp;lt;Site Code&amp;gt;:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#### cd &amp;lt;Site Code&amp;gt;:\ replace with Site Code or add param $SiteCOde and use cd ${$SiteCode}:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get Computer names in collection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PCs = (Get-CMDeviceCollectionDirectMembershipRule -CollectionName $CollectionName).rulename
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Count = $PCs.count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;Total number of PCs = $Count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-Command –ComputerName $PCs –ScriptBlock $scriptblock –ThrottleLimit 50
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>This would work very well but they wanted some error checking to enable them to identify machines they were unable to connect to following the deployment so the final solution which will run a little slower&lt;/p>
&lt;p>Set up function and parameters and create log files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">function Trigger-DeploymentCycle
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CollectionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create log file
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartTime = Get-Date
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Date = Get-Date -Format ddMMyyHHss
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Errorlogpath = &amp;#34;C:\temp\SCCMError&amp;#34; + $Date + &amp;#34;.txt&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Successlogpath = &amp;#34;C:\temp\SCCMSuccess&amp;#34; + $Date + &amp;#34;.txt&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path $Errorlogpath -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path $Successlogpath -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartLog = &amp;#34;Script Started at $StartTime&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StartLog | Out-File -FilePath $Successlogpath -Append
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Create the script block, import the SCCM module, connect to the SCCM site and get the machines in the collection. Note that you will have to change &lt;code>&amp;lt;Site Code&amp;gt;&lt;/code> with your own site code&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$scriptblock = {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000121}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000021}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000022}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Invoke-WMIMethod -Namespace root\ccm -Class SMS_CLIENT -Name TriggerSchedule &amp;#34;{00000000-0000-0000-0000-000000000002}&amp;#34;|Out-Null
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">## import SCCM module
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Import-Module (Join-Path $(Split-Path $env:SMS_ADMIN_UI_PATH) ConfigurationManager.psd1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#open drive for SCCM
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">cd &amp;lt;Site Code&amp;gt;:\ #### cd &amp;lt;Site Code&amp;gt;:\ replace with Site Code or add param $SiteCOde and use cd ${$SiteCode}:\
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get Computer names in collection
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$PCs = (Get-CMDeviceCollectionDirectMembershipRule -CollectionName $CollectionName).rulename
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Count = $PCs.count
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34;Total number of PCs = $Count&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I wanted to give them a progress output so I needed to be able to identify the number of machines in the collection by using the count property. I then needed to output the number of the item within the array which I did with&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$a= [array]::IndexOf($PCs, $PC) + 1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output &amp;#34; Connecting to PC - $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I then pinged the machine,ran the script block and wrote to the log files and finally opened the log files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if (Test-Connection $PC -Quiet -Count 1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Run command on PC
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Invoke-Command -ComputerName $PC -scriptblock $scriptblock
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Success = &amp;#34;SUCCESS - finished - $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Success | Out-File -FilePath $Successlogpath -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output $Success
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage = &amp;#34;ERROR - $PC is not available -- $PC -- $a of $count&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ErrorMessage| Out-File -FilePath $Errorlogpath -Append
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Write-Output $ErrorMessage
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad $Errorlogpath
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">notepad $Successlogpath
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now they can load the function into their PowerShell sessions and type&lt;/p>
&lt;p>&lt;code>TriggerDeplyment COLLECTIONNAME&lt;/code>&lt;/p>
&lt;p>and they will be able to manually trigger the tasks. This function will trigger the following tasks for a list of PCs in a collection.&lt;/p>
&lt;ul>
&lt;li>Machine Policy Assignment Request &amp;ndash; {00000000-0000-0000-0000-000000000021}&lt;/li>
&lt;li>Machine Policy Evaluation &amp;ndash; {00000000-0000-0000-0000-000000000022}&lt;/li>
&lt;li>Software Inventory &amp;ndash; {00000000-0000-0000-0000-000000000002}&lt;/li>
&lt;li>Application Deployment Evaluation Cycle: {00000000-0000-0000-0000-000000000121}&lt;/li>
&lt;/ul>
&lt;p>Here is the list of other tasks you can trigger:&lt;/p>
&lt;ul>
&lt;li>Discovery Data Collection Cycle: {00000000-0000-0000-0000-000000000003}&lt;/li>
&lt;li>Hardware Inventory Cycle: {00000000-0000-0000-0000-000000000001}&lt;/li>
&lt;li>Machine Policy Retrieval and Evaluation Cycle: {00000000-0000-0000-0000-000000000021}&lt;/li>
&lt;li>Software Metering Usage Report Cycle: {00000000-0000-0000-0000-000000000031}&lt;/li>
&lt;li>Software Updates Deployment Evaluation Cycle: {00000000-0000-0000-0000-000000000108}&lt;/li>
&lt;li>Software Updates Scan Cycle: {00000000-0000-0000-0000-000000000113}&lt;/li>
&lt;li>Windows Installer Source List Update Cycle: {00000000-0000-0000-0000-000000000032}&lt;/li>
&lt;li>Hardware Inventory={00000000-0000-0000-0000-000000000001}&lt;/li>
&lt;li>Software Update Scan={00000000-0000-0000-0000-000000000113}&lt;/li>
&lt;li>Software Update Deployment Re-eval={00000000-0000-0000-0000-000000000114}&lt;/li>
&lt;li>Data Discovery={00000000-0000-0000-0000-000000000003}&lt;/li>
&lt;li>Refresh Default Management Point={00000000-0000-0000-0000-000000000023}&lt;/li>
&lt;li>Refresh Location (AD site or Subnet)={00000000-0000-0000-0000-000000000024}&lt;/li>
&lt;li>Software Metering Usage Reporting={00000000-0000-0000-0000-000000000031}&lt;/li>
&lt;li>Sourcelist Update Cycle={00000000-0000-0000-0000-000000000032}&lt;/li>
&lt;li>Cleanup policy={00000000-0000-0000-0000-000000000040}&lt;/li>
&lt;li>Validate assignments={00000000-0000-0000-0000-000000000042}&lt;/li>
&lt;li>Certificate Maintenance={00000000-0000-0000-0000-000000000051}&lt;/li>
&lt;li>Branch DP Scheduled Maintenance={00000000-0000-0000-0000-000000000061}&lt;/li>
&lt;li>Branch DP Provisioning Status Reporting={00000000-0000-0000-0000-000000000062}&lt;/li>
&lt;li>Refresh proxy management point={00000000-0000-0000-0000-000000000037}&lt;/li>
&lt;li>Software Update Deployment={00000000-0000-0000-0000-000000000108}&lt;/li>
&lt;li>State Message Upload={00000000-0000-0000-0000-000000000111}&lt;/li>
&lt;li>State Message Cache Cleanup={00000000-0000-0000-0000-000000000112}&lt;/li>
&lt;/ul>
&lt;p>You can find the function here&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Trigger-DeploymentCycle-c27f7b9d?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Trigger-Deployment&lt;/a>&lt;/p>
&lt;p>and all of &lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/site/search?f%5B0%5D.Type=User&amp;amp;f%5B0%5D.Value=Rob%20Sewell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>my Script Center Submissions&lt;/a> are here&lt;/p>
&lt;p>As always – The internet lies, fibs and deceives and everything you read including this post should be taken with a pinch of salt and examined carefully. All code should be understood and tested prior to running in a live environment.&lt;/p></description></item><item><title>Show AutoGrowth Events with PowerShell to CSV</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-autogrowth-events-with-powershell-to-csv/</link><pubDate>Sun, 15 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-autogrowth-events-with-powershell-to-csv/</guid><description>&lt;p>This week I was reading Pinal Daves post about Autogrowth Events&lt;/p>
&lt;p>&lt;a class="link" href="http://blog.sqlauthority.com/2015/02/03/sql-server-script-whenwho-did-auto-grow-for-the-database/" target="_blank" rel="noopener"
>http://blog.sqlauthority.com/2015/02/03/sql-server-script-whenwho-did-auto-grow-for-the-database/&lt;/a>&lt;/p>
&lt;p>as it happened I had a requirement to make use of the script only a few days later. I was asked to provide the information in a CSV so that the person who required the information could manipulate it in Excel.&lt;/p>
&lt;p>I am a great believer in Automation. If you are going to do something more than once then automate it so I wrote two functions, added them to TFS and now they will be available to all of my team members next time they load PowerShell.&lt;/p>
&lt;p>Why two functions? Well Pinal Daves script gets the information from the default trace for a single database but there may be times when you need to know the autogrowth events that happened on a server with multiple databases.&lt;/p>
&lt;p>I use a very simple method for doing this as I have not found the correct way to parse the default trace with PowerShell. The functions rely on &lt;a class="link" href="https://github.com/RamblingCookieMonster/PowerShell/blob/master/Invoke-Sqlcmd2.ps1" target="_blank" rel="noopener"
>Invoke-SQLCMD2&lt;/a> which I also have in my functions folder and pass the query from Pinal Daves Blog post as a here string&lt;/p>
&lt;p>&lt;code>$Results = Invoke-Sqlcmd2 -ServerInstance $Server -Database master -Query $Query&lt;/code>&lt;/p>
&lt;p>To output to CSV I use the &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh849932.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Export-CSV cmdlet&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">if($CSV)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">{
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Results| Export-Csv -Path $CSV
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>And to open the CSV I add a &lt;code>[switch]&lt;/code> parameter. You can find out more about parameters &lt;a class="link" href="https://technet.microsoft.com/en-us/library/hh847743.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a> or by&lt;/p>
&lt;p>&lt;code>Get-Help about_Functions_Advanced_Parameters&lt;/code>&lt;/p>
&lt;p>so the parameter block of my function looks like&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">param
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">(
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$Server,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$true)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$Database,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$false)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[string]$CSV,
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[Parameter(Mandatory=$false)]
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[switch]$ShowCSV
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now when I am asked again to provide this information it is as easy as typing&lt;/p>
&lt;p>&lt;code>Show-AutogrowthServer -Server SQL2014Ser12R2&lt;/code>&lt;/p>
&lt;p>or&lt;/p>
&lt;p>&lt;code>Show-AutogrowthDatabase -Server SQL2014Ser12R2 -Database Autogrowth&lt;/code>&lt;/p>
&lt;p>and the results will be displayed as below&lt;/p>
&lt;p>&lt;a class="link" href="https://sqldbawithabeard.com/wp-content/uploads/2015/02/autogrowth.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sqldbawithabeard.com/wp-content/uploads/2015/02/autogrowth.jpg?w=660"
loading="lazy"
alt="autogrowth"
>&lt;/a>&lt;/p>
&lt;p>just a side note. Pinal Daves script uses @@servername in the where clause and if you have renamed your host the script will be blank. The resolution to this is to runt he following T-SQL&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">sp_dropserver &amp;#39;OLDSERVERNAME&amp;#39;;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">sp_addserver NEWSERVERNAME, local;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">GO
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can find the scripts here&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Show-Autogrowth-Events-for-8798a8b0?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Show-AutoGrowthServer&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Show-Autogrowth-Events-and-f4833cc8?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Show-AutoGrowthDatabase&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/site/search?f%5B0%5D.Type=User&amp;amp;f%5B0%5D.Value=Rob%20Sewell?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>and all of my Script Center Submissions are here&lt;/a>&lt;/p>
&lt;p>As always - The internet lies, fibs and deceives and everything you read including this post  should be taken with a pinch of salt and examined carefully. All code should be understood and tested prior to running in a live environment.&lt;/p></description></item><item><title>Uploading a Source Folder to Azure File Storage</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</link><pubDate>Sun, 01 Feb 2015 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/uploading-a-source-folder-to-azure-file-storage/</guid><description>&lt;p>Azure File Storage enables you to present an Azure Storage Account to your IaaS VMs as a share using SMB. You can fid out further details here&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/%c2%a0" title="http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/ "
target="_blank" rel="noopener"
>http://azure.microsoft.com/en-gb/documentation/articles/storage-dotnet-how-to-use-files/&lt;/a> &lt;/p>
&lt;p>Once you have created your Azure File Storage Account and connected your Azure Virtual Machines to it, you may need to upload data from your premises into the storage to enable it to be accessed by the Virtual Machines&lt;/p>
&lt;p>To accomplish this I wrote a function and called it Upload-ToAzureFileStorage&lt;/p>
&lt;p>I started by creating a source folder and files to test&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;span class="lnt">11
&lt;/span>&lt;span class="lnt">12
&lt;/span>&lt;span class="lnt">13
&lt;/span>&lt;span class="lnt">14
&lt;/span>&lt;span class="lnt">15
&lt;/span>&lt;span class="lnt">16
&lt;/span>&lt;span class="lnt">17
&lt;/span>&lt;span class="lnt">18
&lt;/span>&lt;span class="lnt">19
&lt;/span>&lt;span class="lnt">20
&lt;/span>&lt;span class="lnt">21
&lt;/span>&lt;span class="lnt">22
&lt;/span>&lt;span class="lnt">23
&lt;/span>&lt;span class="lnt">24
&lt;/span>&lt;span class="lnt">25
&lt;/span>&lt;span class="lnt">26
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\b -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\c -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\d -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4 -ItemType Directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New5\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\1\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\2\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\3\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">New-Item -Path C:\\temp\\TestUpload\\New1\\list\\a\\4\\file.txt -ItemType File
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Then we needed to connect to the subscription, get the storage account access key and create a context to store them&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;span class="lnt">6
&lt;/span>&lt;span class="lnt">7
&lt;/span>&lt;span class="lnt">8
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#Select Azure Subscription
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Select-AzureSubscription -SubscriptionName $AzureSubscriptionName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get the Storage Account Key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$StorageAccountKey = (Get-AzureStorageKey -StorageAccountName $StorageAccountName).Primary
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># create a context for account and key
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ctx=New-AzureStorageContext $StorageAccountName $StorageAccountKey
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>The &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806403.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Get-AzureStorageShare  cmdlet&lt;/a> shows the shares available for the context so we can check if the share exists&lt;/p>
&lt;p>&lt;code>$S = Get-AzureStorageShare -Context $ctx -ErrorAction SilentlyContinue|Where-Object {$\_.Name -eq $AzureShare}&lt;/code>&lt;/p>
&lt;p>and if it doesnt exist create it using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806378.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageShare&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$s = New-AzureStorageShare $AzureShare -Context $ctx
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>For the sake only of doing it a different way we can check for existence of the directory in Azure File Storage that we are going to upload the files to like this&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = Get-AzureStorageFile -Share $s -ErrorAction SilentlyContinue|select Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">if ($d.Name -notcontains $AzureDirectory)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and if it doesnt exist create it using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$d = New-AzureStorageDirectory -Share $s -Path $AzureDirectory
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>Now that we have the directory created in the storage account we need to create any subfolders. First get the folders&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">\# get all the folders in the source directory
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Folders = Get-ChildItem -Path $Source -Directory -Recurse
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>We can then iterate through them using a foreach loop. If we do this and select the FullName property the results will be&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">C:\\temp\\TestUpload\\New1 C:\\temp\\TestUpload\\New2 C:\\temp\\TestUpload\\New3 C:\\temp\\TestUpload\\New4 C:\\temp\\TestUpload\\New5 C:\\temp\\TestUpload\\New1\\list C:\\temp\\TestUpload\\New1\\list\\a C:\\temp\\TestUpload\\New1\\list\\b C:\\temp\\TestUpload\\New1\\list\\c C:\\temp\\TestUpload\\New1\\list\\d C:\\temp\\TestUpload\\New1\\list\\a\\1 C:\\temp\\TestUpload\\New1\\list\\a\\2 C:\\temp\\TestUpload\\New1\\list\\a\\3 C:\\temp\\TestUpload\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>but to create new folders we need to remove the &lt;code>&amp;quot;C:\\temp\\TestUpload&amp;quot;&lt;/code> and replace it with the Directory name in Azure. I chose to do this as follows using the substring method and the length of the source folder path.&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">foreach($Folder in $Folders)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($Folder.FullName).Substring(($source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and tested that the results came out as I wanted&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">AppName\\New1 AppName\\New2 AppName\\New3 AppName\\New4 AppName\\New5 AppName\\New1\\list AppName\\New1\\list\\a AppName\\New1\\list\\b AppName\\New1\\list\\c AppName\\New1\\list\\d AppName\\New1\\list\\a\\1 AppName\\New1\\list\\a\\2 AppName\\New1\\list\\a\\3 AppName\\New1\\list\\a\\4
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I could then create the new folders in azure using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806385.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>New-AzureStorageDirectory&lt;/a> again&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">New-AzureStorageDirectory -Share $s -Path $Path -ErrorAction SilentlyContinue
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>I followed the same process with the files&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;span class="lnt">5
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$files = Get-ChildItem -Path $Source -Recurse -File&amp;lt;/pre&amp;gt;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&amp;lt;pre&amp;gt;foreach($File in $Files)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $f = ($file.FullName).Substring(($Source.Length))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Path = $AzureDirectory + $f
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>and then created the files using &lt;a class="link" href="https://msdn.microsoft.com/en-us/library/dn806404.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Set-AzureStorageFileContent&lt;/a> this has a -Force and a -Confirm switch and I added those into my function by using a [switch] Parameter&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt">10
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#upload the files to the storage
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if($Confirm)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Confirm
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Set-AzureStorageFileContent -Share $s -Source $File.FullName -Path $Path -Force
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You can download the function from the Script Center&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>https://gallery.technet.microsoft.com/scriptcenter/Recursively-upload-a-bfb615fe&lt;/a>&lt;/p>
&lt;p>As also, any comments or queries are welcome and obviously the internet lies so please understand and test all code you find before using it in production&lt;/p></description></item><item><title>Twas 2 Days Before Xmas or Thank you SQLFamily</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/twas-2-days-before-xmas-or-thank-you-sqlfamily/</link><pubDate>Tue, 23 Dec 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/twas-2-days-before-xmas-or-thank-you-sqlfamily/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/12/beard.png" alt="Featured image of post Twas 2 Days Before Xmas or Thank you SQLFamily" />&lt;p>Twas 2 days before Xmas &amp;amp; all through the office,&lt;br>
not a creature was stirring not even old Maurice.&lt;br>
With merriment going on outside of his window&lt;br>
There sat a bearded DBA without much to do&lt;/p>
&lt;p>No changes can be made through the holiday season&lt;br>
We’re on skeleton support, which is a good reason&lt;br>
Ensure you are making the most of your time&lt;br>
You mustn’t be wasting the company dime&lt;/p>
&lt;p>The backups are checked, there isn’t an issue&lt;br>
So documentation writing should ensue&lt;br>
Instead he decided to procrastinate&lt;br>
And so, this little ditty he proceeded to create&lt;/p>
&lt;p>Looking back over last year he did ruminate&lt;br>
About all the progress he had made, it was great&lt;br>
So much had been learned, so many improvements&lt;br>
Derived using content from fine ladies and gents&lt;/p>
&lt;p>Impossible to estimate how much it would cost&lt;br>
Or calculate the amount of revenue lost&lt;br>
For all that he would have been unable to do&lt;br>
Or the times that he knew how to get out of a stew&lt;/p>
&lt;p>But also the friends old, new and the rest&lt;br>
The talking and dining and drinking and jest&lt;br>
I am lucky to be a part of the SQL Family&lt;br>
So thank you one and all, with love from me&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/12/beard.png?ssl=1" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/12/beard.png?resize=387%2C550&amp;amp;ssl=1"
loading="lazy"
alt="beard"
>&lt;/a>&lt;/p></description></item><item><title>Giving Back – #TSQL2sday</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/giving-back-#tsql2sday/</link><pubDate>Tue, 09 Dec 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/giving-back-#tsql2sday/</guid><description>&lt;!-- raw HTML omitted --></description></item><item><title>Making a Change Log Easier With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/making-a-change-log-easier-with-powershell/</link><pubDate>Mon, 08 Dec 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/making-a-change-log-easier-with-powershell/</guid><description>&lt;p>Having a Change Log is a good thing. A quick and simple place to find out what has changed on a server and when. This can be invaluable when troubleshooting, matching a change to a symptom especially when assessed alongside your performance counter collection. Here is a simple way to make use of a change log and automate it&lt;/p>
&lt;p>Create a simple table&lt;/p>
&lt;pre>&lt;code>USE [MDW]
GO
CREATE TABLE [dbo].[ChangeLog](
[ChangeID] [int] IDENTITY(1,1) PRIMARY KEY ,
[Date] [datetime] NOT NULL,
[Server] [varchar](50) NOT NULL,
[UserName] [nvarchar](50) NOT NULL,
[Change] [nvarchar](max) NOT NULL,
)
GO
&lt;/code>&lt;/pre>
&lt;p>You can keep this on a central server or create a database on each server, whichever fits your needs best. You can add other columns if you want your information in a different format&lt;/p>
&lt;p>Once you have your table you can create a couple of Powershell functions to easily and quickly add to and retrieve data from the table. I make use of &lt;a class="link" href="https://github.com/RamblingCookieMonster/PowerShell/blob/master/Invoke-Sqlcmd2.ps1" target="_blank" rel="noopener"
>Invoke-SQLCMD2&lt;/a> in these functions&lt;/p>
&lt;p>This can then be included in any automation tasks that you use to update your environments whether you are using automated deployment methods for releases or using SCCM to patch your environments making it easy to update and also easy to automate by making it part of your usual deployment process.&lt;/p>
&lt;p>To add a new change&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.Synopsis
A function to add a ChangeLog information
.DESCRIPTION
Load function for adding a change to the changelog table in the MDW database on MDWSERVER.
Use Get-ChangeLog $Server to see details
Inputs the username of the account running powershell into the database as the user
REQUIRES Invoke-SQLCMD2
https://blog.robsewell.com
.EXAMPLE
Add-ChangeLog SERVERNAME &amp;quot;Altered AutoGrowth Settings for TempDB to None&amp;quot;
Adds ServerName UserName and Altered AutoGrowth Settings for TempDB to None to the change log table
#&amp;gt;
Function Add-ChangeLog
{
[CmdletBinding()]
Param(
[Parameter(Mandatory=$True)]
[string]$Server,
[Parameter(Mandatory=$True)]
[string]$Change
)
$UserName = $env:USERDOMAIN + '\' + $env:USERNAME
$Query = &amp;quot;INSERT INTO [dbo].[ChangeLog]
([Date]
,[Server]
,[UserName]
,[Change])
VALUES
(GetDate()
,'$Server'
,'$UserName'
,'$Change')
&amp;quot;
Invoke-Sqlcmd2 -ServerInstance MDWSERVER -Database &amp;quot;MDW&amp;quot; -Query $Query -Verbose
}
&lt;/code>&lt;/pre>
&lt;p>You can then run&lt;/p>
&lt;pre>&lt;code>Add-ChangeLog SERVERNAME &amp;quot;Added New Database SuperAppData&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>to add the change to the change log&lt;/p>
&lt;p>To retrieve the data you can use&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.Synopsis
A function to get ChangeLog information
.DESCRIPTION
Load function for finding ChangeLog information. Information is selected from the MDW Database on SERVERNAME
REQUIRES Invooke-SQLCMD2
https://blog.robsewell.com
.EXAMPLE
Get-ChangeLog SERVERNAME
#&amp;gt;
Function Get-ChangeLog
{
[CmdletBinding()]
[OutputType([int])]
Param
(
# Server Name Required
[Parameter(Mandatory=$true,]
$Server
)
$a = @{Expression={$_.Date};Label=&amp;quot;Date&amp;quot;;width=15}, `
@{Expression={$_.Server};Label=&amp;quot;Server&amp;quot;;width=10},
@{Expression={$_.UserName};Label=&amp;quot;UserName&amp;quot;;width=20}, `
@{Expression={$_.Change};Label=&amp;quot;Change&amp;quot;;width=18}
Invoke-Sqlcmd2 -ServerInstance MDWSERVER -Database &amp;quot;MDW&amp;quot; -Query &amp;quot;SELECT * FROM dbo.ChangeLog WHERE Server = '$Server';&amp;quot; -Verbose|Format-table $a -Auto -Wrap
}
&lt;/code>&lt;/pre>
&lt;p>and use&lt;/p>
&lt;pre>&lt;code>Get-ChangeLog SERVERNAME
&lt;/code>&lt;/pre>
&lt;p>To find out what changed when. Happy Automating&lt;/p></description></item><item><title>A look at the SQL Assessment Intelligence Pack in Operational Insights</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-look-at-the-sql-assessment-intelligence-pack-in-operational-insights/</link><pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/a-look-at-the-sql-assessment-intelligence-pack-in-operational-insights/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/11/opsman1.jpg" alt="Featured image of post A look at the SQL Assessment Intelligence Pack in Operational Insights" />&lt;p>Operational Insights is a service that has been added in preview to Azure. It enables you to collect, combine, correlate and visualize all your machine data in one place. It can collect data from all of your machines either via SCOM or by using an agent. Once the data is collected Operational Insights has a number of Intelligence Packs which have pre-configured rules and algorithms to provide analysis in various areas including for SQL Server&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-gb/services/operational-insights/" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-gb/services/operational-insights/&lt;/a>&lt;/p>
&lt;p>I thought I would take a look. I have an installation of SCOM in my lab on my laptop and I read the instructions to see how to connect it to Operational Insights. (You don’t have to have a SCOM installation to use Operational insights you can make use of an agent as well just follow the steps from the page below)&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-us/trial/operational-insights-get-started/" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-us/trial/operational-insights-get-started/&lt;/a>&lt;/p>
&lt;p>It really is very simple&lt;/p>
&lt;p>If you have an Azure subscription already you can sign into the portal and join the preview program by clicking&lt;/p>
&lt;p>New –&amp;gt; App Services –&amp;gt; Operational Insights&lt;/p>
&lt;p>and create a new Operational Insights Workspace.&lt;/p>
&lt;p>Once you have done that, if you have an installation of SCOM 2012 you need to be running Service Pack 1 and download and install the System Center Operational Insights Connector for Operations Manager and import the MPB files into SCOM.&lt;/p>
&lt;p>If you have SCOM 2012R2 the connector is already installed and to connect your SCOM to Operational Insights is very very easy as you can see on&lt;/p>
&lt;p>&lt;a class="link" href="http://azure.microsoft.com/en-us/trial/operational-insights-get-started/?step2=withaccount&amp;amp;step3=SCOMcustomer" target="_blank" rel="noopener"
>http://azure.microsoft.com/en-us/trial/operational-insights-get-started/?step2=withaccount&amp;amp;step3=SCOMcustomer&lt;/a>&lt;/p>
&lt;ol>
&lt;li>In the Operations Manager Console, click Administration.&lt;/li>
&lt;li>Under Administration, select System Center Advisor, and then click Advisor Connection.&lt;/li>
&lt;li>Click Register to Advisor Service.&lt;/li>
&lt;li>Sign in with your Microsoft or Organizational account.&lt;/li>
&lt;li>Choose an existing Operational Insights workspace from the drop down menu&lt;/li>
&lt;li>Confirm your changes.&lt;/li>
&lt;li>In the System Center Advisor Overview page, Under Actions, click Add a Computer/Group.&lt;/li>
&lt;li>Under Options, select Windows Server or All Instance Groups, and then search and add servers that you want data&lt;/li>
&lt;/ol>
&lt;p>That is it. No really, that is it. I was amazed how quickly I was able to get this done in my lab and it would not take very long in a large implementation of SCOM either as you will have your groups of computers defined which will make it easy to decide which groups to use. You could use a separate workspace for each type of server or split up the information per service. It really is very customisable.&lt;/p>
&lt;p>Once you have done that, go and add some of the Intelligence Packs. Each intelligence pack will change the amount  and type of data that is collected. At November 23rd there are&lt;/p>
&lt;ul>
&lt;li>Alert Management – for your SCOM Alerts&lt;/li>
&lt;li>Change Tracking – Tracking Configuration Changes&lt;/li>
&lt;li>Log Management – for event log collection and interrogation&lt;/li>
&lt;li>System Update Assessment – Missing Security Updates&lt;/li>
&lt;li>Malware Assessment – Status of Anti-Malware and Anti-Virus scans&lt;/li>
&lt;li>Capacity Planning – Identify Capacity and Utilisation bottlenecks&lt;/li>
&lt;li>SQL Assessment – The risk and health of SQL Server Environment&lt;/li>
&lt;/ul>
&lt;p>There are also two ‘coming soon’ Intelligence packs&lt;/p>
&lt;ul>
&lt;li>AD Assessment – Risk and health of Active Directory&lt;/li>
&lt;li>Security – Explore security related data and help identify security breaches&lt;/li>
&lt;/ul>
&lt;p>You then (if you are like me) have a period of frustration whilst you wait for all of the data to be uploaded and aggregated but once it is you sign into the Operational Insights Portal&lt;/p>
&lt;p>&lt;a class="link" href="https://preview.opinsights.azure.com" target="_blank" rel="noopener"
>https://preview.opinsights.azure.com&lt;/a> and it will look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman1.jpg"
loading="lazy"
alt="opsman1"
>&lt;/a>&lt;/p>
&lt;p>There is a lot of information there. As it is on my laptop and the lab is not running all of the time and is not connected to the internet most of the time I am not surprised that there are some red parts to my assessment!!&lt;/p>
&lt;p>Obviously I was interested in the SQL Assessment and I explored it a bit further&lt;/p>
&lt;p>Clicking on the SQL Assessment tile takes you to a screen which shows the SQL Assessment broken down into 6 Focus areas&lt;/p>
&lt;p>Security and Compliance, Availability and Business Continuity, Performance and Scalability, Upgrade, Migration and  Deployment, Operations and Monitoring and Change and Configuration Management. MSDN &lt;a class="link" href="http://msdn.microsoft.com/en-us/library/azure/dn873967.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/en-us/library/azure/dn873967.aspx&lt;/a> gives some more information about each one&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Security and Compliance&lt;/strong> – Safeguard the reputation of your organization by defending yourself from security threats and breaches, enforcing corporate policies, and meeting - technical, legal and regulatory compliance requirements.&lt;/li>
&lt;li>&lt;strong>Availability and Business Continuity&lt;/strong> – Keep your services available and your business profitable by ensuring the resiliency of your infrastructure and by having the right - level of business protection in the event of a disaster.&lt;/li>
&lt;li>&lt;strong>Performance and Scalability&lt;/strong> – Help your organization to grow and innovate by ensuring that your IT environment can meet current performance requirements and can respond - quickly to changing business needs.&lt;/li>
&lt;li>&lt;strong>Upgrade, Migration and Deployment&lt;/strong> – Position your IT department to be the key driver of change and innovation, by taking full advantage of new enabling technologies to - unlock more business value for organizational units, workforce and customers.&lt;/li>
&lt;li>&lt;strong>Operations and Monitoring&lt;/strong> – Lower your IT maintenance budget by streamlining your IT operations and implementing a comprehensive preventative maintenance program to - maximize business performance.&lt;/li>
&lt;li>&lt;strong>Change and Configuration Management&lt;/strong> – Protect the day-to-day operations of your organization and ensure that changes won’t negatively affect the business by establishing change control procedures and by tracking and auditing system configurations.&lt;/li>
&lt;/ul>
&lt;p>You will be able to see some dials showing you how well you are doing in each area for the servers whose data has been collected.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman2.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman2.jpg"
loading="lazy"
alt="opsman2"
>&lt;/a>&lt;/p>
&lt;p>Each area will have the High Priority Recommendations shown below the dial and you can click on them to see more information about those recommendations&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman3.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman3.jpg"
loading="lazy"
alt="opsman3"
>&lt;/a>&lt;/p>
&lt;p>You can also click the dial or the see all link to enter the search area where you can customise how you wish to see the data that has been collected, this looks a bit confusing at first&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/opsman4.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/opsman4.jpg"
loading="lazy"
alt="opsman4"
>&lt;/a>&lt;/p>
&lt;p>The top bar contains the search , the timescale and some buttons to save the search, view the saved searches and view the search history, all of which will be shown in the right hand column below&lt;/p>
&lt;p>The left column contains a bar graph for the search and all of the filters. The middle column contains the results of the search and can be viewed in list or tabular format and exported to CSV using the button below. A little bit of experimentation will give you a better understanding of how the filtering works and how you can make use of that for your environment&lt;/p>
&lt;p>By looking at the search for the Operations and Monitoring Focus Area shown above&lt;/p>
&lt;blockquote>
&lt;p>Type:SQLAssessmentRecommendation IsRollup=true RecommendationPeriod=2014-11 FocusArea=”Operations and Monitoring” RecommendationResult=Failed | sort RecommendationWeight desc&lt;/p>
&lt;/blockquote>
&lt;p>I saw that &lt;code>RecommendationResult=Failed&lt;/code> and changed it to &lt;code>RecommendationResult=Passed&lt;/code>. This enabled me to see all of the Recommendations that had been passed in the Focus Area and clicking the export button downloaded a csv file. I deleted &lt;code>RecommendationResult=Passed&lt;/code> from the search and that gave me all of the recommendations that made up that Focus Area&lt;/p>
&lt;ul>
&lt;li>Operations and Monitoring Focus Area&lt;/li>
&lt;li>Recommendation&lt;/li>
&lt;li>Enable Remote Desktop on servers.&lt;/li>
&lt;li>Enable Remote Desktop on virtual machines.&lt;/li>
&lt;li>Ensure computers are able to download updates.&lt;/li>
&lt;li>Configure event logs to overwrite or archive old events automatically.&lt;/li>
&lt;li>Review event log configuration to ensure event data is retained automatically. This relates to System Logs&lt;/li>
&lt;li>Review event log configuration to ensure event data is retained automatically. This relates to Application Logs&lt;/li>
&lt;/ul>
&lt;p>I decided then to do the same for each of the Focus Areas for the SQL Assessment Intelligence Pack&lt;/p>
&lt;p>Security and Compliance Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Change passwords that are the same as the login name.&lt;/li>
&lt;li>Remove logins with blank passwords.&lt;/li>
&lt;li>LAN Manager Hash for Passwords Stored&lt;/li>
&lt;li>Investigate why unsigned kernel modules were loaded.&lt;/li>
&lt;li>Apply security best practices to contained databases.&lt;/li>
&lt;li>Enable User Account control on all computers.&lt;/li>
&lt;li>Consider disabling the xp_cmdshell extended stored procedure.&lt;/li>
&lt;li>Implement Windows authentication on Microsoft Azure-hosted SQL Server deployments.&lt;/li>
&lt;li>Avoid using the Local System account to run the SQL Server service.&lt;/li>
&lt;li>Avoid adding users to the db_owner database role.&lt;/li>
&lt;li>Ensure only essential users are added to the SQL Server sysadmin server role.&lt;/li>
&lt;li>Disable SQL Server guest user in all user databases.&lt;/li>
&lt;li>Avoid running SQL Server Agent jobs using highly-privileged accounts.&lt;/li>
&lt;li>Configure the SQL Server Agent service to use a recommended account.&lt;/li>
&lt;li>Apply Windows password policies to SQL Server logins.&lt;/li>
&lt;li>Investigate failures to validate the integrity of protected files.&lt;/li>
&lt;li>Investigate failures to validate kernel modules.&lt;/li>
&lt;/ul>
&lt;p>Availability and Business Continuity Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Schedule full database backups at least weekly.&lt;/li>
&lt;li>Optimize your backup strategy with Microsoft Azure Blob Storage.&lt;/li>
&lt;li>Avoid using the Simple database recovery model.&lt;/li>
&lt;li>Ensure all installations of Windows are activated.&lt;/li>
&lt;li>Investigate logical disk errors.&lt;/li>
&lt;li>Reduce the maximum Kerberos access token size.&lt;/li>
&lt;li>Investigate connection failures due to SSPI context errors.&lt;/li>
&lt;li>Set the PAGE_VERIFY database option to CHECKSUM.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate a write error on a disk.&lt;/li>
&lt;li>Check the network access to Active Directory domain controllers.&lt;/li>
&lt;li>Review DNS configuration on non-DNS servers.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate memory dumps.&lt;/li>
&lt;li>Increase free space on system drives.&lt;/li>
&lt;li>Investigate why the computer shut down unexpectedly.&lt;/li>
&lt;li>Enable dynamic DNS registration for domain-joined servers.&lt;/li>
&lt;/ul>
&lt;p>Performance and Scalability Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Increase the number of tempdb database files.&lt;/li>
&lt;li>Configure the tempdb database to reduce page allocation contention.&lt;/li>
&lt;li>Ensure all tempdb database files have identical initial sizes and growth increments.&lt;/li>
&lt;li>Set autogrowth increments for database files and log files to fixed values rather than percentage values.&lt;/li>
&lt;li>Set autogrowth increments for transaction log files to less than 1GB.&lt;/li>
&lt;li>Modify auto-grow settings to use a fixed size growth increment of less than 1GB and consider enabling Instant File Initialization.&lt;/li>
&lt;li>Change your Affinity Mask and Affinity I/O MASK settings to prevent conflicts.&lt;/li>
&lt;li>Resolve issues caused by excessive virtual log files.&lt;/li>
&lt;li>Modify the database file layout for databases larger than 1TB.&lt;/li>
&lt;li>Set the AUTO_CLOSE option to OFF for frequently accessed databases.&lt;/li>
&lt;li>Review memory requirements on servers with less than 4GB of physical memory installed.&lt;/li>
&lt;li>Configure system SiteName properties to be dynamic.&lt;/li>
&lt;li>Align the Max Degree of Parallelism option to the number of logical processors.&lt;/li>
&lt;li>Align the Max Degree of Parallelism option to the number of logical processors.&lt;/li>
&lt;li>Consider disabling the AUTO_SHRINK database option.&lt;/li>
&lt;li>Review memory requirements on computers with high paging file use.&lt;/li>
&lt;li>Ensure SQL Server does not consume memory required by other applications and system components.&lt;/li>
&lt;li>Consider changing your power saving settings to optimize performance.&lt;/li>
&lt;li>Increase the initial size of the tempdb database.&lt;/li>
&lt;li>Review the configuration of Maximum Transfer Unit (MTU) size.&lt;/li>
&lt;li>Review your paging file settings.&lt;/li>
&lt;li>Review and optimize memory cache configuration.&lt;/li>
&lt;li>Review the configuration of Maximum Transfer Unit (MTU) size.&lt;/li>
&lt;li>Review the system processor scheduling mode.&lt;/li>
&lt;li>Review network provider ordering settings.&lt;/li>
&lt;li>Remove invalid entries from the PATH environment variable.&lt;/li>
&lt;li>Remove network entries from the PATH environment variable.&lt;/li>
&lt;li>Investigate processes that use a large number of threads.&lt;/li>
&lt;li>Avoid hosting user database files on the same disk volume as tempdb database files.&lt;/li>
&lt;li>Review processes with large working set sizes.&lt;/li>
&lt;li>Reduce the length of the PATH environment variable.&lt;/li>
&lt;li>Reduce the number of entries in the PATH environment variable.&lt;/li>
&lt;li>Ensure SQL Server does not consume memory required by other applications and system components.&lt;/li>
&lt;li>Enable the backup compression default configuration option.&lt;/li>
&lt;li>Ensure the DNS Client service is running and is set to start automatically.&lt;/li>
&lt;li>Consider compressing database tables and indexes.&lt;/li>
&lt;/ul>
&lt;p>Upgrade, Migration and Deployment Focus Area&lt;br>
Recommendation&lt;/p>
&lt;ul>
&lt;li>Ensure all devices run supported operating system versions.&lt;/li>
&lt;li>Ensure that the guest user is enabled in the msdb database.&lt;/li>
&lt;li>Avoid using the Affinity64 Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Affinity Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Affinity I/O Mask configuration setting in new development work.&lt;/li>
&lt;li>Avoid using the Allow Updates configuration option in SQL Server.&lt;/li>
&lt;li>Avoid using the Allow Updates configuration option in SQL Server.&lt;/li>
&lt;li>Avoid using the Affinity64 I/O Mask configuration setting in new development work.&lt;/li>
&lt;li>Configure SQL Server to accept incoming connections.&lt;/li>
&lt;li>Configure SQL Server instances and firewalls to allow communication over TCP/IP.&lt;/li>
&lt;/ul>
&lt;p>As I have no data for Change and Configuration Management I was not able to see the recommendations in my Operation Insights Workspace.&lt;/p>
&lt;p>Edit: Daniele Muscetta has said in the comments that this is a bug which is being tracked&lt;/p>
&lt;p>As you can see from the type and description of the recommendations above these are all areas that a DBA will be concerned about and the benefit of having all of this information gathered, pre-sorted, prioritised and presented to you in this manner will enable you to work towards a better SQL environment and track your progress. You can read more about the SQL Assessment Intelligence Pack here&lt;/p>
&lt;p>&lt;a class="link" href="http://msdn.microsoft.com/en-us/library/azure/dn873958.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/en-us/library/azure/dn873958.aspx&lt;/a>&lt;/p>
&lt;p>As well as the pre-determined queries that are built into the Intelligence pack you can search your data in any way that you require enabling you to present information about the health and risk of your SQL Environment to your team or your management with ease. The “with ease” bit is dependent on you understanding the language and structure of the search queries.&lt;/p>
&lt;p>You will need to put this page into your bookmarks&lt;/p>
&lt;p>&lt;a class="link" href="http://msdn.microsoft.com/library/azure/dn873997.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://msdn.microsoft.com/library/azure/dn873997.aspx&lt;/a>&lt;/p>
&lt;p>As it contains the syntax and definitions to search your data&lt;/p>
&lt;p>A very useful page for a starter like me is&lt;/p>
&lt;p>&lt;a class="link" href="http://blogs.msdn.com/b/dmuscett/archive/2014/10/19/advisor-searches-collection.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>http://blogs.msdn.com/b/dmuscett/archive/2014/10/19/advisor-searches-collection.aspx&lt;/a>&lt;/p>
&lt;p>by Daniele Muscetta which has a list of useful Operational Insights search queries such as&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>SQL Recommendation by Computer&lt;/strong>&lt;/p>
&lt;p>Type=SQLAssessmentRecommendation IsRollup=false RecommendationResult=Failed | measure count() by Computer&lt;/p>
&lt;/blockquote>
&lt;p>If you click the star to the right of the search box you will find the saved searches. For the SQL Assessment Intelligence Pack there are&lt;/p>
&lt;p>Did the agent pass the prerequisite check (if not, SQL Assessment data won’t be complete)&lt;/p>
&lt;p>Focus Areas&lt;/p>
&lt;ul>
&lt;li>How many SQL Recommendation are affecting a Computer a SQL Instance or a - Database?&lt;/li>
&lt;li>How many times did each unique SQL Recommendation trigger?&lt;/li>
&lt;li>SQL Assesments passed by Server&lt;/li>
&lt;li>SQL Recommendation by Computer&lt;/li>
&lt;li>SQL Recommendation by Database&lt;/li>
&lt;li>SQL Recommendation by Instance&lt;/li>
&lt;/ul>
&lt;p>You can use these and you can save your own searches which show the data in a way that is valuable to you.&lt;/p>
&lt;p>Overall I am impressed with this tool and can see how it can be beneficial for a DBA as well as for System Administrators. I was amazed how easy it was to set up and how quickly I was able to start manipulating the data once it had been uploaded.&lt;/p></description></item><item><title>Changing Delay Between Responses for SQL Alerts with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/changing-delay-between-responses-for-sql-alerts-with-powershell/</link><pubDate>Tue, 18 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/changing-delay-between-responses-for-sql-alerts-with-powershell/</guid><description>&lt;p>So you have read that you should have alerts for severity levels 16 to 24 and 823,824 and 825 on &lt;a class="link" href="http://www.sqlskills.com/blogs/glenn/the-accidental-dba-day-17-of-30-configuring-alerts-for-high-severity-problems/" target="_blank" rel="noopener"
>SQLSkills.com&lt;/a> or maybe you have used &lt;a class="link" href="http://www.brentozar.com/blitz/" target="_blank" rel="noopener"
>sp_blitz&lt;/a> and received the &lt;a class="link" href="http://www.brentozar.com/blitz/configure-sql-server-alerts/" target="_blank" rel="noopener"
>Blitz Result: No SQL Server Agent Alerts Configured&lt;/a> and like a good and conscientious DBA you have set them up.&lt;/p>
&lt;p>Hopefully you also have &lt;a class="link" href="https://www.simple-talk.com/blogs/author/13359-jonathan-allen/" target="_blank" rel="noopener"
>Jonathan Allens blog&lt;/a> on your feed and if you look at his historical posts and seen this one where &lt;a class="link" href="https://www.simple-talk.com/blogs/2011/06/27/alerts-are-good-arent-they/" target="_blank" rel="noopener"
>lack of a delay in response broke the Exchange Server!&lt;/a>&lt;/p>
&lt;p>However sometimes the oft used delay between responses of 1 minute is too much. Alerts should be actionable after all and maybe you sync your email every 15 minutes and don’t need to see 15 alerts for the same error or you decide that certain level of errors require a lesser response and therefore you only need to know about them every hour or three. Or possibly you want to enforce a certain delay for all servers and want to set up a system to check regularly and enforce your rule&lt;/p>
&lt;p>Whatever the reason, changing the delay between response for every alert on every server with SSMS could be time consuming and (of course) I will use Powershell to do the job.&lt;/p>
&lt;p>To find the alerts I follow the process I use when finding any new property in powershell&lt;/p>
&lt;pre>&lt;code>$server = 'SERVERNAME'
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
&lt;/code>&lt;/pre>
&lt;p>I know that the Alerts will be found under the JobServer Property&lt;/p>
&lt;pre>&lt;code>$srv.JobServer.Alerts|Get-Member
&lt;/code>&lt;/pre>
&lt;p>Shows me&lt;/p>
&lt;blockquote>
&lt;p>DelayBetweenResponses   Property   int DelayBetweenResponses {get;set;}&lt;/p>
&lt;/blockquote>
&lt;p>And&lt;/p>
&lt;blockquote>
&lt;p> Alter                   Method     void Alter(), void IAlterable.Alter()&lt;/p>
&lt;/blockquote>
&lt;p>So I use both of those as follows&lt;/p>
&lt;pre>&lt;code>Foreach($Alert in $srv.JobServer.Alerts){
$Alert.DelayBetweenResponses = 600 # This is in seconds
$Alert.Alter()
}
&lt;/code>&lt;/pre>
&lt;p>And place it in a foreach loop for the servers I want to change. If I only want to change certain alerts I can do so by filtering on Name&lt;/p>
&lt;pre>&lt;code>Foreach($Alert in $srv.JobServer.Alerts|Where-Object {$_.Name -eq 'NameOfAlert'})
&lt;/code>&lt;/pre>
&lt;p>Or by category&lt;/p>
&lt;pre>&lt;code>Foreach($Alert in $srv.JobServer.Alerts|Where-Object {$_.CategoryName -eq 'Category Name'})
&lt;/code>&lt;/pre>
&lt;p>When you have 5 minutes go and look at the results of&lt;/p>
&lt;pre>&lt;code>$srv.JobServer|Get-Member
&lt;/code>&lt;/pre>
&lt;p>And explore and let me know what you find&lt;/p></description></item><item><title>#tsql2sday #60 – Something New Learned – Problem Step Recorder</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-%2360-something-new-learned-problem-step-recorder/</link><pubDate>Tue, 11 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-%2360-something-new-learned-problem-step-recorder/</guid><description>&lt;h3 id="what-is-t-sql-tuesday">What is T-SQL Tuesday?&lt;/h3>
&lt;p>&lt;a class="link" href="http://chrisyatessql.wordpress.com/2014/11/05/t-sql-tuesday-60-something-new-learned/" target="_blank" rel="noopener"
>&lt;img src="https://chrisyatessql.files.wordpress.com/2012/10/sql-tuesday1.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>T-SQL Tuesday is a monthly blog party hosted by a different blogger each month. This blog party was started by Adam Machanic (&lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>blog&lt;/a>|&lt;a class="link" href="http://twitter.com/adammachanic" target="_blank" rel="noopener"
>twitter&lt;/a>). You can take part by posting your own participating post that fits the topic of the month and follows the requirements Additionally, if you are interested in hosting a future T-SQL Tuesday, contact Adam Machanic on his blog.&lt;/p>
&lt;p>This month’s blog party is hosted by Chris Yates &lt;a class="link" href="http://chrisyatessql.wordpress.com/" target="_blank" rel="noopener"
>blog&lt;/a> |&lt;a class="link" href="https://twitter.com/@Yatessql" target="_blank" rel="noopener"
>twitter&lt;/a> who asked people to share something newly learned.&lt;/p>
&lt;p>I love being a part of the SQL community. It gives me the opportunity to learn as much as I want to about anything I can think of within the data field. In the last couple of months I have presented at &lt;a class="link" href="http://sqlne.sqlpass.org/" target="_blank" rel="noopener"
>Newcastle User Group&lt;/a> and learnt about migrating SQL using Powershell with &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>Stuart Moore&lt;/a>. At our user group in Exeter &lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/&lt;/a> we had &lt;a class="link" href="https://twitter.com/Steph_middleton" target="_blank" rel="noopener"
>Steph Middleton&lt;/a> talking about version control for databases and lightning talks from &lt;a class="link" href="https://twitter.com/pavol" target="_blank" rel="noopener"
>Pavol Rovensky&lt;/a> on Mocking in C# ,&lt;a class="link" href="http://twitter.com/SQLServerMonkey" target="_blank" rel="noopener"
>John Martin&lt;/a> on Azure fault domains and availability sets using a pen and a whiteboard!, &lt;a class="link" href="https://twitter.com/mrs_fatherjack" target="_blank" rel="noopener"
>Annette Allen&lt;/a> on Database Unit Testing,&lt;a class="link" href="https://twitter.com/sqlshark" target="_blank" rel="noopener"
>Terry McCann&lt;/a>  on SQL Certifications. We also had &lt;a class="link" href="http://www.simple-talk.com/community/blogs/jonathanallen/" target="_blank" rel="noopener"
>Jonathan Allen&lt;/a> talking about some free tools and resources to help manage both large and small SQL environments.  I went to SQL Relay in Southampton and saw &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>Stuart Moore&lt;/a> (again!) &lt;a class="link" href="https://twitter.com/SQLScott" target="_blank" rel="noopener"
>Scott Klein&lt;/a> &lt;a class="link" href="https://twitter.com/_AlexYates_" target="_blank" rel="noopener"
>Alex Yates&lt;/a> &lt;a class="link" href="https://twitter.com/thesqlpimp" target="_blank" rel="noopener"
>James Skipworth&lt;/a> and I joined the PASS DBA fundamentals virtual chapter webinar for Changing Your Habits to Improve the Performance of Your T-SQL by &lt;a class="link" href="https://twitter.com/SQLMickey" target="_blank" rel="noopener"
>Mickey Stuewe&lt;/a> and that’s only the ‘in-person’ learning that I did. I also read a lot of blog posts!&lt;/p>
&lt;p>But instead of repeating what I learnt from others within the community I thought I would write a blog post that I have been meaning to write for a few weeks about a solution pre-built into Windows that appears to not be well known. Problem Step Recorder.&lt;/p>
&lt;h3 id="what-is-psr">What is PSR?&lt;/h3>
&lt;p>I found out about a little known tool included in Windows Operating System a couple of months ago which enables you to record what you are doing by taking screenshots of every mouse click. The tool is Step Recorder also known as PSR. It is included by default in Windows 7 , Windows 8 and 8.1 and Windows Server 2008 and above.&lt;/p>
&lt;h3 id="what-does-it-do">What does it do?&lt;/h3>
&lt;p>Simply put, it records “This is what I did” There are many situations when this can be useful&lt;/p>
&lt;ul>
&lt;li>You can use this during installations to help create documentation. “This is what I did” when I installed X and now you can follow those steps and I know I haven’t missed anything.&lt;/li>
&lt;li>You can use it when communicating with 3rd parties or other support teams. “This is what I did” when I got this error and here are all of the steps so that you can re-create the issue and I know that I haven’t missed anything&lt;/li>
&lt;li>You can use this when resolving high priority incidents. “This is what I did” when System X broke, it includes all of the times of my actions.&lt;br>
I still keep my notepad by my keyboard out of habit but I have a record of the exact steps that I took to try to resolve the issue which will be very useful for reporting on the incident in the near future and also placing into a Knowledge Base for others to use if it happens again and I know I haven’t missed anything&lt;/li>
&lt;li>For assisting family members. Like many, I am “The IT guy” and PSR enables me to provide clear instructions with pictures showing exactly where I clicked to those family members who are having trouble with “The internet being broken”&lt;/li>
&lt;/ul>
&lt;p>It does this by automatically taking a screen shot after every mouse click or program event with a timestamp and a description of what happened. It does not record keystrokes though so if you need to record what you have typed there is some manual steps required&lt;/p>
&lt;h3 id="so-how-do-you-access-psr">So how do you access PSR?&lt;/h3>
&lt;p>Simple. Type “psr” into the run box, cmd or PowerShell and it will open&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled-picture.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled-picture.png"
loading="lazy"
alt="Untitled picture"
>&lt;/a>&lt;/p>
&lt;p>Once you click on Start Record it will start recording your clicks and taking screenshots. However I always open the settings by clicking on the drop down to the left of the help icon first and change the number of recent screen captures to store to the maximum value of 100.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/1untitled-picture.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/1untitled-picture.png"
loading="lazy"
alt="1Untitled picture"
>&lt;/a>&lt;/p>
&lt;p>If you do not you will get no warning but PSR will only save the last 25 screenshots it takes and your results will look like the below. It will still record your actions but not keep the screenshots.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348%5B1%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 16: (09/11/2014 13:47:45) User left click on “Chris Yates (@YatesSQL) | Twitter (tab item)”&lt;/p>
&lt;p>No screenshots were saved for this step.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348%5B2%5D.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348%5B3%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 17: (09/11/2014 13:47:47) User left click on “The SQL Professor | ‘Leadership Through Service’ (text)”&lt;/p>
&lt;p>No screenshots were saved for this step.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348%5B4%5D.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1348%5B5%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 18: (09/11/2014 13:47:47) User left click on “T-SQL Tuesday #60 – Something New Learned | The SQL Professor (text)” in “T-SQL Tuesday #60 – Something New Learned | The SQL Professor – Google Chrome”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled.png"
loading="lazy"
alt="untitled"
>&lt;/a>&lt;/p>
&lt;p>You can also set the name and location of the saved file in the settings but if you leave it blank it will prompt for a location and name once you click Stop Record&lt;/p>
&lt;h3 id="how-do-i-add-keyboard-input">How do I add keyboard input?&lt;/h3>
&lt;p>PSR allows you add keyboard input manually. You may need this if you need to include the text you have entered into prompts or address bars or if you wish to add further comment. You can do this by clicking add comment, drawing a box around the relevant part of the screen for the text input and inputting the text into the box&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/2untitled-picture.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/2untitled-picture.png"
loading="lazy"
alt="2Untitled picture"
>&lt;/a>&lt;/p>
&lt;p>In the results this looks like&lt;/p>
&lt;p>Step 1: (09/11/2014 12:56:22) User Comment: “&lt;a class="link" href="http://www.microsoft.com/en-gb/download/details.aspx?id=42573" target="_blank" rel="noopener"
>http://www.microsoft.com/en-gb/download/details.aspx?id=42573&lt;/a>”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled1.png"
loading="lazy"
alt="untitled1"
>&lt;/a>&lt;/p>
&lt;h3 id="what-do-the-results-look-like">What do the results look like?&lt;/h3>
&lt;p>Once you have finished the actions that you want to record (or when you think you are close to 100 screenshots) click stop record and the following screen will be displayed&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/3untitled-picture.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/3untitled-picture.png"
loading="lazy"
alt="3Untitled picture"
>&lt;/a>&lt;/p>
&lt;p>This allows you to review what PSR has recorded. You can then save it to a location of your desire. It is saved as a zip file which has a single .mht file in it. You can open the file without unzipping the archive and it will open in Internet Explorer. As you can see from the shots below you can run PSR on your client and it will still record actions in your RDP sessions although it does not record as much detail. The first two are on my SCOM server in my lab and the second two are on the laptop using the SCOM console&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B1%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 11: (09/11/2014 13:02:13) User left click on “Input Capture Window (pane)” in “SCOM on ROB-LAPTOP – Virtual Machine Connection”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled2.png"
loading="lazy"
alt="untitled2"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B2%5D.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B3%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 12: (09/11/2014 13:02:16) User left click on “Input Capture Window (pane)” in “SCOM on ROB-LAPTOP – Virtual Machine Connection”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled3.png"
loading="lazy"
alt="untitled3"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B4%5D.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B5%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 13: (09/11/2014 13:06:25) User right click on “Management Packs (tree item)” in “Agent Managed – THEBEARDMANAGEMENTGROUP – Operations Manager”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled4.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled4.png"
loading="lazy"
alt="untitled4"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B6%5D.mht" target="_blank" rel="noopener"
>Previous&lt;/a> &lt;a class="link" href="https://blog.robsewell.com/tsql2sday-60-something-new-learned-problem-step-recorder/%24Recording_20141109_1338%5B7%5D.mht" target="_blank" rel="noopener"
>Next&lt;/a>&lt;/p>
&lt;p>Step 14: (09/11/2014 13:06:27) User left click on “Import Management Packs… (menu item)”&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/untitled5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/untitled5.png"
loading="lazy"
alt="untitled5"
>&lt;/a>&lt;/p>
&lt;p>You can then use the zip file as you wish. Maybe you email it to your third party support team (once you have edited any confidential data) or you can attach it to your incident in your IT Service Management solution or attach it to a report. If you wish to create documentation you can open the .mht file in Word, edit it as you see fit and save it appropriately.&lt;/p>
&lt;p>So that is one of the many things that I have learnt recently and I am looking forward to seeing what others have learnt especially as many will have just been to the SQL PASS Summit. You will be able to find the other posts in this blog party &lt;a class="link" href="http://chrisyatessql.wordpress.com/2014/11/05/t-sql-tuesday-60-something-new-learned/#comments" target="_blank" rel="noopener"
>in the comments on Chris’s page&lt;/a>&lt;/p></description></item><item><title>Generating T-SQL Randomly with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-t-sql-randomly-with-powershell/</link><pubDate>Wed, 05 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/generating-t-sql-randomly-with-powershell/</guid><description>&lt;p>I have a lab on my laptop running various servers so that I can problem solve and learn and recently I wanted to add several months of data into a database. I had created a stored procedure to take some parameters perform some logic and insert the data.&lt;/p>
&lt;p>To execute the stored procedure in T-SQL I simply run this&lt;/p>
&lt;pre>&lt;code>EXECUTE [dbo].[usp_Insert_DriveSpace] 'Server1','C','2014-11-05','100','25'
&lt;/code>&lt;/pre>
&lt;p>which uses the server name, drive letter, date, capacity and free space to add the data&lt;/p>
&lt;p>In my wisdom I decided to create some data that was more ‘real-life’ I was interested in storing drive space data and will be learning how to write reports on it. To do this I had pre-populated some tables in the database with 10 Server Names each with 5 drives so I needed 10*5*90 or 4500 statements&lt;/p>
&lt;p>I wanted to populate this with about 3 months of data as if it had been gathered every day. I read &lt;a class="link" href="http://smehrozalam.wordpress.com/2009/06/09/t-sql-using-common-table-expressions-cte-to-generate-sequences/" target="_blank" rel="noopener"
>this post&lt;/a> about using CTEs to create sequences and I am sure it can be done this way but I don’t have the T-SQL skills to do so. If someone can (or has) done that please let me know as I am trying to improve my T-SQL skills and would be interested in how to approach and solve this problem with T-SQL&lt;/p>
&lt;p>I solved it with Powershell in this way.&lt;/p>
&lt;p>Created an array of Servers and an array of Drives to enable me to iterate though each.&lt;/p>
&lt;pre>&lt;code>$Servers = 'Server1','Server2','Server3','Server4','Server5','Server6','Server7','Server8','Server9','Server10'
$Drives = 'C','D','E','F','G'
&lt;/code>&lt;/pre>
&lt;p>Set the drive capacity for each drive. To make my life slightly easier I standardised my ‘servers’&lt;/p>
&lt;pre>&lt;code>$CDriveCapacity = 100
$DDriveCapacity = 50
$EDriveCapacity = 200
$FDriveCapacity = 200
$GDriveCapacity = 500
&lt;/code>&lt;/pre>
&lt;p>I needed to create a date. You can use &lt;code>Get-Date&lt;/code> to get todays date and to get dates or times in the future or the past you can use the &lt;code>AddDays()&lt;/code> function. You can also add ticks, milliseconds, seconds, minutes, hours, months or years&lt;/p>
&lt;pre>&lt;code>(Get-Date).AddDays(1)
&lt;/code>&lt;/pre>
&lt;p>I then needed to format the date. This is slightly confusing. If you just use &lt;code>Get-Date&lt;/code> to get the current date (time) then you can use the &lt;code>format&lt;/code> or &lt;code>uformat&lt;/code> switch to format the output&lt;/p>
&lt;pre>&lt;code>Get-Date -Format yyyyMMdd
Get-Date -UFormat %Y%m%d
&lt;/code>&lt;/pre>
&lt;p>However this does not work once you have used the AddDays() method. You have to use the ToString() method&lt;/p>
&lt;pre>&lt;code>$Date = (Get-Date).AddDays(-7).ToString('yyyy-MM-dd')
&lt;/code>&lt;/pre>
&lt;p>To replicate gathering data each day I decided to use a while loop. I set $x to –95 and pressed CTRL and J to bring up Snippets and typed w and picked the while loop. You can find out more about snippets in &lt;a class="link" href="https://blog.robsewell.com/powershell-snippets-a-great-learning-tool/" target="_blank" rel="noopener"
>my previous post&lt;/a> I started at –95 so that all the identity keys incremented in a real-life manner oldest to newest.&lt;/p>
&lt;pre>&lt;code>$x = -98
while ($x -le 0)
{
$Date = (get-date).AddDays($x).ToString('yyyy-MM-dd')
foreach($Server in $Servers)
{
foreach ($Drive in $Drives)
{
&lt;/code>&lt;/pre>
&lt;p>I could then use the while loop to generate data for each day and loop through each server and each drive and generate the T-SQL but I wanted more!&lt;/p>
&lt;p>I wanted to generate some random numbers for the free space available for each drive. I used the &lt;a class="link" href="http://technet.microsoft.com/en-us/library/hh849905.aspx" target="_blank" rel="noopener"
>Get-Random cmdlet&lt;/a> If you are going to use it make sure you read &lt;a class="link" href="http://www.vtesseract.com/post/15440295910/a-get-random-gotcha-powershell-how-i-was-robbed" target="_blank" rel="noopener"
>this post&lt;/a> to make sure that you don’t get caught by the gotcha. I decided to set the free space for my OS,Data and Log Files to somewhere between 70 and 3 Gb free as in this imaginary scenario these drives are carefully monitored and the data and log file sizes under the control of a careful DBA but still able to go below thresholds.&lt;/p>
&lt;pre>&lt;code>if($Drive -eq 'C')
{
$Free = Get-Random -Maximum 70 -Minimum 3
&lt;/code>&lt;/pre>
&lt;p>I set the TempDB drive to have either 4,7 or 11 Gb free so that i can try to colour code my reports depending on values and if one field only has three values it makes it simpler to verify.&lt;/p>
&lt;p>I set the Backup Drive to somewhere between 50 and 0 so that I will hit 0 sometimes!!&lt;/p>
&lt;p>Here is the full script. It generated 4500 T-SQL statements in just under 16 seconds&lt;/p>
&lt;pre>&lt;code>$Servers = 'Server1','Server2','Server3','Server4','Server5','Server6','Server7','Server8','Server9','Server10'
$Drives = 'C','D','E','F','G'
$CDriveCapacity = 100
$DDriveCapacity = 50
$EDriveCapacity = 200
$FDriveCapacity = 200
$GDriveCapacity = 500
$x = -98
while ($x -le 0)
{
$Date = (get-date).AddDays($x).ToString('yyyy-MM-dd')
foreach($Server in $Servers)
{
foreach ($Drive in $Drives)
{
if($Drive -eq 'C')
{
$Free = Get-Random -Maximum 70 -Minimum 3
Write-Host &amp;amp;quot;EXECUTE \[dbo\].\[usp\_Insert\_DriveSpace\] '$Server','$Drive','$Date','$CDriveCapacity','$Free'&amp;amp;quot;
}
elseif($Drive -eq 'D')
{
$Free = Get-Random -InputObject 4,7,11
Write-Host &amp;amp;quot;EXECUTE \[dbo\].\[usp\_Insert\_DriveSpace\] '$Server','$Drive','$Date','$DDriveCapacity','$Free'&amp;amp;quot;
}
elseif($Drive -eq 'E')
{
$Free = Get-Random -Maximum 70 -Minimum 3
Write-Host &amp;amp;quot;EXECUTE \[dbo\].\[usp\_Insert\_DriveSpace\] '$Server','$Drive','$Date','$EDriveCapacity','$Free'&amp;amp;quot;
}
elseif($Drive -eq 'F')
{
$Free = Get-Random -Maximum 70 -Minimum 3
Write-Host &amp;amp;quot;EXECUTE \[dbo\].\[usp\_Insert\_DriveSpace\] '$Server','$Drive','$Date','$FDriveCapacity','$Free'&amp;amp;quot;
}
elseif($Drive -eq 'G')
{
$Free = Get-Random -Maximum 50 -Minimum 0
Write-Host &amp;amp;quot;EXECUTE \[dbo\].\[usp\_Insert\_DriveSpace\] '$Server','$Drive','$Date','$GDriveCapacity','$Free'&amp;amp;quot;
}
}
}
$X++
}
&lt;/code>&lt;/pre>
&lt;p>Once it had run I simply copied the output into SSMS and was on my way&lt;/p></description></item><item><title>Emailing Disk Space Alerting With Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/emailing-disk-space-alerting-with-powershell/</link><pubDate>Tue, 04 Nov 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/emailing-disk-space-alerting-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/11/image_thumb.png" alt="Featured image of post Emailing Disk Space Alerting With Powershell" />&lt;p>A DBA doesn’t want to run out of space on their servers, even in their labs! To avoid this happening I wrote a Powershell script to provide some alerts by email.&lt;/p>
&lt;p>This is the script and how I worked my way through the solution. I hope it is of benefit to others.&lt;/p>
&lt;p>The script works in the following way&lt;/p>
&lt;ul>
&lt;li>Iterates through a list of servers&lt;/li>
&lt;li>Runs a WMI query to gather disk information&lt;/li>
&lt;li>If the free space has fallen below a threshold, checks to see if it has emailed before and if not emails a warning&lt;/li>
&lt;li>Resets if free space has risen above the threshold&lt;/li>
&lt;li>Logs what it does but manages the space the logs use&lt;/li>
&lt;/ul>
&lt;p>As you will have seen before I use a Servers text file in my scripts. This is a text file with a single server name on each line. You could also use a query against a DBA or MDW database using Invoke-SQLCMD2, which ever is the most suitable for you.&lt;/p>
&lt;pre>&lt;code>$Servers = Get-Content 'PATH\\TO\\Servers.txt' foreach($Server in $Servers) {
&lt;/code>&lt;/pre>
&lt;p>The WMI query is a very simple one to gather the disk information. I format the results and place them in variables for reuse&lt;/p>
&lt;pre>&lt;code> $Disks = Get-WmiObject win32\_logicaldisk -ComputerName $Server | Where-Object {$\_.drivetype -eq 3}
$TotalSpace=\[math\]::Round(($Disk.Size/1073741824),2)
# change to gb and 2 decimal places
$FreeSpace=\[Math\]::Round(($Disk.FreeSpace/1073741824),2)
# change to gb and 2 decimal places
$UsedSpace = $TotalSpace - $FreeSpace
$PercentFree = \[Math\]::Round((($FreeSpace/$TotalSpace)*100),2)
# change to gb and 2 decimal places
&lt;/code>&lt;/pre>
&lt;p>Use a bit of logic to check if the freespace is below a threshold and see if the email has already been sent&lt;/p>
&lt;pre>&lt;code># Check if percent free below warning level
if ($PercentFree -le $SevereLevel) {
# if text file has been created (ie email should already have been sent) do nothing
if(Test-Path $CheckFileSevere) {}
# if percent free below warning level and text file doesnot exist create text file and email
else {
&lt;/code>&lt;/pre>
&lt;p>If it has not create a unique named text file and create the email body using HTML and the values stored in the variables&lt;/p>
&lt;pre>&lt;code>New-Item $CheckFileSevere -ItemType File #Create Email Body $EmailBody = '' $EmailBody += &amp;quot; &amp;quot;
&lt;/code>&lt;/pre>
&lt;p>and then send it&lt;/p>
&lt;pre>&lt;code>$Subject = &amp;quot;URGENT Disk Space Alert 1%&amp;quot;
$Body = $EmailBody
$msg = new-object Net.Mail.MailMessage
$smtp = new-object Net.Mail.SmtpClient($smtpServer)
$smtp.port = '25'
$msg.From = $From
$msg.Sender = $Sender
$msg.To.Add($To)
$msg.Subject = $Subject
$msg.Body = $Body
$msg.IsBodyHtml = $True
$smtp.Send($msg)
&lt;/code>&lt;/pre>
&lt;p>If the freespace is above all of the warning levels, check for existence of the text file and delete it if found so that the next time the script runs it will send an email.&lt;/p>
&lt;pre>&lt;code>if(Test-Path $CheckFile) {
Remove-Item $CheckFile -Force
&lt;/code>&lt;/pre>
&lt;p>To enable logging create a log file each day&lt;/p>
&lt;pre>&lt;code> $Logdate = Get-Date -Format yyyyMMdd
$LogFile = $Location + 'logfile' + $LogDate+ '.txt'
# if daily log file does not exist create one
if(!(Test-Path $LogFile)) {
New-Item $Logfile -ItemType File
}
&lt;/code>&lt;/pre>
&lt;p>And write the info to it at each action&lt;/p>
&lt;pre>&lt;code> $logentrydate = (Get-Date).DateTime
$Log = $logentrydate + ' ' + $ServerName + ' ' + $DriveLetter + ' ' + $VolumeName + ' ' + $PercentFree +' -- Severe Email Sent'
Add-Content -Value $Log -Path $Logfile
&lt;/code>&lt;/pre>
&lt;p>Making sure that you clean up after&lt;/p>
&lt;pre>&lt;code># any logfiles older than 7 days delete
Get-ChildItem -Path $Location \*logfile\* |Where-Object {$_.LastWriteTime -gt (Get-Date).AddDays(7) }|Remove-Item -Force
&lt;/code>&lt;/pre>
&lt;p>I run the script in a Powershell Step in an SQL Agent Job every 5 minutes and now I know when my servers in my lab are running out of space with an email like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/11/image_thumb.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/11/image_thumb.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/SQLDBAWithABeard/OldCodeFromBlog/tree/master/EmailingDiskAlertPost" target="_blank" rel="noopener"
>You can find the script here&lt;/a>&lt;/p></description></item><item><title>Number of VLFs and Autogrowth Settings Colour Coded to Excel with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/number-of-vlfs-and-autogrowth-settings-colour-coded-to-excel-with-powershell/</link><pubDate>Mon, 06 Oct 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/number-of-vlfs-and-autogrowth-settings-colour-coded-to-excel-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/10/image_thumb.png" alt="Featured image of post Number of VLFs and Autogrowth Settings Colour Coded to Excel with PowerShell" />&lt;p>So you have read up on VLFs&lt;/p>
&lt;p>No doubt you will have read &lt;a class="link" href="http://www.sqlskills.com/blogs/kimberly/transaction-log-vlfs-too-many-or-too-few/" target="_blank" rel="noopener"
>this post by Kimberly Tripp&lt;/a> and this &lt;a class="link" href="http://www.sqlskills.com/blogs/kimberly/8-steps-to-better-transaction-log-throughput/" target="_blank" rel="noopener"
>one&lt;/a> and maybe &lt;a class="link" href="https://www.simple-talk.com/sql/database-administration/sql-server-transaction-log-fragmentation-a-primer/" target="_blank" rel="noopener"
>this one too&lt;/a> and you want to identify the databases in your environment which have a large number of VLFs and also the initial size and the autogrowth settings of the log files.&lt;/p>
&lt;p>There are several posts about this and doing this with PowerShell &lt;a class="link" href="https://www.simple-talk.com/sql/database-administration/monitoring-sql-server-virtual-log-file-fragmentation/" target="_blank" rel="noopener"
>like this one&lt;/a> or &lt;a class="link" href="http://www.youdidwhatwithtsql.com/audit-vlfs-on-your-sql-server/1358/" target="_blank" rel="noopener"
>this one&lt;/a>. As is my wont I chose to output to Excel and colour code the cells depending on the number of VLFs or the type of Autogrowth.&lt;/p>
&lt;p>There is not a pure SMO way of identifying the number of VLFs in a log file that I am aware of and it is simple to use DBCC LOGINFO to get that info.&lt;/p>
&lt;p>I also wanted to input the autogrowth settings, size, space used, the logical name and the file path. I started by getting all of my servers into a $Servers Array as follows&lt;/p>
&lt;pre>&lt;code>$Servers = Get-Content 'PATHTO\sqlservers.txt'
&lt;/code>&lt;/pre>
&lt;p>Whilst presenting at the Newcastle User Group, Chris Taylor &lt;a class="link" href="http://chrisjarrintaylor.co.uk/" target="_blank" rel="noopener"
>b&lt;/a> | &lt;a class="link" href="https://twitter.com/sqlgeordie" target="_blank" rel="noopener"
>t&lt;/a> asked a good question. He asked if that was the only way to do this or if you could use your DBA database.&lt;/p>
&lt;p>It is much better to make use of the system you already use to record your databases. It will also make it much easier for you to be able to run scripts against more specific groups of databases without needing to keep multiple text files up to date. You can accomplish this as follows&lt;/p>
&lt;pre>&lt;code>$Query = 'SELECT Name FROM dbo.databases WHERE CONDITION meets your needs'
$Servers = Invoke-Sqlcmd -ServerInstance MANAGEMENTSERVER -Database DBADATABASE -Query $query
&lt;/code>&lt;/pre>
&lt;p>I then create a foreach loop and a server SMO object (Did you read my &lt;a class="link" href="https://blog.robsewell.com/powershell-snippets-a-great-learning-tool" target="_blank" rel="noopener"
>blog post&lt;/a> about snippets? the code for a SMO Server snippet is there) returned the number of rows for DBCC LOGINFO and the information I wanted.&lt;/p>
&lt;pre>&lt;code>foreach ($Server in $Servers)
{
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
foreach ($db in $srv.Databases|Where-Object {$_.isAccessible -eq $True})
{
$DB.ExecuteWithResults('DBCC LOGINFO').Tables[0].Rows.Count
$db.LogFiles | Select Growth,GrowthType,Size, UsedSpace,Name,FileName
}
}
&lt;/code>&lt;/pre>
&lt;p>It’s not very pretty or particularly user friendly so I decided to put it into Excel&lt;/p>
&lt;p>I did this by using my Excel Snippet&lt;/p>
&lt;pre>&lt;code> $snippet = @{
Title = 'Excel Object';
Description = 'Creates a Excel Workbook and Sheet';
Text = @'
# Create a .com object for Excel
`$xl = new-object -comobject excel.application
`$xl.Visible = `$true # Set this to False when you run in production
`$wb = `$xl.Workbooks.Add() # Add a workbook
`$ws = `$wb.Worksheets.Item(1) # Add a worksheet
`$cells=`$ws.Cells
#Do Some Stuff - perhaps -
`$cells.item(`$row,`$col)=`'Server`'
`$cells.item(`$row,`$col).font.size=16
`$Cells.item(`$row,`$col).Columnwidth = 10
`$col++
`$wb.Saveas(`'C:\temp\Test`$filename.xlsx`')
`$xl.quit()
Stop-Process -Name EXCEL
'@
}
New-IseSnippet @snippet
&lt;/code>&lt;/pre>
&lt;p>and placed the relevant bits into the foreach loop&lt;/p>
&lt;pre>&lt;code>foreach ($Server in $Servers)
{
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
foreach ($db in $srv.Databases|Where-Object {$_.isAccessible -eq $True})
{
$VLF = $DB.ExecuteWithResults('DBCC LOGINFO').Tables[0].Rows.Count
$logFile = $db.LogFiles | Select Growth,GrowthType,Size, UsedSpace,Name,FileName
$Name = $DB.name
$cells.item($row,$col)=$Server
$col++
$cells.item($row,$col)=$Name
$col++
$cells.item($row,$col)=$VLF
$col++
$col++
$Type = $logFile.GrowthType.ToString()
$cells.item($row,$col)=$Type
$col++
$cells.item($row,$col)=($logFile.Size)
$col++
$cells.item($row,$col)=($logFile.UsedSpace)
$col++
$cells.item($row,$col)=$logFile.Name
$col++
$cells.item($row,$col)=$logFile.FileName
&lt;/code>&lt;/pre>
&lt;p>I had to use the &lt;code>ToString()&lt;/code> method on the Type property to get Excel to display the text. I wanted to set the colour for the VLF cells to yellow or red dependant on their value and the colour of the growth type cell to red if the value was Percent. This was achieved like this&lt;/p>
&lt;pre>&lt;code>if($VLF -gt $TooMany)
{
$cells.item($row,$col).Interior.ColorIndex = 6 # Yellow
}
if($VLF -gt $WayTooMany)
{
$cells.item($row,$col).Interior.ColorIndex = 3 # Red
}
if($Type -eq 'Percent')
{
$cells.item($row,$col).Interior.ColorIndex = 3 #Red
}
&lt;/code>&lt;/pre>
&lt;p>I also found &lt;a class="link" href="http://theolddogscriptingblog.wordpress.com/2010/06/01/powershell-excel-cookbook-ver-2/" target="_blank" rel="noopener"
>this excellent post&lt;/a> by which has many many snippets of code to work with excel sheets.&lt;/p>
&lt;p>I used&lt;/p>
&lt;pre>&lt;code>$cells.item($row,$col).HorizontalAlignment = 3 #center
$cells.item($row,$col).HorizontalAlignment = 4 #right
$ws.UsedRange.EntireColumn.AutoFit()
&lt;/code>&lt;/pre>
&lt;p>although I had to move the Title so that it was after the above line so that it looked ok.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/wp-content/uploads/2014/10/image.png" target="_blank" rel="noopener"
>&lt;br>
&lt;img src="https://blog.robsewell.com/assets/uploads/2014/10/image_thumb.png"
loading="lazy"
alt="image"
>&lt;br>
&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://gallery.technet.microsoft.com/scriptcenter/Number-of-VLFs-and-7ee0182a" target="_blank" rel="noopener"
>You can find the script here.&lt;/a> As always test it somewhere safe first, understand what it is doing and any questions get in touch.&lt;/p></description></item><item><title>PowerShell Snippets A Great Learning Tool</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-snippets-a-great-learning-tool/</link><pubDate>Tue, 09 Sep 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-snippets-a-great-learning-tool/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/09/image9.png" alt="Featured image of post PowerShell Snippets A Great Learning Tool" />&lt;p>When I talk to people about Powershell they often ask how can they easily learn the syntax. Here’s a good tip&lt;/p>
&lt;p>Open PowerShell ISE and press CTRL + J&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image9.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb9.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You will find a number of snippets that will enable you to write your scripts easily.  Johnathan Medd PowerShell MVP has written a good post about snippets on the &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2014/01/25/using-powershell-ise-snippets-to-remember-tricky-syntax.aspx" target="_blank" rel="noopener"
>Hey, Scripting Guy! blog&lt;/a> so I will not repeat that but suggest that you go and read that post. It will show you how quickly and easily you will be able to write more complex Powershell scripts as you do not have to learn the syntax but can use the snippets to insert all the code samples you require.&lt;/p>
&lt;p>Not only are there default snippets for you to use but you can create your own snippets. However there isn’t a snippet for creating a new snippet so here is the code to do that&lt;/p>
&lt;pre>&lt;code>$snippet1 = @{
Title = 'New-Snippet'
Description = 'Create a New Snippet'
Text = @&amp;quot;
`$snippet = @{
Title = `'Put Title Here`'
Description = `'Description Here`'
Text = @`&amp;quot;
Code in Here
`&amp;quot;@
}
New-IseSnippet @snippet
&amp;quot;@
}
New-IseSnippet @snippet1 –Force
&lt;/code>&lt;/pre>
&lt;p>I frequently use the SQL Server SMO Object in my code so I created this snippet&lt;/p>
&lt;pre>&lt;code> $snippet = @{
Title = 'SMO-Server'
Description = 'Creates a SQL Server SMO Object'
Text = @&amp;quot;
`$srv = New-Object Microsoft.SqlServer.Management.Smo.Server `$Server
&amp;quot;@
}
New-IseSnippet @snippet
&lt;/code>&lt;/pre>
&lt;p>I also use Data Tables a lot so I created a snippet for that too&lt;/p>
&lt;pre>&lt;code> $snippet = @{
Title = 'New-DataTable'
Description = 'Creates a Data Table Object'
Text = @&amp;quot;
# Create Table Object
`$table = New-Object system.Data.DataTable `$TableName
# Create Columns
`$col1 = New-Object system.Data.DataColumn NAME1,([string])
`$col2 = New-Object system.Data.DataColumn NAME2,([decimal])
#Add the Columns to the table
`$table.columns.add(`$col1)
`$table.columns.add(`$col2)
# Create a new Row
`$row = `$table.NewRow()
# Add values to new row
`$row.Name1 = 'VALUE'
`$row.NAME2 = 'VALUE'
#Add new row to table
`$table.Rows.Add($row)
&amp;quot;@
}
New-IseSnippet @snippet
&lt;/code>&lt;/pre>
&lt;p>Denniver Reining has created a &lt;a class="link" href="http://bytecookie.wordpress.com/snippet-manager/" target="_blank" rel="noopener"
>Snippet Manager&lt;/a> which you can use to further expand your snippets usage and it is free as well.&lt;/p>
&lt;p>If you have further examples of useful snippets please feel free to post them in the comments below&lt;/p>
&lt;p>Edit 16/12/2014&lt;/p>
&lt;p>I am proud that this article was nominated for the Tribal Awards. Please go and vote for your winners in all the categories&lt;/p>
&lt;p>&lt;a class="link" href="http://www.sqlservercentral.com/articles/Awards/119953/" target="_blank" rel="noopener"
>http://www.sqlservercentral.com/articles/Awards/119953/&lt;/a>&lt;/p>
&lt;p>Personally in the article category I will be voting for&lt;/p>
&lt;p>&lt;a class="link" href="https://www.simple-talk.com/sql/database-administration/gail-shaws-sql-server-howlers/" target="_blank" rel="noopener"
>Gail Shaw’s SQL Server Howlers&lt;/a>&lt;/p></description></item><item><title>Find Out Which Indexes are on which Filegroups using PowerShell And How To Find Other Information</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/find-out-which-indexes-are-on-which-filegroups-using-powershell-and-how-to-find-other-information/</link><pubDate>Sun, 07 Sep 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/find-out-which-indexes-are-on-which-filegroups-using-powershell-and-how-to-find-other-information/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/09/image8.png" alt="Featured image of post Find Out Which Indexes are on which Filegroups using PowerShell And How To Find Other Information" />&lt;p>A short post today to pass on a script I wrote to fulfil a requirement I had.&lt;/p>
&lt;p>Which indexes are on which filegroups. I found a blog post showing how to &lt;a class="link" href="http://basitaalishan.com/2013/03/03/list-all-objects-and-indexes-per-filegroup-partition/" target="_blank" rel="noopener"
>do it with T-SQL&lt;/a> but as is my wont I decided to see how easy it would be with PowerShell. I also thought that it would make a good post to show how I approach this sort of challenge.&lt;/p>
&lt;p>I generally start by creating a &lt;a class="link" href="http://msdn.microsoft.com/en-GB/library/microsoft.sqlserver.management.smo.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>SQL Server SMO Object&lt;/a> You can use the &lt;a class="link" href="http://msdn.microsoft.com/en-us/library/ms162209%28v=sql.110%29.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>SMO Object Model Diagram&lt;/a> or Get-Member to work out what you need. As we are talking indexes and filegroups I will also create a Database object&lt;/p>
&lt;pre>&lt;code>$Server = &amp;quot;SQL2012Ser2012&amp;quot;
$DBName = &amp;quot;AdventureWorks2012&amp;quot;
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
$DB = $srv.Databases[$DBName]
&lt;/code>&lt;/pre>
&lt;p>Then by piping the database object to Get-Member I can see the properties&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb2.png?resize=630%2C273&amp;amp;ssl=1"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Lets take a look at the table object in the same way&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb3.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I can see the indexes object so I pipe that to Get-Member as well&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image4.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb4.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Now I have enough to information to create the report. I will select the Name, Table, Type and Space Used of the Indexes and format them nicely&lt;/p>
&lt;pre>&lt;code>$Server = &amp;quot;SQL2012Ser2012&amp;quot;
$DBName = &amp;quot;AdventureWorks2012&amp;quot;
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $Server
$DB = $srv.Databases[$DBName]
$db.tables.Indexes|select Name,Parent,Filegroup,IndexType,SpaceUsed|Format-Table –AutoSize
&lt;/code>&lt;/pre>
&lt;p>and here are the results&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb5.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>However, you may want the results to be displayed in a different manner, maybe CSV,HTML or text file and you can do this as follows&lt;/p>
&lt;pre>&lt;code>$db.tables.Indexes|select Name,Parent,Filegroup,IndexType,SpaceUsed|ConvertTo-Csv c:\temp\filegroups.csv
Invoke-Item c:\temp\filegroups.csv
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb6.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>$db.tables.Indexes|select Name,Parent,Filegroup,IndexType,SpaceUsed| Out-File c:\temp\filegroups.txt
Invoke-Item c:\temp\filegroups.txt
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image7.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb7.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>$db.tables.Indexes|select Name,Parent,Filegroup,IndexType,SpaceUsed|ConvertTo-Html |Out-File c:\temp\filegroups.html
Invoke-Item c:\temp\filegroups.html
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image8.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb8.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Hopefully this has shown you how easy it can be to use PowerShell to get all of the information that you need from your SQL Server and how to approach getting that information as well as several ways to display it&lt;/p></description></item><item><title>Refreshing Availability Group Database with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-availability-group-database-with-powershell/</link><pubDate>Thu, 04 Sep 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-availability-group-database-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/09/image1.png" alt="Featured image of post Refreshing Availability Group Database with PowerShell" />&lt;p>Following last weeks post on &lt;a class="link" href="https://blog.robsewell.com/refreshing-a-sql-mirrored-database-using-powershell-2/" target="_blank" rel="noopener"
>Refreshing A Mirrored Database with PowerShell&lt;/a> I thought I would write the script to refresh an Availability Group Database.&lt;/p>
&lt;p>An availability group supports a failover environment for a discrete set of user databases, known as availability databases, that fail over together. An availability group supports a set of primary databases and one to eight sets of corresponding secondary databases.You can read more about Availability groups &lt;a class="link" href="http://msdn.microsoft.com/en-GB/library/ff877884.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>here&lt;/a>&lt;/p>
&lt;p>There are situations where you may need to refresh these databases. Disaster Recovery is an obvious one but also during development to provide testing or development environments to test your High Availability implementations, run through disaster scenarios, create run books or ensure that the code changes still work with AG. There are other scenarios but this post covers the automation of restoring an Availability Group Database from a backup.&lt;/p>
&lt;p>The steps that you need to take to restore an Availability Group Database are&lt;/p>
&lt;ul>
&lt;li>Remove Database from the Availability Group&lt;/li>
&lt;li>Restore the Primary Replica Database&lt;/li>
&lt;li>Backup the Primary Replica Database Transaction Log&lt;/li>
&lt;li>Restore the Secondary and Tertiary Replica Databases with no recovery&lt;/li>
&lt;li>Add the Database back into the Availability Group&lt;/li>
&lt;li>Resolve Orphaned Users – Not covered in this script&lt;/li>
&lt;li>Check the status&lt;/li>
&lt;/ul>
&lt;p>Here is my set up for this post&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I have 3 servers SQL2012SER08AG1, SQL2012SER08AG2 and SQL2012SER08AG3 with 3 databases in an Availability Group called AG_THEBEARD1. SQL2012SER08AG2 is set up as a secondary replica using Synchronous-Commit Mode SQL2012SER08AG3 is set up as a read only replica using Asynchronous-Commit Mode. I have three databases in my Availability Group and today I shall use the database called TestDatabase (I have no imagination today!) to demonstrate the refresh&lt;/p>
&lt;p>The script requires some variables to be set up at the beginning. You can easily change this and make the script into a function and call it if you desire, but for this post I shall consider the script as a standalone. The reasoning for this is that I imagine that it will be placed into a run book or stored for use in a repository for specific use and therefore reduces any pre-requisites for using it.&lt;/p>
&lt;p>First we will remove the database from the Availability Group. This is achieved using the &lt;a class="link" href="http://msdn.microsoft.com/en-us/library/hh213326.aspx#PowerShellProcedure?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>Remove-SqlAvailabilityDatabase CMDLet&lt;/a>&lt;/p>
&lt;pre>&lt;code>Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$SecondaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$TertiaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$PrimaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
&lt;/code>&lt;/pre>
&lt;p>Next Restore the Primary Replica Database, Backup the Primary Replica Database Transaction Log&lt;br>
and Restore the Secondary and Tertiary Replica Databases with no recovery using Restore-SqlDatabase and Backup-SqlDatabase (You can also use the SMO method in &lt;a class="link" href="https://blog.robsewell.com/refreshing-a-sql-mirrored-database-using-powershell-2" target="_blank" rel="noopener"
>the previous post&lt;/a> if you wish)&lt;/p>
&lt;pre>&lt;code>Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $PrimaryServer -ReplaceDatabase
# Backup Primary Database
Backup-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $PrimaryServer -BackupAction 'Log'
# Remove connections to database for Restore
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $SecondaryServer
$srv.KillAllProcesses($dbname)
# Restore Secondary Replica Database
Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $SecondaryServer -NoRecovery -ReplaceDatabase
Restore-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $SecondaryServer -RestoreAction 'Log' -NoRecovery -ReplaceDatabase
# Remove connections to database for Restore
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $TertiaryServer
$srv.KillAllProcesses($dbname)
# Restore Tertiary Replica Database
Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $TertiaryServer -NoRecovery -ReplaceDatabase
Restore-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $TertiaryServer -RestoreAction 'Log' -NoRecovery -ReplaceDatabase
&lt;/code>&lt;/pre>
&lt;p>Then add the database back to the Availability Group&lt;/p>
&lt;pre>&lt;code>Add-SqlAvailabilityDatabase -Path $MyAgPrimaryPath -Database $DBName
Add-SqlAvailabilityDatabase -Path $MyAgSecondaryPath -Database $DBName
Add-SqlAvailabilityDatabase -Path $MyAgTertiaryPath -Database $DBName
&lt;/code>&lt;/pre>
&lt;p>Finally test the status of the Availability Group&lt;/p>
&lt;pre>&lt;code>$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $PrimaryServer
$AG = $srv.AvailabilityGroups[$AGName]
$AG.DatabaseReplicaStates|ft -AutoSize
&lt;/code>&lt;/pre>
&lt;p>I also like to add some output to show the progress of the script. This can be logged using Out-File or displayed on the screen using Out-Host.&lt;/p>
&lt;pre>&lt;code>$EndDate = Get-Date
$Time = $EndDate - $StartDate
Write-Host &amp;quot;
##########################################
Results of Script to refresh $DBName on
$PrimaryServer , $SecondaryServer , $TertiaryServer
on AG $AGName
Time Script anded at $EndDate and took
$Time
&amp;quot; -ForegroundColor Green
&lt;/code>&lt;/pre>
&lt;p>Here are the results of my script&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/09/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/09/image_thumb1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: Availability Group Refresh
Author: Rob Sewell https://blog.robsewell.com
.DESCRIPTION
Refreshes an Availbaility group database from a backup
YOU WILL NEED TO RESOLVE ORPHANED USERS IF REQUIRED
#&amp;gt;
## http://msdn.microsoft.com/en-gb/library/hh213078.aspx#PowerShellProcedure?WT.mc_id=DP-MVP-5002693
# http://msdn.microsoft.com/en-us/library/hh213326(v=sql.110).aspx?WT.mc_id=DP-MVP-5002693
cls
# To Load SQL Server Management Objects into PowerShell
[System.Reflection.Assembly]::LoadWithPartialName(‘Microsoft.SqlServer.SMO’) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(‘Microsoft.SqlServer.SMOExtended’) | out-null
$LoadServer = &amp;quot;SQL2012Ser2012&amp;quot; # The Load Server
$Date = Get-Date -Format ddMMyy
$PrimaryServer = &amp;quot;SQL2012SER08AG1&amp;quot; # The Primary Availability Group Server
$SecondaryServer = &amp;quot;SQL2012SER08AG2&amp;quot; # The Secondary Availability Group Server
$TertiaryServer = &amp;quot;SQL2012SER08AG3&amp;quot; # The Tertiary Availability Group Server
$AGName = &amp;quot;AG_THEBEARD1&amp;quot; # Availability Group Name
$DBName = &amp;quot;TestDatabase&amp;quot; # Database Name
$LoadDatabaseBackupFile = &amp;quot;\\sql2012ser2012\Backups\GoldenBackup\LoadTestDatabase&amp;quot; + $Date + &amp;quot;.bak&amp;quot; # Load database Backup location - Needs access permissions granted
$DatabaseBackupFile = &amp;quot;\\sql2012ser2012\Backups\GoldenBackup\TestDatabase&amp;quot; + $Date + &amp;quot;.bak&amp;quot; # database Backup location - Needs access permissions granted
$LogBackupFile = &amp;quot;\\sql2012ser2012\Backups\GoldenBackup\TestDatabase&amp;quot; + $Date + &amp;quot;.trn&amp;quot; # database Backup location - Needs access permissions granted
# Path to Availability Database Objects
$MyAgPrimaryPath = &amp;quot;SQLSERVER:\SQL\$PrimaryServer\DEFAULT\AvailabilityGroups\$AGName&amp;quot;
$MyAgSecondaryPath = &amp;quot;SQLSERVER:\SQL\$SecondaryServer\DEFAULT\AvailabilityGroups\$AGName&amp;quot;
$MyAgTertiaryPath = &amp;quot;SQLSERVER:\SQL\$TertiaryServer\DEFAULT\AvailabilityGroups\$AGName&amp;quot;
$StartDate = Get-Date
Write-Host &amp;quot;
##########################################
Results of Script to refresh $DBName on
$PrimaryServer , $SecondaryServer , $TertiaryServer
on AG $AGName
Time Script Started $StartDate
&amp;quot; -ForegroundColor Green
cd c:
# Remove old backups
If(Test-Path $LoadDatabaseBackupFile){Remove-Item -Path $LoadDatabaseBackupFile -Force}
If(Test-Path $DatabaseBackupFile){Remove-Item -Path $DatabaseBackupFile}
If(Test-Path $LogBackupFile ) {Remove-Item -Path $LogBackupFile }
Write-Host &amp;quot;Backup Files removed&amp;quot; -ForegroundColor Green
# Remove Secondary Replica Database from Availability Group to enable restore
cd SQLSERVER:\SQL\$SecondaryServer\DEFAULT
Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$SecondaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
Write-Host &amp;quot;Secondary Removed from Availability Group&amp;quot; -ForegroundColor Green
# Remove Tertiary Replica Database from Availability Group to enable restore
cd SQLSERVER:\SQL\$TertiaryServer\DEFAULT
Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$TertiaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
Write-Host &amp;quot;Tertiary removed from Availability Group&amp;quot; -ForegroundColor Green
# Remove Primary Replica Database from Availability Group to enable restore
cd SQLSERVER:\SQL\$PrimaryServer\DEFAULT
Remove-SqlAvailabilityDatabase -Path SQLSERVER:\SQL\$PrimaryServer\DEFAULT\AvailabilityGroups\$AGName\AvailabilityDatabases\$DBName
Write-Host &amp;quot;Primary removed from Availability Group&amp;quot; -ForegroundColor Green
# Backup Load Database
Backup-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $LoadServer
Write-Host &amp;quot;Load Database Backed up&amp;quot; -ForegroundColor Green
# Remove connections to database for Restore
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $PrimaryServer
$srv.KillAllProcesses($dbname)
# Restore Primary Replica Database from Load Database
Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $PrimaryServer -ReplaceDatabase
Write-Host &amp;quot;Primary Database Restored&amp;quot; -ForegroundColor Green
# Backup Primary Database
# Backup-SqlDatabase -Database $DBName -BackupFile $DatabaseBackupFile -ServerInstance $PrimaryServer
Backup-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $PrimaryServer -BackupAction 'Log'
Write-Host &amp;quot;Primary Database Backed Up&amp;quot; -ForegroundColor Green
# Remove connections to database for Restore
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $SecondaryServer
$srv.KillAllProcesses($dbname)
# Restore Secondary Replica Database
Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $SecondaryServer -NoRecovery -ReplaceDatabase
Restore-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $SecondaryServer -RestoreAction 'Log' -NoRecovery -ReplaceDatabase
Write-Host &amp;quot;Secondary Database Restored&amp;quot; -ForegroundColor Green
# Remove connections to database for Restore
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $TertiaryServer
$srv.KillAllProcesses($dbname)
# Restore Tertiary Replica Database
Restore-SqlDatabase -Database $DBName -BackupFile $LoadDatabaseBackupFile -ServerInstance $TertiaryServer -NoRecovery -ReplaceDatabase
Restore-SqlDatabase -Database $DBName -BackupFile $LogBackupFile -ServerInstance $TertiaryServer -RestoreAction 'Log' -NoRecovery -ReplaceDatabase
Write-Host &amp;quot;Tertiary Database Restored&amp;quot; -ForegroundColor Green
# Add database back into Availability Group
cd SQLSERVER:\SQL\$PrimaryServer
Add-SqlAvailabilityDatabase -Path $MyAgPrimaryPath -Database $DBName
Add-SqlAvailabilityDatabase -Path $MyAgSecondaryPath -Database $DBName
Add-SqlAvailabilityDatabase -Path $MyAgTertiaryPath -Database $DBName
Write-Host &amp;quot;Database Added to Availability Group &amp;quot; -ForegroundColor Green
# Check Availability Group Status
$srv = New-Object Microsoft.SqlServer.Management.Smo.Server $PrimaryServer
$AG = $srv.AvailabilityGroups[$AGName]
$AG.DatabaseReplicaStates|ft -AutoSize
$EndDate = Get-Date
$Time = $EndDate - $StartDate
Write-Host &amp;quot;
##########################################
Results of Script to refresh $DBName on
$PrimaryServer , $SecondaryServer , $TertiaryServer
on AG $AGName
Time Script ended at $EndDate and took
$Time
&amp;quot; -ForegroundColor Green
&lt;/code>&lt;/pre></description></item><item><title>Refreshing A SQL Mirrored Database Using Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</link><pubDate>Mon, 25 Aug 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/refreshing-a-sql-mirrored-database-using-powershell/</guid><description>&lt;p>SQL mirroring is a means of providing high availability for your SQL database. It is available in Standard Edition and although the feature is deprecated it is still widely utilised. &lt;a class="link" href="http://msdn.microsoft.com/en-gb/library/ms189852.aspx?WT.mc_id=DP-MVP-5002693" target="_blank" rel="noopener"
>You can read more about it on MSDN here&lt;/a> and &lt;a class="link" href="http://www.brentozar.com/archive/2013/07/database-mirroring-faq/" target="_blank" rel="noopener"
>Jes Borland wrote a useful post answering many questions here&lt;/a>&lt;/p>
&lt;p>There are situations where you may need to refresh these databases. Disaster Recovery is an obvious one but also during development to provide testing or development environments to test your High Availability implementations, run through disaster scenarios, create run books or ensure that the code changes still work with mirroring. There are other scenarios but this post covers the automation of restoring a mirrored database from a backup.&lt;/p>
&lt;p>I have mentioned before and no doubt I shall again, &lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>John Sansom wrote a great post about automation&lt;/a> and I am a strong follower of that principle.&lt;/p>
&lt;p>To refresh a SQL mirror the following steps are required, there are some gotchas that you need to be aware of which I will discuss later&lt;/p>
&lt;ul>
&lt;li>remove mirroring&lt;/li>
&lt;li>restore principle database from backup&lt;/li>
&lt;li>perform a transaction log backup of the principle database&lt;/li>
&lt;li>restore both backups on the mirror server with no recovery&lt;/li>
&lt;li>recreate mirroring&lt;/li>
&lt;li>resolve orphaned users&lt;/li>
&lt;li>check mirroring status&lt;/li>
&lt;/ul>
&lt;p>Regular blog followers will know that I prefer to use Powershell when I can (and where it is relevant to do so) and so I have used Powershell to automate all of the steps above&lt;/p>
&lt;p>The script requires some variables to be set up at the beginning. You can easily change this and make the script into a function and call it if you desire, but for this post I shall consider the script as a standalone. The reasoning for this is that I imagine that it will be placed into a run book or stored for use in a repository for specific use and therefore reduces any pre-requisites for using it.&lt;/p>
&lt;p>Set variables as follows, the last three variables set the types for the backup action type and device type and do not need to be altered.&lt;/p>
&lt;pre>&lt;code>\# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
&lt;/code>&lt;/pre>
&lt;p>After some error checking the first thing is to create server and database SMO objects&lt;/p>
&lt;pre>&lt;code>\# Create Server objects $Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer $Mirror = New-Object Microsoft.SQLServer.Management.Smo. server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
&lt;/code>&lt;/pre>
&lt;p>(Added Extra – Use New-ISESnippet to create a SMO Server Snippet and use CTRL + J to find it&lt;/p>
&lt;pre>&lt;code>New-IseSnippet -Title SMO-Server -Description &amp;quot;Create A SQL Server SMO Object&amp;quot; -Text &amp;quot;`$srv = New-Object Microsoft.SqlServer.Management.Smo.Server `$server&amp;quot;
&lt;/code>&lt;/pre>
&lt;h4 id="remove-mirroring">Remove Mirroring&lt;/h4>
&lt;p>Before we can restore the database we need to remove mirroring&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
&lt;/code>&lt;/pre>
&lt;h4 id="restore-principle-database-from-backup">restore principle database from backup&lt;/h4>
&lt;p>Once mirroring has been removed we can restore the database. &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>Stuart Moore’s Great Series&lt;/a> provides all the code you need to backup and restore databases with Powershell. There is however a bug which can catch you out. Here’s the code&lt;/p>
&lt;pre>&lt;code>$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;p>The bug is as follows, if your restore is going to take longer than 10 minutes and you are using an earlier version of SQL than SQL 2012 SP1 CU8 then you will find that the restore fails after 10 minutes. This is the default timeout. You may try to set the&lt;/p>
&lt;pre>&lt;code>$srv.ConnectionContext.StatementTimeout
&lt;/code>&lt;/pre>
&lt;p>Value to a larger value or 0 and this will work after SQL 2012 SP1 CU8 but prior to that you will still face the same error. The simple workaround is to use &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/7985b7ef-ed89-4dfd-b02a-433cc4e30894" target="_blank" rel="noopener"
>Invoke-SQLCmd2&lt;/a> and to script the restore as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="perform-a-transaction-backup-of-the-principle-database">perform a transaction backup of the principle database&lt;/h4>
&lt;p>We need to have a full and transaction log backup to set up mirroring. Again you may need to use the script method if your backup will take longer than 600 seconds.&lt;/p>
&lt;pre>&lt;code>#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = “Log Backup of “ + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object –TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time &amp;amp;amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 –ServerInstance $PrincipalServer –Database master –Query $query –ConnectionTimeout 0 # comment out if not used
&lt;/code>&lt;/pre>
&lt;h4 id="restore-both-backups-on-the-mirror-server-with-no-recovery">Restore both backups on the mirror server with no recovery&lt;/h4>
&lt;p>To complete the mirroring set up we need to restore the backups onto the mirror server with no recovery as follows&lt;/p>
&lt;pre>&lt;code>#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time &amp;amp;amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran,$File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
&lt;/code>&lt;/pre>
&lt;h4 id="recreate-mirroring">Recreate mirroring&lt;/h4>
&lt;p>You recreate mirroring in the same way as you would if you were using T-SQL simply add the principal endpoint to the mirror, and the mirror and witness endpoints to the principal&lt;/p>
&lt;pre>&lt;code>#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
&lt;/code>&lt;/pre>
&lt;h4 id="resolve-orphaned-users">Resolve orphaned users&lt;/h4>
&lt;p>You will need to resolve any users and permissions on your destination servers. I do not know a way to do this with PowerShell and would be interested if anyone has found a way to replace the password or the SID on a user object, please contact me if you know.&lt;/p>
&lt;p>Many people do this with the &lt;a class="link" href="http://support.microsoft.com/kb/918992" target="_blank" rel="noopener"
>sp_rev_logins stored procedure&lt;/a> which will create the T-SQL for recreating the logins. However, Powershell cannot read the outputs of the message window where the script prints the script. If you know that your logins are staying static then run sp_rev_logins and store the output in a sql file and call it with Invoke-SQLCmd2&lt;/p>
&lt;pre>&lt;code>$SQL = ‘’ #Path to File
Invoke-Sqlcmd2 –ServerInstance $Server –Database master –InputFile $SQL
&lt;/code>&lt;/pre>
&lt;p>The other option is to &lt;a class="link" href="http://dbadiaries.com/how-to-transfer-logins-to-another-sql-server-or-instance" target="_blank" rel="noopener"
>set up a SSIS package following this blog post&lt;/a> and call it from Powershell as follows&lt;/p>
&lt;p>**2020 Edit ** - You should use &lt;a class="link" href="dbatools.io" >dbatools&lt;/a> to do this&lt;/p>
&lt;pre>&lt;code>Invoke-Command –ComputerName $Server –scriptblock {DTExec.exe /File “PATHTOPackage.dtsx”}
&lt;/code>&lt;/pre>
&lt;p>This requires &lt;a class="link" href="http://technet.microsoft.com/en-us/magazine/ff700227.aspx" target="_blank" rel="noopener"
>Powershell Remoting&lt;/a> to have been set up on the server which may or may not be available to you in your environment.&lt;/p>
&lt;p>IMPORTANT NOTE – The script does not include any methods for resolving orphaned users so you will need to test and then add your own solution to the script.&lt;/p>
&lt;h4 id="check-mirroring-status">check mirroring status&lt;/h4>
&lt;p>Lastly you want to check that the script has run successfully and that mirroring is synchronised (I am from the UK!!) To do this I check that time and file used for the last database backup &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/1860/identify-when-a-sql-server-database-was-restored-the-source-and-backup-date/" target="_blank" rel="noopener"
>using this script&lt;/a>&lt;/p>
&lt;pre>&lt;code>#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 1 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize –Wrap
&lt;/code>&lt;/pre>
&lt;p>and that mirroring has synchronised using the following Powershell command&lt;/p>
&lt;pre>&lt;code>$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>Depending on your needs you may add some error checking using the results of the above scripts. As I said at the top of the post, you can turn this script into a function and call it at will or add it to an Agent Job for regular scheduling or just kept in a folder ready to be run when required. The choice is yours but all usual rules apply. Don’t believe anything you read on this blog post, don’t run any scripts on production, test before running any scripts, understand what the code is doing before you run it or I am not responsible if you break anything&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: Refresh Mirrored Database
Author: Rob Sewell https://blog.robsewell.com
Requires: Invoke-SQLCMD2 (included)
Version History:
1.2 22/08/2014
.SYNOPSIS
Refreshes a mirrored database
.DESCRIPTION
This script will refresh a mirrored database, recreate mirroring and chekc status of mirroring.
Further details on the website
Requires the variables at the top of the script to be filled in
IMPORTANT - Orpahaned users are not resolved with this acript without additions. See blog post for options
#&amp;gt;
# Load Invoke-SQLCMD2
#Load the assemblies the script requires
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Management.Common&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoEnum&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.Smo&amp;quot; );
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer.SmoExtended &amp;quot; );
[void][System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;Microsoft.SqlServer.ConnectionInfo&amp;quot;)
[System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;System.Windows.Forms&amp;quot;)|Out-Null
# Set up some variables
$PrincipalServer = '' # Enter Principal Server Name
$MirrorServer = '' # Enter Mirror Server Name
$DBName = '' # Enter Database Name
$FileShare = '' # Enter FileShare with trailing slash
$LocationReplace = $FileShare + $DBName + 'Refresh.bak'
$LocationFUll = $FileShare + $DBName + 'formirroring.bak'
$LocationTran = $FileShare + $DBName + 'formirroring.trn'
$PrincipalEndPoint = 'TCP://SERVERNAME:5022' # Change as required
$MirrorEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$WitnessEndpoint = 'TCP://SERVERNAME:5022' # Change as required
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
######################
&amp;lt;#
.SYNOPSIS
Runs a T-SQL script.
.DESCRIPTION
Runs a T-SQL script. Invoke-Sqlcmd2 only returns message output, such as the output of PRINT statements when -verbose parameter is specified
.INPUTS
None
You cannot pipe objects to Invoke-Sqlcmd2
.OUTPUTS
System.Data.DataTable
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;SELECT login_time AS 'StartTime' FROM sysprocesses WHERE spid = 1&amp;quot;
This example connects to a named instance of the Database Engine on a computer and runs a basic T-SQL query.
StartTime
-----------
2010-08-12 21:21:03.593
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -InputFile &amp;quot;C:\MyFolder\tsqlscript.sql&amp;quot; | Out-File -filePath &amp;quot;C:\MyFolder\tsqlscript.rpt&amp;quot;
This example reads a file containing T-SQL statements, runs the file, and writes the output to another file.
.EXAMPLE
Invoke-Sqlcmd2 -ServerInstance &amp;quot;MyComputer\MyInstance&amp;quot; -Query &amp;quot;PRINT 'hello world'&amp;quot; -Verbose
This example uses the PowerShell -Verbose parameter to return the message output of the PRINT command.
VERBOSE: hello world
.NOTES
Version History
v1.0 - Chad Miller - Initial release
v1.1 - Chad Miller - Fixed Issue with connection closing
v1.2 - Chad Miller - Added inputfile, SQL auth support, connectiontimeout and output message handling. Updated help documentation
v1.3 - Chad Miller - Added As parameter to control DataSet, DataTable or array of DataRow Output type
#&amp;gt;
function Invoke-Sqlcmd2 {
[CmdletBinding()]
param(
[Parameter(Position = 0, Mandatory = $true)] [string]$ServerInstance,
[Parameter(Position = 1, Mandatory = $false)] [string]$Database,
[Parameter(Position = 2, Mandatory = $false)] [string]$Query,
[Parameter(Position = 3, Mandatory = $false)] [string]$Username,
[Parameter(Position = 4, Mandatory = $false)] [string]$Password,
[Parameter(Position = 5, Mandatory = $false)] [Int32]$QueryTimeout = 600,
[Parameter(Position = 6, Mandatory = $false)] [Int32]$ConnectionTimeout = 15,
[Parameter(Position = 7, Mandatory = $false)] [ValidateScript( {test-path $_})] [string]$InputFile,
[Parameter(Position = 8, Mandatory = $false)] [ValidateSet(&amp;quot;DataSet&amp;quot;, &amp;quot;DataTable&amp;quot;, &amp;quot;DataRow&amp;quot;)] [string]$As = &amp;quot;DataRow&amp;quot;
)
if ($InputFile) {
$filePath = $(resolve-path $InputFile).path
$Query = [System.IO.File]::ReadAllText(&amp;quot;$filePath&amp;quot;)
}
$conn = new-object System.Data.SqlClient.SQLConnection
if ($Username)
{ $ConnectionString = &amp;quot;Server={0};Database={1};User ID={2};Password={3};Trusted_Connection=False;Connect Timeout={4}&amp;quot; -f $ServerInstance, $Database, $Username, $Password, $ConnectionTimeout }
else
{ $ConnectionString = &amp;quot;Server={0};Database={1};Integrated Security=True;Connect Timeout={2}&amp;quot; -f $ServerInstance, $Database, $ConnectionTimeout }
&amp;amp;amp;n bsp; $conn.ConnectionString = $ConnectionString
#Following EventHandler is used for PRINT and RAISERROR T-SQL statements. Executed when -Verbose parameter specified by caller
if ($PSBoundParameters.Verbose) {
$conn.FireInfoMessageEventOnUserErrors = $true
$handler = [System.Data.SqlClient.SqlInfoMessageEventHandler] {Write-Verbose &amp;quot;$($_)&amp;quot;}
$conn.add_InfoMessage($handler)
}
$conn.Open()
$cmd = new-object system.Data.SqlClient.SqlCommand($Query, $conn)
$cmd.CommandTimeout = $QueryTimeout
$ds = New-Object system.Data.DataSet
$da = New-Object system.Data.SqlClient.SqlDataAdapter($cmd)
[void]$da.fill($ds)
$conn.Close()
switch ($As) {
'DataSet' { Write-Output ($ds) }
'DataTable' { Write-Output ($ds.Tables) }
'DataRow' { Write-Output ($ds.Tables[0]) }
}
} #Invoke-Sqlcmd2
# Check for existence of Backup file with correct name
If (!(Test-Path $LocationReplace)) {
Write-Output &amp;quot; There is no file called &amp;quot;
Write-Output $LocationReplace
Write-Output &amp;quot;Please correct and re-run&amp;quot;
break
}
# Remove Old Backups
if (Test-Path $locationFull) {
Remove-Item $LocationFUll -Force
}
if (Test-Path $locationTran) {
Remove-Item $LocationTran -Force
}
# Create Server objects
$Principal = New-Object Microsoft.SQLServer.Management.SMO.Server $PrincipalServer
$Mirror = New-Object Microsoft.SQLServer.Management.Smo.server $MirrorServer
#Create Database Objects
$DatabaseMirror = $Mirror.Databases[$DBName]
$DatabasePrincipal = $Principal.Databases[$DBName]
# If database is on Mirror server fail it over to Principal
if ($DatabasePrincipal.IsAccessible -eq $False) {
$DatabaseMirror.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Failover)
}
# remove mirroring
$DatabasePrincipal.ChangeMirroringState([Microsoft.SqlServer.Management.Smo.MirroringOption]::Off)
#Set up Restore using refresh backup
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationReplace, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.Devices.add($restoredevice)
#Perform Restore
$restore.sqlrestore($PrincipalServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($PrincipalServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Full Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup
$Backup.Action = $Full
$Backup.BackupSetDescription = &amp;quot;Full Backup of &amp;quot; + $DBName
$Backup.Database = $DatabasePrincipal.Name
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFull, $File)
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Setup Trans Backup
$Backup = New-Object Microsoft.SqlServer.Management.Smo.Backup|Out-Null
$Full = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Database
$Tran = [Microsoft.SQLServer.Management.SMO.BackupActionType]::Log
$File = [Microsoft.SqlServer.Management.Smo.DeviceType]::File
$Backup.Action = $Tran
$Backup.BackupSetDescription = &amp;quot;Log Backup of &amp;quot; + $DBName
$Backup.Database = $DBName
$BackupDevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$Backup.Devices.Add($BackupDevice)
# Perform Backup
$Backup.SqlBackup($PrincipalServer)
# $query = $Backup.Script($PrincipalServer) # if query time&amp;lt; 600 seconds
$Backup.Devices.Remove($BackupDevice)
# Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
#Set up Restore of Full Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServe r.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationFUll, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer) # if query time&amp;lt; 600 seconds
# $query = $restore.Script($MirrorServer) # if using Invoke-SQLCMD2
$restore.Devices.Remove($restoredevice)
# Invoke-Sqlcmd2 -ServerInstance $MirrorServer -Database master -Query $query -ConnectionTimeout 0 # comment out if not used
# Set up Restore of Log Backup on Mirror Server
$restore = New-Object -TypeName Microsoft.SqlServer.Management.Smo.Restore|Out-Null
$restoredevice = New-Object -TypeName Microsoft.SQLServer.Management.Smo.BackupDeviceItem($LocationTran, $File)|Out-Null
$restore.Database = $DBName
$restore.ReplaceDatabase = $True
$restore.NoRecovery = $true
$restore.Devices.add($restoredevice)
$restore.sqlrestore($MirrorServer)
$restore.Devices.Remove($restoredevice)
#Recreate Mirroring
$DatabaseMirror.MirroringPartner = $PrincipalEndPoint
$DatabaseMirror.Alter()
$DatabasePrincipal.MirroringPartner = $MirrorEndpoint
$DatabasePrincipal.MirroringWitness = $WitnessEndpoint
$DatabasePrincipal.Alter()
# Resolve Orphaned Users if needed
#Check that correct file and backup date used
$query = &amp;quot;SELECT TOP 20 [rs].[destination_database_name] as 'database',
[rs].[restore_date] as 'restoredate',
[bs].[backup_finish_date] as 'backuptime',
[bmf].[physical_device_name] as 'Filename'
FROM msdb..restorehistory rs
INNER JOIN msdb..backupset bs
ON [rs].[backup_set_id] = [bs].[backup_set_id]
INNER JOIN msdb..backupmediafamily bmf
ON [bs].[media_set_id] = [bmf].[media_set_id]
ORDER BY [rs].[restore_date] DESC&amp;quot;
Invoke-Sqlcmd2 -ServerInstance $PrincipalServer -Database msdb -Query $query |Format-Table -AutoSize -Wrap
$DatabasePrincipal | select Name, MirroringStatus, IsAccessible |Format-Table -AutoSize
&lt;/code>&lt;/pre></description></item><item><title>Enable CLR with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/enable-clr-with-powershell/</link><pubDate>Mon, 05 May 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/enable-clr-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/05/050514_0904_enableclrwi2.png" alt="Featured image of post Enable CLR with Powershell" />&lt;p>I had an email last night from someone who attended my PowerShell Box of Tricks session at &lt;a class="link" href="http://sqlsouthwest.co.uk/sqlsat269/" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>&lt;/p>
&lt;p>He was getting an error whilst trying to set CLR Enabled during an automatic install and asked if I had any ideas. The error he had was related to Invoke-SQLcmd and the method he was calling the PowerShell script&lt;/p>
&lt;p>I was unable to replicate his problem on my servers so I looked at other methods that may assist as well as following up with him to try and understand what was causing his issue. In doing so I worked out the following method to change the CLR Enabled setting by SMO and thought it worth a blog post to share&lt;/p>
&lt;p>One way around his issue is to define and then call &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/7985b7ef-ed89-4dfd-b02a-433cc4e30894" target="_blank" rel="noopener"
>Invoke-SQLCmd2 by Chad Miller&lt;/a> within his script. So his script would look in part as follows&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/05/050514_0904_enableclrwi1.png"
loading="lazy"
>&lt;/p>
&lt;p>However, I prefer to use SMO so I examined the Server SMO as follows notice the “.” for local server&lt;/p>
&lt;pre>&lt;code>$srv = New-Object Microsoft.SQLServer.Management.SMO.Server .
$srv |gm
&lt;/code>&lt;/pre>
&lt;p>And noticed the Configuration property&lt;/p>
&lt;pre>&lt;code> $srv.Configuration |Get-Member
&lt;/code>&lt;/pre>
&lt;p>Enabled me to see the IsCLREnabled Property and using Get-Member I could see that the config value was settable&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/05/050514_0904_enableclrwi2.png"
loading="lazy"
>&lt;/p>
&lt;p>With this information I could write a simple script to alter the settings.&lt;/p>
&lt;p>Prior to running the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/05/050514_0904_enableclrwi3.png"
loading="lazy"
>&lt;/p>
&lt;p>We then run the following script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/05/050514_0904_enableclrwi4.png"
loading="lazy"
>&lt;/p>
&lt;p>Line 1 creates a Server SMO object there is a “.” to denote local server at the end of the line although you can use the server name as well&lt;/p>
&lt;p>Line 4 sets the configvalue for the IsCLREnabled property&lt;/p>
&lt;p>And Line 5 Alters the Config object, essentially running the reconfigure&lt;/p>
&lt;p>After running the script&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/05/050514_0904_enableclrwi5.png"
loading="lazy"
>&lt;/p>
&lt;p>Hopefully this short post shows how easy it is to set SQL Server configuration values with Powershell using SMO&lt;/p>
&lt;p>Any questions or comments please feel free to ask&lt;/p></description></item><item><title>Listing the SQL Server SysAdmins With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/listing-the-sql-server-sysadmins-with-powershell/</link><pubDate>Mon, 14 Apr 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/listing-the-sql-server-sysadmins-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/04/2014-04-12_152433.jpg" alt="Featured image of post Listing the SQL Server SysAdmins With PowerShell" />&lt;p>A very short blog today just to pass on this little script.&lt;/p>
&lt;p>I was required to list all of the SysAdmins across a large estate. Obviously I turned to PowerShell 🙂&lt;/p>
&lt;p>I iterated through my server list collection and then created a server SMO object and used the EnumServerRoleMembers method to display all of the sysadmin members&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/04/2014-04-12_152433.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/04/2014-04-12_152433.jpg"
loading="lazy"
alt="2014-04-12_152433"
>&lt;/a>&lt;/p>
&lt;p>This will work on SQL2000 – SQL2012. You can see how you can easily change the rolename in the script to enumerate other server roles.&lt;/p>
&lt;p>Another way you could do it is to use the query&lt;/p>
&lt;pre>&lt;code>SELECT c.name AS Sysadmin_Server_Role_Members
FROM sys.server_principals a
INNER JOIN sys.server_role_members b
ON a.principal_id = b.role_principal_id AND a.type = 'R' AND a.name ='sysadmin'
INNER JOIN sys.server_principals c
ON b.member_principal_id = c.principal_id
&lt;/code>&lt;/pre>
&lt;p>and pass that with &lt;code>Invoke-SQLCMD&lt;/code> through to every server (if you had to use Powershell 🙂 ). That query won’t work with SQL 2000 though&lt;/p></description></item><item><title>How I Check Hundreds of SQL Agent Jobs in 60 Seconds with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-check-hundreds-of-sql-agent-jobs-in-60-seconds-with-powershell/</link><pubDate>Mon, 31 Mar 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/how-i-check-hundreds-of-sql-agent-jobs-in-60-seconds-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/03/033114_2017_howicheckhu6.png" alt="Featured image of post How I Check Hundreds of SQL Agent Jobs in 60 Seconds with Powershell" />&lt;h2 id="editors-note">Editors Note&lt;/h2>
&lt;p>This is still all valid but nowadays you would be much better off using dbatools to gather the information and the ImportExcel module to add it to an Excel sheet :-)&lt;/p>
&lt;h1 id="original-post">Original Post&lt;/h1>
&lt;p>Checking that your Agent Jobs have completed successfully is a vital part of any DBA’s responsibility. It is essential to ensure that all of the hard work you have put into setting up the jobs can be quickly and easily checked. In a large estate this can be very time consuming and if done manually prone to human error. I have repeatedly mentioned &lt;!-- raw HTML omitted -->John Sansoms Blog Post entitled “The Best DBAs Automate Everything” &lt;!-- raw HTML omitted -->and I follow that advice. Today I will share with you one fo the first scripts that I wrote.&lt;/p>
&lt;p>When I started as a DBA I was told that my first job every morning was to check the Agent Jobs and resolve any errors. This is still something I do first before anything else. (Except coffee, experience has taught me that you get your coffee before you log into your computer otherwise on the bad days you can miss out on coffee for many an hour) I have two scripts to do this. The first sends me an email if the number of failed jobs on a server is greater than zero. This helps me to quickly and simply identify where to start in the case of multiple failures and is also a backup to the second script.&lt;/p>
&lt;p>The second script runs on a different server and creates an excel worksheet and colour codes it. This makes it very simple to quickly scroll through the sheet and spot any red cells which designate failed jobs and also provides a nice easy to understand method to show management that on that specific day everything went well (or badly)&lt;/p>
&lt;p>As with any Powershell script which manipulates Office applications you first need to create an object and add the workbook and worksheet to it. I also set a filename date variable and a Date variable for the Sheet.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu1.png"
loading="lazy"
alt="howicheckhu1"
>&lt;/a>&lt;/p>
&lt;p>When you use Powershell to manipulate Excel you can access individual cells by identifying them by Row and Column. I use this to create a description for the work book as follows&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu2.png"
loading="lazy"
alt="howicheckhu2"
>&lt;/a>&lt;/p>
&lt;p>There are lots of properties that you can play with within Excel. As with any Powershell the best way to find what you need is to use the &lt;code>Get-Member&lt;/code> Cmdlet. If you run&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">($cells.item(1,3)|Get-Member).Count
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>You will see that there are 185 Methods and Properties available to you (in Office 2013 on Windows 8.1)
The snippet above creates the following&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu3.png"
loading="lazy"
alt="howicheckhu3"
>&lt;/a>&lt;/p>
&lt;p>As you can see we are going to colour code the Job Status according to the three available results Successful, Failed and Unknown. We are also going to colour code the date column to see when the job was last run, this will enable you to easily identify if the last time the job ran it was successful but last night it didn’t kick off for some reason.&lt;/p>
&lt;p>The next step is a fairly standard loop through available servers by picking them from a SQLServers text file, a list of the server names (ServerName\Instance if required) that you wish to check. You could also just create an array of server names or pick them from a table with &lt;code>Invoke-SQLCmd&lt;/code> but which ever way you do it you need to be able to iterate through the array and then the &lt;code>.Jobs&lt;/code> Collection in the &lt;code>JobServer&lt;/code> Namespace as follows&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu4.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu4.png"
loading="lazy"
alt="howicheckhu4"
>&lt;/a>&lt;/p>
&lt;p>What the script then does is to use the following properties of the &lt;code>$Job&lt;/code> object and write the Excel File according to the logic in the description&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt">1
&lt;/span>&lt;span class="lnt">2
&lt;/span>&lt;span class="lnt">3
&lt;/span>&lt;span class="lnt">4
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">$Job.Name
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job.IsEnabled
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job.LastRunOutcome
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Job.LastRunDate
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>To finish up save the workbook to a share available to all of the DBA Team and quit Excel. Notice that I use a double whammy to make sure Excel is really gone. First I quit the .com object and then I stop the process. I do this because I found that on my server quitting the .com object left the Excel process running and I ended up with dozens and dozens of them. If you have Excel open before you run this script either comment out the last line or save your work (You should save your work anyway regulary!)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu5.png"
loading="lazy"
alt="howicheckhu5"
>&lt;/a>&lt;/p>
&lt;p>As always I take no responsibility for your environment, that’s your Job! Don’t run this on Production unless you know what it is doing and are happy that you have first tested it somewhere safely away from any important systems. Make sure that you understand the correct time to run this job and have qualified the impact on the box it is running on.
Here is a screen shot of the finished Excel Sheet&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/033114_2017_howicheckhu6.png"
loading="lazy"
alt="howicheckhu6"
>&lt;/a>&lt;/p>
&lt;p>As you can see the Data Transfer Job needs investigation! The reason I add to yellow rows above and below each servers list of jobs is to help me identify any server that is not responding as that will be easily recognised as two lots of yellow with nothing between them
I have considered improving this script by inputting the data into a database and running a report from that database but have not had the need to do so yet.&lt;/p>
&lt;p>Here is the script&lt;/p>
&lt;div class="highlight">&lt;div class="chroma">
&lt;table class="lntable">&lt;tr>&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code>&lt;span class="lnt"> 1
&lt;/span>&lt;span class="lnt"> 2
&lt;/span>&lt;span class="lnt"> 3
&lt;/span>&lt;span class="lnt"> 4
&lt;/span>&lt;span class="lnt"> 5
&lt;/span>&lt;span class="lnt"> 6
&lt;/span>&lt;span class="lnt"> 7
&lt;/span>&lt;span class="lnt"> 8
&lt;/span>&lt;span class="lnt"> 9
&lt;/span>&lt;span class="lnt"> 10
&lt;/span>&lt;span class="lnt"> 11
&lt;/span>&lt;span class="lnt"> 12
&lt;/span>&lt;span class="lnt"> 13
&lt;/span>&lt;span class="lnt"> 14
&lt;/span>&lt;span class="lnt"> 15
&lt;/span>&lt;span class="lnt"> 16
&lt;/span>&lt;span class="lnt"> 17
&lt;/span>&lt;span class="lnt"> 18
&lt;/span>&lt;span class="lnt"> 19
&lt;/span>&lt;span class="lnt"> 20
&lt;/span>&lt;span class="lnt"> 21
&lt;/span>&lt;span class="lnt"> 22
&lt;/span>&lt;span class="lnt"> 23
&lt;/span>&lt;span class="lnt"> 24
&lt;/span>&lt;span class="lnt"> 25
&lt;/span>&lt;span class="lnt"> 26
&lt;/span>&lt;span class="lnt"> 27
&lt;/span>&lt;span class="lnt"> 28
&lt;/span>&lt;span class="lnt"> 29
&lt;/span>&lt;span class="lnt"> 30
&lt;/span>&lt;span class="lnt"> 31
&lt;/span>&lt;span class="lnt"> 32
&lt;/span>&lt;span class="lnt"> 33
&lt;/span>&lt;span class="lnt"> 34
&lt;/span>&lt;span class="lnt"> 35
&lt;/span>&lt;span class="lnt"> 36
&lt;/span>&lt;span class="lnt"> 37
&lt;/span>&lt;span class="lnt"> 38
&lt;/span>&lt;span class="lnt"> 39
&lt;/span>&lt;span class="lnt"> 40
&lt;/span>&lt;span class="lnt"> 41
&lt;/span>&lt;span class="lnt"> 42
&lt;/span>&lt;span class="lnt"> 43
&lt;/span>&lt;span class="lnt"> 44
&lt;/span>&lt;span class="lnt"> 45
&lt;/span>&lt;span class="lnt"> 46
&lt;/span>&lt;span class="lnt"> 47
&lt;/span>&lt;span class="lnt"> 48
&lt;/span>&lt;span class="lnt"> 49
&lt;/span>&lt;span class="lnt"> 50
&lt;/span>&lt;span class="lnt"> 51
&lt;/span>&lt;span class="lnt"> 52
&lt;/span>&lt;span class="lnt"> 53
&lt;/span>&lt;span class="lnt"> 54
&lt;/span>&lt;span class="lnt"> 55
&lt;/span>&lt;span class="lnt"> 56
&lt;/span>&lt;span class="lnt"> 57
&lt;/span>&lt;span class="lnt"> 58
&lt;/span>&lt;span class="lnt"> 59
&lt;/span>&lt;span class="lnt"> 60
&lt;/span>&lt;span class="lnt"> 61
&lt;/span>&lt;span class="lnt"> 62
&lt;/span>&lt;span class="lnt"> 63
&lt;/span>&lt;span class="lnt"> 64
&lt;/span>&lt;span class="lnt"> 65
&lt;/span>&lt;span class="lnt"> 66
&lt;/span>&lt;span class="lnt"> 67
&lt;/span>&lt;span class="lnt"> 68
&lt;/span>&lt;span class="lnt"> 69
&lt;/span>&lt;span class="lnt"> 70
&lt;/span>&lt;span class="lnt"> 71
&lt;/span>&lt;span class="lnt"> 72
&lt;/span>&lt;span class="lnt"> 73
&lt;/span>&lt;span class="lnt"> 74
&lt;/span>&lt;span class="lnt"> 75
&lt;/span>&lt;span class="lnt"> 76
&lt;/span>&lt;span class="lnt"> 77
&lt;/span>&lt;span class="lnt"> 78
&lt;/span>&lt;span class="lnt"> 79
&lt;/span>&lt;span class="lnt"> 80
&lt;/span>&lt;span class="lnt"> 81
&lt;/span>&lt;span class="lnt"> 82
&lt;/span>&lt;span class="lnt"> 83
&lt;/span>&lt;span class="lnt"> 84
&lt;/span>&lt;span class="lnt"> 85
&lt;/span>&lt;span class="lnt"> 86
&lt;/span>&lt;span class="lnt"> 87
&lt;/span>&lt;span class="lnt"> 88
&lt;/span>&lt;span class="lnt"> 89
&lt;/span>&lt;span class="lnt"> 90
&lt;/span>&lt;span class="lnt"> 91
&lt;/span>&lt;span class="lnt"> 92
&lt;/span>&lt;span class="lnt"> 93
&lt;/span>&lt;span class="lnt"> 94
&lt;/span>&lt;span class="lnt"> 95
&lt;/span>&lt;span class="lnt"> 96
&lt;/span>&lt;span class="lnt"> 97
&lt;/span>&lt;span class="lnt"> 98
&lt;/span>&lt;span class="lnt"> 99
&lt;/span>&lt;span class="lnt">100
&lt;/span>&lt;span class="lnt">101
&lt;/span>&lt;span class="lnt">102
&lt;/span>&lt;span class="lnt">103
&lt;/span>&lt;span class="lnt">104
&lt;/span>&lt;span class="lnt">105
&lt;/span>&lt;span class="lnt">106
&lt;/span>&lt;span class="lnt">107
&lt;/span>&lt;span class="lnt">108
&lt;/span>&lt;span class="lnt">109
&lt;/span>&lt;span class="lnt">110
&lt;/span>&lt;span class="lnt">111
&lt;/span>&lt;span class="lnt">112
&lt;/span>&lt;span class="lnt">113
&lt;/span>&lt;span class="lnt">114
&lt;/span>&lt;span class="lnt">115
&lt;/span>&lt;span class="lnt">116
&lt;/span>&lt;span class="lnt">117
&lt;/span>&lt;span class="lnt">118
&lt;/span>&lt;span class="lnt">119
&lt;/span>&lt;span class="lnt">120
&lt;/span>&lt;span class="lnt">121
&lt;/span>&lt;span class="lnt">122
&lt;/span>&lt;span class="lnt">123
&lt;/span>&lt;span class="lnt">124
&lt;/span>&lt;span class="lnt">125
&lt;/span>&lt;span class="lnt">126
&lt;/span>&lt;span class="lnt">127
&lt;/span>&lt;span class="lnt">128
&lt;/span>&lt;span class="lnt">129
&lt;/span>&lt;span class="lnt">130
&lt;/span>&lt;span class="lnt">131
&lt;/span>&lt;span class="lnt">132
&lt;/span>&lt;span class="lnt">133
&lt;/span>&lt;span class="lnt">134
&lt;/span>&lt;span class="lnt">135
&lt;/span>&lt;span class="lnt">136
&lt;/span>&lt;span class="lnt">137
&lt;/span>&lt;span class="lnt">138
&lt;/span>&lt;span class="lnt">139
&lt;/span>&lt;span class="lnt">140
&lt;/span>&lt;span class="lnt">141
&lt;/span>&lt;span class="lnt">142
&lt;/span>&lt;span class="lnt">143
&lt;/span>&lt;span class="lnt">144
&lt;/span>&lt;span class="lnt">145
&lt;/span>&lt;span class="lnt">146
&lt;/span>&lt;span class="lnt">147
&lt;/span>&lt;span class="lnt">148
&lt;/span>&lt;span class="lnt">149
&lt;/span>&lt;span class="lnt">150
&lt;/span>&lt;span class="lnt">151
&lt;/span>&lt;span class="lnt">152
&lt;/span>&lt;span class="lnt">153
&lt;/span>&lt;span class="lnt">154
&lt;/span>&lt;span class="lnt">155
&lt;/span>&lt;span class="lnt">156
&lt;/span>&lt;span class="lnt">157
&lt;/span>&lt;span class="lnt">158
&lt;/span>&lt;span class="lnt">159
&lt;/span>&lt;/code>&lt;/pre>&lt;/td>
&lt;td class="lntd">
&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl">#############################################################################################
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># NAME: Agent Job Status to Excel.ps1
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># DATE:22/07/2013
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># COMMENTS: Iterates through the sqlservers.txt file to populate
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Excel File with colour coded status
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># WARNING - This will stop ALL Excel Processes. Read the Blog Post for more info
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># ————————————————————————
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Get List of sql servers to check
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$sqlservers = Get-Content &amp;#39;&amp;#39;; # from a file or a SQL query or whatever
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a .com object for Excel
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl = new-object -comobject excel.application
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.Visible = $true # Set this to False when you run in production
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb = $xl.Workbooks.Add()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$ws = $wb.Worksheets.Item(1)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$date = Get-Date -format f
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Filename = ( get-date ).ToString(&amp;#39;ddMMMyyyHHmm&amp;#39;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells = $ws.Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Create a description
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(1, 3).font.bold = $True
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(1, 3).font.size = 18
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(1, 3) = &amp;#34;Back Up Report $date&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(5, 9) = &amp;#34;Last Job Run Older than 1 Day&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(5, 8).Interior.ColorIndex = 43
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(4, 9) = &amp;#34;Last Job Run Older than 7 Days&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(4, 8).Interior.ColorIndex = 53
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(7, 9) = &amp;#34;Successful Job&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(7, 8).Interior.ColorIndex = 4
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(8, 9) = &amp;#34;Failed Job&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(8, 8).Interior.ColorIndex = 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(9, 9) = &amp;#34;Job Status Unknown&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item(9, 8).Interior.ColorIndex = 15
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#define some variables to control navigation
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$row = 3
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">#insert column headings
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col) = &amp;#34;Server&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col).font.size = 16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cells.item($row, $col).Columnwidth = 10
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col) = &amp;#34;Job Name&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col).font.size = 16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cells.item($row, $col).Columnwidth = 40
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col) = &amp;#34;Enabled?&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col).font.size = 16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cells.item($row, $col).Columnwidth = 15
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col) = &amp;#34;Outcome&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col).font.size = 16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cells.item($row, $col).Columnwidth = 12
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col) = &amp;#34;Last Run Time&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$cells.item($row, $col).font.size = 16
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$Cells.item($row, $col).Columnwidth = 15
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Load SMO extension
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">[System.Reflection.Assembly]::LoadWithPartialName(&amp;#34;Microsoft.SqlServer.Smo&amp;#34;) | Out-Null;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"># Loop through each sql server from sqlservers.txt
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">foreach ($sqlserver in $sqlservers) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Create an SMO Server object
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $srv = New-Object &amp;#34;Microsoft.SqlServer.Management.Smo.Server&amp;#34; $sqlserver;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # For each jobs on the server
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> foreach ($job in $srv.JobServer.Jobs) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobName = $job.Name;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobEnabled = $job.IsEnabled;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $jobLastRunOutcome = $job.LastRunOutcome;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $Time = $job.LastRunDate ;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Set Fill Colour for Job Enabled
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($jobEnabled -eq &amp;#34;FALSE&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> { $colourenabled = &amp;#34;2&amp;#34;}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else {$colourenabled = &amp;#34;48&amp;#34; }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Set Fill Colour for Failed jobs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($jobLastRunOutcome -eq &amp;#34;Failed&amp;#34;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $colour = &amp;#34;3&amp;#34; # RED
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Set Fill Colour for Uknown jobs
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Elseif ($jobLastRunOutcome -eq &amp;#34;Unknown&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> { $colour = &amp;#34;15&amp;#34;} #GREY
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> else {$Colour = &amp;#34;4&amp;#34;} # Success is Green
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $col = 2
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col) = $sqlserver
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col) = $jobName
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col) = $jobEnabled
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Set colour of cells for Disabled Jobs to Grey
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col).Interior.ColorIndex = $colourEnabled
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($colourenabled -eq &amp;#34;48&amp;#34;) {
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 1 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 2 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 3 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 4 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 5 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 6 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row , 7 ).Interior.ColorIndex = 48
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col) = &amp;#34;$jobLastRunOutcome&amp;#34;
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col).Interior.ColorIndex = $colour
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Reset Disabled Jobs Fill Colour
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> if ($colourenabled -eq &amp;#34;48&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> {$cells.item($Row, $col).Interior.ColorIndex = 48}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $col++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $cells.item($Row, $col) = $Time
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> #Set teh Fill Colour for Time Cells
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If ($Time -lt ($(Get-Date).AddDays(-1)))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> { $cells.item($Row, $col).Interior.ColorIndex = 43}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> If ($Time -lt ($(Get-Date).AddDays(-7)))
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> { $cells.item($Row, $col).Interior.ColorIndex = 53}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> }
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> # Add two Yellow Rows
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ws.rows.item($Row).Interior.ColorIndex = 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $ws.rows.item($Row).Interior.ColorIndex = 6
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> $row++
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">}
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$wb.Saveas(&amp;#34;C:\temp\Test$filename.xlsx&amp;#34;)
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">$xl.quit()
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">Stop-Process -Name EXCEL
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/td>&lt;/tr>&lt;/table>
&lt;/div>
&lt;/div>&lt;p>If you have any questions please get in touch&lt;/p></description></item><item><title>Rationalisation of Database with Powershell and T-SQL part two</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/rationalisation-of-database-with-powershell-and-t-sql-part-two/</link><pubDate>Mon, 03 Mar 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/rationalisation-of-database-with-powershell-and-t-sql-part-two/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/03/030314_2100_rationalisa1.png" alt="Featured image of post Rationalisation of Database with Powershell and T-SQL part two" />&lt;p>In the &lt;a class="link" href="https://blog.robsewell.com/rationalisation-of-database-with-powershell-and-t-sql-part-one/" target="_blank" rel="noopener"
>previous post&lt;/a> I showed the script to create an Excel Workbook, colour coded showing the last used date for all of the databases on servers in my sqlservers.txt file. After gathering that information over several months, there is then a requirement for someone to make a decision as to which databases can be removed.&lt;/p>
&lt;p>Obviously there will be some databases that are read-only or if not set specifically as read-only may only be used for reference without data being added. You should hopefully have knowledge of these databases and be able to take them off the list quickly.&lt;/p>
&lt;p>There are other challenges for a DBA to overcome prior to any action. Many questions need to be answered such as&lt;/p>
&lt;p>Who owns the database?&lt;br>
Who is the service owner responsible for the service/application in use by the database?&lt;br>
Even though they may be the service owner who will ultimately sign off permission to remove the database are they aware of how important it is for their people? Or what times of the year it is important to them?&lt;br>
You may find test and development databases that have not been used for months but will they be required next week?&lt;br>
Is it important enough for them to take the time to give the permission?&lt;/p>
&lt;p>And plenty more… Add some in the comments below.&lt;/p>
&lt;p>Our &lt;a class="link" href="http://www.johnsansom.com/the-database-administrators-primary-responsibility/" target="_blank" rel="noopener"
>Primary responsibility&lt;/a> is the data. We need to be able to ensure that the data is safe and can be made available quickly and easily. In this situation we need to have a valid backup and a quick and easy method of restoring it. I chose to solve this by creating a T-SQL script which will :-&lt;/p>
&lt;ul>
&lt;li>Perform a &lt;a class="link" href="http://technet.microsoft.com/en-us/library/ms176064.aspx" target="_blank" rel="noopener"
>DBCC CHECKDB&lt;/a> on the database&lt;/li>
&lt;li>&lt;a class="link" href="http://technet.microsoft.com/en-us/library/ms187893.aspx" target="_blank" rel="noopener"
>Backup the database with CHECKSUM&lt;/a>&lt;/li>
&lt;li>Perform a &lt;a class="link" href="http://technet.microsoft.com/en-us/library/ms188902.aspx" target="_blank" rel="noopener"
>VERIFY ONLY&lt;/a> restore of the database&lt;/li>
&lt;li>Drop the database&lt;/li>
&lt;li>Create an agent job to restore the database from that backup&lt;/li>
&lt;/ul>
&lt;p>The reasoning for these steps is best explained by watching &lt;a class="link" href="http://www.youtube.com/watch?v=Ah0jabU9G8o" target="_blank" rel="noopener"
>this video&lt;/a> and yes I always perform the last step too J&lt;/p>
&lt;p>I could have used PowerShell to do this by examining The SMO for the Server and the JobServer but this time I decided to challenge myself by writing it in T-SQL as I am weaker in that area. The script below is the result of that work. It works for me. I expect that there are other ways of doing this and please feel free to point out any errors or suggestions. That is how I learn. Hopefully these posts will be of use to other DBAs like myself.&lt;/p>
&lt;p>As always with anything you read on the internet. Validate and test. This script works for me on SQL Servers 2005, 2008,2008R2 and 2012 but if you are thinking of running it in your own Production Environment – DON’T.&lt;/p>
&lt;p>Well not until you have tested it somewhere safe first J&lt;/p>
&lt;p>The first challenge I encountered was that I wanted to only have to change the name of the database to be able to run the script and perform all of these steps. That will also lead onto a stored procedure and then I can automate more of this process and schedule at times to suit the database servers as well. I accomplished this by using a temp table and populating it with the variables I will need as shown below&lt;/p>
&lt;pre>&lt;code>-- Drop temp table if it exists
IF OBJECT_ID('tempdb..#vars') IS NOT NULL
DROP TABLE #vars
-- Create table to hold global variable
create table #vars (DBName nvarchar(50), PATH nvarchar(300),DataName nvarchar(50),LogName nvarchar (50),DataLoc nvarchar (256),LogLoc nvarchar (256))
insert into #vars (DBName) values ('DATABASENAME')
-- Declare and set variables
DECLARE @PATH nvarchar(300)
Set @Path = (SELECT 'PATH TO RATIONALISATION FOLDER WITH TRAILING SLASH' + @DBName + '_LastGolden_' + + convert(varchar(50),GetDate(),112) + '.bak' )
DECLARE @DataName nvarchar(50)
Set @DataName = (SELECT f.name
FROM sys.master_files F
join sys.databases D
on&amp;amp;amp;nbsp;d.database_id = f.database_id
WHERE F.type = 0
AND d.Name = @DBNAME)
-- Print @DataName
DECLARE @LogName nvarchar (50)
Set @LogName = (SELECT f.name
FROM sys.master_files F
join sys.databases D
on&amp;amp;amp;nbsp;d.database_id = f.database_id
WHERE F.type = 1
AND d.Name = @DBNAME)
-- PRINT @LogName
Declare @DataLoc nvarchar (256)
Set @DataLoc = (SELECT f.physical_name
FROM sys.master_files F
join sys.databases D
on&amp;amp;amp;nbsp;d.database_id = f.database_id
WHERE F.type = 0
AND d.Name = @DBNAME)
--Print @DataLoc
Declare @LogLoc nvarchar (256)
Set @LogLoc = (SELECT f.physical_name
FROM sys.master_files F
join sys.databases D
on&amp;amp;amp;nbsp;d.database_id = f.database_id
WHERE F.type = 1
AND d.Name = @DBNAME)
--Print @LogLoc
update #vars Set PATH = @PATH
update #vars Set DataName = @DataName
update #vars Set LogName = @LogName
update #vars Set DataLoc = @DataLoc
update #vars Set LogLoc = @LogLoc
-- Select * from #vars
&lt;/code>&lt;/pre>
&lt;p>I then use the variables throughout the script by selecting them from the temp table as follows&lt;/p>
&lt;pre>&lt;code>DECLARE @DBName nvarchar(50)
Set @DBName = (Select DBNAme from #vars)&amp;amp;lt;code&amp;amp;gt;
&lt;/code>&lt;/pre>
&lt;p>And using the variables to create and execute the T-SQL for each of the steps above.&lt;/p>
&lt;p>It is pointless to move onto the next step of the previous one has failed so I created some error handling as follows&lt;/p>
&lt;pre>&lt;code>if @@error != 0 raiserror('Rationalisation Script failed at Verify Restore', 20, -1) with log
GO
&lt;/code>&lt;/pre>
&lt;p>I created the T-SQL for the agent job by first creating the restore script and adding it to a variable and then right-clicking on a previously created restore database job and using the script to new window command&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/03/030314_2100_rationalisa1.png"
loading="lazy"
>&lt;/p>
&lt;p>It was then a case of adding single quotes and reading the code until it would successfully run&lt;/p>
&lt;pre>&lt;code>/***
Rationalisation Script
Script to Automatically Backup, Drop and create Agent Job to restore from that backup
AUTHOR - Rob Sewell https://blog.robsewell.com
DATE - 19/01/2014
USAGE - You need to Change the Database Name after &amp;quot; insert #vars values (' &amp;quot;
You also need to check that the folder after &amp;quot; Set @Path = (SELECT ' &amp;quot; is correct and exists
and Find and replace both entries for THEBEARD\Rob with the account that will be the owner of the job and the database owner
Once this has been run AND you have checked that it has successfully backed up the database and created the job and you have checked hte job works
You may delete the backups but keep the backup folder under UserDbs
***/
--Drop temp table if it exists
IF OBJECT_ID('tempdb..#vars') IS NOT NULL
DROP TABLE #vars
--Create table to hold global variable
create table #vars (DBName nvarchar(50), PATH nvarchar(300),DataName nvarchar(50),LogName nvarchar (50),DataLoc nvarchar (256),LogLoc nvarchar (256))
insert into #vars (DBName) values ('SQL2012Ser2012DB'
)
--Declare and set variables
DECLARE @DBName nvarchar(50)
Set @DBName = (Select DBNAme from #vars)
DECLARE @PATH nvarchar(300)
Set @Path = (SELECT 'PATH TO RATIONALISATION FOLDER' + @DBName + '_LastGolden_' + + convert(varchar(50),GetDate(),112) + '.bak' )
DECLARE @DataName nvarchar(50)
Set @DataName = (SELECT f.name
FROM sys.master_files F
join sys.databases D
on
d.database_id = f.database_id
WHERE F.type = 0
AND d.Name = @DBNAME)
--Print @DataName
DECLARE @LogName nvarchar (50)
Set @LogName = (SELECT f.name
FROM sys.master_files F
join sys.databases D
on
d.database_id = f.database_id
WHERE F.type = 1
AND d.Name = @DBNAME)
--PRINT @LogName
Declare @DataLoc nvarchar (256)
Set @DataLoc = (SELECT f.physical_name
FROM sys.master_files F
join sys.databases D
on
d.database_id = f.database_id
WHERE F.type = 0
AND d.Name = @DBNAME)
--Print @DataLoc
Declare @LogLoc nvarchar (256)
Set @LogLoc = (SELECT f.physical_name
FROM sys.master_files F
join sys.databases D
on
d.database_id = f.database_id
WHERE F.type = 1
AND d.Name = @DBNAME)
--Print @LogLoc
update #vars Set PATH = @PATH
update #vars Set DataName = @DataName
update #vars Set LogName = @LogName
update #vars Set DataLoc = @DataLoc
update #vars Set LogLoc = @LogLoc
-- Select * from #vars
-- DBCC
DECLARE @DBCCSQL nvarchar (4000)
SET @DBCCSQL = '
USE [' + @DBName + ']
DBCC CHECKDB WITH NO_INFOMSGS, ALL_ERRORMSGS
'
-- Print @DBCCSQL
EXECUTE(@DBCCSQL)
-- Break out if error raised We need to do some work if there are errors here
if @@error != 0 raiserror('Rationalisation Script failed at DBCC', 20, -1) with log
GO
-- Declare and set variables
DECLARE @DBName nvarchar(50)
Set @DBName = (Select DBNAme from #vars)
DECLARE @PATH nvarchar(300)
Set @Path = (SELECT PATH from #vars)
Declare @BKUPName nvarchar(300)
Set @BKUPName = (SELECT 'Last Golden Backup For ' + @DBName + '- Full Database Backup')
DECLARE @BackupSQL nvarchar (4000)
SET @BackupSQL = '
BACKUP DATABASE [' + @DBName + '] TO DISK = N''' + @PATH + '''
WITH INIT, NAME = N''' + @BKUPName + ''',
CHECKSUM, STATS = 10
'
--- PRINT @BackupSQL
-- Backup database to Golden backup location
EXECUTE(@BackupSQL)
GO
-- Break Out if there are errors here - If there is no backup we don't want to continue
if @@error != 0 raiserror('Rationalisation Script failed at Backup', 20, -1) with log
GO
DECLARE @PATH nvarchar(300)
Set @Path = (SELECT PATH from #vars)
RESTORE VERIFYONLY
FROM DISK = @PATH;
if @@error != 0 raiserror('Rationalisation Script failed at Verify Restore', 20, -1) with log
GO
-- Declare variables for dropping database
DECLARE @DBName nvarchar(50)
Set @DBName = (Select DBNAme from #vars)
DECLARE @DROPSQL nvarchar (4000)
SET @DROPSQL = '
USE [master]
ALTER DATABASE [' + @DBName + '] SET SINGLE_USER WITH ROLLBACK IMMEDIATE
DROP DATABASE [' + @DBName + ']
'
-- PRINT @DROPSQL
--Drop database
EXECUTE(@DROPSQL)
GO
if @@error != 0 raiserror('Rationalisation Script failed at Drop Database', 20, -1) with log
GO
--Declare variables for creating Job
DECLARE @DBName nvarchar(50)
Set @DBName = (Select DBNAme from #vars)
DECLARE @PATH nvarchar(300)
Set @Path = (Select PATH from #vars)
DECLARE @DataName nvarchar(50)
Set @DataName = (Select DataName from #vars)
DECLARE @LogName nvarchar (50)
Set @LogName = (Select LogName from #vars)
Declare @DataLoc nvarchar (256)
Set @DataLoc = (Select DataLoc from #vars)
Declare @LogLoc nvarchar (256)
Set @LogLoc = (Select LogLoc from #vars)
DECLARE @RestoreCommand nvarchar(4000)
Set @RestoreCommand = '''RESTORE DATABASE [' + @DBName + ']
FROM DISK = N''''' + @PATH + '''''
WITH FILE = 1,
MOVE N''''' + @DataName + ''''' TO N''''' + @DataLoc + ''''',
MOVE N''''' + @LogName + ''''' TO N''''' + @LogLoc + ''''',
NOUNLOAD, REPLACE, STATS = 10
'''
--print @RestoreCommand
--Create Job creation tsql
DECLARE @JOBSQL nvarchar (4000)
SET @JOBSQL = 'USE [msdb]
BEGIN TRANSACTION
DECLARE @ReturnCode INT
SELECT @ReturnCode = 0
/****** Object: JobCategory [[Uncategorized (Local)]]] Script Date: 01/18/2014 14:12:04 ******/
IF NOT EXISTS (SELECT name FROM msdb.dbo.syscategories WHERE name=N''[Uncategorized (Local)]'' AND category_class=1)
BEGIN
EXEC @ReturnCode = msdb.dbo.sp_add_category @class=N''JOB'', @type=N''LOCAL'', @name=N''[Uncategorized (Local)]''
IF (@@ERROR &amp;amp;lt;&amp;amp;gt; 0 OR @ReturnCode &amp;amp;lt;&amp;amp;gt; 0) GOTO QuitWithRollback
END
DECLARE @JOBNAME nvarchar(300)
set @JOBNAME = ''Rationlised - - Restore ' + @DBName + ' from Last Golden Backup''
Declare @JobDesc nvarchar(300)
Set @JobDesc = '' Rationalised Database Restore Script for ' + @DBName + '''
DECLARE @jobId BINARY(16)
EXEC @ReturnCode = msdb.dbo.sp_add_job @job_name= @JOBNAME,
@enabled=1,
@notify_level_eventlog=0,
@notify_level_email=0,
@notify_level_netsend=0,
@notify_level_page=0,
@delete_level=0,
@description=@JobDesc,
@category_name=N''[Uncategorized (Local)]'',
@owner_login_name=N''THEBEARD\Rob'', @job_id = @jobId OUTPUT
IF (@@ERROR &amp;amp;lt;&amp;amp;gt; 0 OR @ReturnCode &amp;amp;lt;&amp;amp;gt; 0) GOTO QuitWithRollback
/****** Object: Step [Restore Database] Script Date: 01/18/2014 14:12:04 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N''Restore Database'',
@step_id=1,
@cmdexec_success_code=0,
@on_success_action=3,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N''TSQL'',
@command= ' + @RestoreCommand + ',
@database_name=N''master'',
@flags=4
/****** Object: Step [Set Owner] Script Date: 01/19/2014 10:14:57 ******/
EXEC @ReturnCode = msdb.dbo.sp_add_jobstep @job_id=@jobId, @step_name=N''Set Owner'',
@step_id=2,
@cmdexec_success_code=0,
@on_success_action=1,
@on_success_step_id=0,
@on_fail_action=2,
@on_fail_step_id=0,
@retry_attempts=0,
@retry_interval=0,
@os_run_priority=0, @subsystem=N''TSQL'',
@command=N''USE [' + @DBName + ']
EXEC sp_changedbowner @loginame = N''''THEBEARD\Rob'''', @map = false'',
@database_name=N''master'',
@flags=0
IF (@@ERROR &amp;amp;lt;&amp;amp;gt; 0 OR @ReturnCode &amp;amp;lt;&amp;amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_update_job @job_id = @jobId, @start_step_id = 1
IF (@@ERROR &amp;amp;lt;&amp;amp;gt; 0 OR @ReturnCode &amp;amp;lt;&amp;amp;gt; 0) GOTO QuitWithRollback
EXEC @ReturnCode = msdb.dbo.sp_add_jobserver @job_id = @jobId, @server_name = N''(local)''
IF (@@ERROR &amp;amp;lt;&amp;amp;gt; 0 OR @ReturnCode &amp;amp;lt;&amp;amp;gt; 0) GOTO QuitWithRollback
COMMIT TRANSACTION
GOTO EndSave
QuitWithRollback:
IF (@@TRANCOUNT &amp;amp;gt; 0) ROLLBACK TRANSACTION
EndSave:
'
--PRINT @JOBSQL
--Create Agent Job
EXECUTE(@JOBSql)
if @@error != 0 raiserror('Rationalisation Script failed at Create Job', 20, -1) with log
GO
DROP Table #vars
&lt;/code>&lt;/pre>
&lt;p>The process I have used is to change the database name in the script and run it and then run the Agent Job and check the database has been created. Then and only then can I drop the database and disable any jobs for the database. Yes that was the last step in the video J as Grant says “a file is just a file, a backup is a restored database”&lt;/p>
&lt;p>Using this script you can reduce the footprint and load on your servers by removing unneeded or unused databases whilst still guaranteeing that should there be a requirement for them you KNOW you can easily restore them. You will still need to take some additional steps like adding a stop to the Agent Job to recreate any users and any other jobs that the database needs but that is more specific to your environment and you will be best placed to achieve this&lt;/p></description></item><item><title>Rationalisation of Database with Powershell and T-SQL part one</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/rationalisation-of-database-with-powershell-and-t-sql-part-one/</link><pubDate>Tue, 25 Feb 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/rationalisation-of-database-with-powershell-and-t-sql-part-one/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/02/usage-excel.jpg" alt="Featured image of post Rationalisation of Database with Powershell and T-SQL part one" />&lt;p>I have recently been involved in a project to rationalise databases. It is easy in a large organisation for database numbers to rapidly increase and sometimes the DBA may not be aware of or be able to control the rise if they don’t have knowledge of all of the database servers on the estate.&lt;/p>
&lt;p>There are lots of benefits of rationalisation to the business. Reduced cpu usage = reduced heat released = lower air-con bill for the server room and less storage used = quicker backups and less tapes used or better still less requirement for that expensive new SAN. You may be able to consolidate data and provide one version of the truth for the business as well. Removing servers can release licensing costs which could then be diverted elsewhere or pay for other improvements.&lt;/p>
&lt;p>William Durkin &lt;a class="link" href="http://williamdurkin.com/" target="_blank" rel="noopener"
>b&lt;/a>  &lt;a class="link" href="https://twitter.com/sql_williamd" target="_blank" rel="noopener"
>t&lt;/a> presented to the &lt;a class="link" href="http://sqlsouthwest.co.uk" target="_blank" rel="noopener"
>SQL South West User Group&lt;/a> about this and will be doing the session at SQL Saturday in Exeter in March 2014 Please check out his session for a more detailed view&lt;/p>
&lt;p>I needed to be able to identify databases that could possibly be deleted and realised that an easy way to achieve this would be to use a script to check for usage of the database.&lt;/p>
&lt;p>No need to recreate the wheel so I went to Aaron Bertrands blog &lt;a class="link" href="http://sqlblog.com/blogs/aaron_bertrand/archive/2008/05/06/when-was-my-database-table-last-accessed.aspx" target="_blank" rel="noopener"
>http://sqlblog.com/blogs/aaron_bertrand/archive/2008/05/06/when-was-my-database-table-last-accessed.aspx&lt;/a> and used his script. Instead of using an audit file I decided to use Powershell so that I could output the results to Excel and colour code them. This made it easier to check the results and also easier to show to Managers and Service Owners&lt;/p>
&lt;pre>&lt;code>#################################################################################
# NAME: lastdbusage.ps1
# AUTHOR: Rob Sewell
# https://blog.robsewell.com
# DATE:19/10/2013
#
# COMMENTS: Fill Excel WorkBook with details fo last access times for each database
#
# NOTES : Does NOT work with SQL 2000 boxes
$FileName = '' # Set a filename for the output
# Get List of sql servers to check
$sqlservers = Get-Content '' # serverlist, database query whatever
# Set SQL Query
$query = &amp;quot;WITH agg AS
(
SELECT
max(last_user_seek) last_user_seek,
max(last_user_scan) last_user_scan,
max(last_user_lookup) last_user_lookup,
max(last_user_update) last_user_update,
sd.name dbname
FROM
sys.dm_db_index_usage_stats, master..sysdatabases sd
WHERE
sd.name not in('master','tempdb','model','msdb')
AND
database_id = sd.dbid group by sd.name
)
SELECT
dbname,
last_read = MAX(last_read),
last_write = MAX(last_write)
FROM
(
SELECT dbname, last_user_seek, NULL FROM agg
UNION ALL
SELECT dbname, last_user_scan, NULL FROM agg
UNION ALL
SELECT dbname, last_user_lookup, NULL FROM agg
UNION ALL
SELECT dbname, NULL, last_user_update FROM agg
) AS x (dbname, last_read, last_write)
GROUP BY
dbname
ORDER BY 1;
&amp;quot;
#Open Excel
$xl = new-object -comobject excel.application
$wb = $xl.Workbooks.Add()
# Load SMO extension
[System.Reflection.Assembly]::LoadWithPartialName(&amp;quot;Microsoft.SqlServer.Smo&amp;quot;) | Out-Null;
# Loop through each sql server from sqlservers.txt
foreach ($sqlserver in $sqlservers) {
# Get the time SQL was restarted
$svr = New-Object 'Microsoft.SQLServer.Management.Smo.Server' $SQLServer
$db = $svr.Databases['TempDB']
$CreateDate = $db.CreateDate
#Run Query against SQL Server
$Results = Invoke-Sqlcmd -ServerInstance $sqlServer -Query $query -Database master
# Add a new sheet
$ws = $wb.Worksheets.Add()
$name = &amp;quot;$sqlserver&amp;quot;
# Name the Sheet
$ws.name = $Name
$cells = $ws.Cells
$xl.Visible = $true
#define some variables to control navigation
$row = 2
$col = 2
$cells.item($row, $col) = $SQLServer + ' Was Rebooted at ' + $CreateDate
$cells.item($row, $col).font.size = 16
$Cells.item($row, $col).Columnwidth = 10
$row = 3
$col = 2
# Set some titles
$cells.item($row, $col) = &amp;quot;Server&amp;quot;
$cells.item($row, $col).font.size = 16
$Cells.item($row, $col).Columnwidth = 10
$col++
$cells.item($row, $col) = &amp;quot;Database&amp;quot;
$cells.item($row, $col).font.size = 16
$Cells.item($row, $col).Columnwidth = 40
$col++
$cells.item($row, $col) = &amp;quot;Last Read&amp;quot;
$cells.item($row, $col).font.size = 16
$Cells.item($row, $col).Columnwidth = 20
$col++
$cells.item($row, $col) = &amp;quot;Last Write&amp;quot;
$cells.item($row, $col).font.size = 16
$Cells.item($row, $col).Columnwidth = 20
$col++
foreach ($result in $results) {
# Check if value is NULL
$DBNull = [System.DBNull]::Value
$LastRead = $Result.last_read
$LastWrite = $Result.last_write
$row++
$col = 2
$cells.item($Row, $col) = $sqlserver
$col++
$cells.item($Row, $col) = $Result.dbname
$col++
if ($LastRead -eq $DBNull) {
$LastRead = &amp;quot;Not Since Last Reboot&amp;quot;
$colour = &amp;quot;46&amp;quot;
$cells.item($Row, $col).Interior.ColorIndex = $colour
$cells.item($Row, $col) = $LastRead
}
else {
$cells.item($Row, $col) = $LastRead
}
$col++
if ($LastWrite -eq $DBNull) {
$LastWrite = &amp;quot;Not Since Last Reboot&amp;quot;
$colour = &amp;quot;46&amp;quot;
$cells.item($Row, $col).Interior.ColorIndex = $colour
$cells.item($Row, $col) = $LastWrite
}
else {
$cells.item($Row, $col) = $LastWrite
}
}
}
$xl.DisplayAlerts = $false
$wb.Saveas($FileName)
$xl.quit()
Stop-Process -Name *excel*
&lt;/code>&lt;/pre>
&lt;p>What it does is place the query in a variable. Get the contents of the SQL Server text file holding all my known SQL Servers and runs the query against each of them storing the results in a variable. It then creates an Excel Workbook and a new sheet for each server and populates the sheet including a bit of colour formatting before saving it. The results look like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/02/usage-excel.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/02/usage-excel.jpg"
loading="lazy"
alt="usage excel"
>&lt;/a>&lt;/p>
&lt;p>The tricky bit was understanding how to match the NULL result from the query. This was done by assigning a variable to &lt;code>[System.DBNull]::Value&lt;/code> and using that.&lt;/p>
&lt;p>Of course these stats are reset when SQL Server restarts so I also included the SQL server restart time using the create date property  of the TempDB. I gathered these stats for a few months before starting any rationalisation.&lt;/p>
&lt;p>My next post will be about the next step in the process.&lt;/p></description></item><item><title>Why You Should Visit the Sponsors at #SQLSatExeter and Other Community Events</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-you-should-visit-the-sponsors-at-#sqlsatexeter-and-other-community-events/</link><pubDate>Mon, 10 Feb 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/why-you-should-visit-the-sponsors-at-#sqlsatexeter-and-other-community-events/</guid><description>&lt;p>SQL Saturdays and other community events rely on sponsors and you know that you will often get entered into a raffle for a prize in exchange for your contact details and there will be freebies of various types from many vendors but there is more that you can get from visiting the sponsors.&lt;/p>
&lt;p>&lt;strong>FREE COFFEE&lt;/strong>&lt;/p>
&lt;p>At &lt;a class="link" href="http://www.sqlsaturday.com/269/" target="_blank" rel="noopener"
>SQL Saturday Exeter on the 22nd March 2014&lt;/a>  we are putting free coffee amongst the sponsors. Yes, it’s a ruse in some ways to put you in the same room as the sponsors whilst your mind is buzzing with all the new SQL learning you have been doing and you are feeling confident and inspired about SQL and what you can achieve.&lt;/p>
&lt;p>We need the sponsors to put on the events and the sponsors need us to help put them in contact with purchasers of their wares. It is good for all community events if the sponsors can put SQL Saturday Exeter (or another community event} into their CRM as the point of first contact or the place a decision was made for a purchase as it will mean that when they analyse their data in readiness for next years budget community events will still be important to them and they will spend their money and we will continue to be able to benefit from superb free or &lt;a class="link" href="http://sqlsouthwest.co.uk/sql-saturday-269-precon-training-day-details/" target="_blank" rel="noopener"
>very cheap training and learning&lt;/a>, networking and down right good fun at next years events&lt;/p>
&lt;p>&lt;strong>DIRECT CONTACT WITH THE PEOPLE WHO MAKE YOUR TOOLS&lt;/strong>&lt;/p>
&lt;p>For example, I use &lt;a class="link" href="http://www.red-gate.com/products/dba/sql-monitor/" target="_blank" rel="noopener"
>Red Gate’s SQL Monitor&lt;/a> and make use of the graphs to baseline, to see when there are variations to that baseline and to get alerted about long running queries, deadlocks and many other useful DBA information.&lt;/p>
&lt;p>Whilst at the &lt;a class="link" href="http://www.red-gate.com/" target="_blank" rel="noopener"
>Red Gate&lt;/a> stand at &lt;a class="link" href="http://www.sqlsaturday.com/228/eventhome.aspx" target="_blank" rel="noopener"
>SQL Saturday in Cambridge&lt;/a> I got talking to Daniel Rothig who is one of the developers for SQL Monitor and I was able to ask him about using SQL Monitor.&lt;/p>
&lt;p>I wanted to know how best to use the base lining feature and how best to describe some of the detail I was seeing to none-technical people. He and &lt;a class="link" href="https://twitter.com/fatherjack" target="_blank" rel="noopener"
>Jonathan Allen&lt;/a> was able to give me some examples and knowledge to improve my capabilities in this area. It was fantastic to be able to discuss the product with him and see where they are wanting to take it.&lt;/p>
&lt;p>&lt;strong>THE SPONSORS WIN TOO&lt;/strong>&lt;/p>
&lt;p>Obviously the sponsors need customers and that is why they put a large amount of marketing activity into SQL Community Events. They want to put their products in front of the people who will be using them and make sales.&lt;/p>
&lt;p>But there is a further benefit too Daniel asked me to show him how I used the tool and what I would improve if I could.  I explained that I was having trouble getting the Regex correct for writing exceptions for the alerts for long running queries and I said that I wished there was button I could press to automatically ignore that query that sometimes. He said he would take that back to the team. Excellent, I was able to get a way to improve a good tool to make me work smarter and my experience better&lt;/p>
&lt;p>I don’t know if my idea will make it to Production but I hope so. Daniel also said it was useful to see the way users of their software navigated the application and used the features and that that knowledge would help future development&lt;/p>
&lt;p>Daniel said&lt;/p>
&lt;p>“I’m sure we can make a sale or two on a SQL Saturday – but then, why am I there, and not a sales team? We’ve found it’s more valuable to meet people in the community, learn about their jobs and problems, and search for a gleam in their eyes when we show them our solutions. We take home those first impressions, and the feedback from long-time users, to make our software more focused, relevant, and useful.&lt;/p>
&lt;p>And the conversations are always great fun – so come and say hi!”&lt;/p>
&lt;p>It’s a win all ways round&lt;/p>
&lt;p>&lt;strong>WE’LL PUT BISCUITS WITH THE COFFEE TOO AT SQL SAT EXETER!!&lt;/strong>&lt;/p>
&lt;p>Find out more about SQL Saturday Exeter at &lt;a class="link" href="http://sqlsouthwest.co.uk/" title="http://sqlsouthwest.co.uk/"
target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/&lt;/a>&lt;/p></description></item><item><title>Viewing SQL Endpoint Permissions with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-sql-endpoint-permissions-with-powershell/</link><pubDate>Sun, 09 Feb 2014 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/viewing-sql-endpoint-permissions-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2014/02/ps1.jpg" alt="Featured image of post Viewing SQL Endpoint Permissions with PowerShell" />&lt;p>A quick and simple post today as I have been very busy. I needed to list the users with permissions on mirroring endpoints today so I wrote this script and figured it was worth sharing.&lt;/p>
&lt;p>It’s a simple script which takes a server name from a Read-Host prompt. Displays the available endpoints and asks which one you want and shows you the permissions&lt;/p>
&lt;pre>&lt;code>$Server = Read-Host &amp;quot;Please Enter the Server&amp;quot;
$Endpoints = $srv.Endpoints |select Name -ExpandProperty Name
$EndpointName = Read-Host &amp;quot;Please Enter the Endpoint Name `n Available Names are `n $Endpoints&amp;quot;
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
$Endpoint = $srv.Endpoints[$EndpointName]
$Endpoint.enumObjectPermissions()
&lt;/code>&lt;/pre>
&lt;p>and heres a screenshot of the results&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/02/ps1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/02/ps1.jpg"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>If you want to do it with T-SQL&lt;/p>
&lt;pre>&lt;code>select s.name as grantee,
e.name as endpoint,
p.permission_name as permission,
p.state_desc as state_desc
from sys.server_permissions p
join sys.server_principals s on s.principal_id = p.grantee_principal_id
join sys.endpoints e on p.major_id = e.endpoint_id
where p.type='CO'
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2014/02/image13.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2014/02/image_thumb9.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item><item><title>Using PowerShell to get Azure Endpoint Ports</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-get-azure-endpoint-ports/</link><pubDate>Mon, 02 Dec 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-get-azure-endpoint-ports/</guid><description>&lt;p>A quick blog today. I was reading &lt;a class="link" href="http://www.mssqltips.com/sqlservertip/3076/how-to-read-the-sql-server-database-transaction-log/" target="_blank" rel="noopener"
>this blog post about How to read the SQL Error Log&lt;/a> and I thought I would try some of the examples. I started my Azure VM using &lt;a class="link" href="https://blog.robsewell.com/?p=534" target="_blank" rel="noopener"
>the steps in my previous post&lt;/a>&lt;/p>
&lt;p>I ran&lt;/p>
&lt;pre>&lt;code>Get-AzureVM -ServiceName TheBestBeard -Name Fade2black
&lt;/code>&lt;/pre>
&lt;p>and then&lt;/p>
&lt;pre>&lt;code> Get-AzureVM -ServiceName TheBestBeard -Name Fade2black|Get-AzureEndpoint |Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>and bingo I had my SQL Port to put in SSMS and can go and play some more with SQL&lt;/p></description></item><item><title>Dropping All Tables From A SQL Database with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dropping-all-tables-from-a-sql-database-with-powershell/</link><pubDate>Sat, 30 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dropping-all-tables-from-a-sql-database-with-powershell/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2013/11/image7.png" alt="Featured image of post Dropping All Tables From A SQL Database with PowerShell" />&lt;p>This post could also have been titled confusion with &lt;code>foreach&lt;/code> or &lt;code>For-EachObject&lt;/code>&lt;/p>
&lt;p>The scenario – Having created a blank database a number of users and permissions for an external consultant to create a test database for an application I got a phone call.&lt;/p>
&lt;blockquote>
&lt;p>Please can you drop all the tables from the database as we need to re-run the installer with some different parameters&lt;/p>
&lt;/blockquote>
&lt;p>Sure, I thought. No problem. I will use PowerShell. A simple script is all I need&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image3.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>That ought to do it. Loop through the tables and drop each one. But when I ran it I got this error&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image4.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>What I did (which I should have done first up but time pressures hadn’t allowed) was drop the database and write a script to recreate it and all the users and permissions required using my &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Create Windows User Function&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/add-user-to-database-role-with-powershell/" target="_blank" rel="noopener"
>Add User to Database Role Function&lt;/a> but it got me thinking.&lt;/p>
&lt;p>So I went home and &lt;a class="link" href="https://blog.robsewell.com/?p=534" target="_blank" rel="noopener"
>fired up my Azure VMs&lt;/a> and had a play and found two ways of resolving it. But first lets understand what is happening here. I &lt;a class="link" href="http://blog.incworx.com/blog/sharepoint-developer-blog/collection-was-modified-enumeration-operation-may-not-execute-looks-hard-but-it-isnt-v2" target="_blank" rel="noopener"
>read this post&lt;/a> which explains it quite well for his script.&lt;/p>
&lt;blockquote>
&lt;p>We are going through a list collection and deleting any instance of our event receiver, in the “Foreach loop”. But once we delete an item we are modifying the current list collection. The “Foreach” loop looks to see what the current value is, before it moves on to the next item. But since we deleted the current item, we get the “Collection was modified; enumeration operation may not execute” error.&lt;/p>
&lt;p>Now that understand what is going on, we can now look at a solution to correct the error.&lt;/p>
&lt;p>The simplest way to avoid modifying the collection would be with a “For Loop”.  With a “For Loop”, no modifications are made that will interrupt the looping process.&lt;/p>
&lt;/blockquote>
&lt;p>So when PowerShell has dropped the table it returns to the tables collection to find the current table before moving on to the next table but as we have deleted the table it falls over.&lt;/p>
&lt;p>So lets fix it.&lt;/p>
&lt;p>First lets create a test database with PowerShell. A piece of code that is useful to keep for scenarios like this. If you are creating a database for something other than a quick demo or a test then go and explore the other properties of the database object that you will surely want to configure. But for this demo the following is fine, it will use default options. The same applies for the tables script below.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image5.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image5.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Now lets create some tables.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image6.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image6.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>And check they have been created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image7.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image7.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Now following the advice from above we can do the following&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image8.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image8.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>First we count the number of tables and set it to a variable and then create a for loop. Note if you put &lt;code>$i –le $tables&lt;/code>.Count then the script will only delete 4 tables! In the script block we are setting the &lt;code>$table&lt;/code> variable to the first in the collection and then drops it. List the table names again to check or run &lt;code>$tables.Count&lt;/code> and you will see that all the tables have been deleted.&lt;/p>
&lt;p>This was the other solution I found. It makes use of the scripter method to script the Drop commands for the tables add them to a Query string and pass that to &lt;code>Invoke-SQLCmd&lt;/code> to run it.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image9.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image9.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item><item><title>Starting My Azure SQL Server VMs with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/starting-my-azure-sql-server-vms-with-powershell/</link><pubDate>Wed, 27 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/starting-my-azure-sql-server-vms-with-powershell/</guid><description>&lt;p>The last post about &lt;a class="link" href="https://blog.robsewell.com/?p=505" target="_blank" rel="noopener"
>Launching Azure VMs with PowerShell&lt;/a> made someone ask me to explain how I start my Azure VMs normally so here goes.&lt;/p>
&lt;p>When I decide to write a blog post or develop and test a script or run through demos from a presentation or blog post I fire up my Azure Virtual machines with PowerShell. This is how I do it&lt;/p>
&lt;p>Open PowerShell and check that I am connected to my default subscription by running &lt;code>Get-AzureSubscription&lt;/code>&lt;/p>
&lt;p>Note – You must have installed Windows Azure PowerShell and installed the PublishSettingsFile or used &lt;code>Add-AzureAccount&lt;/code> for your subscription following the steps here&lt;/p>
&lt;p>&lt;a class="link" href="http://www.windowsazure.com/en-us/manage/install-and-configure-windows-powershell/" target="_blank" rel="noopener"
>http://www.windowsazure.com/en-us/manage/install-and-configure-windows-powershell/&lt;/a>&lt;/p>
&lt;p>Then I run the following three Cmdlets&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;code>Get-AzureVM&lt;/code> shows me the VMs associated with that subscription.&lt;/p>
&lt;p>I then pipe to &lt;code>Start-AzureVM&lt;/code> as I want to start both machines. If I only wanted one I would check that&lt;/p>
&lt;pre>&lt;code>Get-AzureVM -name Fade2Black -ServiceName TheBestBeard
&lt;/code>&lt;/pre>
&lt;p>returned the correct machine and then pipe that to &lt;code>Start-AzureVM&lt;/code>&lt;/p>
&lt;p>Once the VMs have started I use &lt;code>Get-AzureRemoteDesktopFile&lt;/code> giving a local path for the rdp file and specifying &lt;code>–Launch&lt;/code> to run the RDP session&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and away we go 🙂&lt;/p>
&lt;p>Once I have finished simply run&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and my machines are stopped and no longer running my credit down.&lt;/p></description></item><item><title>What Runs on the SQL Server when you run a PowerShell script?–Question from #SQLRelay</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/what-runs-on-the-sql-server-when-you-run-a-powershell-scriptquestion-from-#sqlrelay/</link><pubDate>Sat, 23 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/what-runs-on-the-sql-server-when-you-run-a-powershell-scriptquestion-from-#sqlrelay/</guid><description>&lt;p>Last week I ran a PowerShell lab at SQL Relay in Cardiff. There are still a few places available for SQL Relay week 2. &lt;a class="link" href="http://www.sqlrelay.co.uk/" target="_blank" rel="noopener"
>Take a look here for more details&lt;/a> and follow the twitter &lt;a class="link" href="https://twitter.com/search?q=%23sqlrelay" target="_blank" rel="noopener"
>hashtag #SQLRelay&lt;/a> for up to date information&lt;/p>
&lt;p>The link for my slides and demos from the second part are here &lt;a class="link" href="https://t.co/Fik2odyUMA" title="https://t.co/Fik2odyUMA"
target="_blank" rel="noopener"
>https://t.co/Fik2odyUMA&lt;/a>&lt;/p>
&lt;p>Whilst we were discussing &lt;a class="link" href="https://blog.robsewell.com/checking-for-a-database-backup-with-powershell/" target="_blank" rel="noopener"
>Show-LastDatabaseBackup&lt;/a> Kev Chant &lt;a class="link" href="https://twitter.com/KevChant" target="_blank" rel="noopener"
>@KevChant&lt;/a> asked where it was getting the information from and I answered that PowerShell was running SQL commands under the hood against the server and if you ran profiler that is what you would see. We didn’t have time to do that in Cardiff but I thought I would do it today to show what happens&lt;/p>
&lt;p>A reminder of what &lt;code>Show-LastDatabaseBackup&lt;/code> function does&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image10.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image10.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>If we start a trace with Profiler and run this function we get these results in PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image11.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image11.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>In Profiler we see that it is running the following T-SQL for&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image12.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image12.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>exec sp_executesql N' SELECT dtb.name AS [Name] FROM master.sys.databases AS dtb WHERE (dtb.name=@_msparam_0)',N'@_msparam_0 nvarchar(4000)',@_msparam_0=N'RageAgainstTheMachine'
&lt;/code>&lt;/pre>
&lt;p>and then for&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image13.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image13.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>exec sp_executesql N' create table #tempbackup (database_name nvarchar(128), [type] char(1), backup_finish_date datetime) insert into #tempbackup select database_name, [type], max(backup_finish_date) from msdb..backupset where [type] = ''D'' or [type] = ''L'' or [type]=''I'' group by database_name, [type] SELECT (select backup_finish_date from #tempbackup where type = @_msparam_0 and db_id(database_name) = dtb.database_id) AS [LastBackupDate] FROM master.sys.databases AS dtb WHERE (dtb.name=@_msparam_1) drop table #tempbackup ',N'@_msparam_0 nvarchar(4000),@_msparam_1 nvarchar(4000)',@_msparam_0=N'D',@_msparam_1=N'RageAgainstTheMachine'
&lt;/code>&lt;/pre>
&lt;p>For&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image14.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image14.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>exec sp_executesql N' create table #tempbackup (database_name nvarchar(128), [type] char(1), backup_finish_date datetime) insert into #tempbackup select database_name, [type], max(backup_finish_date) from msdb..backupset where [type] = ''D'' or [type] = ''L'' or [type]=''I'' group by database_name, [type] SELECT (select backup_finish_date from #tempbackup where type = @_msparam_0 and db_id(database_name) = dtb.database_id) AS [LastDifferentialBackupDate] FROM master.sys.databases AS dtb WHERE (dtb.name=@_msparam_1) &amp;amp;lt;mailto:dtb.name=@_msparam_1)&amp;amp;gt; drop table #tempbackup ',N'@_msparam_0 nvarchar(4000),@_msparam_1 nvarchar(4000)',@_msparam_0=N'I',@_msparam_1=N'RageAgainstTheMachine'
&lt;/code>&lt;/pre>
&lt;p>And for&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/11/image15.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/11/image15.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>exec sp_executesql N' create table #tempbackup (database_name nvarchar(128), [type] char(1), backup_finish_date datetime) insert into #tempbackup select database_name, [type], max(backup_finish_date) from msdb..backupset where [type] = ''D'' or [type] = ''L'' or [type]=''I'' group by database_name, [type] SELECT (select backup_finish_date from #tempbackup where type = @_msparam_0 and db_id(database_name) = dtb.database_id) AS [LastLogBackupDate] FROM master.sys.databases AS dtb WHERE (dtb.name=@_msparam_1) &amp;amp;lt;mailto:dtb.name=@_msparam_1)&amp;amp;gt; drop table #tempbackup ',N'@_msparam_0 nvarchar(4000),@_msparam_1 nvarchar(4000)',@_msparam_0=N'L',@_msparam_1=N'RageAgainstTheMachine'
&lt;/code>&lt;/pre>
&lt;p>So the answer to your question Kev is&lt;/p>
&lt;p>Yes it does get the information from the msdb database&lt;/p></description></item><item><title>#TSQL2sDay Why My Head is Always in The Cloud</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-why-my-head-is-always-in-the-cloud/</link><pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/#tsql2sday-why-my-head-is-always-in-the-cloud/</guid><description>&lt;p>&lt;a class="link" href="http://www.sqlchicken.com/2013/11/t-sql-tuesday-48-cloud-atlas/" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/www.sqlchicken.com/wp-content/uploads/2013/11/20121003200545_thumb.jpg?resize=175%2C175"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>Todays post is my first for the TSQL2sDay series. For those not familiar this is rotating blog party that was started by Adam Machanic &lt;a class="link" href="http://twitter.com/adammachanic" target="_blank" rel="noopener"
>(@AdamMachanic&lt;/a> &lt;a class="link" href="http://sqlblog.com/blogs/adam_machanic/" target="_blank" rel="noopener"
>blog&lt;/a>) back in 2009. If you want to catch up on all the fun to date check out this nice archive (&lt;a class="link" href="http://t.co/g3tzA9nP27" target="_blank" rel="noopener"
>link&lt;/a>) put together by Steve Jones &lt;a class="link" href="http://twitter.com/way0utwest" target="_blank" rel="noopener"
>(@way0utwest&lt;/a> &lt;a class="link" href="http://voiceofthedba.com/" target="_blank" rel="noopener"
>blog&lt;/a>). Thank you Steve!!!&lt;/p>
&lt;p>&lt;a class="link" href="http://owenrichardson.com/2011/07/07/cloud-computing/" target="_blank" rel="noopener"
>&lt;img src="https://owenrichardson.files.wordpress.com/2011/07/wpid-photo-jul-7-2011-1738.jpg?w=432&amp;amp;h=650&amp;amp;resize=207%2C310"
loading="lazy"
alt="Azure Ballon - Credit http://owenrichardson.com/"
>&lt;/a>&lt;/p>
&lt;p>This one is hosted by Jorge Segarra &lt;a class="link" href="https://twitter.com/SQLChicken" target="_blank" rel="noopener"
>@SQLChicken:&lt;/a>  &lt;a class="link" href="http://www.sqlchicken.com/2013/11/t-sql-tuesday-48-cloud-atlas/" target="_blank" rel="noopener"
>who said&lt;/a> This month’s topic is all about the cloud. What’s your take on it? Have you used it? If so, let’s hear your experiences. Haven’t used it? Let’s hear why or why not? Do you like/dislike recent changes made to cloud services? It’s clear skies for writing! So let’s hear it folks, where do you stand with the cloud?&lt;/p>
&lt;p>My wife would tell you that my head is always in the cloud and she’s right (she usually is) just not like that picture! I would love to float gracefully above the land and gaze upon the view but its the landing that bothers me and will always stop me from trying it&lt;/p>
&lt;p>Credit &lt;a class="link" href="http://owenrichardson.com/" target="_blank" rel="noopener"
>http://owenrichardson.com/&lt;/a>&lt;/p>
&lt;p>She’s right, pedantically and literally too, because this year I have spent a lot of time with my head and my fingers and my thinking in &lt;a class="link" href="http://www.windowsazure.com/" target="_blank" rel="noopener"
>Virtual Machines using Windows Azure&lt;/a>. That is where I have learnt a lot of my SQL and Powershell this year. After &lt;a class="link" href="http://sqlsouthwest.co.uk/sqlsat269/" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a> and &lt;a class="link" href="https://blog.robsewell.com/12-things-i-learnt-at-sqlbits-xi/" target="_blank" rel="noopener"
>SQL Bits in Nottingham&lt;/a> this year I have needed a place to practice and learn, an environment to try things and break things and mend them again and experiment.&lt;/p>
&lt;p>I learn just as well by doing things as I do reading about them. Stuart Moore  &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a> has a great post called &lt;a class="link" href="http://stuart-moore.com/learning-play-sql-server/" title="http://stuart-moore.com/learning-play-sql-server/"
target="_blank" rel="noopener"
>Learning to Play with SQL Server&lt;/a> and whist I haven’t been as rough with my Azure SQL instances as he suggests I have been able to practice at will without worry and thanks to my MSDN subscription without cost. I have taken examples from blog posts and demos from User Group Sessions and run them on my Windows Azure VMs&lt;/p>
&lt;p>Every single blog post I have written this year that has examples has been written in Azure and screen shots from Azure. Whilst some of my Powershell scripts in the &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a> series had already been written to solve one particular problem or another at MyWork, every single one was refined and demo’d and all the screen shots were from Azure and several were developed on Azure too&lt;/p>
&lt;p>My first ever session to the SQL South West user group was about &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>Spinning up and Shutting Down VMS in Azure&lt;/a> was about Azure and was an interesting experience in &lt;a class="link" href="http://en.wikipedia.org/wiki/Murphy%27s_law" target="_blank" rel="noopener"
>Murphys Law&lt;/a> which meant I &lt;a class="link" href="https://blog.robsewell.com/lessons-learnt-from-my-first-talk-at-sql-southwest/" target="_blank" rel="noopener"
>ended up having to deliver it  on Azure&lt;/a>.&lt;/p>
&lt;p>The second time I have talked was about the PowerShell Box of Tricks series to the Cardiff User Group. Having learnt my lesson from the first time I had bought a mini HDMI to VGA converter and I had tested it using a couple of monitors at home and it worked wonderfully. However, when I got to Cardiff my little Asus convertible didn’t provide enough grunt to power the funky presentation screen. Luckily thanks to Stuart Moore &lt;a class="link" href="https://twitter.com/napalmgram" target="_blank" rel="noopener"
>@napalmgram&lt;/a> who was also there doing his &lt;a class="link" href="http://stuart-moore.com/category/31-days-of-sql-server-backup-and-restore-with-powershell/" target="_blank" rel="noopener"
>excellent PowerShell Back Up and Restore Sessio&lt;/a>n who let me use his Mac I was able to deliver the session using Office Web App to run the PowerPoint from my SkyDrive whilst all the demos were on ………Yup you guessed it Windows Azure !!!&lt;/p>
&lt;p>So I feel qualified to answer Jorge’s questions and take part in T-SQL Tuesday this time round.&lt;/p>
&lt;p>I like Azure. I like the ease I can spin up and down machines or any PaaS services at will. I love that I can do it with PowerShell because I really enjoy using PowerShell in my day to day work and at home too. Living as I do in a beautifully convenient bungalow in the country, I still enjoy the frustration of watching that spinning ring as my videos buffer on our 1.8Mbs at best internet connection. Whilst that does have an impact on using Azure it is a damn sight better than waiting many days trying to download one single file. Something like an ISO file for the latest SQL Server CTP for example.&lt;/p>
&lt;p>There is no way I would have got a look at SQL Server 2014 if it wasn’t for Azure. I was able to spin up a SQL Server 2014 machine in only a few minutes and log in and have a play and then delete it. I have done the same with Server 2012 and 2012 R2. It has enabled me to try setting up Availability Groups and other technologies not yet implemented at MyWork&lt;/p>
&lt;p>I wouldn’t have been able to do any of that on my machines at home as I don’t have anything capable of running Hyper-V whilst this 8 year old desktop still keeps hanging on despite the odd noises. (Negotiations are currently in place to replace it with something shiny and new. &lt;a class="link" href="https://blog.robsewell.com/?p=513" target="_blank" rel="noopener"
>Just need that lottery win now !!)&lt;/a>&lt;/p>
&lt;p>I have also transferred my Cricket Averages database to WASD and am talking with a friend of mine about developing an app that will use the mobile service as well.&lt;/p>
&lt;p>The rate of change is much quicker in the cloud, things change and change quickly. As quickly as I had written my post about &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>Spinning up and Shutting Down VMS in Azure&lt;/a> Microsoft changed the rules and didn’t charge for machines that were turned off. New services appear all the time. New services move quickly through from Preview to release and as &lt;a class="link" href="http://www.scarydba.com/2013/11/05/more-azure-goodies/" target="_blank" rel="noopener"
>Grant Fritchey noticed this week&lt;/a> new views have been added to to Windows Azure SQL Database under the covers. I think this is something we are just going to have to live with. The scale of the cloud means it is much easier to test improvements at large scale and that means they can be released quicker.  It makes it more challenging to keep up I admit but it’s a constant drip of new things rather than a big bang all at once.&lt;/p>
&lt;p>Azure has brought me to where I am today and I think it will continue to be part of my future. If I remember to submit my PowerShell session for SQL Saturday Exeter (&lt;a class="link" href="http://www.sqlsaturday.com/269/callforspeakers.aspx" target="_blank" rel="noopener"
>Submit yours here&lt;/a>) and it gets chosen then you will be able to see me there &lt;a class="link" href="http://www.sqlsaturday.com/269/" target="_blank" rel="noopener"
>(if you register here&lt;/a>) using Azure to give back to the SQL Community&lt;/p></description></item><item><title>SQL Saturday Exeter&amp;ndash;What&amp;rsquo;s the Point? My Experience of 2013 SQLSatExeter</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-saturday-exeterndashwhatrsquos-the-point-my-experience-of-2013-sqlsatexeter/</link><pubDate>Sun, 10 Nov 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-saturday-exeterndashwhatrsquos-the-point-my-experience-of-2013-sqlsatexeter/</guid><description>&lt;p> &lt;/p>
&lt;p>Disclaimer – I am on the committee organising the next &lt;a class="link" href="http://sqlsouthwest.co.uk/sqlsat269/" target="_blank" rel="noopener"
>SQL Saturday Exeter&lt;/a>. To be kept up to date about SQL Saturday #269 in the South West, follow &lt;a class="link" href="https://twitter.com/sqlsatexeter" target="_blank" rel="noopener"
>@SQLSatExeter&lt;/a> and&lt;a class="link" href="https://twitter.com/search?q=%23sqlsatexeter&amp;amp;src=hash&amp;amp;f=realtime" target="_blank" rel="noopener"
>#SQLSatExeter&lt;/a> on twitter and see details at the bottom. This post is about my experience at this years event.&lt;/p>
&lt;p>In March this year the SQL South West User Group hosted SQL Saturday #194 in Exeter. I was a new member to the User Group having finally been able to join them for the first time in January. At that meeting Chris Testa O’Neill presented a session and was very passionate about the SQL Community and the benefit of the SQL Saturdays and other events.  I am always keen to learn new things and find ways of developing my skills. As I haven’t won the lottery I also look out for good deals as well!!&lt;/p>
&lt;h4 id="sql-saturday-pre-cons-are-exceptional-value">SQL SATURDAY PRE-CONS ARE EXCEPTIONAL VALUE&lt;/h4>
&lt;p>It was relatively easy to persuade my bosses to pay for my pre-con. For £150 I was able to spend a whole day in a room with about a dozen people being trained in SQL Server Security by Denny Cherry &lt;a class="link" href="https://twitter.com/@mrdenny" target="_blank" rel="noopener"
>@mrdenny&lt;/a>. The conversation went along the lines of&lt;/p>
&lt;p>“I want to go to this training session being delivered by this guy. &lt;a class="link" href="https://mvp.microsoft.com/en-us/mvp/Denny%20Cherry-4021851" target="_blank" rel="noopener"
>Link to MVP page&lt;/a>. It’s £150 and is in Exeter so no other costs required”&lt;/p>
&lt;p>My boss – “OK”&lt;/p>
&lt;p>Of course there was a little more fun and games to be had with the payment but it was easy for me to get training sorted and £150 is not going to break the training budget.&lt;/p>
&lt;p>Looking back through my notes from the session today I realise quite how much I have taken from it into my role at work. I can’t really comment which and what though that wouldn’t be good security!!&lt;/p>
&lt;p>I remember an enjoyable day with plenty of technical learning, a lot of questions and answers and plenty of laughs as well. But more than that was the opportunity to mix with other professionals and talk with them. During the breaks and at lunch there were plenty of opportunities to chew the fat, learn how others do things, make new friends and put faces to twitter handles. (NOTE : I do look pretty much like my &lt;a class="link" href="https://pbs.twimg.com/profile_images/75950380/n675059923_1450.jpg" target="_blank" rel="noopener"
>twitter profile picture&lt;/a> so if you see me at SQL Community events I expect you to come up and say hi, that&amp;rsquo;s part of the benefit of attending these events, having a good natter)&lt;/p>
&lt;p>Take a look at the end of this post for details of 2014 Pre-Cons&lt;/p>
&lt;h4 id="sql-saturday--cant-get-cheaper-than-free">SQL SATURDAY – CAN’T GET CHEAPER THAN FREE&lt;/h4>
&lt;p>SQL Saturdays are FREE&lt;/p>
&lt;p>SQL Saturdays offer sessions from internationally renowned and local SQL speakers on subjects relevant to you and your job, your future career, your development plan or just to challenge yourself by learning about something outside of your comfort zone. For Nothing. Add in the networking opportunities, the prizes from the sponsors, (if you were at Exeter this year the beer and the pasty) and if you added it up its a sizeable investment in yourself, your career and your development (did I mention a free beer and pasty?)&lt;/p>
&lt;p>NOT BAD FOR FREE!!&lt;/p>
&lt;p>To enable that, SQL Saturday organisers have to go out and talk sponsors into putting their hands into their pockets. They will only do that if it is worthwhile to them. You can make it easier for the organisers by going and spending time with the sponsors during the breaks, chatting with them and giving them your details. Also, if you choose to use one of their products please tell the sponsors you spoke to them at a SQL Saturday. They are (usually) data professionals who will record that and use that to make future decisions which will we hope include sponsoring SQL Saturdays.&lt;/p>
&lt;p>This year on the Saturday I went to the following sessions&lt;/p>
&lt;p>A temporary fix for a short term problem by Ian Meade Advanced SQL Server 2012 HA and DR Architectures by Christian Bolton Busting common T-SQL myths by Dave Morrison Power View and the Cube by Régis Baccaro Natural Born Killers, performance issues to avoid by Richard Douglas Tracking server performance without slowing it down by Jonathan Allen which I also Room Monitored Increasing Business and IT collaboration by Chris Testa-O&amp;rsquo;Neill&lt;/p>
&lt;p>It was a really good day. I learnt so much from all those knowledgeable and talented people. It really kicked me on in my development at work. I was able to take from each of those sessions and use that knowledge to do my job better and I made new friends and new contacts. Just going back to my notes today has reminded me of something that I need to look into for work.
Some of the conversations I have had at events this year have been fascinating - learning how other people do the same thing you do in a completely different but equally valid way,  problem-solving with a different set and type of minds than the ones at MyWork, laughing at the same things and moaning about similar frustrations. All have been both entertaining and rewarding and I think are worth mentioning as things I enjoyed about going to SQL Community events this year and play a part in the reason I shall continue to go to them (Just hope my boss doesn&amp;rsquo;t read this and think he won’t have to pay as I will go anyway!)&lt;/p>
&lt;p>It’s busy and hectic, the sessions come along thick and fast and there are lots of people around to talk to. I wish I had made use of the SQL Saturday mobile phone app and I definitely recommend researching ahead of time and planning your day out.&lt;/p>
&lt;p>This years sessions have not been decided yet but I have seen some of the submissions and there are some fabulous sessions there. You could also submit a session yourself. Choosing the sessions will be tough, but we want to offer the opportunity to speak to as many people as possible both new and experienced speakers.&lt;/p>
&lt;p>You can submit your sessions at this link &lt;a class="link" href="http://www.sqlsaturday.com/269/callforspeakers.aspx" target="_blank" rel="noopener"
>http://www.sqlsaturday.com/269/callforspeakers.aspx&lt;/a>&lt;/p>
&lt;h4 id="round-up-sql-saturday-exeter-why-wouldnt-you-come">ROUND-UP SQL SATURDAY EXETER WHY WOULDN’T YOU COME&lt;/h4>
&lt;p>For a newbie, as I was last time, SQL Saturday Exeter was a revelation.&lt;/p>
&lt;p>An opportunity to learn without spending thousands of my own or MyWorks money to sit in a lecture room and listen to a trainer.&lt;/p>
&lt;p>A chance to develop my understanding in a friendly environment amongst my peers where I could ask questions.&lt;/p>
&lt;p>A place to meet new people and build relationships who have helped me with situations at work throughout the year. I reckon I&amp;rsquo;m in credit already&lt;/p>
&lt;p>This year I have attended SQL Bits and SQL Saturday Cambridge and this month I shall be at SQL Relay in Cardiff and in Bristol. That all started with SQL Saturday 194 in Exeter 2013&lt;/p>
&lt;h4 id="what-about-next-years-sql-saturday-exeter">WHAT ABOUT NEXT YEARS SQL SATURDAY EXETER?&lt;/h4>
&lt;p>Next years SQL Saturday in Exeter, SQL Saturday #269, will be held at the same place - &lt;a class="link" href="http://www.jurysinns.com/hotels/exeter" target="_blank" rel="noopener"
>Jury’s Inn Hotel Exeter&lt;/a> on March 21/22nd 2014.&lt;/p>
&lt;p>We had such amazing submissions for our pre-cons that we have had to find more rooms to be able to fit them all in.. You can see for yourself the quality of the sessions and speakers for SQL Saturday Exeter 2014 at the following link&lt;/p>
&lt;p>&lt;a class="link" href="http://sqlsouthwest.co.uk/sql-saturday-269-precon-training-day-details/" target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/sql-saturday-269-precon-training-day-details/&lt;/a>&lt;/p>
&lt;p>What do you think? I want to split myself into 8 and go to every one!&lt;/p>
&lt;h4 id="what-should-you-do-now">WHAT SHOULD YOU DO NOW?&lt;/h4>
&lt;p>I suggest that you should book Saturday 22nd March 2014 out in your calendar right this minute. Done that? Good.&lt;/p>
&lt;p>Now go to this link&lt;/p>
&lt;p>&lt;a class="link" href="http://www.sqlsaturday.com/269/" target="_blank" rel="noopener"
>http://www.sqlsaturday.com/269/&lt;/a>&lt;/p>
&lt;p>and register for FREE to attend and let us know &lt;a class="link" href="https://twitter.com/sqlsatexeter" target="_blank" rel="noopener"
>@SQLSatExeter&lt;/a>&lt;/p>
&lt;p>Next make yourself a coffee (Other beverages are available) and head to the pre-con page&lt;/p>
&lt;p>&lt;a class="link" href="http://sqlsouthwest.co.uk/sql-saturday-269-precon-training-day-details/" target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/sql-saturday-269-precon-training-day-details/&lt;/a>&lt;/p>
&lt;p>This bit is up to you, the choice is hard. I can’t tell you which one of our eight fabulous sessions you want to go to. It’s not for me to say which amazing speaker you want to spend a day with for a bargain price but if you need further info please get in touch and we will try and help. Unfortunately our human cloning experiment is not stable enough to allow you to go to more than one!&lt;/p>
&lt;p>Then, let me know you have done so and come and say hi when you are here.&lt;/p></description></item><item><title>Launching Azure VM After Starting With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/launching-azure-vm-after-starting-with-powershell/</link><pubDate>Sat, 26 Oct 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/launching-azure-vm-after-starting-with-powershell/</guid><description>&lt;p>So this morning I decided I was going to run through this blog post on understanding query plans &lt;a class="link" href="http://sqlmag.com/t-sql/understanding-query-plans" target="_blank" rel="noopener"
>http://sqlmag.com/t-sql/understanding-query-plans&lt;/a>. I logged into my Azure Portal to check my balance and clicked start on the machine and then immediately clicked connect.&lt;/p>
&lt;p>D’oh&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image3.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course the RDP session wouldn’t open as the machine was not up so I went and made a coffee. Whilst doing that I thought of a way of doing it with PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>A little Do Until loop on the PowerState Property 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course if I was doing it all though PowerShell I would have done this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/10/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/10/image2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item><item><title>Searching for Installed Windows Update With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/searching-for-installed-windows-update-with-powershell/</link><pubDate>Mon, 30 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/searching-for-installed-windows-update-with-powershell/</guid><description>&lt;p>&lt;a class="link" href="https://blog.robsewell.com/?p=480" target="_blank" rel="noopener"
>Yesterdays Post Show-WindowsUpdatesLocal&lt;/a> does enable you to search for an installed update as follows&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal|Where-Object {$_.HotFixID -eq ‘KB2855336’} |Select Date, HotfixID, Result,Title|Format-Table –AutoSize
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image108.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image108.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I thought I would be able to do it quicker especially if I was searching a server with a lot of updates so I thought I would create a function to answer the  question Is this update installed on that server&lt;/p>
&lt;p>It is very similar to &lt;a class="link" href="https://blog.robsewell.com/?p=480" target="_blank" rel="noopener"
>Show-WindowsUpdatesLocal&lt;/a> but does not include the Title or Description on the grounds that if you are searching for it you should know those!!&lt;/p>
&lt;p>It also only adds the output to the collection if the KB is in the HotFixID property as shown below&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image109.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image109.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>If we use &lt;a class="link" href="http://blogs.msdn.com/b/rob/archive/2013/04/19/measuring-how-long-commands-take-in-windows.aspx" target="_blank" rel="noopener"
>Measure-Command&lt;/a> to compare the two we can see&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image110.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image110.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image111.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image111.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>From 3.89 seconds on my poor overworked machine to 1.79 seconds 🙂&lt;/p>
&lt;p>You can find the code here&lt;/p>
&lt;pre>&lt;code>############################################################# ########
#
# NAME: Search-WindowsUpdatesLocal.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:22/09/2013
#
# COMMENTS: Load function to show search for windows updates by KB locally
#
# USAGE: Search-WindowsUpdatesLocal KB2792100|Format-Table -AutoSize -Wrap
#
Function Search-WindowsUpdatesLocal ([String] $Search) {
$Search = $Search + &amp;quot;\d*&amp;quot;
$Searcher = New-Object -comobject Microsoft.Update. Searcher
$History = $Searcher.GetTotalHistoryCount()
$Updates = $Searcher.QueryHistory(1, $History)
# Define a new array to gather output
$OutputCollection = @()
Foreach ($update in $Updates) {
$Result = $null
Switch ($update.ResultCode) {
0 { $Result = 'NotStarted'}
1 { $Result = 'InProgress' }
2 { $Result = 'Succeeded' }
3 { $Result = 'SucceededWithErrors' }
4 { $Result = 'Failed' }
5 { $Result = 'Aborted' }
default { $Result = $_ }
}
$string = $update.title
$SearchAnswer = $string | Select-String -Pattern $Search | Select-Object { $_.Matches }
$output = New-Object -TypeName PSobject
$output | add-member NoteProperty “Date” -value $Update.Date
$output | add-member NoteProperty “HotFixID” -value $SearchAnswer.‘ $_.Matches ‘.Value
$output | Add-Member NoteProperty &amp;quot;Result&amp;quot; -Value $Result
if ($output.HotFixID) {
$OutputCollection += $output
}
}
$OutputCollection
}
&lt;/code>&lt;/pre></description></item><item><title>Show Windows Updates Locally With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-windows-updates-locally-with-powershell/</link><pubDate>Sun, 29 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-windows-updates-locally-with-powershell/</guid><description>&lt;p>I wanted to be able to quickly show the Windows Updates on a server. This came about during a discussion about auditing.&lt;/p>
&lt;p>Of course, there is no point in re-inventing the wheel so I had a quick Google and  found a couple of posts on from  &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2009/03/09/how-can-i-list-all-updates-that-have-been-added-to-a-computer.aspx" target="_blank" rel="noopener"
>Hey Scripting Guy&lt;/a> blog and one from &lt;a class="link" href="http://blogs.technet.com/b/tmintner/archive/2006/07/07/440729.aspx" target="_blank" rel="noopener"
>Tim Minter&lt;/a>. Neither quite did what I wanted so I modified them as follows.&lt;/p>
&lt;p>We start by creating a Update object and find the total number of updates and setting them to a variable &lt;code>$History&lt;/code> which we pass to the &lt;code>QueryHistory&lt;/code> Method. This enables us to show all the updates&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image100.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image100.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Passing this to &lt;code>Get-Member&lt;/code> shows&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image101.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image101.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>which doesn’t show the KB so I read a bit more and found &lt;a class="link" href="http://lyncdup.com/2013/09/list-all-microsoftwindows-updates-with-powershell-sorted-by-kbhotfixid-get-microsoftupdate/?utm_source=rss&amp;amp;utm_medium=rss&amp;amp;utm_campaign=list-all-microsoftwindows-updates-with-powershell-sorted-by-kbhotfixid-get-microsoftupdate&amp;amp;utm_source=feedburner&amp;amp;utm_medium=feed&amp;amp;utm_campaign=Feed%3A&amp;#43;LyncdUp&amp;#43;%28Lync%27d&amp;#43;Up%29" target="_blank" rel="noopener"
>Tom Arbuthnot’s Blog Post&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image102.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image102.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>this transforms the &lt;code>ResultCode&lt;/code> Property to something meaningful and places the KB in its own column.&lt;/p>
&lt;p>I have created a function called &lt;code>Show-WindowsUpdatesLocal&lt;/code> It’s Local because doing it for a remote server takes a different approach but I will show that another day.&lt;/p>
&lt;p>This means you can call the function and use the results however you like&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image103.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image103.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal| Select Date, HotfixID, Result|Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image104.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image104.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal|Where-Object {$_.Result -eq ‘Failed’} |Select Date, HotfixID, Result,Title|Format-Table -AutoSize
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image105.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image105.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Output to file&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal|Format-Table -AutoSize|Out-File c:\temp\updates.txt
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image106.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image106.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Output to CSV&lt;/p>
&lt;pre>&lt;code>Show-WindowsUpdatesLocal|Export-Csv c:\temp\updates.csv
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image107.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image107.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You can get the code here&lt;/p>
&lt;pre>&lt;code>############################################################# #########
#
# NAME: Show-WindowsUpdatesLocal.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:22/09/2013
#
# COMMENTS: Load function to show all windows updates locally
#
# USAGE: Show-WindowsUpdatesLocal
# Show-WindowsUpdatesLocal| Select Date, HotfixID, Result|Format-Table -AutoSize
# Show-WindowsUpdatesLocal|Where-Object {$_.Result -eq 'Failed'} |Select Date, HotfixID, Result,Title| Format-Table -AutoSize
# Show-WindowsUpdatesLocal|Format-Table -AutoSize| Out-File c:\temp\updates.txt
# Show-WindowsUpdatesLocal|Export-Csv c:\temp\updates.csv
#
Function Show-WindowsUpdatesLocal {
$Searcher = New-Object -ComObject Microsoft.Update. Searcher
$History = $Searcher.GetTotalHistoryCount()
$Updates = $Searcher.QueryHistory(1, $History)
# Define a new array to gather output
$OutputCollection = @()
Foreach ($update in $Updates) {
$Result = $null
Switch ($update.ResultCode) {
0 { $Result = 'NotStarted'}
1 { $Result = 'InProgress' }
2 { $Result = 'Succeeded' }
3 { $Result = 'SucceededWithErrors' }
4 { $Result = 'Failed' }
5 { $Result = 'Aborted' }
default { $Result = $_ }
}
$string = $update.title
$Regex = “KB\d*”
$KB = $string | Select-String -Pattern $regex | Select-Object { $_.Matches }
$output = New-Object -TypeName PSobject
$output | add-member NoteProperty “Date” -value $Update.Date
$output | add-member NoteProperty “HotFixID” -value $KB.‘ $_.Matches ‘.Value
$output | Add-Member NoteProperty &amp;quot;Result&amp;quot; -Value $Result
$output | add-member NoteProperty “Title” -value $string
$output | add-member NoteProperty “Description” -value $update.Description
$OutputCollection += $output
}
$OutputCollection
}
&lt;/code>&lt;/pre></description></item><item><title>Finding Text In All Files In A Folder With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/finding-text-in-all-files-in-a-folder-with-powershell/</link><pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/finding-text-in-all-files-in-a-folder-with-powershell/</guid><description>&lt;p>Whilst writing my &lt;a class="link" href="https://blog.robsewell.com/?p=434" target="_blank" rel="noopener"
>PowerShell Box of Tricks GUI&lt;/a> I realised that I had hard-coded the path to the sqlservers.txt file in several functions and I wanted one place where I could set this. At the top of the GUI script I added a variable and in the ReadMe explained this needed to be set but I needed to change it in all of the functions where it was referenced.&lt;/p>
&lt;p>&lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2011/08/04/use-an-easy-powershell-command-to-search-files-for-information.aspx" target="_blank" rel="noopener"
>The Hey Scripting Guy Blog came to the rescue&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image97.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image97.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Only four entries so i did them manually but &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2008/01/17/how-can-i-use-windows-powershell-to-replace-characters-in-a-text-file.aspx" target="_blank" rel="noopener"
>You can also use PowerShell to replace the entries.&lt;/a>&lt;/p></description></item><item><title>The PowerShell Box Of Tricks GUI</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-powershell-box-of-tricks-gui/</link><pubDate>Tue, 24 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/the-powershell-box-of-tricks-gui/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2013/09/image86.png" alt="Featured image of post The PowerShell Box Of Tricks GUI" />&lt;p>When I started as a DBA at MyWork I faced a challenge. Many hundreds of databases, dozens of servers and no idea what was on where. It was remembering this situation when new team members were appointed that lead me to write the &lt;a class="link" href="https://blog.robsewell.com/using-powershell-to-find-a-database-amongst-hundreds/" target="_blank" rel="noopener"
>Find-Database script&lt;/a> and I had written a simple GUI using &lt;code>Read-Host&lt;/code> to enable the newbies to see the functions I had created&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image85.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image85.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Whilst writing this series of posts I decided that I would create a new GUI&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image86.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image86.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I wanted the choice to be made and then the form to close so I had to use a separate function for calling all the functions referenced in the form. This function takes an input &lt;code>$x&lt;/code> and depending on the value runs a particular code block. Inside the code block I ask some questions using &lt;code>Read-Host&lt;/code> to set the variables, load the function and run it as shown below for &lt;a class="link" href="https://blog.robsewell.com/checking-drive-sizes-with-powershell/" target="_blank" rel="noopener"
>Show-DriveSizes&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image87.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image87.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Then I set about creating the GUI. First we load the Forms Assembly, create a new Form object and add a title&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image88.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image88.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Then using the &lt;a class="link" href="http://www.alkanesolutions.co.uk/2013/04/19/embedding-base64-image-strings-inside-a-powershell-application/" target="_blank" rel="noopener"
>details found here&lt;/a> I I converted the image to ASCI and use it as the background image and set the size of the Form&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image89.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image89.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I choose a default font for the form. Note there are many many properties that you can set for all of these objects so &lt;a class="link" href="http://google.com" target="_blank" rel="noopener"
>use your best learning aid&lt;/a> and find the ones you need.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image90.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image90.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I then create three labels. I will show one. I think the code is self-explanatory and you will be able to see what is going on. Don’t forget to the last line though! That adds it to the form, if you miss it you can spend a few minutes scratching your head wondering why it hasn’t appeared!!!&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image91.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image91.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>We need a Text Box for the User to put their choice in. Again the code is fairly easy to understand&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image92.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image92.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The next bit of code enables the user to use Enter and Escape keys to Go or to Quit. Notice that both call the &lt;code>Close()&lt;/code> method to close the Form and return to the PowerShell console&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image93.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image93.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Add a button for OK and one for quit&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image94.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image94.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and finally Activate the Form, Show it and run the function to call the correct function&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image95.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image95.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The &lt;code>Return-Answer&lt;/code> function simply calls the &lt;code>Return-Function&lt;/code> function. I am not sure if that is the best way of doing it but it works in the way i wanted it to&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image96.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image96.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p></description></item><item><title>Add User to SQL Server Database Role with PowerShell and Quickly Creating Test Users</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</link><pubDate>Mon, 23 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-user-to-sql-server-database-role-with-powershell-and-quickly-creating-test-users/</guid><description>&lt;p>There is a newer &lt;a class="link" href="https://blog.robsewell.com/blog/quickly-creating-test-users-in-sql-server-with-powershell-using-the-sqlserver-module-and-dbatools/" target="_blank" rel="noopener"
>up to date version of this post here&lt;/a> using the &lt;a class="link" href="https://dbatools.io" target="_blank" rel="noopener"
>dbatools module&lt;/a> and the sqlserver module&lt;/p>
&lt;p>But if you want to continue with this way read on!!&lt;/p>
&lt;p>Having created &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Windows Users&lt;/a> or &lt;a class="link" href="https://blog.robsewell.com/creating-sql-user-and-adding-to-server-role-with-powershell/" target="_blank" rel="noopener"
>SQL Users&lt;/a> using the last two days posts, today we shall add them to a role on a database.&lt;/p>
&lt;p>As I discussed &lt;a class="link" href="https://blog.robsewell.com/checking-sql-server-user-role-membership-with-powershell/" target="_blank" rel="noopener"
>previously&lt;/a> I believe that to follow good practice I try to ensure that database permissions are granted by role membership and each role is created with the minimum amount of permissions required for successful execution of the task involved.&lt;/p>
&lt;p>So with each database having the correct roles created and the users created we just need to add the user to the database and to the role. This is easily done with PowerShell.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image70.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image70.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The &lt;code>Add-UserToRole&lt;/code> function takes four parameters Server,Database,User and Role and does a series of error checks.&lt;/p>
&lt;p>With these functions you can easily create a number of Users and add them to database roles quickly and easily and repeatedly.&lt;/p>
&lt;p>If the test team come to you and require 10 Test Users and 3 Test Administrators adding to the test database. I create 2 notepad files&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image71.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image71.png"
loading="lazy"
alt="image"
>&lt;/a>  &lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image72.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image72.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and use them with the &lt;code>Add-SQLAccountToSQLRole&lt;/code> and &lt;code>Add-UserToRole&lt;/code> functions to create the users&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image73.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image73.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Here are the results in PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image74.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image74.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and in SSMS&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image75.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image75.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The Code is here&lt;/p>
&lt;pre>&lt;code>############################################################# ################################
#
# NAME: Add-UserToRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to add user or group to a role on a database
#
# USAGE: Add-UserToRole fade2black Aerosmith Test db_owner
#
Function Add-UserToRole ([string] $server, [String] $Database , [string]$User, [string]$Role)
{
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
#Check Database Name entered correctly
$db = $svr.Databases[$Database]
if($db -eq $null)
{
Write-Output &amp;quot; $Database is not a valid database on $Server&amp;quot;
Write-Output &amp;quot; Databases on $Server are :&amp;quot;
$svr.Databases|select name
break
}
#Check Role exists on Database
$Rol = $db.Roles[$Role]
if($Rol -eq $null)
{
Write-Output &amp;quot; $Role is not a valid Role on $Database on $Server &amp;quot;
Write-Output &amp;quot; Roles on $Database are:&amp;quot;
$db.roles|select name
break
}
if(!($svr.Logins.Contains($User)))
{
Write-Output &amp;quot;$User not a login on $server create it first&amp;quot;
break
}
if (!($db.Users.Contains($User)))
{
# Add user to database
$usr = New-Object ('Microsoft.SqlServer.Management. Smo.User') ($db, $User)
$usr.Login = $User
$usr.Create()
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User was not a login on $Database on $server&amp;quot;
Write-Output &amp;quot;$User added to $Database on $Server and $Role Role&amp;quot;
}
else
{
#Add User to the Role
$Rol = $db.Roles[$Role]
$Rol.AddMember($User)
Write-Output &amp;quot;$User added to $Role Role in $Database on $Server &amp;quot;
}
}
&lt;/code>&lt;/pre></description></item><item><title>Creating SQL User and adding to Server Role with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-user-and-adding-to-server-role-with-powershell/</link><pubDate>Sat, 21 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-user-and-adding-to-server-role-with-powershell/</guid><description>&lt;p>Another post in the &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a> series.&lt;/p>
&lt;p>In yesterdays post &lt;a class="link" href="https://blog.robsewell.com/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/" target="_blank" rel="noopener"
>Creating a Windows User and Adding to SQL Role&lt;/a> we created a Windows User, today it’s a SQL User. Again it is nice and simple and allows you to pipe input from other sources enabling you to easily and quickly repeat any process that needs SQL Users.&lt;/p>
&lt;p>It is pretty similar as you would expect. We create a Login Object, set the Logintype to  SqlLogin add the Password and create it with the Create Method. It is then added to the Role Specified&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image69.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image69.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The same error checking is performed as the Windows Login function. If the login already exists on the server it will just add it to the role and if the role has been mistyped it will let you know. It does this by checking if the role object is Null for the Roles and the Contains Method for the Logins&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image99.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image99.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The function is called as follows.&lt;/p>
&lt;pre>&lt;code>Add-SQLAccountToSQLRole FADE2BLACK Test Password01 dbcreator
&lt;/code>&lt;/pre>
&lt;p>The code can be found here&lt;/p>
&lt;pre>&lt;code>############################################################# ###########
#
# NAME: Add-SQLAccountToSQLRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to create a sql user and add them to a server role
#
# USAGE: Add-SQLAccountToSQLRole FADE2BLACK Test Password01 dbcreator
# Add-SQLAccountToSQLRole FADE2BLACK Test Password01 public
Function Add-SQLAccountToSQLRole ([String]$Server, [String] $User, [String]$Password, [String]$Role) {
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
# Check if Role entered Correctly
$SVRRole = $svr.Roles[$Role]
if ($SVRRole -eq $null) {
Write-Host &amp;quot; $Role is not a valid Role on $Server&amp;quot;
}
else {
#Check if User already exists
if ($svr.Logins.Contains($User)) {
$SqlUser = New-Object -TypeName Microsoft. SqlServer.Management.Smo.Login $Server, $User
$LoginName = $SQLUser.Name
if ($Role -notcontains &amp;quot;public&amp;quot;) {
$SVRRole.AddMember($LoginName)
}
}
else {
$SqlUser = New-Object -TypeName Microsoft. SqlServer.Management.Smo.Login $Server, $User
$SqlUser.LoginType = 'SqlLogin'
$SqlUser.PasswordExpirationEnabled = $false
$SqlUser.Create($Password)
$LoginName = $SQLUser.Name
if ($Role -notcontains &amp;quot;public&amp;quot;) {
$SVRRole.AddMember($LoginName)
}
}
}
}
&lt;/code>&lt;/pre></description></item><item><title>Creating a Windows User and adding to a SQL Server Role with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/</link><pubDate>Fri, 20 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-a-windows-user-and-adding-to-a-sql-server-role-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image67.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image67.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The function does some simple error checking. If the login already exists on the server it will just add it to the role and if the role has been mistyped it will let you know. It does this by checking if the Role object is Null for the Roles and the Contains Method for the Logins&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image98.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image98.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>Add-WindowsAccountToSQLRole FADE2BLACK ‘FADE2BLACK\Test’ public
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>###########################################################
#
# NAME: Add-WindowsAccountToSQLRole.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:11/09/2013
#
# COMMENTS: Load function to create a windows user and add them to a server role
#
# USAGE: Add-WindowsAccountToSQLRole FADE2BLACK 'FADE2BLACK\Test' dbcreator
# Add-WindowsAccountToSQLRole FADE2BLACK 'FADE2BLACK\Test' public
Function Add-WindowsAccountToSQLRole ([String]$Server, [String] $User, [String]$Role) {
$Svr = New-Object ('Microsoft.SqlServer.Management.Smo. Server') $server
# Check if Role entered Correctly
$SVRRole = $svr.Roles[$Role]
if ($SVRRole -eq $null) {
Write-Output &amp;quot; $Role is not a valid Role on $Server&amp;quot;
}
else {
#Check if User already exists
if ($svr.Logins.Contains($User)) {
$SqlUser = New-Object -TypeName Microsoft. SqlServer.Management.Smo.Login $Server, $User
$LoginName = $SQLUser.Name
if ($Role -notcontains &amp;quot;public&amp;quot;) {
$svrole = $svr.Roles | where {$_.Name -eq $Role}
$svrole.AddMember(&amp;quot;$LoginName&amp;quot;)
}
}
else {
$SqlUser = New-Object -TypeName Microsoft. SqlServer.Management.Smo.Login $Server, $User
$SqlUser.LoginType = 'WindowsUser'
$SqlUser.Create()
$LoginName = $SQLUser.Name
if ($Role -notcontains &amp;quot;public&amp;quot;) {
$svrole = $svr.Roles | where {$_.Name -eq $Role}
$svrole.AddMember(&amp;quot;$LoginName&amp;quot;)
}
}
}
}
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted --></description></item><item><title>Displaying the Windows Event Log with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/displaying-the-windows-event-log-with-powershell/</link><pubDate>Wed, 18 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/displaying-the-windows-event-log-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>I’ll start by saying this is a bit of a cheat. PowerShell has a perfectly good cmdlet called &lt;a class="link" href="http://technet.microsoft.com/en-us/library/hh849834.aspx" target="_blank" rel="noopener"
>Get-EventLog&lt;/a> and plenty of &lt;a class="link" href="http://technet.microsoft.com/en-us/library/ee176846.aspx" target="_blank" rel="noopener"
>ways to use it&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>#####################################################################
#
# NAME: Show-EventLog.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:06/08/2013
#
# COMMENTS: Load function for Showing the windows event logs on a server
# ————————————————————————
# Define a server an event log the number of events and display
# pipe to this and then to out-gridview to only show Errors - where {$_. entryType -match &amp;quot;Error&amp;quot;}
Function Show-EventLog ($Server, $log, $Latest) {
Get-EventLog -computername $server -log $log -newest $latest | Out-GridView
}
&lt;/code>&lt;/pre></description></item><item><title>Showing and Killing SQL Server Processes with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/showing-and-killing-sql-server-processes-with-powershell/</link><pubDate>Tue, 17 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/showing-and-killing-sql-server-processes-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>Create a Server Object and notice that there is a Method named EnumProcesses by piping it to &lt;code>Get-Member&lt;/code> and then look at the Properties and Methods of EnumProcesses&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>#######################################################################
#
# NAME: Show-SQLProcesses.ps1
# AUTHOR: Rob Sewell http://sqldbawithabeard.com
# DATE:06/08/2013
#
# COMMENTS: Load function for Showing Processes on a SQL Server
####################################
Function Show-SQLProcesses ($SQLServer)
{
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
$Server.EnumProcesses()|Select Spid,BlockingSpid, Login, Host,Status,Program, Command,Database,Cpu,MemUsage |Format-Table -wrap -auto
$OUTPUT= [System.Windows.Forms.MessageBox]::Show(&amp;quot;Do you want to Kill a process?&amp;quot; , &amp;quot;Question&amp;quot; , 4)
if ($OUTPUT -eq &amp;quot;YES&amp;quot; )
{
$spid = Read-Host &amp;quot;Which SPID?&amp;quot;
$Server.KillProcess($Spid)
}
else
{
}
}
&lt;/code>&lt;/pre></description></item><item><title>Show The Last Backups On A Server with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-the-last-backups-on-a-server-with-powershell/</link><pubDate>Sun, 15 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/show-the-last-backups-on-a-server-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>The &lt;code>Show-LastServerBackup&lt;/code> function iterates through each database on the server and takes each of the three properties mentioned in &lt;!-- raw HTML omitted -->yesterdays post&lt;!-- raw HTML omitted -->. However this time I created an empty hash table and added each result to it as follows&lt;/p>
&lt;p>I created the hash table with &lt;code>@()&lt;/code> and then assign each property to a variable inside the loop and add it to a temporary PSObject with some custom NoteProperties to fit the data&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-LastServerBackup.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:06/08/2013
#
# COMMENTS: Load function for Showing Last Backup of each database on a server
# ————————————————————————
Function Show-LastServerBackup ($SQLServer) {
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
$Results = @();
foreach ($db in $server.Databases) {
$DBName = $db.name
$LastFull = $db.lastbackupdate
if ($lastfull -eq '01 January 0001 00:00:00')
{$LastFull = 'NEVER'}
$LastDiff = $db.LastDifferentialBackupDate
if ($lastdiff -eq '01 January 0001 00:00:00')
{$Lastdiff = 'NEVER'}
$lastLog = $db.LastLogBackupDate
if ($lastlog -eq '01 January 0001 00:00:00')
{$Lastlog = 'NEVER'}
$TempResults = New-Object PSObject;
$TempResults | Add-Member -MemberType NoteProperty -Name &amp;quot;Server&amp;quot; -Value $Server;
$TempResults | Add-Member -MemberType NoteProperty -Name &amp;quot;Database&amp;quot; -Value $DBName;
$TempResults | Add-Member -MemberType NoteProperty -Name &amp;quot;Last Full Backup&amp;quot; -Value $LastFull;
$TempResults | Add-Member -MemberType NoteProperty -Name &amp;quot;Last Diff Backup&amp;quot; -Value $LastDiff;
$TempResults | Add-Member -MemberType NoteProperty -Name &amp;quot;Last Log Backup&amp;quot; -Value $LastLog;
$Results += $TempResults;
}
$Results
}
&lt;/code>&lt;/pre></description></item><item><title>Checking For A Database Backup with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-for-a-database-backup-with-powershell/</link><pubDate>Sat, 14 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-for-a-database-backup-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-LastServerBackup.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:06/08/2013
#
# COMMENTS: Load function for Showing Last Backup of each database on a server
# ————————————————————————
Function Show-LastDatabaseBackup ($SQLServer, $sqldatabase) {
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
$db = $server.Databases[$sqldatabase]
Write-Output &amp;quot;Last Full Backup&amp;quot;
$LastFull = $db.lastbackupdate
if ($lastfull -eq '01 January 0001 00:00:00')
{$LastFull = 'NEVER'}
Write-Output $LastFull
Write-Output &amp;quot;Last Diff Backup&amp;quot;
$LastDiff = $db.LastDifferentialBackupDate
if ($lastdiff -eq '01 January 0001 00:00:00')
{$Lastdiff = 'NEVER'}
Write-Output $Lastdiff
Write-Output &amp;quot;Last Log Backup&amp;quot; $lastLog = $db. LastLogBackupDate
if ($lastlog -eq '01 January 0001 00:00:00')
{$Lastlog = 'NEVER'}
Write-Output $lastlog
}
&lt;/code>&lt;/pre></description></item><item><title>Searching the SQL Error Log with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/searching-the-sql-error-log-with-powershell/</link><pubDate>Fri, 13 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/searching-the-sql-error-log-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Search-SQLErrorLog.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:22/07/2013
#
# COMMENTS: Load function for Searching SQL Error Log and exporting and displaying to CSV
# ————————————————————————
Function Search-SQLErrorLog ([string] $SearchTerm , [string] $SQLServer) {
$FileName = 'c:\TEMP\SQLLogSearch.csv'
$Search = '*' + $SearchTerm + '*'
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
$server.ReadErrorLog(5)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |Export-Csv $FileName
$server.ReadErrorLog(4)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |ConvertTo-Csv |Out-File $FileName -append
$server.ReadErrorLog(3)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |ConvertTo-Csv |Out-File $FileName -append
$server.ReadErrorLog(2)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |ConvertTo-Csv |Out-File $FileName -append
$server.ReadErrorLog(1)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |ConvertTo-Csv |Out-File $FileName -append
$server.ReadErrorLog(0)| Where-Object {$_.Text -like $Search} | Select LogDate, ProcessInfo, Text |ConvertTo-Csv |Out-File $FileName -append
Invoke-Item $filename
}
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted --></description></item><item><title>List Databases (and Properties) on SQL Server with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/list-databases-and-properties-on-sql-server-with-powershell/</link><pubDate>Wed, 11 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/list-databases-and-properties-on-sql-server-with-powershell/</guid><description>&lt;p>Another post in the &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a> series. Here is another script which I use to save me time and effort during my daily workload enabling me to spend more time on more important (to me) things!&lt;/p>
&lt;p>Todays question which I often get asked is What databases are on that server?&lt;/p>
&lt;p>This is often a follow up to a question that requires the &lt;a class="link" href="https://blog.robsewell.com/using-powershell-to-find-a-database-amongst-hundreds/" target="_blank" rel="noopener"
>Find-Database script&lt;/a>. It is often asked by support teams investigating issues. It can also be asked by developers checking the impact of other services on their DEV/UAT environments, by change managers investigating impact of changes, by service managers investigating the impact of downtime, when capacity planning for a new service and numerous other situations.&lt;/p>
&lt;p>A simple quick and easy question made simpler with this function which can also be called when creating documentation&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image54.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image54.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>Show-DatabasesOnServer SERVERNAME
&lt;/code>&lt;/pre>
&lt;p>and use the results as you need&lt;!-- raw HTML omitted -->
&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image55.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image55.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>This only shows you the name but if you need more information about your databases then have a look and see what you require.&lt;/p>
&lt;p>Use `Get-Member` to see what is there. I ran the following code to count the number of Properties available for Databases (Using PowerShell V3 on SQL Server 2012 SP1 11.0.3350.0 )&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image56.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image56.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>154 Properties that you can examine and that is just for databases:-)&lt;/p>
&lt;p>Picking out a few properties you could do something like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image57.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image57.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>If you want aliases for your column headings you will need to add a bit of code to the select.&lt;/p>
&lt;p>For Example, maybe you want to Database Name as a heading and the Size in Gb (Its in Mb in the example above) You would need to create a hash table with a Label element and an Expression element. The Label is the column heading and the Expression can just be the data or a calculation on data.&lt;/p>
&lt;p>So select Name becomes&lt;/p>
&lt;pre>&lt;code>select @{label=&amp;quot;Database Name&amp;quot;;Expression={$_.Name}}
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>Select @{label=&amp;quot;Size GB&amp;quot;;Expression={&amp;quot;{0:N3}&amp;quot; -f ($_.Size/1024)}}
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>$srv.databases|select @{label=&amp;quot;Server&amp;quot;;Expression={$_.Parent.name}},`
@{label=&amp;quot;Database Name&amp;quot;;Expression={$_.Name}}, Owner, Collation, CompatibilityLevel,`
RecoveryModel, @{label=&amp;quot;Size GB&amp;quot;;Expression={&amp;quot;{0:N3}&amp;quot; -f ($_.Size/1024)}}|`
Format-Table -Wrap –AutoSize
&lt;/code>&lt;/pre>
&lt;p>and the results&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image58.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image58.png?resize=630%2C173"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and here is the full code&lt;/p>
&lt;pre>&lt;code>&amp;lt;#PSScriptInfo
.VERSION 1.0
.GUID 48bf0316-66c3-4253-9154-6fc5b28e482a
.AUTHOR Rob Sewell
.DESCRIPTION Returns Database Name and Size in MB for databases on a SQL server
.COMPANYNAME
.COPYRIGHT
.TAGS SQL, Database, Databases, Size
.LICENSEURI
.PROJECTURI
.ICONURI
.EXTERNALMODULEDEPENDENCIES
.REQUIREDSCRIPTS
.EXTERNALSCRIPTDEPENDENCIES
.RELEASENOTES
#&amp;gt;
&amp;lt;#
.Synopsis
Returns the databases on a SQL Server and their size
.DESCRIPTION
Returns Database Name and Size in MB for databases on a SQL server
.EXAMPLE
Show-DatabasesOnServer
This will return the user database names and sizes on the local machine default instance
.EXAMPLE
Show-DatabasesOnServer -Servers SERVER1
This will return the database names and sizes on SERVER1
.EXAMPLE
Show-DatabasesOnServer -Servers SERVER1 -IncludeSystemDatabases
This will return all of the database names and sizes on SERVER1 including system databases
.EXAMPLE
Show-DatabasesOnServer -Servers 'SERVER1','SERVER2\INSTANCE'
This will return the user database names and sizes on SERVER1 and SERVER2\INSTANCE
.EXAMPLE
$Servers = 'SERVER1','SERVER2','SERVER3'
Show-DatabasesOnServer -Servers $servers|out-file c:\temp\dbsize.txt
This will get the user database names and sizes on SERVER1, SERVER2 and SERVER3 and export to a text file c:\temp\dbsize.txt
.NOTES
AUTHOR : Rob Sewell https://blog.robsewell.com
Initial Release 22/07/2013
Updated with switch for system databases added assembly loading and error handling 20/12/2015
Some tidying up and ping check 01/06/2016
#&amp;gt;
Function Show-DatabasesOnServer
{
[CmdletBinding()]
param (
# Server Name or array of Server Names - Defaults to $ENV:COMPUTERNAME
[Parameter(Mandatory = $false,
ValueFromPipeline = $true,
ValueFromPipelineByPropertyName = $true,
Position = 0)]
$Servers = $Env:COMPUTERNAME,
# Switch to include System Databases
[Parameter(Mandatory = $false)]
[switch]$IncludeSystemDatabases
)
[void][reflection.assembly]::LoadWithPartialName( &amp;quot;Microsoft.SqlServer. Smo&amp;quot; );
foreach ($Server in $Servers) {
if ($Server.Contains('\')) {
$ServerName = $Server.Split('\')[0]
$Instance = $Server.Split('\')[1]
}
else {
$Servername = $Server
}
## Check for connectivity
if ((Test-Connection $ServerName -count 1 -Quiet) -eq $false) {
Write-Error &amp;quot;Could not connect to $ServerName - Server did not respond to ping&amp;quot;
$_.Exception
continue
}
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $Server
if ($IncludeSystemDatabases) {
try {
$Return = $srv.databases| Select Name, Size
}
catch {
Write-Error &amp;quot;Failed to get database information from $Server&amp;quot;
$_.Exception
continue
}
}
else {
try {
$Return = $srv.databases.Where{$_.IsSystemObject -eq $false} | Select Name, Size
}
catch {
Write-Error &amp;quot;Failed to get database information from $Server&amp;quot;
$_.Exception
continue
}
}
Write-Output &amp;quot;`n The Databases on $Server and their Size in MB `n&amp;quot;
$Return
}
}
&lt;/code>&lt;/pre></description></item><item><title>Reading Todays SQL Error Log With PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/reading-todays-sql-error-log-with-powershell/</link><pubDate>Wed, 11 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/reading-todays-sql-error-log-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>Show-LatestSQLErrorLog fade2black|Out-File -FilePath c:\temp\log.txt
Invoke-Item c:\temp\log.txt
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-Last24HoursSQLErrorLog.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:22/07/2013
#
# COMMENTS: Load function for reading last days current SQL Error Log for Server
# ————————————————————————
Function Show-Last24HoursSQLErrorLog ([string]$Server) {
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
$logDate = (get-date).AddDays(-1)
$Results = $srv.ReadErrorLog(0) |Where-Object {$_.LogDate -gt $logDate}| format-table -Wrap -AutoSize
$Results
}
&lt;/code>&lt;/pre></description></item><item><title>Dropping SQL Users with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/dropping-sql-users-with-powershell/</link><pubDate>Tue, 10 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/dropping-sql-users-with-powershell/</guid><description>&lt;p>As you may have noticed, I love PowerShell!&lt;/p>
&lt;p>I have developed a series of functions over time which save me time and effort whilst still enabling me to provide a good service to my customers. I keep them all in a functions folder and call them whenever. I call it my &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a>&lt;/p>
&lt;p>I am going to write a short post about each one over the next few weeks as I write my presentation on the same subject which I will be presenting to SQL User Groups.&lt;/p>
&lt;p>Todays post is not about a question but about a routine task DBAs do. Dropping Logins&lt;/p>
&lt;p>Whilst best practice says add users to active directory groups, add the group to roles and give the roles the correct permissions there are many situations where this is not done and DBAs are required to manually remove logins. This can be a time consuming task but one that is essential. There was a time at MyWork when this was achieved via a script that identified which servers had a users login and the task was to connect to each server in SSMS and remove the user from each database and then drop the server login. As you can imagine it was not done diligently. Prior to an audit I was tasked with ensuring that users that had left MyWork did not have logins to any databases. It was this that lead to the &lt;a class="link" href="https://blog.robsewell.com/checking-for-sql-server-logins-with-powershell/" target="_blank" rel="noopener"
>Checking for SQL Logins&lt;/a> script and to this one&lt;/p>
&lt;p>It starts exactly the same as the Checking for SQL Logins script by grabbing the list of SQL Servers from the text file and creating an array of user names including all the domains as I work in a multi-domain environment&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image51.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image51.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Then iterate through each database ignoring those that may need special actions due to the application and call the drop method&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image52.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image52.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Repeat the process for the servers and send or save the report as required. Simple and easy and has undoubtedly saved me many hours compared to the previous way of doing things 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image53.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image53.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;h4 id="important-note">IMPORTANT NOTE&lt;/h4>
&lt;p>This script will not delete logins if they have granted permissions to other users. I always recommend running the &lt;a class="link" href="https://blog.robsewell.com/checking-for-sql-server-logins-with-powershell/" target="_blank" rel="noopener"
>Checking for SQL Logins&lt;/a> script after running this script to ensure all logins have been dropped&lt;/p>
&lt;p>This script can be found&lt;/p>
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Drop-SQLUsers.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:06/08/2013
#
# COMMENTS: Load function to Display a list of server, database and login for SQL servers listed
# in sqlservers.txt file and then drop the users
#
# I always recommend running the Checking for SQL Logins script after running this script to ensure all logins have been dropped
#
# Does NOT drop Users who have granted permissions
#BE CAREFUL
Function Drop-SQLUsers ($Usr) {
[System.Reflection.Assembly]::LoadWithPartialName('Microsoft.SqlServer. SMO') | out-null
# Suppress Error messages - They will be displayed at the end
$ErrorActionPreference = &amp;quot;SilentlyContinue&amp;quot;
# cls
# Pull a list of servers from a local text file
$servers = Get-Content 'c:\temp\sqlservers.txt'
# Create an array for the username and each domain slash username
$logins = @(&amp;quot;DOMAIN1\$usr&amp;quot;, &amp;quot;DOMAIN2\$usr&amp;quot;, &amp;quot;DOMAIN3\$usr&amp;quot; , &amp;quot;$usr&amp;quot;)
Write-Output &amp;quot;#################################&amp;quot;
Write-Output &amp;quot;Dropping Logins for $Logins&amp;quot;
#loop through each server and each database and
Write-Output &amp;quot;#########################################&amp;quot;
Write-Output &amp;quot;`n Database Logins`n&amp;quot;
foreach ($server in $servers) {
if (Test-Connection $Server -Count 1 -Quiet) {
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
#drop database users
foreach ($database in $srv.Databases) {
if ($database -notlike &amp;quot;*dontwant*&amp;quot;) {
foreach ($login in $logins) {
if ($database.Users.Contains($login)) {
$database.Users[$login].Drop();
Write-Output &amp;quot; $server , $database , $login - Database Login has been dropped&amp;quot;
}
}
}
}
}
}
Write-Output &amp;quot;`n#########################################&amp;quot;
Write-Output &amp;quot;`n Servers Logins`n&amp;quot;
foreach ($server in $servers) {
if (Test-Connection $Server -Count 1 -Quiet) {
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
#drop server logins
foreach ($login in $logins) {
if ($srv.Logins.Contains($login)) {
$srv.Logins[$login].Drop();
Write-Output &amp;quot; $server , $login Login has been dropped&amp;quot;
}
}
}
}
Write-Output &amp;quot;`n#########################################&amp;quot;
Write-Output &amp;quot;Dropping Database and Server Logins for $usr - Completed &amp;quot;
Write-Output &amp;quot;If there are no logins displayed above then no logins were found or dropped!&amp;quot;
Write-Output &amp;quot;###########################################&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Alter SQL Mirroring Endpoint Owner with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/alter-sql-mirroring-endpoint-owner-with-powershell/</link><pubDate>Sun, 08 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/alter-sql-mirroring-endpoint-owner-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;blockquote>
&lt;p>Login domain\user’ has granted one or more permissions. Revoke the permission before dropping the login (Microsoft SQL Server, Error: 15173)&lt;/p>
&lt;/blockquote>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/mirroring-endpoitn-check.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/mirroring-endpoitn-check.jpg"
loading="lazy"
alt="mirroring endpoitn check"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/alter-endpoint.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/alter-endpoint.jpg"
loading="lazy"
alt="alter endpoint"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/alterendpointps.jpg" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/alterendpointps.jpg"
loading="lazy"
alt="alterendpointPS"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>$svrs = ## list of servers Get-Content from text fiel etc
foreach ($svr in $svrs) {
$server = New-Object Microsoft.SQLServer.Management.Smo.Server $svrs
foreach ($endpoint in $server.Endpoints['Mirroring']) {
if ($endpoint.Owner = 'Domain\User') {
$endpoint.Owner = 'Domain\NEWUser'
$endpoint.Alter()
}
}
}
&lt;/code>&lt;/pre></description></item><item><title>Creating SQL Server Database with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-database-with-powershell/</link><pubDate>Sun, 08 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/creating-sql-server-database-with-powershell/</guid><description>&lt;p>This morning I have been setting up my Azure Servers in preparation for my presentation to the Cardiff SQL User Group this month.&lt;/p>
&lt;p>I used my scripts from &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>My Post on Spinning Up Azure SQL Boxes&lt;/a> to create two servers and then I wanted to create some databases&lt;/p>
&lt;p>I decided it was time to write a Create-Database function using a number of scripts that I have used to create individual databases.&lt;/p>
&lt;h2 id="errors">Errors&lt;/h2>
&lt;p>Whilst finalising the function I didn’t quite get it right sometimes and was faced with an error.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image39.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image39.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Not the most useful of errors to troubleshoot. The issue could be anywhere in the script&lt;/p>
&lt;p>You can view the last errors PowerShell has shown using $Errors. This gives you the last 500 errors but you can see the last error by using $Error[0] if you pipe it to Format-List you can get a more detailed error message so I added a try catch to the function which gave me an error message I could resolve.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image40.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image40.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Much better. The problem was&lt;/p>
&lt;blockquote>
&lt;p>Cannot create file ‘C:\Program Files\Microsoft SQL Server\MSSQL11.MSSQLSERVER\MSSQL\DATA\.LDF’ because it already exists.&lt;/p>
&lt;/blockquote>
&lt;p>Mistyping a variable has caused this. Creating an empty file name variable which then threw the error the second(and third,fourth fifth) times I ran the script but this error pointed me to it.&lt;/p>
&lt;h2 id="creating-database">Creating Database&lt;/h2>
&lt;p>There are a vast number of variables you can set when creating a database. I decided to set File Sizes, File Growth Sizes, Max File Sizes and Recovery Model. I only set Server and Database Name as mandatory parameters and gave the other parameters default values&lt;/p>
&lt;p>&lt;a class="link" href="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image41.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image41.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>We take the parameters for file sizes in MB and set them to KB&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image42.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image42.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Then set the default file locations. Create a database object, a Primary file group object and add the file group object to the database object&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image43.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image43.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Add a User File Group for User objects&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image44.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image44.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Create a database file on the primary file group using the variables set earlier&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image45.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image45.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Do the same for the user file and then create a Log File&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image46.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image46.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Set the Recovery Model and create the database and then set the user file group as the default&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image47.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image47.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Finally catch the errors&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image48.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image48.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>It can then be called as follows&lt;/p>
&lt;pre>&lt;code>Create-Database SERVERNAME DATABASENAME
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image49.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image49.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>or by setting all the parameters&lt;/p>
&lt;pre>&lt;code>Create-Database -Server Fade2black -DBName DatabaseTest -SysFileSize 10 -UserFileSize 15 -LogFileSize 20 -UserFileGrowth 7 -UserFileMaxSize 150 -LogFileGrowth 8 -LogFileMaxSize 250 -DBRecModel FULL
&lt;/code>&lt;/pre>
&lt;p>&lt;a class="link" href="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image50.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image50.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>This means that I can easily and quickly set up several databases of different types and sizes&lt;/p>
&lt;p>The script can be found here&lt;/p>
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Create-Database.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:08/09/2013
#
# COMMENTS: Load function for creating a database
# Only Server and DB Name are mandatory the rest will be set to small defaults
#
# USAGE: Create-Database -Server Fade2black -DBName Test35 -SysFileSize 10 -UserFileSize 15 -LogFileSize 20
# -UserFileGrowth 7 -UserFileMaxSize 150 -LogFileGrowth 8 -LogFileMaxSize 250 -DBRecModel FULL
# ————————————————————————
Function Create-Database {
Param(
[Parameter(Mandatory = $true)]
[String]$Server ,
[Parameter(Mandatory = $true)]
[String]$DBName,
[Parameter(Mandatory = $false)]
[int]$SysFileSize = 5,
[Parameter(Mandatory = $false)]
[int]$UserFileSize = 25,
[Parameter(Mandatory = $false)]
[int]$LogFileSize = 25,
[Parameter(Mandatory = $false)]
[int]$UserFileGrowth = 5,
[Parameter(Mandatory = $false)]
[int]$UserFileMaxSize = 100,
[Parameter(Mandatory = $false)]
[int]$LogFileGrowth = 5,
[Parameter(Mandatory = $false)]
$LogFileMaxSize = 100,
[Parameter(Mandatory = $false)]
[String]$DBRecModel = 'FULL'
)
try {
# Set server object
$srv = New-Object ('Microsoft.SqlServer.Management.SMO.Server') $server
$DB = $srv.Databases[$DBName]
# Define the variables
# Set the file sizes (sizes are in KB, so multiply here to MB)
$SysFileSize = [double]($SysFileSize * 1024.0)
$UserFileSize = [double] ($UserFileSize * 1024.0)
$LogFileSize = [double] ($LogFileSize * 1024.0)
$UserFileGrowth = [double] ($UserFileGrowth * 1024.0)
$UserFileMaxSize = [double] ($UserFileMaxSize * 1024.0)
$LogFileGrowth = [double] ($LogFileGrowth * 1024.0)
$LogFileMaxSize = [double] ($LogFileMaxSize * 1024.0)
Write-Output &amp;quot;Creating database: $DBName&amp;quot;
# Set the Default File Locations
$DefaultDataLoc = $srv.Settings.DefaultFile
$DefaultLogLoc = $srv.Settings.DefaultLog
# If these are not set, then use the location of the master db mdf/ ldf
if ($DefaultDataLoc.Length -EQ 0) {$DefaultDataLoc = $srv. Information.MasterDBPath}
if ($DefaultLogLoc.Length -EQ 0) {$DefaultLogLoc = $srv.Information. MasterDBLogPath}
# new database object
$DB = New-Object ('Microsoft.SqlServer.Management.SMO.Database') ($srv, $DBName)
# new filegroup object
$PrimaryFG = New-Object ('Microsoft.SqlServer.Management.SMO. FileGroup') ($DB, 'PRIMARY')
# Add the filegroup object to the database object
$DB.FileGroups.Add($PrimaryFG )
# Best practice is to separate the system objects from the user objects.
# So create a seperate User File Group
$UserFG = New-Object ('Microsoft.SqlServer.Management.SMO. FileGroup') ($DB, 'UserFG')
$DB.FileGroups.Add($UserFG)
# Create the database files
# First, create a data file on the primary filegroup.
$SystemFileName = $DBName + &amp;quot;_System&amp;quot;
$SysFile = New-Object ('Microsoft.SqlServer.Management.SMO. DataFile') ($PrimaryFG , $SystemFileName)
$PrimaryFG.Files.Add($SysFile)
$SysFile.FileName = $DefaultDataLoc + $SystemFileName + &amp;quot;.MDF&amp;quot;
$SysFile.Size = $SysFileSize
$SysFile.GrowthType = &amp;quot;None&amp;quot;
$SysFile.IsPrimaryFile = 'True'
# Now create the data file for the user objects
$UserFileName = $DBName + &amp;quot;_User&amp;quot;
$UserFile = New-Object ('Microsoft.SqlServer.Management.SMO. Datafile') ($UserFG, $UserFileName)
$UserFG.Files.Add($UserFile)
$UserFile.FileName = $DefaultDataLoc + $UserFileName + &amp;quot;.NDF&amp;quot;
$UserFile.Size = $UserFileSize
$UserFile.GrowthType = &amp;quot;KB&amp;quot;
$UserFile.Growth = $UserFileGrowth
$UserFile.MaxSize = $UserFileMaxSize
# Create a log file for this database
$LogFileName = $DBName + &amp;quot;_Log&amp;quot;
$LogFile = New-Object ('Microsoft.SqlServer.Management.SMO.LogFile') ($DB, $LogFileName)
$DB.LogFiles.Add($LogFile)
$LogFile.FileName = $DefaultLogLoc + $LogFileName + &amp;quot;.LDF&amp;quot;
$LogFile.Size = $LogFileSize
$LogFile.GrowthType = &amp;quot;KB&amp;quot;
$LogFile.Growth = $LogFileGrowth
$LogFile.MaxSize = $LogFileMaxSize
#Set the Recovery Model
$DB.RecoveryModel = $DBRecModel
#Create the database
$DB.Create()
#Make the user filegroup the default
$UserFG = $DB.FileGroups['UserFG']
$UserFG.IsDefault = $true
$UserFG.Alter()
$DB.Alter()
Write-Output &amp;quot; $DBName Created&amp;quot;
Write-Output &amp;quot;System File&amp;quot;
$SysFile| Select Name, FileName, Size, MaxSize, GrowthType| Format-List
Write-Output &amp;quot;User File&amp;quot;
$UserFile| Select Name, FileName, Size, MaxSize, GrowthType, Growth| Format-List
Write-Output &amp;quot;LogFile&amp;quot;
$LogFile| Select Name, FileName, Size, MaxSize, GrowthType, Growth| Format-List
Write-Output &amp;quot;Recovery Model&amp;quot;
$DB.RecoveryModel
}
Catch {
$error[0] | fl * -force
}
}
&lt;/code>&lt;/pre></description></item><item><title>Using PowerShell to find a database amongst hundreds</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-find-a-database-amongst-hundreds/</link><pubDate>Sat, 07 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/using-powershell-to-find-a-database-amongst-hundreds/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image34.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image34.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I create an empty hash table and then populate it with the results&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image35.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image35.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Set a results variable to the names from the hash table and count the number of records&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image36.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image36.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and call it like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image37.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image37.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Note that the search uses the contains method so no need for wildcards&lt;/p>
&lt;p>Results come out like this&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image38.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image38.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Find-Database.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:22/07/2013
#
# COMMENTS: Load function for finding a database
# USAGE: Find-Database DBName
##################################
Function Find-Database ([string]$Search) {
[System.Reflection.Assembly]::LoadWithPartialName('Microsoft.SqlServer. SMO') | out-null
# Pull a list of servers from a local text file
$servers = Get-Content 'sqlservers.txt'
#Create an empty Hash Table
$ht = @{}
$b = 0
#Convert Search to Lower Case
$DatabaseNameSearch = $search.ToLower()
Write-Output &amp;quot;#################################&amp;quot;
Write-Output &amp;quot;Searching for $DatabaseNameSearch &amp;quot;
Write-Output &amp;quot;#################################&amp;quot;
#loop through each server and check database name against input
foreach ($server in $servers) {
if (Test-Connection $Server -Count 1 -Quiet) {
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
foreach ($database in $srv.Databases) {
$databaseName = $database.Name.ToLower()
if ($databaseName.Contains($DatabaseNameSearch)) {
$DatabaseNameResult = $database.name
$Key = &amp;quot;$Server -- $DatabaseNameResult&amp;quot;
$ht.add($Key , $b)
$b = $b + 1
}
}
}
}
$Results = $ht.GetEnumerator() | Sort-Object Name|Select Name
$Resultscount = $ht.Count
if ($Resultscount -gt 0) {
Write-Output &amp;quot;############### I Found It!! #################&amp;quot;
foreach ($R in $Results) {
Write-Output $R.Name
}
}
Else {
Write-Output &amp;quot;############ I am really sorry. I cannot find&amp;quot; $DatabaseNameSearch &amp;quot;Anywhere ##################### &amp;quot;
}
}
&lt;/code>&lt;/pre></description></item><item><title>Checking Drive Sizes with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-drive-sizes-with-powershell/</link><pubDate>Fri, 06 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-drive-sizes-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image31.png"
loading="lazy"
alt="image"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image32.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image32.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and here are the results from my Azure VM. (See &lt;a class="link" href="https://blog.robsewell.com/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>My previous posts on how to create your own Azure VMs with PowerShell&lt;/a>)&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/09/image33.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/image33.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>#############################################################################
#
# NAME: Show-DriveSizes.ps1
# AUTHOR: Rob Sewell http://sqldbawiththebeard.com
# DATE:22/07/2013
#
# COMMENTS: Load function for displaying drivesizes
# USAGE: Show-DriveSizes server1
###########################################
Function Show-DriveSizes ([string]$Server) {
$Date = Get-Date
Write-Host -foregroundcolor DarkBlue -backgroundcolor yellow &amp;quot;$Server - - $Date&amp;quot;
#interogate wmi service and return disk information
$disks = Get-WmiObject -Class Win32_logicaldisk -Filter &amp;quot;Drivetype=3&amp;quot; -ComputerName $Server
$diskData = $disks | Select DeviceID, VolumeName ,
# select size in Gbs as int and label it SizeGb
@{Name = &amp;quot;SizeGB&amp;quot;; Expression = {$_.size / 1GB -as [int]}},
# select freespace in Gbs and label it FreeGb and two deciaml places
@{Name = &amp;quot;FreeGB&amp;quot;; Expression = {&amp;quot;{0:N2}&amp;quot; -f ($_.Freespace / 1GB)}},
# select freespace as percentage two deciaml places and label it PercentFree
@{Name = &amp;quot;PercentFree&amp;quot;; Expression = {&amp;quot;{0:P2}&amp;quot; -f ($_.Freespace / $_. Size)}}
$diskdata
}
&lt;/code>&lt;/pre></description></item><item><title>SQL Server Operators and Notifications with Powershell – Strange Enumerate issue fixed by @napalmgram</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-operators-and-notifications-with-powershell-strange-enumerate-issue-fixed-by-@napalmgram/</link><pubDate>Thu, 05 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-server-operators-and-notifications-with-powershell-strange-enumerate-issue-fixed-by-@napalmgram/</guid><description>&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-04_125056.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>$server | Get-Member
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>$Server.JobServer|gm
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>$Server.JobServer.Operators | gm
&lt;/code>&lt;/pre>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-04_125717.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-04_130052.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-04_174005.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-04_173953.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/2013-09-04_174056.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/2013-09-04_174112.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-05_113931.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/09/2013-09-05_114601.jpg"
loading="lazy"
alt="alt"
>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-SQLServerOperators.ps1
# AUTHOR: Rob Sewell https://blog.robsewell.com
# DATE:03/09/2013
#
# COMMENTS: Load function for Enumerating Operators and Notifications
# ————————————————————————
Function Show-SQLServerOperators ($SQLServer) {
Write-Output &amp;quot;############### $SQLServer ##########################&amp;quot;
Write-Output &amp;quot;#####################################################`n&amp;quot;
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
foreach ($Operator in $server.JobServer.Operators) {
$Operator = New-Object (&amp;quot;$SMO.Agent.Operator&amp;quot;) ($server.JobServer, $Operator)
$OpName = $Operator.Name
Write-Output &amp;quot;Operator $OpName&amp;quot;
Write-Output &amp;quot;`n###### Job Notifications ######&amp;quot;
$Operator.EnumJobNotifications()| Select JobName | Format-Table
Write-Output &amp;quot;#####################################################`n&amp;quot;
Write-Output &amp;quot;`n###### Alert Notifications #######&amp;quot;
$Operator.EnumNotifications() | Select AlertName | Format-Table
Write-Output &amp;quot;#####################################################`n&amp;quot;
}
}
&lt;/code>&lt;/pre></description></item><item><title>SQL login object permissions via PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-login-object-permissions-via-powershell/</link><pubDate>Wed, 04 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-login-object-permissions-via-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-SQLServerPermissions.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:06/08/2013
#
# COMMENTS: Load function for Enumerating Server and Database Role permissions or object permissions
#
# USAGE Show-SQLServerPermissions Server1
# ————————————————————————
Function Show-SQLServerPermissions ($SQLServer) {
$server = new-object &amp;quot;Microsoft.SqlServer.Management.Smo.Server&amp;quot; $SQLServer
$selected = &amp;quot;&amp;quot;
$selected = Read-Host &amp;quot;Enter Selection
1.) Role Membership or
2.) Object Permissions&amp;quot;
Switch ($Selected) {
1 {
Write-Host &amp;quot;#### Server Role Membership on $Server ############################################## `n`n&amp;quot;
foreach ($Role in $Server.Roles) {
if ($Role.EnumServerRoleMembers().count -ne 0) {
Write-Host &amp;quot;############### Server Role Membership for $role on $Server #########################`n&amp;quot;
$Role.EnumServerRoleMembers()
}
}
Write-Host &amp;quot;################################################################ ######################&amp;quot;
Write-Host &amp;quot;################################################################ ######################`n `n `n&amp;quot;
foreach ($Database in $Server.Databases) {
Write-Host &amp;quot;`n#### $Database Permissions on $Server ###############################################`n&amp;quot;
foreach ($role in $Database.Roles) {
if ($Role.EnumMembers().count -ne 0) {
Write-Host &amp;quot;########### Database Role Permissions for $Database $Role on $Server ################`n&amp;quot;
$Role.EnumMembers()
}
}
}
}
2 {
Write-Host &amp;quot;################## Object Permissions on $Server ################################`n&amp;quot;
foreach ($Database in $Server.Databases) {
Write-Host &amp;quot;`n#### Object Permissions on $Database on $Server #################################`n&amp;quot;
foreach ($user in $database.Users) {
foreach ($databasePermission in $database. EnumDatabasePermissions($user.Name)) {
Write-Host $databasePermission.PermissionState $databasePermission.PermissionType &amp;quot;TO&amp;quot; $databasePermission.Grantee
}
foreach ($objectPermission in $database. EnumObjectPermissions($user.Name)) {
Write-Host $objectPermission.PermissionState $objectPermission.PermissionType &amp;quot;ON&amp;quot; $objectPermission.ObjectName &amp;quot;TO&amp;quot; $objectPermission. Grantee
}
}
}
}
}
}
&lt;/code>&lt;/pre>
&lt;!-- raw HTML omitted --></description></item><item><title>Checking SQL Server User Role Membership with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-server-user-role-membership-with-powershell/</link><pubDate>Mon, 02 Sep 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-server-user-role-membership-with-powershell/</guid><description>&lt;!-- raw HTML omitted -->
&lt;pre>&lt;code>############################################################################# ################
#
# NAME: Show-SQLUserPermissions.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:06/08/2013
#
# COMMENTS: Load function to Display the permissions a user has across the estate
# NOTE - Will not show permissions granted through AD Group Membership
#
# USAGE Show-SQLUserPermissions DBAwithaBeard
Function Show-SQLUserPermissions ($user)
{
[System.Reflection.Assembly]::LoadWithPartialName('Microsoft.SqlServer.SMO') | out-null
# Suppress Error messages - They will be displayed at the end
$ErrorActionPreference = &amp;quot;SilentlyContinue&amp;quot;
#cls
$Query = @&amp;quot;
SELECT
IL.ServerName
FROM [dbo].[InstanceList] IL
WHERE NotContactable = 0
AND Inactive = 0
AND DatabaseEngine = 'Microsoft SQL Server'
&amp;quot;@
Try
{
$Results = (Invoke-Sqlcmd -ServerInstance HMDBS02 -Database DBADatabase -Query $query -ErrorAction Stop).ServerName
}
catch
{
Write-Error &amp;quot;Unable to Connect to the DBADatabase - Please Check&amp;quot;
}
# Create an array for the username and each domain slash username
$logins = @(&amp;quot;DOMAIN1\$user&amp;quot;,&amp;quot;DOMAIN3\$user&amp;quot;, &amp;quot;DOMAIN4\$user&amp;quot; ,&amp;quot;$user&amp;quot; )
Write-Output &amp;quot;#################################&amp;quot;
Write-Output &amp;quot;Logins for `n $logins displayed below&amp;quot;
Write-Output &amp;quot;################################# `n&amp;quot;
#loop through each server and each database and display usernames, servers and databases
Write-Output &amp;quot; Server Logins&amp;quot;
foreach($server in $Results)
{
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
foreach($login in $logins)
{
if($srv.Logins.Contains($login))
{
Write-Output &amp;quot;`n $server , $login &amp;quot;
foreach ($Role in $Srv.Roles)
{
$RoleMembers = $Role. EnumServerRoleMembers()
if($RoleMembers -contains $login)
{
Write-Output &amp;quot; $login is a member of $Role on $Server&amp;quot;
}
}
}
else
{
}
}
}
Write-Output &amp;quot;`n#########################################&amp;quot;
Write-Output &amp;quot;`n Database Logins&amp;quot;
foreach($server in $servers)
{
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
foreach($database in $srv.Databases)
{
foreach($login in $logins)
{
if($database.Users.Contains($login))
{
Write-Output &amp;quot;`n $server , $database , $login &amp;quot;
foreach($role in $Database.Roles)
{
$RoleMembers = $Role.EnumMembers()
if($RoleMembers -contains $login)
{
Write-Output &amp;quot; $login is a member of $Role Role on $Database on $Server&amp;quot;
}
}
}
else
{
continue
}
}
}
}
Write-Output &amp;quot;`n#########################################&amp;quot;
Write-Output &amp;quot;Finished - If there are no logins displayed above then no logins were found!&amp;quot;
Write-Output &amp;quot;#########################################&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>Checking for SQL Server logins with PowerShell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-for-sql-server-logins-with-powershell/</link><pubDate>Sat, 31 Aug 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-for-sql-server-logins-with-powershell/</guid><description>&lt;p>As some of you may know, I love PowerShell!&lt;/p>
&lt;p>I use it all the time in my daily job as a SQL DBA and at home whilst learning as well.&lt;/p>
&lt;p>Not only do I use PowerShell for automating tasks such as Daily Backup Checks, Drive Space Checks, Service Running Checks, File Space Checks, Failed Agent Job Checks, SQL Error Log Checks, DBCC Checks and more but also for those questions which come up daily and interfere with concentrating on a complex or time consuming task.&lt;/p>
&lt;p>I have developed a series of functions over time which save me time and effort whilst still enabling me to provide a good service to my customers. I keep them all in a functions folder and call them whenever I need them. I also have a very simple GUI which I have set up for my colleagues to enable them to easily answer simple questions quickly and easily which I will blog about later. I call it my &lt;a class="link" href="https://blog.robsewell.com/tags/#box-of-tricks" target="_blank" rel="noopener"
>PowerShell Box of Tricks&lt;/a>&lt;/p>
&lt;p>I am going to write a short post about each one over the next few weeks as I write my presentation on the same subject which I will be presenting to SQL User Groups.&lt;/p>
&lt;p>Todays question which I often get asked is Which database does this account have access to?&lt;/p>
&lt;p>This question can come from Support Desks when they are investigating a users issue, Developers when they are testing an application as well as audit activities. It is usually followed by what permissions do they have which is covered by my next blog post.&lt;/p>
&lt;p>I start by getting the list of servers from my text file and creating an array of logins for each domain as I work in a multi domain environment&lt;/p>
&lt;p>&lt;a class="link" href="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image10.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image_thumb10.png?resize=538%2C98"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Then loop through each server and if the login exists write it out to the window.&lt;/p>
&lt;p>&lt;a class="link" href="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image19.png" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image_thumb19.png?resize=567%2C173"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>I then repeat this but loop through each database as well&lt;/p>
&lt;p>&lt;a class="link" href="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image20.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image_thumb20.png?resize=572%2C155"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>A little bit of formatting is added and then a quick easy report that can easily be copied to an email as required.&lt;/p>
&lt;p>To call it simply load the function&lt;/p>
&lt;p>&lt;a class="link" href="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image22.png" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image_thumb22.png?resize=357%2C23"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>and get the results&lt;/p>
&lt;p>&lt;a class="link" href="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image21.png" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/09/image_thumb21.png?resize=624%2C226"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>The code is below&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.Synopsis
A workflow to display users server and database logins across a SQL estate
.DESCRIPTION
Display a list of server login and database user and login for SQL servers listed
in sqlservers.txt file from a range of domains
AUTHOR: Rob Sewell https://blog.robsewell.com
LAST UPDATE: DATE:07/01/2015
.EXAMPLE
Show-SQLUserLogins DBAwithaBeard
Shows the SQL Server logins and database users matching DOMAIN1\DBAWithaBeard,DOMAIN2\DBAWithaBeard, DBAWithaBeard
#&amp;gt;
Workflow Show-UserLogins
{
param ([string]$usr)
$servers = Get-Content '\sql\Powershell Scripts\sqlservers.txt'
$ErrorActionPreference = &amp;quot;SilentlyContinue&amp;quot;
# Create an array for the username and each domain slash username
$logins = @(&amp;quot;DOMAIN1\$usr&amp;quot;,&amp;quot;DOMAIN2\$usr&amp;quot;, &amp;quot;DOMAIN3\$usr&amp;quot; ,&amp;quot;$usr&amp;quot; )
Write-Output &amp;quot;#################################&amp;quot;
Write-Output &amp;quot;SQL Servers, Databases and Logins for `n$logins displayed below &amp;quot;
Write-Output &amp;quot;################################# `n&amp;quot;
#loop through each server and each database and display usernames, servers and databases
Write-Output &amp;quot; Server Logins`n&amp;quot;
foreach -parallel ($server in $servers)
{
inlinescript
{
[System.Reflection.Assembly]::LoadWithPartialName('Microsoft.SqlServer.SMO') | out-null
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $Using:server
if(!$srv.Version)
{
Write-Output &amp;quot;$Using:server is not contactable - Please Check Manually&amp;quot;
}
else
{
foreach ($login in $Using:logins)
{
if($srv.Logins.Contains($login))
{
Write-Output &amp;quot; $Using:server -- $login &amp;quot;
}
else
{
continue
}
}
}
}
}
Write-Output &amp;quot;`n###########################&amp;quot;
Write-Output &amp;quot;`n Database Logins`n&amp;quot;
foreach -parallel ($server in $servers)
{
inlinescript
{
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $Using:server
if(!$srv.Version)
{
Write-Output &amp;quot;$Using:server is not contactable - Please Check Manually&amp;quot;
}
else
{
foreach($database in $srv.Databases|Where-Object{$_.IsAccessible -eq $True})
{
foreach($login in $Using:logins)
{
if($database.Users.Contains($login))
{
Write-Output &amp;quot; $Using:server -- $database -- $login &amp;quot;
}
else
{
}
}
}
}
}
}
Write-Output &amp;quot;`n#########################################&amp;quot;
Write-Output &amp;quot;Finished - If there are no logins displayed above then no logins were found!&amp;quot;
Write-Output &amp;quot;#########################################&amp;quot;
}
&lt;/code>&lt;/pre></description></item><item><title>SQL Express Migration Auto Close Setting</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-express-migration-auto-close-setting/</link><pubDate>Sat, 31 Aug 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sql-express-migration-auto-close-setting/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2013/08/image_thumb.png" alt="Featured image of post SQL Express Migration Auto Close Setting" />&lt;p>With over 700 databases to look after at MyWork automation is high on my list of priorities. I have two PowerShell scripts which run regularly checking SQL Error logs. One checks for the output from DBCC CHECKDB and one for errors. They then email the results to the DBA team.&lt;/p>
&lt;p>This week we noticed that a new database was creating a lot of entries. It appeared to be starting up every few minutes. A bit of investigation by my colleague revealed that this database had been created on SQL Express and migrated to SQL Server.&lt;/p>
&lt;p>SQL Express sets AUTO_CLOSE to on by default and this is what was creating the entries.&lt;/p>
&lt;p>What does the AUTO_CLOSE setting do?&lt;/p>
&lt;p>According to BoL &lt;a class="link" href="http://technet.microsoft.com/en-us/library/ms190249%28v=sql.105%29.aspx" target="_blank" rel="noopener"
>Link&lt;/a>&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>Description&lt;/th>
&lt;th>Default value&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>When set to ON, the database is shut down cleanly and its resources are freed after the last user exits. The database automatically reopens when a user tries to use the database again.&lt;/td>
&lt;td>True for all databases when using SQL Server 2000 Desktop Engine or SQL Server Express, and False for all other editions, regardless of operating system.&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>When set to OFF, the database remains open after the last user exits.&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>That explains what was happening, the database was shutting down as the session finished and then starting back up again when the next one started. Repeatedly. Filling up the log files with entries, resetting the DMVs and using resources unnecessarily.&lt;/p>
&lt;p>To find databases with this setting on query the master.sys.databases for the is_auto_close_on column &lt;a class="link" href="http://technet.microsoft.com/en-us/library/ms178534.aspx" target="_blank" rel="noopener"
>Link&lt;/a> or check the properties page in SSMS&lt;/p>
&lt;p>&lt;a class="link" href="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/08/image.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/08/image_thumb.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>You can change the setting there or with T-SQL&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/08/image3.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/08/image3.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>Of course I like to do it with PowerShell!!&lt;/p>
&lt;p>To find the databases with AUTO_CLOSE setting on&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/08/image1.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/08/image_thumb1.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;p>To change the setting with PowerShell&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/assets/uploads/2013/08/image2.png" target="_blank" rel="noopener"
>&lt;img src="https://blog.robsewell.com/assets/uploads/2013/08/image_thumb2.png"
loading="lazy"
alt="image"
>&lt;/a>&lt;/p>
&lt;pre>&lt;code>$svrs = ## list of servers Get-Content from text fiel etc
foreach ($svr in $svrs) {
$server = New-Object Microsoft.SQLServer.Management.Smo.Server $svrs
foreach ($db in $server.Databases) {
if ($db.AutoClose = $true) {
Write-Output &amp;quot;$Server - $($DB.Name) AutoClose ON&amp;quot;
}
}
}
$Svr = 'SERVERNAME'
$DB = 'DatabaseName'
$server = New-Object Microsoft.SQLServer.Management.Smo.Server $svrs
$db.AutoClose = $false
$db.Alter()
&lt;/code>&lt;/pre></description></item><item><title>sp_BlitzIndex™ ouput to Excel with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/sp_blitzindex-ouput-to-excel-with-powershell/</link><pubDate>Sun, 23 Jun 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/sp_blitzindex-ouput-to-excel-with-powershell/</guid><description>&lt;p>I am impressed with the output from &lt;a class="link" href="http://www.brentozar.com/blitzindex/" target="_blank" rel="noopener"
>sp_BlitzIndex™&lt;/a> and today I tried to save it to an excel file so that I could pass it on to the developer of the service. When I opened it in Excel and imported it from the csv file it didn’t keep the T-SQL in one column due the commas which bothered me so I decided to use Powershell to output the format to Excel as follows&lt;/p>
&lt;pre>&lt;code>#############################################################################################
#
# NAME: SPBlitzIndexToCSV.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:22/06/2013
#
# COMMENTS: This script will take the output from spBlitzIndex™ and
# export it to csv without splitting the tsql commands
# ————————————————————————
$Server = Read-Host &amp;quot;Please enter Server&amp;quot;
$Database = Read-Host &amp;quot;Enter Database Name to run spBlitzIndex against&amp;quot;
$filePath = &amp;quot;C:\temp\BlitzIndexResults&amp;quot;
$Date = Get-Date -format ddMMYYYY
$FileName = &amp;quot;Blitzindex_&amp;quot; + $Database + &amp;quot;_&amp;quot; + $Date + &amp;quot;.csv&amp;quot;$Query = &amp;quot;EXEC dbo.sp_BlitzIndex @database_name='$Database';&amp;quot;
$Blitz = Invoke-SQLCMD -server $Server -database master -query $Query$Blitz|Export-Csv $FilePath
$FileName
&lt;/code>&lt;/pre>
&lt;p>Please don’t ever trust anything you read on the internet and certainly don’t implement it on production servers without first both understanding what it will do and testing it thoroughly. This solution worked for me in my environment I hope it is of use to you in yours but I know nothing about your environment and you know little about mine&lt;/p></description></item><item><title>Powershell can read email &amp; insert excel file attachment into a SQL Database</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-can-read-email-insert-excel-file-attachment-into-a-sql-database/</link><pubDate>Thu, 20 Jun 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-can-read-email-insert-excel-file-attachment-into-a-sql-database/</guid><description>&lt;p>So at our SQL SouthWest User Group session last week we had sessions from Jonathan &lt;a class="link" href="https://twitter.com/fatherjack" target="_blank" rel="noopener"
>@fatherjack&lt;/a> and Annette &lt;a class="link" href="https://twitter.com/Mrsfatherjack" target="_blank" rel="noopener"
>@Mrsfatherjack&lt;/a> on SSRS and SSIS respectively. During Annettes SSIS session a question was asked about reading email attachments and then loading them into a database. No-one had an answer using SSIS but I said it could be done with Powershell . So I have written the following script.&lt;/p>
&lt;p>What it does is open an Outlook com object, search for an email with a certain subject and save it in the temp folder and then import it into a SQL database. This needs to be done on a machine with Outlook and Excel installed. It is possible to process the email using EWS in an Exchange environment and other people have written scripts to do so.&lt;/p>
&lt;p>It uses two functions Out-Datatable from &lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/4208a159-a52e-4b99-83d4-8048468d29dd" target="_blank" rel="noopener"
>http://gallery.technet.microsoft.com/scriptcenter/4208a159-a52e-4b99-83d4-8048468d29dd&lt;/a>&lt;/p>
&lt;p>and Write-Datatable from&lt;/p>
&lt;p>&lt;a class="link" href="http://gallery.technet.microsoft.com/scriptcenter/2fdeaf8d-b164-411c-9483-99413d6053ae" target="_blank" rel="noopener"
>http://gallery.technet.microsoft.com/scriptcenter/2fdeaf8d-b164-411c-9483-99413d6053ae&lt;/a>&lt;/p>
&lt;p>The first takes the output from parsing the Excel File and converts it into a datatable object which can then be piped to the second which uses the BulkCopy method. Alternatively if you require it you could add each row of the excel file to an array and then use Invoke-SQLCmd to insert the data row by row.&lt;/p>
&lt;pre>&lt;code>while($row1 -le
$lastusedrange) {
$Col1 = $ws.Cells.Item($row1,1).Value2
$Col2 = $ws.Cells.Item($row1,2).Value2
$Col3 = $ws.Cells.Item($row1,3).Value2
$query = &amp;quot;INSERT INTO Database.Schema.Table
(Column1
,Column2
,Column3 )
VALUES
('$Col1'
,'$Col2'
,'$Col3')
GO
&amp;quot;
$dt = invoke-sqlcmd -query $query -ServerInstance $Server -database $database
## For Testing Write-Host $query
#############################################################################################
#
# NAME: ExcelEmailAttachmentToDatabase.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:15/06/2013
#
# COMMENTS: This script will read your email using outlook com object and save Excel Attachment
# and import it into a database
# REQUIRES: It uses two functions Out-Datatable from
# http://gallery.technet.microsoft.com/scriptcenter/4208a159-a52e-4b99-83d4-8048468d29dd
# and Write-Datatable from
# http://gallery.technet.microsoft.com/scriptcenter/2fdeaf8d-b164-411c-9483-99413d6053ae
#
# ------------------------------------------------------------------------
# Create Outlook Object
Add-type-assembly &amp;quot;Microsoft.Office.Interop.Outlook&amp;quot;|out-null
$olFolders = &amp;quot;Microsoft.Office.Interop.Outlook.olDefaultFolders&amp;quot; -as [type]
$outlook = new-object -comobject outlook.application
$namespace = $outlook.GetNameSpace(&amp;quot;MAPI&amp;quot;)
# Set Folder to Inbox
$folder = $namespace.getDefaultFolder($olFolders::olFolderInBox)
# CHeck Email For Subject and set to variable
$Email = $folder.items | Where-Object Subject -Contains $Subject
$Attachments = $Email.Attachments
$filepath = $env:TEMP
$filename = &amp;quot;TestFilename.xlsx&amp;quot;
$Subject = &amp;quot;This is a Test&amp;quot;
$server = 'test server'
$Database = 'Test Database'
$Table = 'tbl_DataloadTest'
foreach ($Attachment in $Attachments) {
$attachName = $Attachment.filename
If
($attachName.Contains(&amp;quot;xlsx&amp;quot;)) {
$Attachment.saveasfile((Join-Path $filepath $filename))
}
}
# Create an Excel Object
$xl = New-Object -comobject Excel.Application
&amp;amp;lt;#
##For testing
$xl.visible = $true
#&amp;amp;gt;
# Open the File
$wb = $xl.WorkBooks.Open(&amp;quot;$filepath\$filename&amp;quot;)
$ws = $wb.Worksheets.Item(1)
# If your data does not start at A1 you may need
$column1 = 1
$row1 = 2
$lastusedrange = $ws.UsedRange.Rows.Count
$dt = @()
while ($row1 -le $lastusedrange) {
$Col1 = $ws.Cells.Item($row1, 1).Value2
$Col2 = $ws.Cells.Item($row1, 2).Value2
$Col3 = $ws.Cells.Item($row1, 3).Value2
$newrow = ($Col1, $col2, $col3)
$dt += $newrow
# Move to next row
$row1 = $row1 + 1
}
$xl.Quit()
[System.Runtime.Interopservices.Marshal]::ReleaseComObject($xl)
$Input = $dt|Out-DataTable
Write-DataTable -ServerInstance $server -Database $Database -TableName $Table -Data $Input
&lt;/code>&lt;/pre>
&lt;p>Visit your own User Group – You can find them here&lt;a class="link" href="http://www.sqlpass.org/" target="_blank" rel="noopener"
>http://www.sqlpass.org/&lt;/a>&lt;/p>
&lt;p>If you are in the South West UK then come and join our group. Free training and conversation with like minded people once a month and pizza too what could be better!!&lt;/p></description></item><item><title>Add Adventure Works Database to Windows Azure VM</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-adventure-works-database-to-windows-azure-vm/</link><pubDate>Sun, 19 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/add-adventure-works-database-to-windows-azure-vm/</guid><description>&lt;p>This has been an interesting journey. The Adventure Works database is frequently used in blogs and reference books and I wanted to install it in my Windows Azure Learning Lab and I also wanted to automate the process.&lt;/p>
&lt;p>The easiest way is to download the Windows Azure MDF file from  &lt;a class="link" href="http://msftdbprodsamples.codeplex.com/" target="_blank" rel="noopener"
>http://msftdbprodsamples.codeplex.com/&lt;/a> jump through all the security warnings in Internet Explorer and save the file and then create the database as follows&lt;/p>
&lt;pre>&lt;code>CREATE DATABASE AdventureWorks2012
ON (FILENAME = 'PATH TO \AdventureWorks2012_Data.mdf')
FOR ATTACH_REBUILD_LOG ;
&lt;/code>&lt;/pre>
&lt;p>That is the way I will do it from now on! After reading &lt;a class="link" href="http://answers.oreilly.com/topic/2006-how-to-download-a-file-from-the-internet-with-windows-powershell/" target="_blank" rel="noopener"
>this page&lt;/a> I tried to download the file with Powershell but it would not as I could not provide a direct link to the file. Maybe someone can help me with that. So I thought I would use my SkyDrive to hold the MDF file and map a drive on the server.&lt;/p>
&lt;p>to do this you need to add the Desktop Experience feature to the server. This can be done as follows&lt;/p>
&lt;pre>&lt;code>Import-Module ServerManager
Add-WindowsFeature Desktop-Experience -restart
&lt;/code>&lt;/pre>
&lt;p>This will take a few minutes to install, reboot and then configure the updates before you can log back in. While it is doing this log into your SkyDrive and navigate to a folder and copy the URL to notepad&lt;/p>
&lt;p>It will look something like this&lt;/p>
&lt;p>&lt;a class="link" href="https://skydrive.live.com/?lc=2137#cid=XXXXXXXXXXXXXXXX&amp;amp;id=CYYYYYYYYYYYYYYYY" title="https://skydrive.live.com/?lc=2137#cid=XXXXXXXXXXXXXXXX&amp;amp;id=CYYYYYYYYYYYYYYYY"
target="_blank" rel="noopener"
>https://skydrive.live.com/?lc=2137#cid=XXXXXXXXXXXXXXXX&amp;amp;id=CYYYYYYYYYYYYYYYY&lt;/a>&lt;/p>
&lt;p>Copy the GUID after the cid=&lt;/p>
&lt;p>and write this command&lt;/p>
&lt;pre>&lt;code>net use T: \\d.docs.live.net@SSL\XXXXXXXXXXXXXXXX /user:$user $password
&lt;/code>&lt;/pre>
&lt;p>I keep this in a script and pass the user and password in via &lt;code>Read-Host&lt;/code>&lt;/p>
&lt;p>However, if you try to copy the item from the folder you will get an error&lt;/p>
&lt;p>The file size exceeds the limit allowed and cannot be saved&lt;/p>
&lt;p>So you will need to alter a registry key as follows&lt;/p>
&lt;pre>&lt;code>Set-ItemProperty -Path HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\WebClient\Parameters -Name FileSizeLimitInBytes -Value 4294967295
&lt;/code>&lt;/pre>
&lt;p>and then restart the WebClient service Then run the &lt;code>net use&lt;/code> command to map the drive and copy the file with &lt;code>Copy-Item&lt;/code>&lt;/p>
&lt;p>But my script to auto install the Adventure Works database via Powershell once you have completed all the pre-requisites is&lt;/p>
&lt;pre>&lt;code>$user = Read-Host &amp;quot;user&amp;quot;
$password = Read-Host &amp;quot;Password&amp;quot;
net use T: \\d.docs.live.net@SSL\XXXXXXXXXXXXXXX /user:$user $password
New-Item c:\AW -ItemType directory
Copy-Item T:\Documents\Azure\AdventureWorks2012_Data.mdf C:\AW
Invoke-Sqlcmd -ServerInstance YourServerName -Database master -Query &amp;quot;CREATE DATABASE AdventureWorks2012
ON (FILENAME = 'C:\AW\AdventureWorks2012_Data.mdf')
FOR ATTACH_REBUILD_LOG ;&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>To be honest I don’t think I will use this method as my copy failed twice before it succeeded so I will just download the file and create the database!!&lt;/p>
&lt;p>Please don’t ever trust anything you read on the internet and certainly don’t implement it on production servers without first both understanding what it will do and testing it thoroughly. This solution worked for me in my environment I hope it is of use to you in yours but I know nothing about your environment and you know little about mine&lt;/p></description></item><item><title>Checking SQL Error Logs, Event Logs and Stopping Services with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-error-logs-event-logs-and-stopping-services-with-powershell/</link><pubDate>Sun, 19 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/checking-sql-error-logs-event-logs-and-stopping-services-with-powershell/</guid><description>&lt;p>It was patching time this week at MyWork so I thought I would share some Powershell scripts I use to speed up the process.&lt;/p>
&lt;p>I keep these in their own folder and cd to it. Then I can just type the first few letters and tab and Powershell completes it. Nice and easy and time saving&lt;/p>
&lt;p>The first thing I do is to stop the SQL services with the StopSQLServices.ps1&lt;/p>
&lt;p>Get the server name with Read-Host then I like to see the before and after using&lt;/p>
&lt;pre>&lt;code>get-service -ComputerName $server|Where-Object { $_.Name -like '*SQL*' }
&lt;/code>&lt;/pre>
&lt;p>This uses the Get-service CMDlet to find the services with SQL in the name and display them. Then we pass the running services to an array and use the stop method with a while to check if the services are stopped before displaying the services again. Note this will stop all services with SQL in the name so if for example you are using Redgates SQL Monitor it will stop those services too. If that could be an issue then you may need to alter the where clause. As always test test test before implementing in any live environment.&lt;/p>
&lt;p>Once the services are stopped I RDP using the RDP script which again uses Read-host to get a server and then opens up a RDP with a simple &lt;code>Invoke-Command&lt;/code>. This means I can stay in Powershell.&lt;/p>
&lt;p>Then I patch the server and reboot using the ping script to set up a continuous ping.&lt;/p>
&lt;p>If you want to install Windows Updates via Powershell you can &lt;a class="link" href="http://blogs.technet.com/b/heyscriptingguy/archive/2012/11/08/use-a-powershell-module-to-run-windows-update.aspx" target="_blank" rel="noopener"
>use the details here.&lt;/a> I like to jump on the box to keep an eye on it.&lt;/p>
&lt;p>To check the event log The EventLog.ps1 script is very simple&lt;/p>
&lt;pre>&lt;code>Get-EventLog -computername $server -log $log -newest $latest | Out-GridView
&lt;/code>&lt;/pre>
&lt;p>Enter the server name and then application or system and it will display the results using out-gridview which will allow you to filter the results as required. I have another version of this script with a message search as well.&lt;/p>
&lt;p>You can simply add &lt;code>where {$_.entryType -match “Error”} &lt;/code>if you only want the errors or Warning for the warnings. I like to look at it all.&lt;/p>
&lt;p>Check the SQL error log with this script which uses the SMO method&lt;/p>
&lt;pre>&lt;code>$Server = Read-Host &amp;quot;Please Enter the Server&amp;quot;
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
$Results = $srv.ReadErrorLog(0) | format-table -Wrap -AutoSize
$Results
&lt;/code>&lt;/pre>
&lt;p>I love these four lines they make it so easy for me to look at the SQL error log whenever I need to. If you want you can pipe to Out-GridView or even to notepad. If I want to check one of the previous error logs I change ReadErrorLog(0) to ReadErrorLog(1) or 2 or 3 etc. I have a daily script which emails me any SQL error log errors and DBCC errors every day so I am aware of any issues before&lt;/p>
&lt;p>Then the AutoServices.ps1 to show the state of the auto start services. Strangely you cannot get the Start Type from Get-Service so I use Get-WMIObject. If any have failed to start then I use Get-Service to get the service  and pipe to Start-Service&lt;/p>
&lt;p>This is what works for me I hope it is of use to you&lt;/p>
&lt;p>Please don’t ever trust anything you read on the internet and certainly don’t implement it on production servers without first both understanding what it will do and testing it thoroughly. This solution worked for me in my environment I hope it is of use to you in yours but I know nothing about your environment and you know little about mine&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: StopSQLServices.ps1
Author: Rob Sewell https://blog.robsewell.com
Requires:
Version History:
Added New Header 23 August 2014
.SYNOPSIS
.DESCRIPTION
.PARAMETER
.PARAMETER
.PARAMETER
.EXAMPLE
#&amp;gt;
#############################################################################################
#
# NAME: StopSQLServices.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com @fade2blackuk
# DATE:15/05/2013
#
# COMMENTS: This script will stop all SQL Services on a server
# ------------------------------------------------------------------------
$Server = Read-Host &amp;quot;Please Enter the Server - This WILL stop all SQL services&amp;quot;
Write-Host &amp;quot;########### Services on $Server BEFORE ##############&amp;quot; -ForegroundColor Green -BackgroundColor DarkYellow
get-service -ComputerName $server|Where-Object { $_.Name -like '*SQL*' }Write-Host &amp;quot;########### Services on $Server BEFORE ##############&amp;quot; -ForegroundColor Green -BackgroundColor DarkYellow
## $Services = Get-WmiObject Win32_Service -ComputerName $server| Where-Object { $_.Name -like '*SQL*'-and $_.State-eq 'Running' }
$Services = Get-Service -ComputerName $server|Where-Object { $_.Name -like '*SQL*' -and $_.Status -eq 'Running' }
foreach ($Service in $Services) {
$ServiceName = $Service.displayname
(get-service -ComputerName $Server -Name $ServiceName).Stop()
while ((Get-Service -ComputerName $server -Name $ServiceName).status -ne 'Stopped')
{&amp;lt;#do nothing#&amp;gt;}
}
Write-Host &amp;quot;########### Services on $Server After ##############&amp;quot; -ForegroundColor Green -BackgroundColor DarkYellow
Get-Service -ComputerName $server|Where-Object { $_.Name -like '*SQL*' }
Write-Host &amp;quot;########### Services on $Server After ##############&amp;quot; -ForegroundColor Green -BackgroundColor DarkYellow
#############################################################################################
#
# NAME: RDP.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com @fade2blackuk
# DATE:15/05/2013
#
# COMMENTS: This script to open a RDP
# ------------------------------------------------------------------------
$server = Read-Host &amp;quot;Server Name?&amp;quot;
Invoke-Expression &amp;quot;mstsc /v:$server&amp;quot;
#############################################################################################
#
# NAME: Ping.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com @fade2blackuk
# DATE:15/05/2013
#
# COMMENTS: This script to set up a continous ping
# Use CTRL + C to stop it
# ------------------------------------------------------------------------
$server = Read-Host &amp;quot;Server Name?&amp;quot;
Invoke-Expression &amp;quot;ping -t $server&amp;quot;
#############################################################################################
#
# NAME: SQLErrorLog.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com @fade2blackuk
# DATE:15/05/2013
#
# COMMENTS: This script will display the SQL Error Log for a remote server
# ------------------------------------------------------------------------
$Server = Read-Host &amp;quot;Please Enter the Server&amp;quot;
$srv = New-Object ('Microsoft.SqlServer.Management.Smo.Server') $server
$srv.ReadErrorLog(0) | Out-GridView
#############################################################################################
#
# NAME: Autoservices.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com @fade2blackuk
# DATE:15/05/2013
#
# COMMENTS: # Script to show the services running that are set to Automatic startup -
# good for checking after reboot
# ------------------------------------------------------------------------
$Server = Read-Host &amp;quot;Which Server?&amp;quot;
Get-WmiObject Win32_Service -ComputerName $Server |
Where-Object { $_.StartMode -like 'Auto' }|
Select-Object __SERVER, Name, StartMode, State | Format-Table -auto
Write-Host &amp;quot;SQL Services&amp;quot;
Get-WmiObject Win32_Service -ComputerName $Server |
Where-Object { $_.DisplayName -like '*SQL*' }|
Select-Object __SERVER, Name, StartMode, State | Format-Table -auto
&lt;/code>&lt;/pre></description></item><item><title>Lessons Learnt from my first talk at SQL SouthWest</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/lessons-learnt-from-my-first-talk-at-sql-southwest/</link><pubDate>Fri, 17 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/lessons-learnt-from-my-first-talk-at-sql-southwest/</guid><description>&lt;p>Edit 2022 -&lt;/p>
&lt;p>Find your User Groups here &lt;a class="link" href="https://www.meetup.com/en-AU/pro/azuredatatechgroups" target="_blank" rel="noopener"
>Azure Data Community&lt;/a>&lt;/p>
&lt;p>The timing was good enough that I could offer to do a talk based on my &lt;a class="link" href="https://blog.robsewell.com/azure/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/" target="_blank" rel="noopener"
>previous post on Windows Azure&lt;/a> for my SQL User Group &lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>SQL SouthWest&lt;/a> when Jonathan and Annette.( &lt;a class="link" href="https://twitter.com/fatherjack" target="_blank" rel="noopener"
>@FatherJack&lt;/a> and &lt;a class="link" href="https://twitter.com/Mrs_Fatherjack" target="_blank" rel="noopener"
>@MrsFatherJack&lt;/a>) put out a call for volunteers (Edit Sept 2020 - Brave enough to say now that Jonathan just told me I was doing it !! In the nicest possible way).&lt;/p>
&lt;p>I did my best with the &lt;a class="link" href="http://en.wikipedia.org/wiki/7_Ps_%28military_adage%29" target="_blank" rel="noopener"
>7 P’s&lt;/a>. I ran through it at lunchtime, I made sure I had power and a HDMI lead after checking with Jonathan, I got a glass of water. I knew the first line I was going to say&lt;/p>
&lt;p>However, I neglected to check that I would have HDMI in at the location so everything that was on my laptop was useless! My laptop did very odd things to the USB stick when I tried to transfer to Jonathans laptop and he didn’t have Powershell V3 installed so whilst Neil Hambly &lt;a class="link" href="https://twitter.com/Neil_Hambly" target="_blank" rel="noopener"
>@Neil_Hambly&lt;/a> from Confio was speaking I was busy ignoring a very interesting talk on Waits to install and configure Powershell Azure on my Azure VM. Sorry Neil.&lt;/p>
&lt;p>But in the end it more or less worked and we are lucky to have such a patient and supportive user group who helped me along the way as well. Thank you folks&lt;/p>
&lt;p>Things I took away from the evening&lt;/p>
&lt;ol>
&lt;li>Double check you have all the connections&lt;/li>
&lt;li>Practice and Practice some more&lt;/li>
&lt;li>Think about the times when something is running and what you will say when there is nothing to see&lt;/li>
&lt;li>Presenting completely inside a RDP session adds unnecessary complication&lt;/li>
&lt;li>The Demo Gods WILL hit you and the curse of the red text will fall upon you during the presentation. Accept it and move on.&lt;/li>
&lt;li>Have an opening line&lt;/li>
&lt;li>Remember to breath (especially when the demo falls over)&lt;/li>
&lt;li>Enjoy it!&lt;/li>
&lt;/ol>
&lt;p>It didn’t go perfectly but people gave me some good feedback and I am pleased to say that I have pointed people towards something new that will help them and passed over my knowledge and that to me is what the SQL Community is all about. I have a load of other ideas for things I can talk about and blog about so it is going to be a very busy time for me as I work my way through them and do all the other exciting things coming my way in the SQL world.&lt;/p>
&lt;p>Visit your own User Group – You can find them here &lt;a class="link" href="https://www.meetup.com/en-AU/pro/azuredatatechgroups" target="_blank" rel="noopener"
>Azure Data Community&lt;/a>&lt;/p>
&lt;p>If you are in the South West UK then come and join our group. Free training and conversation with like minded people once a month and pizza too what could be better!!&lt;/p></description></item><item><title>Spinning up and shutting down Windows Azure Lab with Powershell</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/</link><pubDate>Tue, 14 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/spinning-up-and-shutting-down-windows-azure-lab-with-powershell/</guid><description>&lt;p>So at SQL Bits I went to &lt;a class="link" href="http://sqlbits.com/Speakers/Chris_Testa-O_Neill" target="_blank" rel="noopener"
>Chris Testa-O’Neill’s&lt;/a> session on certification. This has inspired me to start working on passing the MCSE exams. My PC at home doesn’t have much grunt and my tablet wont run SQL. I considered some new hardware but I knew I would have a hard time getting authorisation from the Home Financial Director (Mrs F2B) despite my all the amazing justification and benefits I could provide!!&lt;/p>
&lt;p>So I looked at &lt;a class="link" href="http://www.windowsazure.com/en-us/" target="_blank" rel="noopener"
>Windows Azure&lt;/a> as a means of having some servers to play with. After watching &lt;a class="link" href="http://blogs.msdn.com/b/plankytronixx/archive/2013/03/19/video-explanation-of-pop-up-labs-in-the-cloud.aspx" target="_blank" rel="noopener"
>this video&lt;/a> and then &lt;a class="link" href="http://channel9.msdn.com/Series/Windows-Azure-Virtual-Machines-and-Networking-Tutorials/Creating-Windows-Azure-Virtual-Machines-with-PowerShell" target="_blank" rel="noopener"
>this video&lt;/a> I took the plunge and dived in.&lt;/p>
&lt;p>After setting up my account I read a few blogs about Powershell and Windows Azure.&lt;/p>
&lt;p>&lt;a class="link" href="http://adminian.com/2013/04/16/how-to-setup-windows-azure-powershell/" target="_blank" rel="noopener"
>http://adminian.com/2013/04/16/how-to-setup-windows-azure-powershell/&lt;/a>&lt;/p>
&lt;p>Note – Here I only spin up extra small instances and don’t configure SQL as per Microsoft’s recommendations. I am only using these VMs for learning and talking at my user group your needs may be different&lt;/p>
&lt;p>First you’ll need &lt;a class="link" href="http://www.microsoft.com/web/downloads/platform.aspx" target="_blank" rel="noopener"
>Microsoft Web Platform Installer&lt;/a>. Then download and install Windows Azure PowerShell,&lt;/p>
&lt;pre>&lt;code>Import-Module c:\Program Files\Microsoft SDKs\Windows Azure\PowerShell\Azure\Azure.psd1
&lt;/code>&lt;/pre>
&lt;p>This gives you all the Windows Azure Powershell Cmdlets.&lt;/p>
&lt;p>&lt;code>Get-AzurePublishSettingsFile&lt;/code> which will give you a download for a file.  PowerShell will use this to control your Windows Azure so although you need it now, keep it safe and probably out of your usual directories so it doesn’t get compromised.&lt;/p>
&lt;p>&lt;code>Import-AzurePublishSettingsFile&lt;/code> and the file path to import it into Powershell.&lt;/p>
&lt;p>&lt;code>Get-AzureSubscription&lt;/code> to see the results and note the subscription name.&lt;/p>
&lt;p>Now we create a storage account&lt;/p>
&lt;pre>&lt;code>New-AzureStorageAccount -StorageAccountName chooseaname -label 'a label' -Description 'The Storage Account for the Lab Spin Up and Down' -Location 'West Europe'
&lt;/code>&lt;/pre>
&lt;p>&lt;code>Get-AzureLocation &lt;/code>will show you the available locations if you want a different one.I then set the storage account to be default for my subscription&lt;/p>
&lt;pre>&lt;code>Set-AzureSubscription -SubscriptionName 'Subscription Name from Earlier' -CurrentStorageAccount 'theoneyouchose'
&lt;/code>&lt;/pre>
&lt;p>I spent a couple of days sorting out the following scripts. They set up three SQL Servers, configure them to allow SSMS, Powershell and RDP connections and also remove them all. The reasoning behind this is that you will be charged for servers even when they are turned off&lt;/p>
&lt;p>First we set some variables&lt;/p>
&lt;pre>&lt;code>$image = 'fb83b3509582419d99629ce476bcb5c8__Microsoft-SQL-Server-2012SP1-Standard-CY13SU04-SQL11-SP1-CU3-11.0.3350.0-B'
$SQL1 = 'SQL1'
$SQL2 = 'SQL2'
$SQL3 = 'SQL3'
$size = 'ExtraSmall'
$AdminUser = 'ChoosePCAdminName'
$password = 'SUPERCOMpl1c@teDPassword'
$Service = 'theservicenameyouchoose'
$Location = 'West Europe'
&lt;/code>&lt;/pre>
&lt;p>To choose an image run &lt;code>Get-AzureVMImage|select name&lt;/code> and pick the one for you. I chose a size of extra small as it is cheaper. As I won’t be pushing the servers very hard I don’t need any extra grunt. Set up a service the first time and use the location switch but then to use the same service again remove the location switch otherwise you will get an error stating DNS name already in use which is a little confusing until you know.&lt;/p>
&lt;pre>&lt;code>$vm = New-AzureVMConfig -Name $SQL1 -InstanceSize $size -ImageName $image |
Add-AzureProvisioningConfig -AdminUsername $AdminUser -Password $password -Windows |
Add-AzureEndpoint -Name &amp;quot;SQL&amp;quot; -Protocol &amp;quot;tcp&amp;quot; -PublicPort 57502 -LocalPort 1433|
Add-AzureEndpoint -Name PS-HTTPS -Protocol TCP -LocalPort 5986 -PublicPort 5986\
&lt;/code>&lt;/pre>
&lt;p>This creates a VM object and adds two endpoints for the server, one for Powershell and one for SSMS. When you provision more than one server you will need to make sure you use a different Public Port for each server otherwise you will get an error. You will need to note which server has which port when you need to connect with SSMS.&lt;/p>
&lt;p>Once you have your VM object just pass it to New-AzureVM as shown&lt;/p>
&lt;pre>&lt;code>New-AzureVM -ServiceName $Service -VMs $vm
&lt;/code>&lt;/pre>
&lt;p>Providing you have no errors you can then just wait until you see this.&lt;/p>
&lt;p>&lt;a class="link" href="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/image_thumb1.png" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/image_thumb_thumb.png"
loading="lazy"
alt="image_thumb"
>&lt;/a>&lt;/p>
&lt;p>It will take a few minutes. Long enough to get a cuppa. Even then you won’t be able to connect straightaway as Azure will be provisioning the server still.&lt;/p>
&lt;p>The next bit of the script downloads the RDP shortcut to a folder on the desktop and assigns a variable for the clean up script. I use this because the next time you spin up a server it may not use exactly the same port for RDP.&lt;/p>
&lt;pre>&lt;code>$SQL1RDP = &amp;quot;$ENV:userprofile\Desktop\Azure\RDP\$SQL1.rdp&amp;quot;
Get-AzureRemoteDesktopFile -ServiceName $Service -name $SQL1 -LocalPath $SQL1RDP
Invoke-Expression $SQL1RDP
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>Invoke-Expression&lt;/code> will open up a RDP connection but unless you have gone to get a cuppa I would check in your management portal before trying to connect as the server may still be provisioning. In fact,I would go to your Windows Azure Management Portal and check your virtual machine tab where you will see your VMs being provisioned&lt;/p>
&lt;p>Now you have three servers but to be able to connect to them from your desktop and practice managing them you still need to do a bit of work. RDP to each server run the following script in Powershell.&lt;/p>
&lt;pre>&lt;code># Configure PowerShell Execution Policy to Run all Scripts – It’s a one time Progress
Set-ExecutionPolicy –ExecutionPolicy Unrestricted
netsh advfirewall firewall add rule name=SQL-SSMS dir=in action=allow enable=yes profile=any
netsh advfirewall firewall add rule name=SQL-SSMS dir=out action=allow program=any enable=yes profile=any
netsh advfirewall firewall set rule group=&amp;quot;Remote Administration&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;File and Printer Sharing&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Service Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Performance Logs and Alerts&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Event Log Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Scheduled Tasks Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Volume Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Desktop&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Windows Firewall Remote Management&amp;quot; new enable =yes
netsh advfirewall firewall set rule group=&amp;quot;windows management instrumentation (wmi)&amp;quot; new enable =yes\
&lt;/code>&lt;/pre>
&lt;p>I use netsh advfirewall as I find it easy and I understand it. I know you can do it with &lt;code>Set-NetFirewallProfile&lt;/code> but that’s the beauty of Powershell you can still use all your old cmd knowledge as well. This will allow you to remote manage the servers. You can do it from your laptop with the creation of some more endpoints but I just use one server as a management server for my learning.&lt;/p>
&lt;p>The last part of the script changes SQL to Mixed authentication mode and creates a SQL user with sysadmin and restarts the SQL service on each server and that’s it. Its ready to go.&lt;/p>
&lt;p>Open up SSMS on your desktop and connect to &lt;code>YourServiceName.Cloudapp.Net, PortNumber&lt;/code> (57500-5702 in this example)
To remove all of the implementation run the code that is commented out in steps. First it assigns a variable to each VHD, then it removes the VM. You should then wait a while before removing the VHDs as it takes a few minutes to remove the lease and finally remove the RDP shortcuts as next time they will be different.&lt;/p>
&lt;pre>&lt;code>&amp;lt;#
.NOTES
Name: CreateLab.ps1
Author: Rob Sewell https://blog.robsewell.com
Requires: Get the Windows Azures CmdLets then run this
Version History:
Added New Header 23 August 2014
.SYNOPSIS
This script will create 3 Windows Azure SQL Servers and open up RDP connections
ready for use. There is also the scripts to remove the Windows Azure Objects to save on
usage costs
.DESCRIPTION
.PARAMETER
.PARAMETER
.PARAMETER
.EXAMPLE
#&amp;gt;
# Get the Subscription File and Import it
Get-AzurePublishSettingsFile
Import-AzurePublishSettingsFile FilepathtoPublishSettingsFile
&amp;lt;# Run this once to set up a Storage Account
New-AzureStorageAccount -StorageAccountName storageaccountname -location 'West Europe' -Label 'Storage Account for My Lab'
#&amp;gt;
Get-AzureSubscription #Note the name
#Set the storage account to the subscription
Set-AzureSubscription -SubscriptionName SubscriptionName -CurrentStorageAccount storageaccountname
#Some variables
# Use Get-AzureVMimage to find the one you want ie Get-AzureVMImage | where { ($_.ImageName -like &amp;quot;*SQL*&amp;quot;) }|select ImageName
$image = 'fb83b3509582419d99629ce476bcb5c8__Microsoft-SQL-Server-2012SP1-Standard-CY13SU04-SQL11-SP1-CU3-11.0.3350.0-B'
$SQL1 = 'SQL1'
$SQL2 = 'SQL2'
$SQL3 = 'SQL3'
$size = 'ExtraSmall'
$AdminUser = 'ChoosePCAdminName'
$password = 'SUPERCOMpl1c@teDPassword'
$Service = 'theservicenameyouchoose'
$Location = 'West Europe'
&amp;lt;# Run this the first time to create a Service
New-AzureService -ServiceName $Service -Location $Location -Label 'SQLDBA with a Beard Service'
#&amp;gt;
#Configure the VMs
$vm = New-AzureVMConfig -Name $SQL1 -InstanceSize $size -ImageName $image |
Add-AzureProvisioningConfig -AdminUsername $AdminUser -Password $password -Windows|
Add-AzureEndpoint -Name &amp;quot;SQL&amp;quot; -Protocol &amp;quot;tcp&amp;quot; -PublicPort 57500 -LocalPort 1433
$vm2 = New-AzureVMConfig -Name $SQL2 -InstanceSize $size -ImageName $image |
Add-AzureProvisioningConfig -AdminUsername $AdminUser -Password $password -Windows |
Add-AzureEndpoint -Name &amp;quot;SQL&amp;quot; -Protocol &amp;quot;tcp&amp;quot; -PublicPort 57501 -LocalPort 1433
$vm3 = New-AzureVMConfig -Name $SQL3 -InstanceSize $size -ImageName $image |
Add-AzureProvisioningConfig -AdminUsername $AdminUser -Password $password -Windows |
Add-AzureEndpoint -Name &amp;quot;SQL&amp;quot; -Protocol &amp;quot;tcp&amp;quot; -PublicPort 57502 -LocalPort 1433|
Add-AzureEndpoint -Name PS-HTTPS -Protocol TCP -LocalPort 5986 -PublicPort 5986
#Provision the VMs
New-AzureVM -ServiceName $Service -VMs $vm, $vm2,$vm3
# Get the RDP Files
$SQL1RDP = &amp;quot;$ENV:userprofile\Desktop\Azure\RDP\$SQL1.rdp&amp;quot;
$SQL2RDP = &amp;quot;$ENV:userprofile\Desktop\Azure\RDP\$SQL2.rdp&amp;quot;
$SQL3RDP = &amp;quot;$ENV:userprofile\Desktop\Azure\RDP\$SQL3.rdp&amp;quot;
Get-AzureRemoteDesktopFile -ServiceName $Service -name $SQL1 -LocalPath $SQL1RDP
Get-AzureRemoteDesktopFile -ServiceName $Service -name $SQL2 -LocalPath $SQL2RDP
Get-AzureRemoteDesktopFile -ServiceName $Service -name $SQL3 -LocalPath $SQL3RDP
# Open the RDP Fies - Check the machine is up in your Management Portal
Invoke-Expression $SQL1RDP
Invoke-Expression $SQL2RDP
Invoke-Expression $SQL3RDP
# Now run the SetupVM script for each server
&amp;lt;#
This is the clean up script to remove the servers and services
Run this first
$SQL1Disk = Get-AzureDisk|where {$_.attachedto.rolename -eq $SQL1}
$SQL2Disk = Get-AzureDisk|where {$_.attachedto.rolename -eq $SQL2}
$SQL3Disk = Get-AzureDisk|where {$_.attachedto.rolename -eq $SQL3}
#Then This
Remove-AzureVM -Name $SQL1 -ServiceName $Service
Remove-AzureVM -Name $SQL2 -ServiceName $Service
Remove-AzureVM -Name $SQL3 -ServiceName $Service
Then wait a while and run this
$SQL1Disk|Remove-AzureDisk -DeleteVHD
$SQL2Disk|Remove-AzureDisk -DeleteVHD
$SQL3Disk|Remove-AzureDisk -DeleteVHD
#Remove-AzureService $Service
Get-ChildItem &amp;quot;$ENV:userprofile\Desktop\Azure\RDP\*.rdp&amp;quot;|Remove-Item
#&amp;gt;
&amp;lt;#
This is the clean up script for variables
Remove-Variable [a..z]* -Scope Global
Remove-Variable [1..9]* -Scope Global
#&amp;gt;
.NOTES
Name: SetUpVMSQL1.ps1
Author: Rob Sewell https://blog.robsewell.com
Requires:
Version History:
Added New Header 23 August 2014
.SYNOPSIS
This script will set up the SQL1 VM ready for use and enable SQL Authentication
Add a user called SQLAdmin with a password of P@ssw0rd
Restart SQL Service.Run on SQL1
.DESCRIPTION
.PARAMETER
.PARAMETER
.PARAMETER
.EXAMPLE
#&amp;gt;
# Configure PowerShell Execution Policy to Run all Scripts � It�s a one time Progress
Set-ExecutionPolicy �ExecutionPolicy Unrestricted
netsh advfirewall firewall add rule name=SQL-SSMS dir=in action=allow enable=yes profile=any
netsh advfirewall firewall add rule name=SQL-SSMS dir=out action=allow program=any enable=yes profile=any
netsh advfirewall firewall set rule group=&amp;quot;Remote Administration&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;File and Printer Sharing&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Service Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Performance Logs and Alerts&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Event Log Management&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Scheduled Tasks Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Volume Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Desktop&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Windows Firewall Remote Management&amp;quot; new enable =yes
netsh advfirewall firewall set rule group=&amp;quot;windows management instrumentation (wmi)&amp;quot; new enable =yes
# To Load SQL Server Management Objects into PowerShell
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMO�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMOExtended�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SqlWmiManagement�) | out-null
SQLPS
$Name = 'SQL1'
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
EXEC xp_instance_regwrite N'HKEY_LOCAL_MACHINE', N'Software\Microsoft\MSSQLServer\MSSQLServer', N'LoginMode', REG_DWORD, 2
GO
&amp;quot;
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
CREATE LOGIN [SQLAdmin] WITH PASSWORD=N'P@ssw0rd', DEFAULT_DATABASE=[master]
GO
ALTER SERVER ROLE [sysadmin] ADD MEMBER [SQLAdmin]
GO
&amp;quot;
get-Service -ComputerName $Name -Name MSSQLSERVER|Restart-Service -force\
&amp;lt;#
.NOTES
Name: SetUpVMSQL2.ps1
Author: Rob Sewell https://blog.robsewell.com
Requires:
Version History:
Added New Header 23 August 2014
.SYNOPSIS
.DESCRIPTION
.PARAMETER
.PARAMETER
.PARAMETER
.EXAMPLE
#&amp;gt;
#############################################################################################
#
# NAME: SetupVMSQL2.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:10/05/2013
#
#
# COMMENTS: This script will set up the SQL1 VM ready for use and enable SQL Authentication
# Add a user called SQLAdmin with a password of P@ssw0rd
# Restart SQL Service
# ------------------------------------------------------------------------
# Run on SQL2
# Configure PowerShell Execution Policy to Run all Scripts � It�s a one time Progress
Set-ExecutionPolicy �ExecutionPolicy Unrestricted
netsh advfirewall firewall add rule name=SQL-SSMS dir=in action=allow enable=yes profile=any
netsh advfirewall firewall add rule name=SQL-SSMS dir=out action=allow program=any enable=yes profile=any
netsh advfirewall firewall set rule group=&amp;quot;Remote Administration&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;File and Printer Sharing&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Service Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Performance Logs and Alerts&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Event Log Management&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Scheduled Tasks Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Volume Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Desktop&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Windows Firewall Remote Management&amp;quot; new enable =yes
netsh advfirewall firewall set rule group=&amp;quot;windows management instrumentation (wmi)&amp;quot; new enable =yes
# To Load SQL Server Management Objects into PowerShell
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMO�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMOExtended�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SqlWmiManagement�) | out-null
SQLPS
$Name = 'SQL2'
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
EXEC xp_instance_regwrite N'HKEY_LOCAL_MACHINE', N'Software\Microsoft\MSSQLServer\MSSQLServer', N'LoginMode', REG_DWORD, 2
GO
&amp;quot;
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
CREATE LOGIN [SQLAdmin] WITH PASSWORD=N'P@ssw0rd', DEFAULT_DATABASE=[master]
GO
ALTER SERVER ROLE [sysadmin] ADD MEMBER [SQLAdmin]
GO
&amp;quot;
get-Service -ComputerName $Name -Name MSSQLSERVER|Restart-Service -force\
&amp;lt;#
.NOTES
Name: SetUpVMSQL3.ps1
Author: Rob Sewell https://blog.robsewell.com
Requires:
Version History:
Added New Header 23 August 2014
.SYNOPSIS
.DESCRIPTION
.PARAMETER
.PARAMETER
.PARAMETER
.EXAMPLE
#&amp;gt;
#############################################################################################
#
# NAME: SetupVMSQL3.ps1
# AUTHOR: Rob Sewell http://newsqldbawiththebeard.wordpress.com
# DATE:10/05/2013
#
#
# COMMENTS: This script will set up the SQL3 VM ready for use and enable SQL Authentication
# Add a user called SQLAdmin with a password of P@ssw0rd
# and enable PS Remoting
# Restart SQL Service
# ------------------------------------------------------------------------
# Run on SQL3
# Configure PowerShell Execution Policy to Run all Scripts � It�s a one time Progress
Set-ExecutionPolicy �ExecutionPolicy Unrestricted
netsh advfirewall firewall add rule name=SQL-SSMS dir=in action=allow enable=yes profile=any
netsh advfirewall firewall add rule name=SQL-SSMS dir=out action=allow program=any enable=yes profile=any
netsh advfirewall firewall set rule group=&amp;quot;Remote Administration&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;File and Printer Sharing&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Service Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Performance Logs and Alerts&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Event Log Management&amp;quot; new enable=yes
Netsh advfirewall firewall set rule group=&amp;quot;Remote Scheduled Tasks Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Volume Management&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Remote Desktop&amp;quot; new enable=yes
netsh advfirewall firewall set rule group=&amp;quot;Windows Firewall Remote Management&amp;quot; new enable =yes
netsh advfirewall firewall set rule group=&amp;quot;windows management instrumentation (wmi)&amp;quot; new enable =yes
#Extra one for PS Remoting
netsh advfirewall firewall add rule name=&amp;quot;Port 5986&amp;quot; dir=in action=allow protocol=TCP localport=5986
# To Load SQL Server Management Objects into PowerShell
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMO�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SMOExtended�) | out-null
[System.Reflection.Assembly]::LoadWithPartialName(�Microsoft.SqlServer.SqlWmiManagement�) | out-null
SQLPS
$Name = 'SQL3'
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
EXEC xp_instance_regwrite N'HKEY_LOCAL_MACHINE', N'Software\Microsoft\MSSQLServer\MSSQLServer', N'LoginMode', REG_DWORD, 2
GO
&amp;quot;
Invoke-Sqlcmd -ServerInstance $Name -Database master -Query &amp;quot;USE [master]
GO
CREATE LOGIN [SQLAdmin] WITH PASSWORD=N'P@ssw0rd', DEFAULT_DATABASE=[master]
GO
ALTER SERVER ROLE [sysadmin] ADD MEMBER [SQLAdmin]
GO
&amp;quot;
get-Service -ComputerName $Name -Name MSSQLSERVER|Restart-Service -force
Enable-PSRemoting -force
&lt;/code>&lt;/pre>
&lt;p>Please don’t ever trust anything you read on the internet and certainly don’t implement it on production servers without first both understanding what it will do and testing it thoroughly. This solution worked for me in my environment I hope it is of use to you in yours but I know nothing about your environment and you know little about mine&lt;/p></description></item><item><title>Documenting SQL Server the easy way with Power Doc</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/documenting-sql-server-the-easy-way-with-power-doc/</link><pubDate>Thu, 09 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/documenting-sql-server-the-easy-way-with-power-doc/</guid><description>&lt;p>You know how it is. Question questions questions. As a DBA you are the fount of all knowledge. You are the protector of the data after all so obviously you know every little thing that is needed to be known.&lt;/p>
&lt;p>Frequently, I am asked&lt;/p>
&lt;p>How many processors does that server have?&lt;br>
How much RAM is on that server? What type?&lt;br>
What OS? Which Patches were installed&lt;/p>
&lt;p>or more SQL based questions about configuration&lt;/p>
&lt;p>Which SQL Product? Which version? Which Service Pack?&lt;br>
What are the linked servers on that server?&lt;br>
Or you want to know which login have which roles on the server or the autogrowth settings or any number of other ‘little things’&lt;/p>
&lt;p>As the DBA as they are asking about my servers I should know and whilst I have a lot of info in my head, there’s not enough room for it all!! So I have to break from what I am doing and dive into Powershell or SSMS and get them the info that they need. When this happens I often thought I wish I could have this information to hand but I have never had time to organise it myself.&lt;/p>
&lt;p>Worse still, imagine your boss walks through the door and says we have to provide information for an audit. Can you give me full details of all the SQL Servers and their configurations both windows and SQL and I need it by the end of play tomorrow.&lt;/p>
&lt;p>It happens.&lt;/p>
&lt;p>Its Personal Development Review time. I should have asked my boss to give me an objective of thoroughly documenting the SQL Server estate this year. I could have done it in a few hours. You only think of these things when its too late.&lt;/p>
&lt;p>How can I do this? I hear you cry. Head over to &lt;a class="link" href="https://sqlpowerdoc.codeplex.com" title="https://sqlpowerdoc.codeplex.com"
target="_blank" rel="noopener"
>https://sqlpowerdoc.codeplex.com&lt;/a> and you will see.&lt;/p>
&lt;p>SQL PowerDoc was written by Kendal VanDyke who is a practiced IT professional with over a decade of experience in SQL Server development and administration. Kendal is currently a principal consultant with UpSearch SQL, where he helps companies keep their SQL Servers running in high gear. Kendal is also a Microsoft MVP for SQL Server and president of the PASS chapter MagicPASS in Orlando, FL. You can find his blog at &lt;a class="link" href="http://www.kendalvandyke.com/" target="_blank" rel="noopener"
>http://www.kendalvandyke.com/&lt;/a> and on Twitter at &lt;a class="link" href="https://twitter.com/@SQLDBA" target="_blank" rel="noopener"
>@SQLDBA&lt;/a>&lt;/p>
&lt;p>I found out about Power Doc a few weeks ago. It looked so cool, I tested it at home and then on my dev server and then on the whole estate. It is CPU heavy on the box it is running on if you have a load of servers. I don’t know how long it took to run as it ran overnight but the information you get back is staggering, enough to satisfy even the most inquisitive of auditors or questioners. You can pass it to your server team too and they will love it as it can do a Windows based inventory.&lt;/p>
&lt;p>What does it document? What DOESNT it document? If you head over to &lt;a class="link" href="https://sqlpowerdoc.codeplex.com/wikipage?title=What%27s%20Documented" target="_blank" rel="noopener"
>https://sqlpowerdoc.codeplex.com/wikipage?title=What%27s%20Documented&lt;/a> the list you see doesn’t reflect the sheer amount of data you can get back. Run it against your own machine and you will see what I mean.&lt;/p>
&lt;p>As well as documenting everything it also runs around 100 checks to diagnose potential issues and problems. You can see where autogrowth is set to percentage, databases that haven’t been backed up, auto shrink, Max Memory set too high, the list goes on. Even the links to the MSDN articles are in there for the things it finds.&lt;/p>
&lt;p>The documentation is thorough and even if you haven’t use Powershell before everything you need is on the website to run PowerDoc.&lt;/p>
&lt;p>So much thought and effort has been put into this it’s difficult to see how it could be improved.&lt;/p>
&lt;p>What I have done then is added the Excel file to our dba SharePoint team site and enabled the right people access to it. Equally they tell others and I get bothered slightly less.&lt;/p></description></item><item><title>12 Things I learnt at SQLBits XI</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/12-things-i-learnt-at-sqlbits-xi/</link><pubDate>Tue, 07 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/12-things-i-learnt-at-sqlbits-xi/</guid><description>&lt;ul>
&lt;li>
&lt;h3 id="the-quality-of-the-speakers-and-sessions-is-exceptional">The quality of the speakers and sessions is exceptional&lt;/h3>
&lt;p>&lt;a class="link" href="http://sqlbits.com/information/Agenda.aspx" target="_blank" rel="noopener"
>http://sqlbits.com/information/Agenda.aspx&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;h3 id="the-helpers-are-awesome">The Helpers are awesome&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/clip_image001.jpg" target="_blank" rel="noopener"
>&lt;img src="https://i1.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/clip_image001_thumb.jpg?resize=313%2C502"
loading="lazy"
alt="clip_image001"
>&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="often-sessions-fill-up-very-quickly--get-there-early">Often Sessions fill up very quickly – Get there early&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="http://t.co/y2S9IDnama" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/clip_image002.jpg?resize=372%2C211"
loading="lazy"
alt="clip_image002"
>&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="the-guidebook-app-is-pretty-good-but-with-a-map-it-would-be-better">The GuideBook app is pretty good but with a map it would be better&lt;/h3>
&lt;p>&lt;a class="link" href="http://guidebook.com/" target="_blank" rel="noopener"
>http://guidebook.com/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;h3 id="you-can-learn-as-much-outside-of-the-sessions-as-you-can-in-them">You can learn as much outside of the sessions as you can in them&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://plus.google.com/photos/109984741094039234638/albums/5874913179986208577" target="_blank" rel="noopener"
>&lt;img src="https://i2.wp.com/lh6.googleusercontent.com/-3d8PCx0AlFA/UYfqxH0fHhI/AAAAAAAAd-E/k_EnX5cpOZY/w960-h641-no/DSC_5670.JPG?resize=622%2C415&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="there-are-amazing-prizes">There are amazing prizes&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="https://www.facebook.com/photo.php?fbid=599765410034832&amp;amp;set=pb.330145840330125.-2207520000.1367904819.&amp;amp;type=3&amp;amp;theater" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/fbcdn-sphotos-c-a.akamaihd.net/hphotos-ak-snc6/602577_599765410034832_674054200_n.jpg?resize=616%2C392&amp;amp;ssl=1"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>A LEGO R2D2 !!!&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="bring-your-sense-of-humour">Bring your sense of humour&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>&lt;a class="link" href="http://sphotos-a.ak.fbcdn.net/hphotos-ak-prn1/945206_599117553432951_1586348603_n.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sphotos-a.ak.fbcdn.net/hphotos-ak-prn1/945206_599117553432951_1586348603_n.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://sphotos-b.ak.fbcdn.net/hphotos-ak-ash3/603597_599117663432940_27947956_n.jpg" target="_blank" rel="noopener"
>&lt;img src="https://sphotos-b.ak.fbcdn.net/hphotos-ak-ash3/603597_599117663432940_27947956_n.jpg"
loading="lazy"
>&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="the-sql-community-contains-the-most-gracious-and-generous-willing-to-help-people">The SQL community contains the most gracious and generous, willing to help people&lt;/h3>
&lt;/li>
&lt;li>
&lt;h3 id="you-can-connect-with-your-user-group-and-get-a-mini-sql-bits-every-month">You can connect with your user group and get a mini SQL Bits every month&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>Find your User Group Here &lt;a class="link" href="http://sqlsouthwest.co.uk/national_ug.htm" target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/national_ug.htm&lt;/a>&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="if-there-is-no-user-group-in-your-area-people-will-help-you-to-start-one">If there is no user group in your area people will help you to start one&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>RT @&lt;a class="link" href="https://hootsuite.com/dashboard#" target="_blank" rel="noopener"
>fatherjack&lt;/a> Interesting chat about a potential new user group in the uk. Anyone around Newcastle area looking for some free training?&lt;/p>
&lt;ul>
&lt;li>
&lt;h3 id="every-session-is-videoed-and-will-be-available-online-for-free">Every session is videoed and will be available online. For free.&lt;/h3>
&lt;/li>
&lt;li>
&lt;h3 id="you-will-learn-and-have-fun">You will learn and have fun&lt;/h3>
&lt;/li>
&lt;/ul>
&lt;p>Too awesome for words! “@&lt;a class="link" href="https://hootsuite.com/dashboard#" target="_blank" rel="noopener"
>justjonlevett&lt;/a>: Lego Server! @&lt;a class="link" href="https://hootsuite.com/dashboard#" target="_blank" rel="noopener"
>fusionio&lt;/a> &lt;a class="link" href="https://hootsuite.com/dashboard#" target="_blank" rel="noopener"
>#sqlbits&lt;/a>&lt;a class="link" href="http://t.co/bhxPaTIq4K" target="_blank" rel="noopener"
>pic.twitter.com/bhxPaTIq4K&lt;/a>”&lt;/p>
&lt;h3 id="more-blogs-about-sql-bits-xi-and-photos">More blogs about SQL Bits XI and Photos&lt;/h3>
&lt;p>SQL Bits Facebook &lt;a class="link" href="https://www.facebook.com/SQLBits" target="_blank" rel="noopener"
>https://www.facebook.com/SQLBits&lt;/a>&lt;/p>
&lt;p>Roger Van Unen Gallery &lt;a class="link" href="https://plus.google.com/photos/109984741094039234638/albums/5874913179986208577" target="_blank" rel="noopener"
>https://plus.google.com/photos/109984741094039234638/albums/5874913179986208577&lt;/a>&lt;/p>
&lt;p>JR’s Gallery &lt;a class="link" href="https://skydrive.live.com/?cid=7b73b60f4c7d77c9&amp;amp;id=7B73B60F4C7D77C9%212222" target="_blank" rel="noopener"
>https://skydrive.live.com/?cid=7b73b60f4c7d77c9&amp;amp;id=7B73B60F4C7D77C9%212222&lt;/a>&lt;/p>
&lt;p>Steve Jones Blog &lt;a class="link" href="http://voiceofthedba.wordpress.com/2013/05/06/fun-at-sql-bits/" target="_blank" rel="noopener"
>http://voiceofthedba.wordpress.com/2013/05/06/fun-at-sql-bits/&lt;/a>&lt;/p>
&lt;p>Chris Webbs Blog &lt;a class="link" href="http://cwebbbi.wordpress.com/2013/05/05/sqlbits-xi-summary/" target="_blank" rel="noopener"
>http://cwebbbi.wordpress.com/2013/05/05/sqlbits-xi-summary/&lt;/a>&lt;/p>
&lt;p>Find more from the Facebook Page or &lt;a class="link" href="https://twitter.com/search?q=%23sqlbits&amp;amp;src=typd" target="_blank" rel="noopener"
>#sqlbits&lt;/a>&lt;/p>
&lt;p>Finally a BIG Thank you to all these people &lt;a class="link" href="http://sqlbits.com/about/WhosWho.aspx" target="_blank" rel="noopener"
>http://sqlbits.com/about/WhosWho.aspx&lt;/a>&lt;/p>
&lt;p>and the fantastic helpers without whom SQL Bits would never happen&lt;/p>
&lt;p>Till Next year&lt;/p></description></item><item><title>Powershell won’t save when running as a scheduled job</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-wont-save-when-running-as-a-scheduled-job/</link><pubDate>Tue, 07 May 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/powershell-wont-save-when-running-as-a-scheduled-job/</guid><description>&lt;h3 id="or-how-sqlbits-put-me-in-touch-with-laerte-and-solved-a-problem">Or, How SQLBits put me in touch with Laerte and solved a problem&lt;/h3>
&lt;p>I have a scheduled Powershell job which I use to create an Excel file colour coded for backup checks. (I will blog about it another time) It works brilliantly on my desktop and saves the file to a UNC path and emails the team the location. It works brilliantly when run in Powershell on the server. When I schedule it to run though it doesn’t do so well. The job completes without errors but no file is saved.&lt;/p>
&lt;p>If you examine the processes running at the time you can see the excel process is running  so I knew it was doing something but couldn’t work out why it was failing.&lt;/p>
&lt;p>It was one of those jobs that gets put to the bottom of the list because the service worked ok I just needed to have it running on the server rather than a desktop for resilience, recovery and security purposes. Every now and then I would try and work out what was going on but new work and new problems would always arrive and it has been like that for 6 or maybe even 9 months.&lt;/p>
&lt;p>&lt;a class="link" href="https://blog.robsewell.com/12-things-i-learnt-at-sqlbits-xi/" target="_blank" rel="noopener"
>As you know&lt;/a> I attended SQLBits this weekend and I went into a session with Laerte Junior. Laerte is a SQL Server MVP and can be found at &lt;a class="link" href="https://www.simple-talk.com/author/laerte-junior/" target="_blank" rel="noopener"
>simple-talk&lt;/a> as well as his own blog &lt;a class="link" href="http://shellyourexperience.com/" target="_blank" rel="noopener"
>http://shellyourexperience.com/&lt;/a> or on twitter &lt;a class="link" href="https://twitter.com/LaerteSQLDBA" target="_blank" rel="noopener"
>@LaerteSQLDBA&lt;/a> Oh and He loves Star Wars 🙂&lt;/p>
&lt;p>&lt;a class="link" href="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/laerte_junior1.jpg" target="_blank" rel="noopener"
>&lt;img src="https://i0.wp.com/sqldbawithabeard.com/wp-content/uploads/2013/05/laerte_junior1_thumb.jpg?resize=168%2C223"
loading="lazy"
alt="Laerte_Junior[1]"
>&lt;/a>After a fascinating session I asked him if I could show him my problem. He very graciously said yes and after looking at the code and listening to me explain the problem he suggested this very simple solution which he said had taken him a great deal of searching to find. It’s a bug with COM objects and requires the creation of folders as shown below. I cam into work today, tried it and it worked. HOORAY another thing off my list and big thanks to Laerte&lt;/p>
&lt;pre>&lt;code>#Region Bug_Jobs_ComObjects #(32Bit, always)
# Create Folder #
New-Item –name C:\Windows\System32\config\systemprofile\Desktop  –itemtype directory
# #(64Bit)
# Create folder #
New-Item –name C:\Windows\SysWOW64\config\systemprofile\Desktop  –itemtype directory
#EndRegion Bug_Jobs_ComObjects
&lt;/code>&lt;/pre>
&lt;p>This worked for me however I had already implemented another fix for a possible gotcha so I will tell you of that one too&lt;/p>
&lt;p>Sometimes Powershell cannot save to UNC paths because of  IE enhanced security.&lt;/p>
&lt;p>Either log in as user and add server to intranet site zones or disable the warning in registry as follows&lt;/p>
&lt;pre>&lt;code>[HKEY_CURRENT_USER\Software\Policies\Microsoft\Windows\CurrentVersion\Internet Settings\ZoneMap] &amp;quot;UNCAsIntranet&amp;quot;=dword:00000000
&lt;/code>&lt;/pre>
&lt;p>Please don’t ever trust anything you read on the internet and certainly don’t implement it on production servers without first both understanding what it will do and testing it thoroughly. This solution worked for me in my environment I hope it is of use to you in yours but I know nothing about your environment and you know little about mine&lt;/p></description></item><item><title>Those Pesky ‘s</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/those-pesky-s/</link><pubDate>Mon, 11 Feb 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/those-pesky-s/</guid><description>&lt;h3 id="changing-domain-names-in-a-column">Changing Domain Names in a Column&lt;/h3>
&lt;p>A quick little post for today. Not particularly SQL related but the points at the end are relevant.&lt;/p>
&lt;p>I had a task when moving a service to a new development area to change the domain name within columns in several tables from “DOMAIN1\USER” to “DOMAIN2\USER”&lt;/p>
&lt;p>In SQL I was able to do this quite easily as follows&lt;/p>
&lt;pre>&lt;code>USE [DATABASENAME]
GO
-- Declare variables
DECLARE @Live nvarchar(10)
DECLARE @Dev nvarchar(10)
-- Set the variable to the Domains
Set @Live = 'Live Domain'
Set @Dev = 'Dev Domain'
--Update tables
UPDATE [TABLENAME]
SET [User] = REPLACE([User], @Live, @Dev)
GO
UPDATE [TABLENAME]
SET [Group] = REPLACE([Group], @Live, @Dev)
GO
&lt;/code>&lt;/pre>
&lt;p>I also had to do the same for some Oracle databases too and this is where the fun started!&lt;/p>
&lt;p>I needed to create the update scripts for documentation for the Oracle databases.&lt;/p>
&lt;p>I wanted to create&lt;/p>
&lt;pre>&lt;code>update schema.tablename set userid = replace ('DOMAIN1\USER', 'DOMAIN1', 'DOMAIN2') WHERE USERID = 'DOMAIN1\USER';
&lt;/code>&lt;/pre>
&lt;p>for each userid in the table.I had trouble with the script I found in our DBA area as it kept failing with&lt;/p>
&lt;p>ORA-00911: invalid character&lt;/p>
&lt;p>at the \&lt;/p>
&lt;p>as it wouldn’t add the ‘ ‘ around DOMAIN1\USER&lt;/p>
&lt;p>Not being an Oracle DBA but wanting to solve the issue once and for all I tried a whole host of solutions trying to find the escape character. i asked the Oracle DBAs but they were unable to help Checking the IT Pros handbook (also known as Google!) made me more confused but in the end I solved it.&lt;/p>
&lt;pre>&lt;code>select 'update schema.table set userid = replace (''' || userid || ''', ''DOMAIN1'', ''DOMAIN2'') WHERE USERID = ''' || USERID || ''';' FROM schema.tablename;
&lt;/code>&lt;/pre>
&lt;p>A whole host of ‘s in there!!&lt;/p>
&lt;p>I put this in my blog as it is relevant to my situation and an experience I have had that I couldn’t easily solve. Maybe it will help another person searching for the same thing.&lt;/p>
&lt;p>It raises some interesting points&lt;/p>
&lt;p>The script provided ( I use that term loosely, it had the right name and was in the right place to use for this process) had obviously not been run as it didn’t work or someone had manually added the ‘s. I wasn’t go to do that for the number of users required.&lt;/p>
&lt;p>If it no good, if it doesn’t do what i expected or is still in development then mark it as so, so that everyone knows. In the name of the script, in the comments in the script or by keeping live tested scripts in one place. Which ever method you choose is fine as long as it is appropriate to your environment and everyone knows about it&lt;/p>
&lt;p>I probably say a dozen times a day to my new colleague&lt;/p>
&lt;p>“In case you/I get run over by a bus”&lt;/p>
&lt;p>It is all very well being the one who knows everything but it is pointless if you aren’t there SPOF’s (Single Points of Failure) apply to people as well as hardware.&lt;/p>
&lt;p>Enable your service to be supported by preparing proper documentation.&lt;/p>
&lt;p>This doesn’t have to be reams of paperwork. It can sometimes be as simple as placing things in a recognised place or a single comment in the script.&lt;/p>
&lt;p>I hold my hands up. I am guilty of this too. I have been so busy I haven’t done this as much as I should have over the last few months of last year. I have tried but not done as well as I should have. In my defence, I have spent plenty of time recently rectifying this, which is why this situation was so memorable.&lt;/p>
&lt;p>Some links I have read in the past related to this by  people who know more than me.&lt;/p>
&lt;p>&lt;a class="link" href="http://www.brentozar.com/archive/2013/01/documentation-it-doesnt-suck/" target="_blank" rel="noopener"
>Documentation It Doesn’t Suck – Brent Ozar&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://www.johnsansom.com/your-lack-of-documentation-is-costing-you-more-than-you-think/" target="_blank" rel="noopener"
>Your Lack Of Documentation is Costing you More than you Think – John Samson&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="http://www.bradmcgehee.com/2012/06/do-you-document-your-sql-server-instances/" target="_blank" rel="noopener"
>Do You Document Your SQL Server Instances? – Brad McGhee&lt;/a>&lt;/p></description></item><item><title>You Have To Start Somewhere</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/you-have-to-start-somewhere/</link><pubDate>Sun, 10 Feb 2013 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/you-have-to-start-somewhere/</guid><description>&lt;img src="https://sqldbawithabeard.github.io/blogrobsewell/assets/uploads/2013/02/medium_33194896_thumb.jpg" alt="Featured image of post You Have To Start Somewhere" />&lt;p>![medium_33194896]({{ &amp;ldquo;/assets/uploads/2013/02/medium_33194896_thumb.jpg&amp;rdquo; | relative_url }})&lt;/p>
&lt;p>The hardest part is looking at the blank page and beginning to type. It’s much easier to go and play with the settings of the site, to look at plugins and other cool things. The only other blog I have written was &lt;a class="link" href="http://wombatsdojogle.wordpress.com" target="_blank" rel="noopener"
>http://wombatsdojogle.wordpress.com&lt;/a>. This was a little easer as there was always ‘something’ that needed to be written about. Whether it was training or route planning or every day on the road I had material and an obvious thing to write.&lt;/p>
&lt;p>This is a little harder for me so I will begin as follows&lt;/p>
&lt;p>During different careers working in secure units, working for a small family firm doing everything from delivery driving to office work and working for myself selling things via eBay and at car boot sales I have always been interested in computers. I was (still am) the fella who could fix and sort things out. Towards the end I was getting paid for it too. I helped small businesses and individuals, I set up systems, reinstalled operating systems, dealt with viruses. You know the sort of thing. When things dried up and circumstances changed meaning I could spend some time away from home I got a job at an arts university. In a small team my responsibilities ranged from password resets and printer installs to rolling out new PCs and laptops and helping to merge active directory domains. I loved it. The travel too and from work was a pain at times but the job was grand though the pay wasn’t!!&lt;/p>
&lt;p>I joined MyWork in a service desk role. Not your typical log and flog sort of place but a 24/7 team responsible for the first answering of the phone to a significant amount of second line fixing and routine IT tasks invaluable to the running of MyWork. A couple of years later after many suggestions of jobs I should apply for and plenty of encouragement from colleagues I applied for and got the position of Oracle DBA. That didn’t work out quite as expected and two months later I was asked to move to be a SQL DBA. That was 18 months ago and I am astonished by how much I have learnt so far and still slightly daunted by the sheer amount there still is to learn.&lt;/p>
&lt;p>The reason I was asked to move is that responsibility for the SQL estate had moved to the team and the one SQL DBA was struggling with the sheer amount of work required. He had joined only a few months earlier and found that best practice and SQL had not been applied particularly well and with more than 700 databases to support he couldn’t keep up.&lt;/p>
&lt;p>He and I began to make changes. Permissions for developers were removed – no more sysadmins for developers on live systems. Backups were run 7 days a week and checked every day. Service accounts were set up to run the various SQL services per server. Documentation was begun. All the good things that should be done were started to be done.&lt;/p>
&lt;p>There were arguments and outbursts. Developers took time to understand that we were doing things for the best of MyWork and not to annoy them or stop them working. We got things wrong for sure. We didn’t communicate well with colleagues in other teams at times but we had the backing of our line management.&lt;/p>
&lt;p>Then my colleague left to go to pastures new. I had been a SQL DBA for exactly 6 months and I was on my own. Then my line manager left so I had to look after the general maintenance of the Oracle estate as well. There are also some Ingres databases critical to MyWork and they were my responsibility as well.&lt;/p>
&lt;p>For a few months I somehow managed to keep everything going without making any major booboos. It was a struggle. I was fighting my lack of knowledge, the sheer amount of work and running much too hard on caffeine and nicotine. At the end of last year some salvation arrived. First an Oracle DBA joined then a team lead (also an Oracle DBA) and another SQL DBA. Not the many years experienced SQL DBA I had hoped for who could advise me and teach me but I sure am glad he’s here.&lt;/p>
&lt;p>In the last few weeks I am beginning to see the benefit of this. No longer on call all the time. Not as much fire fighting. Able to plan my day instead of walking in and dealing with whoever or whatever was shouting loudest. I was finally able to go to the local SQL User Group for the first time last month.&lt;/p>
&lt;p>&lt;a class="link" href="http://sqlsouthwest.co.uk/" target="_blank" rel="noopener"
>http://sqlsouthwest.co.uk/&lt;/a>&lt;/p>
&lt;p>and meet up with some fabulous people.&lt;/p>
&lt;p>I decided to start to write a blog about my experience. I hope it will show me how far I have come, how much I have learnt and the way I have done it. It may be of use to people and hopefully it will increase my interaction with the rest of the SQL community who are without doubt the most interactive and helpful group of people mainly without egos.&lt;/p>
&lt;p>I have an idea of my next post. It will be about resolving the challenge and time spent checking and resolving backups.&lt;/p>
&lt;p>The idea for it started with reading a blog post by John Samson &lt;a class="link" href="http://www.johnsansom.com" target="_blank" rel="noopener"
>http://www.johnsansom.com&lt;/a> who can be found on twitter &lt;a class="link" href="https://twitter.com/SqlBrit" target="_blank" rel="noopener"
>@SQLBrit&lt;/a>&lt;/p>
&lt;p>The blog post is one of the most read on his blog and is titled&lt;/p>
&lt;h3 id="the-best-database-administrators-automate-everythinghttpwwwjohnsansomcomthe-best-database-administrators-automate-everything">&lt;a class="link" href="http://www.johnsansom.com/the-best-database-administrators-automate-everything/" target="_blank" rel="noopener"
>The Best Database Administrators Automate Everything&lt;/a>&lt;/h3>
&lt;p>Here is a quote from that blog entry&lt;/p>
&lt;blockquote>
&lt;h4 id="automate-everything">Automate Everything&lt;/h4>
&lt;p>That’s right, I said everything. Just sit back and take the &lt;em>time&lt;/em> to consider this point for a moment. Let it wander around your mind whilst you consider the processes and tasks that you could look to potentially automate. Now eliminate the word &lt;em>potentially&lt;/em> from your vocabulary and evaluate how you could automate &lt;strong>e-v-e-r-y-t-h-i-n-g&lt;/strong> that you do.&lt;/p>
&lt;p>Even if you believe that there is only a remote possibility that you will need to repeat a given task, just go ahead and automate it anyway! Chances are that when the need to repeat the process comes around again, you will either be under pressure to get it done, or even better have more important_Proactive Mode_ tasks/projects to be getting on with&lt;/p>
&lt;/blockquote>
&lt;p>I have tried my best to follow this advice. I haven’t always succeeded. Many times I just didn’t have the time to spare to write the automation even though it would save me time later. Now with more assistance in my team I am starting to resolve that&lt;/p>
&lt;p>My interest in PowerShell, which was piqued when I wanted to organise my photos and a colleague pointed me at a script to sort my photos into year and month, encouraged me to create my favourite automation process which I will describe next time.&lt;/p>
&lt;p>photo credit: &lt;a class="link" href="http://www.flickr.com/photos/emdot/33194896/" target="_blank" rel="noopener"
>emdot&lt;/a> via &lt;a class="link" href="http://photopin.com" target="_blank" rel="noopener"
>photopin&lt;/a> &lt;a class="link" href="http://creativecommons.org/licenses/by/2.0/" target="_blank" rel="noopener"
>cc&lt;/a>&lt;/p></description></item><item><title>Post: Chat</title><link>https://sqldbawithabeard.github.io/blogrobsewell/blog/post-chat/</link><pubDate>Fri, 08 Jan 2010 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/blog/post-chat/</guid><description>&lt;p>Abbott: Strange as it may seem, they give ball players nowadays very peculiar names.&lt;/p>
&lt;p>Costello: Funny names?&lt;/p>
&lt;p>Abbott: Nicknames, nicknames. Now, on the St. Louis team we have Who&amp;rsquo;s on first, What&amp;rsquo;s on second, I Don&amp;rsquo;t Know is on third&amp;ndash;&lt;/p>
&lt;p>Costello: That&amp;rsquo;s what I want to find out. I want you to tell me the names of the fellows on the St. Louis team.&lt;/p>
&lt;p>Abbott: I&amp;rsquo;m telling you. Who&amp;rsquo;s on first, What&amp;rsquo;s on second, I Don&amp;rsquo;t Know is on third&amp;ndash;&lt;/p>
&lt;p>Costello: You know the fellows&amp;rsquo; names?&lt;/p>
&lt;p>Abbott: Yes.&lt;/p>
&lt;p>Costello: Well, then who&amp;rsquo;s playing first?&lt;/p>
&lt;p>Abbott: Yes.&lt;/p>
&lt;p>Costello: I mean the fellow&amp;rsquo;s name on first base.&lt;/p>
&lt;p>Abbott: Who.&lt;/p>
&lt;p>Costello: The fellow playin&amp;rsquo; first base.&lt;/p>
&lt;p>Abbott: Who.&lt;/p>
&lt;p>Costello: The guy on first base.&lt;/p>
&lt;p>Abbott: Who is on first.&lt;/p>
&lt;p>Costello: Well, what are you askin&amp;rsquo; me for?&lt;/p>
&lt;p>Abbott: I&amp;rsquo;m not asking you&amp;ndash;I&amp;rsquo;m telling you. Who is on first.&lt;/p>
&lt;p>Costello: I&amp;rsquo;m asking you&amp;ndash;who&amp;rsquo;s on first?&lt;/p>
&lt;p>Abbott: That&amp;rsquo;s the man&amp;rsquo;s name.&lt;/p>
&lt;p>Costello: That&amp;rsquo;s who&amp;rsquo;s name?&lt;/p>
&lt;p>Abbott: Yes.&lt;/p>
&lt;p>Costello: When you pay off the first baseman every month, who gets the money?&lt;/p>
&lt;p>Abbott: Every dollar of it. And why not, the man&amp;rsquo;s entitled to it.&lt;/p>
&lt;p>Costello: Who is?&lt;/p>
&lt;p>Abbott: Yes.&lt;/p>
&lt;p>Costello: So who gets it?&lt;/p>
&lt;p>Abbott: Why shouldn&amp;rsquo;t he? Sometimes his wife comes down and collects it.&lt;/p>
&lt;p>Costello: Who&amp;rsquo;s wife?&lt;/p>
&lt;p>Abbott: Yes. After all, the man earns it.&lt;/p>
&lt;p>Costello: Who does?&lt;/p>
&lt;p>Abbott: Absolutely.&lt;/p>
&lt;p>Costello: Well, all I&amp;rsquo;m trying to find out is what&amp;rsquo;s the guy&amp;rsquo;s name on first base?&lt;/p>
&lt;p>Abbott: Oh, no, no. What is on second base.&lt;/p>
&lt;p>Costello: I&amp;rsquo;m not asking you who&amp;rsquo;s on second.&lt;/p>
&lt;p>Abbott: Who&amp;rsquo;s on first!&lt;/p>
&lt;p>Costello: St. Louis has a good outfield?&lt;/p>
&lt;p>Abbott: Oh, absolutely.&lt;/p>
&lt;p>Costello: The left fielder&amp;rsquo;s name?&lt;/p>
&lt;p>Abbott: Why.&lt;/p>
&lt;p>Costello: I don&amp;rsquo;t know, I just thought I&amp;rsquo;d ask.&lt;/p>
&lt;p>Abbott: Well, I just thought I&amp;rsquo;d tell you.&lt;/p>
&lt;p>Costello: Then tell me who&amp;rsquo;s playing left field?&lt;/p>
&lt;p>Abbott: Who&amp;rsquo;s playing first.&lt;/p>
&lt;p>Costello: Stay out of the infield! The left fielder&amp;rsquo;s name?&lt;/p>
&lt;p>Abbott: Why.&lt;/p>
&lt;p>Costello: Because.&lt;/p>
&lt;p>Abbott: Oh, he&amp;rsquo;s center field.&lt;/p>
&lt;p>Costello: Wait a minute. You got a pitcher on this team?&lt;/p>
&lt;p>Abbott: Wouldn&amp;rsquo;t this be a fine team without a pitcher?&lt;/p>
&lt;p>Costello: Tell me the pitcher&amp;rsquo;s name.&lt;/p>
&lt;p>Abbott: Tomorrow.&lt;/p>
&lt;p>Costello: Now, when the guy at bat bunts the ball&amp;ndash;me being a good catcher&amp;ndash;I want to throw the guy out at first base, so I pick up the ball and throw it to who?&lt;/p>
&lt;p>Abbott: Now, that&amp;rsquo;s he first thing you&amp;rsquo;ve said right.&lt;/p>
&lt;p>Costello: I DON&amp;rsquo;T EVEN KNOW WHAT I&amp;rsquo;M TALKING ABOUT!&lt;/p>
&lt;p>Abbott: Don&amp;rsquo;t get excited. Take it easy.&lt;/p>
&lt;p>Costello: I throw the ball to first base, whoever it is grabs the ball, so the guy runs to second. Who picks up the ball and throws it to what. What throws it to I don&amp;rsquo;t know. I don&amp;rsquo;t know throws it back to tomorrow&amp;ndash;a triple play.&lt;/p>
&lt;p>Abbott: Yeah, it could be.&lt;/p>
&lt;p>Costello: Another guy gets up and it&amp;rsquo;s a long ball to center.&lt;/p>
&lt;p>Abbott: Because.&lt;/p>
&lt;p>Costello: Why? I don&amp;rsquo;t know. And I don&amp;rsquo;t care.&lt;/p>
&lt;p>Abbott: What was that?&lt;/p>
&lt;p>Costello: I said, I DON&amp;rsquo;T CARE!&lt;/p>
&lt;p>Abbott: Oh, that&amp;rsquo;s our shortstop!&lt;/p></description></item><item><title>Links</title><link>https://sqldbawithabeard.github.io/blogrobsewell/links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/links/</guid><description/></item><item><title>Search</title><link>https://sqldbawithabeard.github.io/blogrobsewell/search/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sqldbawithabeard.github.io/blogrobsewell/search/</guid><description/></item></channel></rss>